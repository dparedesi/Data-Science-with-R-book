% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
\documentclass[
]{krantz}
\usepackage{xcolor}
\usepackage[left=1.5in, right=1.5in, top=1.25in, bottom=1.25in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.33,0.33,0.33}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.14,0.14,0.14}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.43,0.43,0.43}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.43,0.43,0.43}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\newcounter{none} % for unnumbered tables
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage[]{natbib}
\bibliographystyle{apalike}
  
%\usepackage{booktabs}
\usepackage{float}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Data Science with R},
  pdfauthor={Author: Mg. Daniel Paredes Inilupu},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

\title{Data Science with R}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Data Analysis and prediction algorithms with R. Third Edition}
\author{Author: Mg. Daniel Paredes Inilupu}
\date{2025-12-25}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\chapter*{Preface}\label{preface}


Welcome to the third edition of \emph{Data Science with R}!

In an era where data-driven decisions shape industries from healthcare to finance, mastering R gives you the power to extract insights, build predictive models, and communicate findings effectively. This book has evolved from personal learning notes into a comprehensive resource that takes you from fundamentals to advanced data science techniques using practical, hands-on exercises.

This book is designed for beginners with no prior R experience who want a structured path into data science, as well as analysts looking to upgrade from spreadsheets to reproducible R workflows. It also serves students, professionals, and practitioners seeking to modernize their machine learning skills with tidymodels. Basic familiarity with statistics concepts is helpful but not required, as all code examples are self-contained and explained step-by-step.

The third edition reflects the latest developments in the R ecosystem. We have updated everything to run on R 4.5.2 and RStudio 2025.09.2. A major shift in this edition is the full migration to tidymodels for machine learning and the adoption of modern tidyverse patterns, including the native pipe operator. We have also introduced entirely new topics such as Generative AI and LLM integration with R, AI-assisted coding workflows, ethics in data science, and enhanced text mining. You will also find expanded content on interactive visualization, deep learning with Keras and TensorFlow, big data processing with Sparklyr, and reproducible workflows using Git and GitHub.

Each chapter builds on previous concepts, but you can also jump to topics of interest. If you are learning R from scratch, start with the Fundamentals in the first two chapters. Chapter 3 covers visualization with ggplot2, while Chapter 12 dives into building machine learning models. For those interested in working with Large Language Models, Chapter 14 covers Generative AI. Throughout the book, you will find hands-on exercises to test your understanding. Solutions are provided, but we encourage you to try them yourself first.

Just like previous editions, many exercises are inspired by practical classroom experiences and activities from the \href{https://online-learning.harvard.edu/series/professional-certificate-data-science}{Professional Certificate in Data Science}\footnote{\url{https://online-learning.harvard.edu/series/professional-certificate-data-science}} by \textbf{HarvardX}. The code used to generate this book is available on GitHub, encouraging transparency and reproducibility.

\section*{Support This Work}\label{support-this-work}


Over 700 hours went into creating this resource. If you find it valuable, consider purchasing the PDF on \href{https://leanpub.com/data-science-with-r}{Leanpub}. Your purchase includes:

\begin{itemize}
\tightlist
\item
  Future updates at no extra cost
\item
  Three months of direct Q\&A access with the author
\item
  Support for keeping the web version free for everyone
\end{itemize}

The web version available at \href{https://dparedesi.github.io/Data-Science-with-R-book/}{GitHub Pages}\footnote{\url{https://dparedesi.github.io/Data-Science-with-R-book/}} seeks to democratize data science knowledge. Share it and let's contribute together to freeing knowledge.

\section*{Stay Connected}\label{stay-connected}


This book has reached readers in Mexico, Colombia, Spain, Peru, Chile, and many other countries. I deeply thank readers of previous editions for their comments and suggestions, which have been fundamental to improving each version.

If you have questions or suggestions, write to me at \href{mailto:dparedesi@uni.pe}{\nolinkurl{dparedesi@uni.pe}}. I usually respond within 48 hours.

This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.

\chapter*{Acknowledgments}\label{acknowledgments}


\section*{Family}\label{family}


First and foremost, I want to express my profound gratitude to my wife, Desislava, for her invaluable emotional support during the countless hours I dedicated to this project. Her knowledge in R was also key---contributing solutions and perspectives that enriched this work.

\section*{Mentors and Inspirations}\label{mentors-and-inspirations}


A special thanks to \href{https://hsph.harvard.edu/profile/rafael-a-irizarry/}{Rafael Irizarry}\footnote{\url{https://hsph.harvard.edu/profile/rafael-a-irizarry/}}, a true benchmark in the R world, whose didactic approach to teaching advanced techniques significantly advanced my learning. I also extend my gratitude to the developers who, with their dedication, continue to create and maintain this wonderful language.

My gratitude also goes to Briguit Reinaldo, CEO of Cedhinfo, whose tireless work brings the teaching of computer technologies to more people in Peru, inspiring many to explore new opportunities.

\section*{Contributors}\label{contributors}


Finally, I want to acknowledge the valuable contribution of engineering students from UNI who participated in grammatical review, paraphrasing, exercise creation, and topic proposals. Special thanks to \href{https://www.linkedin.com/in/josep-agama-749a61190/}{Josep Agama}\footnote{\url{https://www.linkedin.com/in/josep-agama-749a61190/}} and \href{https://www.linkedin.com/in/aespinozacontreras/}{Andrés Espinoza}\footnote{\url{https://www.linkedin.com/in/aespinozacontreras/}} for their fundamental contributions to the first three chapters.

\chapter*{Introduction}\label{introduction}


\textbf{What You'll Learn in This Chapter:}

\begin{itemize}
\tightlist
\item
  Understand why R is an excellent choice for data science
\item
  Install R and RStudio on your computer
\item
  Navigate the RStudio interface confidently
\item
  Write and execute your first R code
\end{itemize}

Data science requires a multidisciplinary approach that combines statistics, programming, data mining, and domain expertise. This book is designed to help you develop those skills through practical, hands-on examples in R.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Venn diagram showing data science as intersection of statistics, programming, domain knowledge, and data mining}]{assets/images/01-introduction/multidisciplinaria} \end{center}

\section*{Why R?}\label{why-r}


R is a language created by statisticians for data analysis, making it an excellent choice for your data science journey. It is free and open-source, meaning there are no licensing costs and you can inspect how any function works under the hood. Its rich ecosystem includes over 19,000 packages on CRAN covering virtually any analytical task, from machine learning to bioinformatics.

One of R's strongest features is reproducibility, allowing you to write scripts once and share them with colleagues to obtain consistent results anywhere. It also offers best-in-class visualization through ggplot2 for publication-quality graphics and Shiny for interactive dashboards. Furthermore, you will find an active community with extensive documentation, tutorials, and a welcoming presence on social media.

While Python is also popular in data science, R excels particularly in statistical analysis and data visualization. These are the core skills we will develop throughout this book, leveraging the tidyverse ecosystem to make data manipulation intuitive and readable.

\section*{Installing R}\label{installing-r}


You can download R from the Comprehensive R Archive Network (\textbf{CRAN}).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Search for CRAN on Google:
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={Google search results page showing CRAN R Project download link}]{assets/images/01-introduction/CRAN-google} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  On the CRAN page, select the version for your operating system---Linux, Mac OS X, or Windows:
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={CRAN homepage with download links for Linux, macOS, and Windows}]{assets/images/01-introduction/CRAN-website} \end{center}

The following steps show the Windows installation process. The steps for Mac and Linux are similar---simply select your operating system and follow the corresponding download link.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  On the CRAN website, click on \texttt{base} to download the core R installation. This includes all the basic packages you need to get started. Later chapters will show you how to install additional packages.
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={CRAN Windows download page with base R installation link}]{assets/images/01-introduction/CRAN-windows} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Click on the download link to get the latest stable version:
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={CRAN download link for latest R version installer}]{assets/images/01-introduction/CRAN-64-bits} \end{center}

Once downloaded, run the installer and follow the on-screen instructions.

\textbf{Installation Tip:} When the installer asks about options, the default settings work perfectly for beginners. You can always customize your installation later.

\section*{Installing RStudio}\label{installing-rstudio}


Although you could start using R directly in the console, we recommend installing RStudio---an integrated development environment (IDE) that makes working with R significantly more productive and enjoyable.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Search for RStudio on Google:
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={Google search results for RStudio download}]{assets/images/01-introduction/rstudio-google} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  You'll see the Posit website (RStudio's parent company). Click on \textbf{DOWNLOAD} in the upper right menu:
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={RStudio website homepage with Download button in navigation}]{assets/images/01-introduction/rstudio-website-0} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Scroll down until you find the download options. Select the \textbf{Free} RStudio Desktop option:
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={RStudio Desktop download options showing Free and Pro versions}]{assets/images/01-introduction/rstudio-website-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  The page will display a download button optimized for your operating system. You can also choose from the list of all available installers below:
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth,alt={RStudio installer download button for current operating system}]{assets/images/01-introduction/rstudio-website-2} \end{center}

Once the installer is downloaded, run it and follow the on-screen instructions.

\textbf{Having trouble?} Installation issues are usually straightforward to resolve. Check the \href{https://cran.r-project.org/faqs.html}{CRAN FAQ} or search ``R installation {[}your OS{]}'' for community solutions. The \href{https://community.rstudio.com/}{RStudio Community} is also an excellent resource.

\section*{RStudio Sections}\label{rstudio-sections}


When you start RStudio for the first time, you'll see three main sections:

\begin{center}\includegraphics[width=0.8\linewidth,alt={Initial RStudio window showing three panels: console, environment, and files}]{assets/images/01-introduction/VirtualBox_Windows-7-Enterprise_22_03_2018_16_21_16} \end{center}

One of the great advantages of R over point-and-click analysis software is that we can save our work as \textbf{Scripts}---text files containing R code that can be shared, version-controlled, and re-run at any time.

To create a new Script, click on \textbf{File → New File → R Script}:

\begin{center}\includegraphics[width=0.8\linewidth,alt={RStudio File menu expanded showing New File then R Script option}]{assets/images/01-introduction/VirtualBox_Windows-7-Enterprise_22_03_2018_16_21_42} \end{center}

This opens the fourth panel, giving you the complete RStudio layout:

\begin{center}\includegraphics[width=0.8\linewidth,alt={RStudio interface with four panels: source editor, console, environment, and plots}]{assets/images/01-introduction/rstudio} \end{center}

Let's understand the layout. The \textbf{Source Editor} in the top-left is where you write and edit your R scripts. Think of it as your code notebook where you can save, organize, and run code. Below it is the \textbf{Console} (bottom-left), where code executes and results appear. You can type commands directly here for quick experiments.

On the right side, the \textbf{Environment/History} panel (top-right) shows all variables and functions you have created in your current session, while the history tab tracks your commands. Finally, the \textbf{Files/Plots/Help} panel (bottom-right) serves multiple purposes, allowing you to browse files, view generated plots, and access package documentation.

\subsection*{Essential Keyboard Shortcuts}\label{essential-keyboard-shortcuts}


Mastering keyboard shortcuts will significantly speed up your workflow. The most commonly used command is running the current line or selection, which you can do by pressing \texttt{Ctrl\ +\ Enter} (or \texttt{Cmd\ +\ Enter} on Mac). To run the entire script, use \texttt{Ctrl\ +\ Shift\ +\ S} (\texttt{Cmd\ +\ Shift\ +\ S}).

Creating a new script is as easy as pressing \texttt{Ctrl\ +\ Shift\ +\ N} (\texttt{Cmd\ +\ Shift\ +\ N}), and you should save your work frequently with \texttt{Ctrl\ +\ S} (\texttt{Cmd\ +\ S}). A shortcut specific to R is inserting the assignment operator (\texttt{\textless{}-}), which is done with \texttt{Alt\ +\ -} (\texttt{Option\ +\ -}). Finally, you can quickly comment or uncomment lines using \texttt{Ctrl\ +\ Shift\ +\ C} (\texttt{Cmd\ +\ Shift\ +\ C}).

\textbf{Pro Tip:} Press \texttt{Alt\ +\ Shift\ +\ K} (Windows/Linux) or \texttt{Option\ +\ Shift\ +\ K} (Mac) in RStudio to see the complete list of keyboard shortcuts.

\section*{Testing Your Installation}\label{testing-your-installation}


Let's verify everything is working correctly. Go to the Console panel and calculate how much 13 multiplied by 265 is. Click on the console, type the following, and press \textbf{Enter}:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{13} \SpecialCharTok{*} \DecValTok{265}
\CommentTok{\#\textgreater{} [1] 3445}
\end{Highlighting}
\end{Shaded}

You should see \texttt{3445} as the result. Let's understand the output format:

\textbf{Understanding R Output:}

\begin{itemize}
\tightlist
\item
  The \texttt{{[}1{]}} before the result indicates this is the first element of the output. R can return multiple values, and the bracketed number helps you track which element you're looking at.
\item
  In this book, we use \texttt{\#\#} to distinguish R output from R code. Lines starting with \texttt{\#\#} show what you'll see in your console after running the code.
\end{itemize}

Now let's try something more interesting. R isn't just a calculator---it's a powerful tool for working with data. Try this in your console:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a vector of values}
\NormalTok{values }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{40}\NormalTok{, }\DecValTok{50}\NormalTok{)}

\CommentTok{\# Calculate the mean}
\FunctionTok{mean}\NormalTok{(values)}
\CommentTok{\#\textgreater{} [1] 30}

\CommentTok{\# How many elements are there?}
\FunctionTok{length}\NormalTok{(values)}
\CommentTok{\#\textgreater{} [1] 5}
\end{Highlighting}
\end{Shaded}

You've just created your first data structure (a vector) and applied functions to it---fundamental concepts we'll explore in depth in the next chapter.

\subsection*{Writing Scripts}\label{writing-scripts}


While the console is great for quick experiments, scripts are essential for reproducible work. Try this in the \textbf{Source Editor} (not the console):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# My First R Script}
\CommentTok{\# Calculating basic statistics}

\CommentTok{\# Create some data}
\NormalTok{temperatures }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{22}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{24}\NormalTok{)}

\CommentTok{\# Calculate statistics}
\FunctionTok{mean}\NormalTok{(temperatures)    }\CommentTok{\# Average temperature}
\FunctionTok{max}\NormalTok{(temperatures)     }\CommentTok{\# Highest temperature}
\FunctionTok{min}\NormalTok{(temperatures)     }\CommentTok{\# Lowest temperature}
\end{Highlighting}
\end{Shaded}

To execute code from the script:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Run a single line}: Place your cursor on the line and press \texttt{Ctrl\ +\ Enter} (or \texttt{Cmd\ +\ Enter} on Mac)
\item
  \textbf{Run selected lines}: Highlight the lines you want to run and press \texttt{Ctrl\ +\ Enter}
\item
  \textbf{Run the entire script}: Press \texttt{Ctrl\ +\ Shift\ +\ S} (or \texttt{Cmd\ +\ Shift\ +\ S} on Mac)
\end{enumerate}

Notice that lines starting with \texttt{\#} are \textbf{comments}---R ignores them, but they're invaluable for explaining your code to others (and to your future self!).

\textbf{Challenge: Test Your Setup}

Try these exercises to confirm everything works:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculate \texttt{sqrt(144)} in the console (the square root of 144)
\item
  Create a new script with three different calculations and save it as \texttt{my\_first\_script.R}
\item
  Use the assignment operator (\texttt{\textless{}-}) to store a value: \texttt{my\_number\ \textless{}-\ 42}
\item
  Print your stored value by typing \texttt{my\_number} and pressing Enter
\end{enumerate}

\section*{What's Next?}\label{whats-next}


Congratulations! You have successfully set up your R environment and written your first R code. You now understand why R is a powerful choice for data science and how to navigate the four panels of the RStudio interface. You have also learned to use the console, write scripts, and apply essential keyboard shortcuts.

In the next chapter, we will dive into \textbf{R Fundamentals}, learning about objects, data types, vectors, and functions that form the foundation of all R programming. You will discover how R stores and manipulates data, setting the stage for the data analysis and visualization techniques to come.

Let's continue the journey!

\part{Fundamentals and Key Tools}\label{part-fundamentals-and-key-tools}

\chapter{Objects}\label{objects}

In the world of programming, an \textbf{object} is like a container that holds information. This information can be of different types: numbers, text, complex data, and even code. The important thing is that an object groups everything necessary to represent an entity or concept.

In R, practically everything is an object. The variables we will use to store data, the functions we will use to process that data, and even the data itself, are objects.

\section{What are objects in R?}\label{what-are-objects-in-r}

Imagine you are organizing your move to the United States. Each item you pack in a box (clothes, books, appliances) can be considered an object. Each object has characteristics that define it: a name, a type, a size, a weight, etc.

In R, objects also have characteristics that define them. These characteristics are called \textbf{attributes}. For instance, every object has a \textbf{Name} so we can refer to it, and a \textbf{Type} that indicates what kind of data it contains (numeric, character, logical, etc.). Objects also have a \textbf{Class} defining their structure and behavior (such as vector, list, or data frame) and a \textbf{Length} indicating the number of elements they contain.

\subsection{R as an object-oriented language}\label{r-as-an-object-oriented-language}

R is an \textbf{object-oriented} programming language, meaning it relies on the concept of objects to organize and process information. This approach offers several advantages, such as \textbf{Modularity}, allowing us to divide a program into smaller, manageable parts. It also promotes \textbf{Reusability}, as objects can be used in different parts of the program or even in other projects. Furthermore, objects provide \textbf{Encapsulation}, hiding implementation details to facilitate their use and maintenance.

\subsection{The power of abstraction}\label{the-power-of-abstraction}

The concept of an object allows us to \textbf{abstract} the complexity of the real world. Instead of thinking about the details of how data is stored and processed in computer memory, we can think in terms of objects representing real-world entities.

For example, instead of thinking of a series of numbers representing the temperatures of different cities, we can think of a ``temperatures'' object containing all that information.

This abstraction facilitates understanding and handling information, allowing us to focus on the logic of the problem we want to solve.

\section{Variables: The first objects on your journey}\label{variables-the-first-objects-on-your-journey}

Before we start packing for our move to the United States, we need to know what things we will take. Each object we decide to take is represented in R as a \textbf{variable}.

Think of variables as labels we put on each object. For example, we could use the variable \texttt{state} to save the name of the state we are moving to, or the variable \texttt{num\_suitcases} to save the number of suitcases we will take.

\subsection{Creating variables in R}\label{creating-variables-in-r}

In R, we don't need to declare a variable before using it. We simply assign it a value using the \texttt{\textless{}-} symbol.

\begin{quote}
\textbf{Note:} You might see the \texttt{=} symbol used for assignment in other programming languages or even in some R code. While \texttt{=} works in R, the \texttt{\textless{}-} operator is the standard and idiomatic way to assign values to variables. It helps distinguish between assigning a value to a variable and passing arguments to a function (where \texttt{=} is always used).
\end{quote}

\textbf{Example:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Assign the value "California" to the variable "state"}
\NormalTok{state }\OtherTok{\textless{}{-}} \StringTok{"California"}

\CommentTok{\# Assign the value 5 to the variable "num\_suitcases"}
\NormalTok{num\_suitcases }\OtherTok{\textless{}{-}} \DecValTok{5}
\end{Highlighting}
\end{Shaded}

To see the value we have saved in a variable, we simply type its name in the RStudio console and press Enter.

\textbf{Example:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{state }\OtherTok{\textless{}{-}} \StringTok{"California"}

\NormalTok{state}
\CommentTok{\#\textgreater{} [1] "California"}
\end{Highlighting}
\end{Shaded}

When executing this code, you will see the value \texttt{"California"} appear in the console.

\subsection{Operations with variables}\label{operations-with-variables}

We can also use variables to perform operations. For example, if we want to calculate the total cost of our plane trip, we could use the variables \texttt{ticket\_price} and \texttt{num\_people}.

\textbf{Example:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ticket\_price }\OtherTok{\textless{}{-}} \DecValTok{300}
\NormalTok{num\_people }\OtherTok{\textless{}{-}} \DecValTok{4}

\NormalTok{total\_cost }\OtherTok{\textless{}{-}}\NormalTok{ ticket\_price }\SpecialCharTok{*}\NormalTok{ num\_people}

\NormalTok{total\_cost}
\CommentTok{\#\textgreater{} [1] 1200}
\end{Highlighting}
\end{Shaded}

In this example, we first assign values to the variables \texttt{ticket\_price} and \texttt{num\_people}. Then, we multiply these variables to calculate the \texttt{total\_cost} and display its value in the console.

\subsection{Best practices for naming variables}\label{best-practices-for-naming-variables}

\textbf{Watch out for capitalization!}

R is case-sensitive. If you create a variable called \texttt{state} and then try to access it as \texttt{State}, R will not find it.

\textbf{Descriptive names}

It is important to use descriptive names for variables, clearly indicating what information they contain. Instead of using variables like \texttt{x} or \texttt{y}, it is better to use names like \texttt{ticket\_price} or \texttt{num\_suitcases}.

\textbf{Rules for naming variables}

When naming your variables, remember that they can contain letters, numbers, and underscores (\texttt{\_}), but they cannot start with a number or contain spaces. Also, keep in mind that R is case-sensitive, so capitalization matters.

\subsection{Data types}\label{data-types}

Variables in R can contain different types of data. \textbf{Numeric} variables are used for numbers, such as the population of a city or the cost of a plane ticket. \textbf{Character} variables store text, like the name of a state (``California'') or a city (``Los Angeles''). \textbf{Logical} variables represent binary truth values, \texttt{TRUE} or \texttt{FALSE}, which are useful for conditions, such as indicating whether we want to visit a specific city.

\section{Object types for complex data}\label{object-types-for-complex-data}

The variables we have seen so far are very useful for storing individual information, such as the name of a city or the number of suitcases we will carry on our move. However, in the real world, we often need to work with more complex datasets.

Imagine you want to save the names of all the cities you plan to visit on your trip to the United States. Would you have to create a variable for each city? That would be very tedious!

Fortunately, R offers other types of objects that allow us to organize and manipulate information more efficiently. Let's look at some of them:

\subsection{Vectors: organizing information of the same type}\label{vectors-organizing-information-of-the-same-type}

Vectors are like trains transporting a series of objects of the same type. They can be numbers, text, or logical values, but all elements of a vector must be of the same type. For example, we could use a vector to save the name of each state in the United States, or a vector to save the population of each state.

\textbf{Creating vectors:} To create a vector, we can use the \texttt{c()} function (which stands for ``combine'') and list the elements we want to include, separated by commas.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a vector with the names of some states}
\NormalTok{states }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"California"}\NormalTok{, }\StringTok{"Texas"}\NormalTok{, }\StringTok{"Florida"}\NormalTok{, }\StringTok{"New York"}\NormalTok{)}

\CommentTok{\# Create a vector with the population of each state (in millions)}
\NormalTok{population }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{39.2}\NormalTok{, }\FloatTok{29.0}\NormalTok{, }\FloatTok{21.4}\NormalTok{, }\FloatTok{19.4}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

If we want to know the amount of data our vector has, its length, we will use the \texttt{length()} function. The \texttt{class()} function tells us the class of the object, that is, what type of data it contains.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{length}\NormalTok{(population)  }
\CommentTok{\#\textgreater{} [1] 4}
\FunctionTok{class}\NormalTok{(states)     }
\CommentTok{\#\textgreater{} [1] "character"}
\FunctionTok{class}\NormalTok{(population)   }
\CommentTok{\#\textgreater{} [1] "numeric"}
\end{Highlighting}
\end{Shaded}

We can use the \texttt{names()} function to assign names to the elements of a vector. This can be useful for identifying each element.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(population) }\OtherTok{\textless{}{-}}\NormalTok{ states}
\NormalTok{population}
\CommentTok{\#\textgreater{} California      Texas    Florida   New York }
\CommentTok{\#\textgreater{}       39.2       29.0       21.4       19.4}
\end{Highlighting}
\end{Shaded}

In addition to \texttt{c()}, there are other useful functions for creating vectors. The \texttt{seq()} function creates a sequence of numbers, allowing us to specify the start value, the end value, and the increment.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a vector with numbers from 1 to 10}
\NormalTok{numbers }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)}

\CommentTok{\# Create a vector with numbers from 2 to 20, by 2}
\NormalTok{even\_numbers }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Another useful function is \texttt{rep()}, which repeats a value or a vector a specified number of times.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a vector with the value 1 repeated 5 times}
\NormalTok{ones }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)}

\CommentTok{\# Create a vector with the sequence "A", "B" repeated 3 times}
\NormalTok{letters }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), }\DecValTok{3}\NormalTok{)  }\CommentTok{\# Output: "A" "B" "A" "B" "A" "B"}
\end{Highlighting}
\end{Shaded}

\textbf{Accessing vector elements:} Each element of a vector has a position, indicated by a number in brackets. The first element is at position 1, the second at position 2, and so on.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Show the first element of the "states" vector}
\NormalTok{states[}\DecValTok{1}\NormalTok{]  }\CommentTok{\# Output: "California"}

\CommentTok{\# Show the third element of the "population" vector}
\NormalTok{population[}\DecValTok{3}\NormalTok{]  }\CommentTok{\# Output: 21.4}
\end{Highlighting}
\end{Shaded}

We can also access multiple elements at once using the \texttt{:} operator. For example, to access elements from the second to the fourth of the \texttt{states} vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{states[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{4}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] "Texas"    "Florida"  "New York"}
\end{Highlighting}
\end{Shaded}

\textbf{Operations with vectors:} We can perform mathematical operations with numeric vectors. For example, if we want to calculate the total population of the four states, we can use the \texttt{+} operator to sum the elements of the \texttt{population} vector.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{population }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{39.2}\NormalTok{, }\FloatTok{29.0}\NormalTok{, }\FloatTok{21.4}\NormalTok{, }\FloatTok{19.4}\NormalTok{) }

\NormalTok{population[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ population[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ population[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ population[}\DecValTok{4}\NormalTok{]  }
\CommentTok{\#\textgreater{} [1] 109}
\end{Highlighting}
\end{Shaded}

If we want to perform the same operation more concisely, R allows us to sum all elements of a vector directly:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{population }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{39.2}\NormalTok{, }\FloatTok{29.0}\NormalTok{, }\FloatTok{21.4}\NormalTok{, }\FloatTok{19.4}\NormalTok{) }

\FunctionTok{sum}\NormalTok{(population)  }
\CommentTok{\#\textgreater{} [1] 109}
\end{Highlighting}
\end{Shaded}

R also offers other tools for performing operations with vectors. For example, if we want to calculate the square root of the population of each state:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(population)  }
\CommentTok{\#\textgreater{} [1] 6.260990 5.385165 4.626013 4.404543}
\end{Highlighting}
\end{Shaded}

In this case, the \texttt{sqrt()} function calculates the square root of each element of the \texttt{population} vector individually. This is possible because many functions in R are vectorized, meaning they can operate directly on vectors, element by element. Vectorized functions are very efficient as they avoid the need to write loops to process each element of the vector separately.
We will explore functions in R and how to use them for more complex data analysis in greater depth later.

\textbf{Vector coercion:} Unlike other programming languages, R tries to interpret or change a value when it encounters an error. For example, if we try to convert a character vector to numeric, R will convert the elements it can and replace the ones it cannot with \texttt{NA}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"3"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"6"}\NormalTok{, }\StringTok{"a"}\NormalTok{, }\StringTok{"bridge"}\NormalTok{, }\StringTok{"4"}\NormalTok{)}
\FunctionTok{as.numeric}\NormalTok{(example)}
\CommentTok{\#\textgreater{} Warning: NAs introduced by coercion}
\CommentTok{\#\textgreater{} [1]  3 NA  6 NA NA  4}
\end{Highlighting}
\end{Shaded}

\textbf{Sorting vectors:} We can sort the elements of a vector using the \texttt{sort()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{districts }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Comas"}\NormalTok{, }\StringTok{"Lince"}\NormalTok{, }\StringTok{"Miraflores"}\NormalTok{, }\StringTok{"Lurigancho"}\NormalTok{, }\StringTok{"Chorrillos"}\NormalTok{)}
\FunctionTok{sort}\NormalTok{(districts) }
\CommentTok{\#\textgreater{} [1] "Chorrillos" "Comas"      "Lince"      "Lurigancho" "Miraflores"}
\end{Highlighting}
\end{Shaded}

We can also order a vector using its indices with the \texttt{order()} function. This way, we get a vector with the positions the elements of the original vector would occupy if they were sorted. This can be useful when we want to sort a vector based on another vector or when we want to preserve the original vector without modifying it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indices }\OtherTok{\textless{}{-}} \FunctionTok{order}\NormalTok{(districts)  }\CommentTok{\# Output: 5 1 2 4 3}
\NormalTok{districts[indices]}
\CommentTok{\#\textgreater{} [1] "Chorrillos" "Comas"      "Lince"      "Lurigancho" "Miraflores"}
\end{Highlighting}
\end{Shaded}

\textbf{NA in vectors:} If a vector contains NA values, some operations may return NA. We can use the \texttt{is.na()} function to identify NA values and filter them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example\_na }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{28}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{19}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{89}\NormalTok{, }\DecValTok{45}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{86}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{28}\NormalTok{, }\ConstantTok{NA}\NormalTok{)}
\NormalTok{example\_no\_na }\OtherTok{\textless{}{-}}\NormalTok{ example\_na[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(example\_na)]}
\FunctionTok{mean}\NormalTok{(example\_no\_na)  }\CommentTok{\# Output: 38.66667}
\CommentTok{\#\textgreater{} [1] 35.66667}
\end{Highlighting}
\end{Shaded}

\subsection{Lists: grouping objects of different types}\label{lists-grouping-objects-of-different-types}

Lists are like containers that can hold different types of objects. Imagine a box where you can put clothes, books, tools, and any other object you need. In R, lists allow you to group diverse information into a single object.

\textbf{Creating lists:} To create a list, we use the \texttt{list()} function and specify the elements we want to include, separated by commas. Each element can have a name, indicated with the \texttt{=} symbol.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a list with information about a city}
\NormalTok{city\_info }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{name =} \StringTok{"San Francisco"}\NormalTok{, }
                  \AttributeTok{population =} \DecValTok{880000}\NormalTok{, }
                  \AttributeTok{cost\_of\_living =} \FloatTok{3.8}\NormalTok{, }
                  \AttributeTok{climate =} \StringTok{"Temperate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Accessing list elements:} To access the elements of a list, we can use their names or their positions.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Access the "name" element of the "city\_info" list}
\NormalTok{city\_info}\SpecialCharTok{$}\NormalTok{name  }\CommentTok{\# Output: "San Francisco"}

\CommentTok{\# Access the second element of the "city\_info" list}
\NormalTok{city\_info[[}\DecValTok{2}\NormalTok{]]  }\CommentTok{\# Output: 880000}
\end{Highlighting}
\end{Shaded}

\subsection{Matrices: organizing data in rows and columns}\label{matrices-organizing-data-in-rows-and-columns}

Matrices are like tables that organize information in rows and columns. All elements of a matrix must be of the same type.

\textbf{Creating matrices:} To create a matrix, we use the \texttt{matrix()} function. We must specify the data we want to include, the number of rows (\texttt{nrow}), and the number of columns (\texttt{ncol}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a matrix with distances between cities (in miles)}
\NormalTok{city\_distances }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2600}\NormalTok{, }\DecValTok{2100}\NormalTok{, }\DecValTok{950}\NormalTok{, }
                           \DecValTok{2600}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1100}\NormalTok{, }\DecValTok{2700}\NormalTok{, }
                           \DecValTok{2100}\NormalTok{, }\DecValTok{1100}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{2100}\NormalTok{, }
                           \DecValTok{950}\NormalTok{, }\DecValTok{2700}\NormalTok{, }\DecValTok{2100}\NormalTok{, }\DecValTok{0}\NormalTok{), }
                         \AttributeTok{nrow =} \DecValTok{4}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{4}\NormalTok{)}
\NormalTok{city\_distances}
\CommentTok{\#\textgreater{}      [,1] [,2] [,3] [,4]}
\CommentTok{\#\textgreater{} [1,]    0 2600 2100  950}
\CommentTok{\#\textgreater{} [2,] 2600    0 1100 2700}
\CommentTok{\#\textgreater{} [3,] 2100 1100    0 2100}
\CommentTok{\#\textgreater{} [4,]  950 2700 2100    0}
\end{Highlighting}
\end{Shaded}

\textbf{Accessing matrix elements:} To access the elements of a matrix, we use brackets and specify the row and column of the element we want.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Access the element in row 1, column 3 of the "city\_distances" matrix}
\NormalTok{city\_distances[}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{] }
\CommentTok{\#\textgreater{} [1] 2100}
\end{Highlighting}
\end{Shaded}

\subsection{Arrays: multidimensional matrices}\label{arrays-multidimensional-matrices}

Arrays are like matrices that have more than two dimensions. Imagine a matrix that, in addition to rows and columns, has depth. In R, arrays allow you to organize data in more complex structures.

\textbf{Creating arrays:} To create an array, we use the \texttt{array()} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create an array with maximum and minimum temperatures of }
\CommentTok{\# three cities during the summer months (June, July, August)}
\NormalTok{temperatures }\OtherTok{\textless{}{-}} \FunctionTok{array}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{28}\NormalTok{,  }\CommentTok{\# City 1}
                        \DecValTok{28}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{32}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{30}\NormalTok{,  }\CommentTok{\# City 2}
                        \DecValTok{22}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{25}\NormalTok{), }\CommentTok{\# City 3}
                      \AttributeTok{dim =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))  }\CommentTok{\# 3 cities, 2 temperatures (max/min), 3 months}
\NormalTok{temperatures}
\CommentTok{\#\textgreater{} , , 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]   25   22}
\CommentTok{\#\textgreater{} [2,]   28   25}
\CommentTok{\#\textgreater{} [3,]   30   28}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} , , 2}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]   28   25}
\CommentTok{\#\textgreater{} [2,]   20   18}
\CommentTok{\#\textgreater{} [3,]   32   30}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} , , 3}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]   22   18}
\CommentTok{\#\textgreater{} [2,]   25   23}
\CommentTok{\#\textgreater{} [3,]   28   25}
\end{Highlighting}
\end{Shaded}

\textbf{Accessing array elements:} To access the elements of an array, we use brackets and specify the position of the element in each dimension.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Access the maximum temperature of city 2 in July}
\NormalTok{temperatures[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }
\CommentTok{\#\textgreater{} [1] 20}
\end{Highlighting}
\end{Shaded}

\subsection{Factors: representing categorical data}\label{factors-representing-categorical-data}

Factors are a special type of object used to represent categorical data, that is, data that can be classified into groups. For example, the type of climate (``warm'', ``temperate'', ``cold''), the region of a country (``north'', ``south'', ``east'', ``west''), or the type of housing (``house'', ``apartment'').

\textbf{Creating factors:} To create a factor, we use the \texttt{factor()} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a factor with climate types of different cities}
\NormalTok{climate\_types }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Temperate"}\NormalTok{, }\StringTok{"Warm"}\NormalTok{, }\StringTok{"Cold"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\textbf{Levels of a factor:} The different values a factor can take are called levels. In the previous example, the levels of the \texttt{climate\_types} factor are ``Temperate'', ``Warm'', and ``Cold''.

\textbf{Utility of factors:} Factors are very useful for data analysis, as they allow grouping and comparing information efficiently. For example, we could use the \texttt{climate\_types} factor to analyze how the cost of living varies in cities with different climates.

\section{The Universe of Objects in R}\label{the-universe-of-objects-in-r}

Throughout this chapter, we have explored the different types of objects inhabiting the R universe. From the simplest variables to multidimensional arrays, each object plays an important role in building our data analyses.

\subsection{Philosophy of objects in R}\label{philosophy-of-objects-in-r}

In R, everything is an object. This philosophy has profound implications for how code is written and executed. By treating everything as an object, R promotes consistency, modularity, and reuse.

Objects allow us to encapsulate information and behavior, facilitating code organization and maintenance. Furthermore, the ability to create our own objects gives us great power to model and solve complex problems.

By understanding the philosophy of objects in R, we can make the most of the language's capabilities for data analysis.

\subsection{Comparison with other languages}\label{comparison-with-other-languages}

While many modern programming languages use the object-oriented paradigm, R has a particular approach. In languages like Python or Java, creating classes and objects is a fundamental part of the language. In R, while it is possible to create classes and objects, the language focuses more on the use of functions to manipulate and transform data.

This difference is due in part to R's history as a language for statistical analysis. In this context, functions are a natural tool for performing calculations and analyses.

\section{Exercises}\label{exercises}

Now that you know the different types of objects in R, it's time to put your knowledge to the test.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create four variables to plan your move. Define \texttt{city\_name} with the city you would like to move to, \texttt{population} with its number of inhabitants, and \texttt{distance} with the kilometers from your current location. Also, create a logical variable \texttt{want\_to\_live\_there} indicating if you truly want to live there.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{city\_name }\OtherTok{\textless{}{-}} \StringTok{"Seattle"}
\NormalTok{population }\OtherTok{\textless{}{-}} \DecValTok{724745} 
\NormalTok{distance }\OtherTok{\textless{}{-}} \DecValTok{8340}  \CommentTok{\# Approximate distance from Lima, Peru}
\NormalTok{want\_to\_live\_there }\OtherTok{\textless{}{-}} \ConstantTok{TRUE}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a vector called \texttt{nearby\_cities} containing the names of three cities near the city you chose in the previous exercise.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nearby\_cities }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Tacoma"}\NormalTok{, }\StringTok{"Bellevue"}\NormalTok{, }\StringTok{"Everett"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Construct a list called \texttt{my\_list} that groups different types of information about yourself. It should include your name, your age, a vector with your three favorite colors, and a logical value indicating if you simplify like chocolate.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{name =} \StringTok{"Ana"}\NormalTok{, }
                \AttributeTok{age =} \DecValTok{30}\NormalTok{, }
                \AttributeTok{favorite\_colors =} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }
                \AttributeTok{likes\_chocolate =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Create a matrix called \texttt{monthly\_expenses} containing your estimated monthly expenses in the following categories:
\end{enumerate}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Category & January & February & March \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Housing & & & \\
Transport & & & \\
Food & & & \\
Entertainment & & & \\
\end{longtable}
}

Complete the matrix with numerical values.

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{monthly\_expenses }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1500}\NormalTok{, }\DecValTok{1500}\NormalTok{, }\DecValTok{1500}\NormalTok{,  }\CommentTok{\# Housing}
                             \DecValTok{300}\NormalTok{,  }\DecValTok{250}\NormalTok{,  }\DecValTok{350}\NormalTok{,   }\CommentTok{\# Transport}
                             \DecValTok{500}\NormalTok{,  }\DecValTok{400}\NormalTok{,  }\DecValTok{550}\NormalTok{,   }\CommentTok{\# Food}
                             \DecValTok{200}\NormalTok{,  }\DecValTok{150}\NormalTok{,  }\DecValTok{250}\NormalTok{),  }\CommentTok{\# Entertainment}
                           \AttributeTok{nrow =} \DecValTok{4}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{,}
                           \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Housing"}\NormalTok{, }\StringTok{"Transport"}\NormalTok{, }\StringTok{"Food"}\NormalTok{, }\StringTok{"Entertainment"}\NormalTok{),}
                                           \FunctionTok{c}\NormalTok{(}\StringTok{"January"}\NormalTok{, }\StringTok{"February"}\NormalTok{, }\StringTok{"March"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Create a factor called \texttt{climate\_types} containing the names of the different climate types in the United States (you can use ``Temperate'', ``Warm'', ``Cold'', etc.). Assign labels to the factor levels to make them more descriptive (for example, ``Cold climate'', ``Temperate climate'', etc.).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{climate\_types }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Temperate"}\NormalTok{, }\StringTok{"Warm"}\NormalTok{, }\StringTok{"Cold"}\NormalTok{, }\StringTok{"Warm"}\NormalTok{, }\StringTok{"Temperate"}\NormalTok{),}
                     \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Cold"}\NormalTok{, }\StringTok{"Temperate"}\NormalTok{, }\StringTok{"Warm"}\NormalTok{),}
                     \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Cold climate"}\NormalTok{, }\StringTok{"Temperate climate"}\NormalTok{, }\StringTok{"Warm climate"}\NormalTok{))}

\NormalTok{climate\_types}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Create a vector called \texttt{cities\_to\_visit} with the names of 5 cities you would like to visit in the United States. Then, create another vector called \texttt{days\_per\_city} with the number of days you would like to spend in each city. Finally, create a third vector called \texttt{daily\_cost} with the estimated daily cost in each city (in dollars).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cities\_to\_visit }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{, }\StringTok{"San Francisco"}\NormalTok{, }\StringTok{"Miami"}\NormalTok{)}
\NormalTok{days\_per\_city }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{)  }
\NormalTok{daily\_cost }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{200}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{150}\NormalTok{, }\DecValTok{220}\NormalTok{, }\DecValTok{170}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Create a vector called \texttt{max\_temperatures} with the average maximum temperatures (in Celsius) of the cities you want to visit during the month of July. Then, create a vector called \texttt{min\_temperatures} with the average minimum temperatures. Finally, create a matrix containing these two vectors as columns, and name the rows with the names of the cities.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max\_temperatures }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{29}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{31}\NormalTok{)  }\CommentTok{\# Max temperatures in July}
\NormalTok{min\_temperatures }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{21}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{25}\NormalTok{)  }\CommentTok{\# Min temperatures in July}

\CommentTok{\# Create the matrix}
\NormalTok{temperatures }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(max\_temperatures, min\_temperatures), }\AttributeTok{nrow =} \DecValTok{5}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{,}
                       \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(cities\_to\_visit, }\FunctionTok{c}\NormalTok{(}\StringTok{"Maximum"}\NormalTok{, }\StringTok{"Minimum"}\NormalTok{)))}

\NormalTok{temperatures}
\CommentTok{\#\textgreater{}               Maximum Minimum}
\CommentTok{\#\textgreater{} New York           29      21}
\CommentTok{\#\textgreater{} Los Angeles        28      18}
\CommentTok{\#\textgreater{} Chicago            27      19}
\CommentTok{\#\textgreater{} San Francisco      22      15}
\CommentTok{\#\textgreater{} Miami              31      25}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Create a three-dimensional array containing information about the climate of the cities you want to visit. The first dimension should represent the cities, the second dimension should represent the months of the year (``January'', ``February'', \ldots, ``December''), and the third dimension should represent two variables: ``Temperature'' and ``Precipitation''. You can use dummy values to fill the array.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create an array with dimensions 5 cities x 12 months x 2 variables}
\NormalTok{climate }\OtherTok{\textless{}{-}} \FunctionTok{array}\NormalTok{(}\AttributeTok{dim =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{2}\NormalTok{),}
                \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(cities\_to\_visit,}
\NormalTok{                                month.name,}
                                \FunctionTok{c}\NormalTok{(}\StringTok{"Temperature"}\NormalTok{, }\StringTok{"Precipitation"}\NormalTok{)))}

\CommentTok{\# Fill the array with dummy values (example)}
\NormalTok{climate[,, }\StringTok{"Temperature"}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{10}\SpecialCharTok{:}\DecValTok{35}\NormalTok{, }\DecValTok{60}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)  }\CommentTok{\# Temperatures between 10 and 35 degrees}
\NormalTok{climate[,, }\StringTok{"Precipitation"}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{100}\NormalTok{, }\DecValTok{60}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)  }\CommentTok{\# Precipitation between 0 and 100 mm}

\NormalTok{climate}
\CommentTok{\#\textgreater{} , , Temperature}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}               January February March April May June July August September}
\CommentTok{\#\textgreater{} New York           21       23    31    10  27   20   29     30        27}
\CommentTok{\#\textgreater{} Los Angeles        18       26    22    21  16   26   33     14        33}
\CommentTok{\#\textgreater{} Chicago            14       30    26    34  22   10   13     30        26}
\CommentTok{\#\textgreater{} San Francisco      12       11    29    23  33   10   28     20        21}
\CommentTok{\#\textgreater{} Miami              14       27    32    20  27   21   12     15        14}
\CommentTok{\#\textgreater{}               October November December}
\CommentTok{\#\textgreater{} New York           13       16       10}
\CommentTok{\#\textgreater{} Los Angeles        16       35       13}
\CommentTok{\#\textgreater{} Chicago            33       28       13}
\CommentTok{\#\textgreater{} San Francisco      13       16       12}
\CommentTok{\#\textgreater{} Miami              18       29       33}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} , , Precipitation}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}               January February March April May June July August September}
\CommentTok{\#\textgreater{} New York           42       40    81     5  57   32   84     11        24}
\CommentTok{\#\textgreater{} Los Angeles        72       60    39    90  75   37   45     65        87}
\CommentTok{\#\textgreater{} Chicago            84       39     2    60 100   65   58     98        55}
\CommentTok{\#\textgreater{} San Francisco      73       97    36     3  30   98    9      2        94}
\CommentTok{\#\textgreater{} Miami              13       35    80    13  38   32   52     93        60}
\CommentTok{\#\textgreater{}               October November December}
\CommentTok{\#\textgreater{} New York           34       95       89}
\CommentTok{\#\textgreater{} Los Angeles        75       15       76}
\CommentTok{\#\textgreater{} Chicago            59       10       52}
\CommentTok{\#\textgreater{} San Francisco      48       41        6}
\CommentTok{\#\textgreater{} Miami              59       44       26}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Imagine you have a vector with the daily maximum temperatures of a US city for a year. Create a program that, using only the concepts learned in this chapter (variables, vectors, matrices, arrays, and factors), identifies the longest streak of consecutive days with maximum temperatures above a given threshold (for example, 25 degrees Celsius).
\end{enumerate}

Solution

This exercise requires efficient vector handling and algorithmic logic to identify the longest streak. Here is a possible solution:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a vector with dummy maximum temperatures for a year}
\NormalTok{temperatures }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{10}\SpecialCharTok{:}\DecValTok{35}\NormalTok{, }\DecValTok{365}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# Define the temperature threshold}
\NormalTok{threshold }\OtherTok{\textless{}{-}} \DecValTok{25}

\CommentTok{\# Create a logical vector indicating if the temperature exceeds the threshold}
\NormalTok{hot\_days }\OtherTok{\textless{}{-}}\NormalTok{ temperatures }\SpecialCharTok{\textgreater{}}\NormalTok{ threshold}

\CommentTok{\# Initialize variables to track the longest streak}
\NormalTok{current\_streak }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{longest\_streak }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{start\_longest\_streak }\OtherTok{\textless{}{-}} \DecValTok{0}

\CommentTok{\# Iterate through the hot days vector}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(hot\_days)) \{}
  \ControlFlowTok{if}\NormalTok{ (hot\_days[i]) \{}
\NormalTok{    current\_streak }\OtherTok{\textless{}{-}}\NormalTok{ current\_streak }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \ControlFlowTok{if}\NormalTok{ (current\_streak }\SpecialCharTok{\textgreater{}}\NormalTok{ longest\_streak) \{}
\NormalTok{      longest\_streak }\OtherTok{\textless{}{-}}\NormalTok{ current\_streak}
\NormalTok{      start\_longest\_streak }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{{-}}\NormalTok{ current\_streak}
\NormalTok{    \}}
\NormalTok{    current\_streak }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{  \}}
\NormalTok{\}}

\CommentTok{\# Show the longest streak and its position}
\FunctionTok{cat}\NormalTok{(}\StringTok{"The longest streak of hot days is:"}\NormalTok{, longest\_streak, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} The longest streak of hot days is: 6}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Starts on day:"}\NormalTok{, start\_longest\_streak, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Starts on day: 53}
\end{Highlighting}
\end{Shaded}

This code uses a \texttt{for} loop to traverse the hot days vector and two variables (\texttt{current\_streak} and \texttt{longest\_streak}) to track the longest streak.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  Imagine you have a vector with the daily stock prices of a company for a year. Create a program that, using only the concepts learned in this chapter, determines the time period in which you could have bought and sold the shares to obtain the maximum profit. Assume you can only buy and sell once.
\end{enumerate}

Solution

This exercise is a variant of the classic ``maximize stock profit'' problem. Solving it optimally can be complex, but with the concepts from this chapter, we can create an algorithm that finds a solution (though not necessarily the optimal one).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a vector with dummy stock prices for a year}
\NormalTok{prices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{50}\SpecialCharTok{:}\DecValTok{150}\NormalTok{, }\DecValTok{365}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# Initialize variables to track max profit}
\NormalTok{max\_profit }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{buy\_day }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sell\_day }\OtherTok{\textless{}{-}} \DecValTok{1}

\CommentTok{\# Iterate through the prices vector}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{(}\FunctionTok{length}\NormalTok{(prices) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) \{}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in}\NormalTok{ (i }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(prices)) \{}
\NormalTok{    profit }\OtherTok{\textless{}{-}}\NormalTok{ prices[j] }\SpecialCharTok{{-}}\NormalTok{ prices[i]}
    \ControlFlowTok{if}\NormalTok{ (profit }\SpecialCharTok{\textgreater{}}\NormalTok{ max\_profit) \{}
\NormalTok{      max\_profit }\OtherTok{\textless{}{-}}\NormalTok{ profit}
\NormalTok{      buy\_day }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{      sell\_day }\OtherTok{\textless{}{-}}\NormalTok{ j}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\CommentTok{\# Show max profit and buy/sell days}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Maximum profit:"}\NormalTok{, max\_profit, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Maximum profit: 100}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Buy day:"}\NormalTok{, buy\_day, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Buy day: 9}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Sell day:"}\NormalTok{, sell\_day, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Sell day: 73}
\end{Highlighting}
\end{Shaded}

This code uses two nested \texttt{for} loops to compare all possible pairs of buy and sell days.

\chapter{Functions}\label{functions}

\section{Introduction to the world of functions}\label{introduction-to-the-world-of-functions}

In the previous chapter, we explored the different types of objects we can use to store and organize information in R. We learned to create variables, vectors, lists, matrices, and arrays, and saw how to access their elements and perform operations with them.

Now, in this chapter, we will go a step further and delve into the world of \textbf{functions}. Functions are one of the fundamental pillars of programming in R, allowing us to perform more complex tasks and automate our work.

\subsection{What are functions?}\label{what-are-functions}

Imagine a coffee machine. You provide the ingredients (water, coffee, sugar), and the machine performs a series of steps to produce a cup of coffee. Similarly, a function in R is a set of instructions that receives input data (the \textbf{arguments}) and performs a series of operations to produce a result (the \textbf{return value}).

Functions allow us to encapsulate a set of instructions into a single block of code, facilitating reuse and code organization. Instead of writing the same instructions over and over again, we can create a function that performs them for us.

\subsection{Why use functions?}\label{why-use-functions}

Functions offer several advantages, starting with \textbf{Reusability}, which allows us to use the same logic in different parts of our code or across projects. They also improve \textbf{Organization} by breaking code into logical blocks, and enhance \textbf{Readability} by keeping scripts concise. Finally, functions provide \textbf{Abstraction}, hiding complex implementation details so we can focus on the problem logic.

\subsection{First functions: exploring basic R functions}\label{first-functions-exploring-basic-r-functions}

R includes a large number of predefined functions. For instance, \texttt{sum()} calculates the total of a vector's elements, while \texttt{mean()} computes their arithmetic average.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\FunctionTok{sum}\NormalTok{(numbers)  }\CommentTok{\# Output: 15}
\CommentTok{\#\textgreater{} [1] 15}

\NormalTok{temperatures }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{29}\NormalTok{, }\DecValTok{27}\NormalTok{)}
\FunctionTok{mean}\NormalTok{(temperatures)  }\CommentTok{\# Output: 27}
\CommentTok{\#\textgreater{} [1] 27}
\end{Highlighting}
\end{Shaded}

Other common functions include \texttt{round()}, which limits the number of decimal places, and \texttt{length()}, which tells us how many elements a vector contains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi  }\CommentTok{\# Output: 3.141593}
\CommentTok{\#\textgreater{} [1] 3.141593}
\FunctionTok{round}\NormalTok{(pi, }\DecValTok{2}\NormalTok{)  }\CommentTok{\# Output: 3.14}
\CommentTok{\#\textgreater{} [1] 3.14}

\NormalTok{cities }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{)}
\FunctionTok{length}\NormalTok{(cities)  }\CommentTok{\# Output: 3}
\CommentTok{\#\textgreater{} [1] 3}
\end{Highlighting}
\end{Shaded}

These are just a few of the many predefined functions that R offers. As we progress through the book, we will explore more functions and learn how to use them to perform more complex data analysis.

\section{Anatomy of a function}\label{anatomy-of-a-function}

In the previous section, we saw what functions are and why they are so useful in programming. Now, we are going to delve into the structure of a function, so you can create your own functions and automate tasks in your data analysis.

\subsection{Arguments: the ingredients of the function}\label{arguments-the-ingredients-of-the-function}

To make a cup of coffee, you need ingredients: water, coffee, and maybe sugar or milk. Similarly, functions in R need \textbf{arguments} to do their job. Arguments are the input data that the function uses to perform its operations.

For example, the \texttt{sum()} function needs a vector of numbers as an argument to calculate the sum of its elements.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\FunctionTok{sum}\NormalTok{(numbers)  }\CommentTok{\# Output: 15}
\CommentTok{\#\textgreater{} [1] 15}
\end{Highlighting}
\end{Shaded}

A function's arguments are specified in parentheses after the function name. If a function requires multiple arguments, they are separated by commas.

For example, imagine we want to create a function to calculate the total cost of a plane trip. This function might need the \texttt{ticket\_price}, the \texttt{num\_people} traveling, and an optional \texttt{discount} (such as a reduction for students or senior citizens).

The function could be called \texttt{calculate\_vacation\_cost} and would be used as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{calculate\_vacation\_cost}\NormalTok{(}\AttributeTok{ticket\_price =} \DecValTok{300}\NormalTok{, }\AttributeTok{num\_people =} \DecValTok{2}\NormalTok{, }\AttributeTok{discount =} \FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In this case, we are passing three arguments to the function: \texttt{ticket\_price} with value 300, \texttt{num\_people} with value 2, and \texttt{discount} with value 0.1 (representing a 10\% discount).

\subsection{Body: the instructions of the function}\label{body-the-instructions-of-the-function}

The \textbf{body} of a function is the set of instructions that are executed when the function is called. These instructions can be any valid R code: variable assignments, mathematical operations, conditionals, loops, calls to other functions, etc.

The body of a function is defined within curly braces \texttt{\{\}}.

For example, the body of the function \texttt{calculate\_trip\_cost} could be:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_vacation\_cost }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(ticket\_price, num\_people, }\AttributeTok{discount =} \DecValTok{0}\NormalTok{) \{}
\NormalTok{  total\_cost }\OtherTok{\textless{}{-}}\NormalTok{ ticket\_price }\SpecialCharTok{*}\NormalTok{ num\_people }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ discount)}
  \FunctionTok{return}\NormalTok{(total\_cost)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

In this body, first the total cost of the trip is calculated by multiplying the ticket price by the number of people and by (1 minus the discount). Then, \texttt{return()} is used to return the \texttt{total\_cost}.

Note that in the function definition, the argument \texttt{discount} has a default value of 0. This means that if we do not specify a value for \texttt{discount} when calling the function, the value 0 will be used.

For example, if we do not specify a value for \texttt{discount}, the function uses the default value 0, and the total cost is 600:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Call the function without specifying the discount}
\FunctionTok{calculate\_vacation\_cost}\NormalTok{(}\AttributeTok{ticket\_price =} \DecValTok{300}\NormalTok{, }\AttributeTok{num\_people =} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 600}
\end{Highlighting}
\end{Shaded}

If we want to apply a discount, we can specify it when calling the function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{calculate\_vacation\_cost}\NormalTok{(}\AttributeTok{ticket\_price =} \DecValTok{300}\NormalTok{, }\AttributeTok{num\_people =} \DecValTok{2}\NormalTok{, }\AttributeTok{discount =} \FloatTok{0.1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 540}
\end{Highlighting}
\end{Shaded}

In this case, the total cost is 540, since a 10\% discount is applied.

\subsection{Return value: the result of the function}\label{return-value-the-result-of-the-function}

The \textbf{return value} is the result the function produces after executing its instructions. It can be a simple value (a number, text, a logical value) or a more complex object (a vector, a list, a data frame).

In R, the return value is specified with the \texttt{return()} function. If \texttt{return()} is not used, the function will return the result of the last expression evaluated in the body.

In the \texttt{calculate\_vacation\_cost} example, the return value is the \texttt{total\_cost} of the trip, which is a number.

\subsection{Examples: creating simple functions step by step}\label{examples-creating-simple-functions-step-by-step}

Let's see an example of how to create a simple function that converts degrees Celsius to Fahrenheit:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{celsius\_to\_fahrenheit }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(celsius) \{}
\NormalTok{  fahrenheit }\OtherTok{\textless{}{-}}\NormalTok{ (celsius }\SpecialCharTok{*} \DecValTok{9} \SpecialCharTok{/} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+} \DecValTok{32}
  \FunctionTok{return}\NormalTok{(fahrenheit)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{celsius\_to\_fahrenheit} is the name of the function, and \texttt{celsius} is its argument representing the input temperature. Inside the body, the function calculates the equivalent Fahrenheit value using the formula \texttt{(celsius\ *\ 9\ /\ 5)\ +\ 32} and stores it in the variable \texttt{fahrenheit}, which is then sent back as the result using \texttt{return()}.

Now we can use our function to convert temperatures:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{celsius\_to\_fahrenheit}\NormalTok{(}\DecValTok{0}\NormalTok{)   }\CommentTok{\# Output: 32}
\CommentTok{\#\textgreater{} [1] 32}
\FunctionTok{celsius\_to\_fahrenheit}\NormalTok{(}\DecValTok{100}\NormalTok{)  }\CommentTok{\# Output: 212}
\CommentTok{\#\textgreater{} [1] 212}
\end{Highlighting}
\end{Shaded}

Congratulations! You just created your first function in R. As we progress through the chapter, you will learn to create more complex functions and use them to solve real-world problems.

\section{Mastering the use of functions}\label{mastering-the-use-of-functions}

We have already seen how to create simple functions with basic arguments, including the possibility of assigning default values. Now, we will explore even more advanced techniques to master the use of functions and write more flexible and efficient code.

\subsection{\texorpdfstring{Functions with a variable number of arguments (\texttt{...}): Adapting to different situations}{Functions with a variable number of arguments (...): Adapting to different situations}}\label{functions-with-a-variable-number-of-arguments-...-adapting-to-different-situations}

Sometimes, we don't know beforehand how many arguments a function will receive. For these cases, R offers us the possibility of defining functions with a variable number of arguments using the three dots (\texttt{...}).

For example, the \texttt{sum()} function can receive any number of arguments:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{) }
\CommentTok{\#\textgreater{} [1] 6}
\FunctionTok{sum}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# Output: 15}
\CommentTok{\#\textgreater{} [1] 15}
\end{Highlighting}
\end{Shaded}

We can use the three dots (\texttt{...}) to create our own functions that accept a variable number of arguments. For example, a function that calculates the average of several numbers:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_average }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(...) \{}
\NormalTok{  numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(...)}
\NormalTok{  average }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(numbers)}
  \FunctionTok{return}\NormalTok{(average)}
\NormalTok{\}}

\FunctionTok{calculate\_average}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 2}
\FunctionTok{calculate\_average}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 3}
\end{Highlighting}
\end{Shaded}

In this example, the three dots (\texttt{...}) capture all the arguments passed to the function and store them in the \texttt{numbers} vector. Then, the function calculates the average of the numbers in the vector and returns it as a result.

It is important to note that when using \texttt{...}, we lose the ability to name the arguments individually. However, we gain flexibility by being able to pass a variable number of arguments to the function.

\subsection{Variable scope: local and global variables}\label{variable-scope-local-and-global-variables}

The \textbf{scope} of a variable refers to the part of the code where the variable is accessible. In R, variables defined inside a function have a \textbf{local} scope, meaning they are only accessible within the function. Variables defined outside any function have a \textbf{global} scope, meaning they are accessible from anywhere in the code.

For example, in the function \texttt{calculate\_average}, the variable \texttt{numbers} has a local scope:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_average }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(...) \{}
\NormalTok{  numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(...)}
\NormalTok{  average }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(numbers)}
  \FunctionTok{return}\NormalTok{(average)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

If we try to access the variable numbers outside the function, we will get an error:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers  }\CommentTok{\# Error: object \textquotesingle{}numbers\textquotesingle{} not found}
\end{Highlighting}
\end{Shaded}

This is because \texttt{numbers} only exists inside the \texttt{calculate\_average} function. When the function finishes executing, the local variables defined inside it cease to exist.

On the other hand, if we define a variable outside any function, it will be a global variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conversion\_rate }\OtherTok{\textless{}{-}} \FloatTok{0.621371}  \CommentTok{\# Conversion rate from kilometers to miles}
\end{Highlighting}
\end{Shaded}

We can access the \texttt{conversion\_rate} variable from anywhere in the code, even inside a function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kilometers\_to\_miles }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(kilometers) \{}
\NormalTok{  miles }\OtherTok{\textless{}{-}}\NormalTok{ kilometers }\SpecialCharTok{*}\NormalTok{ conversion\_rate}
  \FunctionTok{return}\NormalTok{(miles)}
\NormalTok{\}}

\FunctionTok{kilometers\_to\_miles}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 62.1371}
\end{Highlighting}
\end{Shaded}

It is important to keep variable scope in mind when writing functions to avoid errors and confusion. If a variable is not defined in the current scope (local), R will look in the global scope. If the variable is not found in any scope, an error will occur.

For example, imagine we want to calculate the total cost of a trip, including the cost of the plane ticket, accommodation, and other expenses. We can create a function that receives these expenses as arguments and calculates the total cost:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_trip\_cost }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(ticket, accommodation, other\_expenses) \{}
\NormalTok{  total\_cost }\OtherTok{\textless{}{-}}\NormalTok{ ticket }\SpecialCharTok{+}\NormalTok{ accommodation }\SpecialCharTok{+}\NormalTok{ other\_expenses}
  \FunctionTok{return}\NormalTok{(total\_cost)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

If we call this function with expense values, we get the total cost:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{calculate\_trip\_cost}\NormalTok{(}\AttributeTok{ticket =} \DecValTok{300}\NormalTok{, }\AttributeTok{accommodation =} \DecValTok{500}\NormalTok{, }\AttributeTok{other\_expenses =} \DecValTok{100}\NormalTok{) }
\CommentTok{\#\textgreater{} [1] 900}
\end{Highlighting}
\end{Shaded}

Now, imagine we want to apply a tax to the total cost. We could define a global variable \texttt{tax\_rate}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tax\_rate }\OtherTok{\textless{}{-}} \FloatTok{0.16}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Warning:} Relying on global variables inside a function (like \texttt{tax\_rate} in the example below) is generally considered bad practice. It makes the function dependent on the external environment, which can lead to unexpected errors if the global variable changes or doesn't exist. It is better to pass all necessary values as arguments to the function.
\end{quote}

And then modify the function to include the tax:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_trip\_cost }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(ticket, accommodation, other\_expenses) \{}
\NormalTok{  total\_cost }\OtherTok{\textless{}{-}}\NormalTok{ ticket }\SpecialCharTok{+}\NormalTok{ accommodation }\SpecialCharTok{+}\NormalTok{ other\_expenses}
\NormalTok{  total\_cost }\OtherTok{\textless{}{-}}\NormalTok{ total\_cost }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ tax\_rate)}
  \FunctionTok{return}\NormalTok{(total\_cost)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

When calling the function again, the total cost will include the tax:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{calculate\_trip\_cost}\NormalTok{(}\AttributeTok{ticket =} \DecValTok{300}\NormalTok{, }\AttributeTok{accommodation =} \DecValTok{500}\NormalTok{, }\AttributeTok{other\_expenses =} \DecValTok{100}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1044}
\end{Highlighting}
\end{Shaded}

In this case, the \texttt{calculate\_trip\_cost} function can access the global variable \texttt{tax\_rate} because it is not defined locally within the function.

If we try to use a variable that is not defined in any scope, we will get an error:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_trip\_cost }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(ticket, accommodation, other\_expenses) \{}
\NormalTok{  total\_cost }\OtherTok{\textless{}{-}}\NormalTok{ ticket }\SpecialCharTok{+}\NormalTok{ accommodation }\SpecialCharTok{+}\NormalTok{ other\_expenses }\SpecialCharTok{+}\NormalTok{ tip}
  \FunctionTok{return}\NormalTok{(total\_cost)}
\NormalTok{\}}

\FunctionTok{calculate\_trip\_cost}\NormalTok{(}\AttributeTok{ticket =} \DecValTok{300}\NormalTok{, }\AttributeTok{accommodation =} \DecValTok{500}\NormalTok{, }\AttributeTok{other\_expenses =} \DecValTok{100}\NormalTok{)  }\CommentTok{\# Error: object \textquotesingle{}tip\textquotesingle{} not found}
\end{Highlighting}
\end{Shaded}

In this case, the variable \texttt{tip} is not defined either locally or globally, so the function cannot access it.

It is important to understand the concept of variable scope to write functions that work correctly and avoid errors.

\subsection{Examples: functions to calculate taxes, discounts, etc.}\label{examples-functions-to-calculate-taxes-discounts-etc.}

Functions are very useful for automating repetitive tasks, such as calculating taxes, discounts, or converting units. Let's look at some examples with different levels of difficulty:

\textbf{Calculating shipping cost for a package}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_shipping\_cost }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(weight, destination) \{}
  \ControlFlowTok{if}\NormalTok{ (destination }\SpecialCharTok{==} \StringTok{"local"}\NormalTok{) \{}
\NormalTok{    cost }\OtherTok{\textless{}{-}} \DecValTok{5} \SpecialCharTok{+} \FloatTok{0.1} \SpecialCharTok{*}\NormalTok{ weight}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (destination }\SpecialCharTok{==} \StringTok{"national"}\NormalTok{) \{}
\NormalTok{    cost }\OtherTok{\textless{}{-}} \DecValTok{10} \SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*}\NormalTok{ weight}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{  }\CommentTok{\# destination == "international"}
\NormalTok{    cost }\OtherTok{\textless{}{-}} \DecValTok{20} \SpecialCharTok{+} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ weight}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(cost)}
\NormalTok{\}}

\CommentTok{\# Usage example}
\NormalTok{package\_weight }\OtherTok{\textless{}{-}} \FloatTok{2.5}  \CommentTok{\# Weight in kilograms}
\NormalTok{destination }\OtherTok{\textless{}{-}} \StringTok{"national"}
\NormalTok{shipping\_cost }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_shipping\_cost}\NormalTok{(package\_weight, destination)}

\NormalTok{shipping\_cost}
\CommentTok{\#\textgreater{} [1] 10.5}
\end{Highlighting}
\end{Shaded}

In this example, the \texttt{calculate\_shipping\_cost()} function calculates the shipping cost of a package based on its weight and destination. The function uses a conditional structure (\texttt{if}-\texttt{else\ if}-\texttt{else}) to apply different shipping rates depending on the destination.

\textbf{Calculating income tax with brackets}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_income\_tax }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(income) \{}
  \ControlFlowTok{if}\NormalTok{ (income }\SpecialCharTok{\textless{}=} \DecValTok{10000}\NormalTok{) \{}
\NormalTok{    rate }\OtherTok{\textless{}{-}} \FloatTok{0.10}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (income }\SpecialCharTok{\textless{}=} \DecValTok{20000}\NormalTok{) \{}
\NormalTok{    rate }\OtherTok{\textless{}{-}} \FloatTok{0.15}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    rate }\OtherTok{\textless{}{-}} \FloatTok{0.20}
\NormalTok{  \}}
\NormalTok{  tax }\OtherTok{\textless{}{-}}\NormalTok{ income }\SpecialCharTok{*}\NormalTok{ rate}
  \FunctionTok{return}\NormalTok{(tax)}
\NormalTok{\}}

\CommentTok{\# Usage example}
\NormalTok{income }\OtherTok{\textless{}{-}} \DecValTok{15000}
\NormalTok{tax }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_income\_tax}\NormalTok{(income)}

\NormalTok{tax}
\CommentTok{\#\textgreater{} [1] 2250}
\end{Highlighting}
\end{Shaded}

In this example, the \texttt{calculate\_income\_tax()} function calculates a person's income tax based on their income. The function uses a conditional structure (\texttt{if}-\texttt{else\ if}-\texttt{else}) to apply different tax rates according to the income bracket.

\textbf{Calculating trip cost with multiple options}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_trip\_cost }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(origin\_city, destination\_city, }
                                 \AttributeTok{transport\_type =} \StringTok{"plane"}\NormalTok{, }
                                 \AttributeTok{num\_people =} \DecValTok{1}\NormalTok{, }
                                 \AttributeTok{hotel =} \ConstantTok{NULL}\NormalTok{, }
                                 \AttributeTok{daily\_expenses =} \DecValTok{100}\NormalTok{, }
                                 \AttributeTok{trip\_duration =} \DecValTok{7}\NormalTok{) \{}
  
  \CommentTok{\# Calculate transport cost}
  \ControlFlowTok{if}\NormalTok{ (transport\_type }\SpecialCharTok{==} \StringTok{"plane"}\NormalTok{) \{}
\NormalTok{    transport\_cost }\OtherTok{\textless{}{-}} \DecValTok{300} \SpecialCharTok{*}\NormalTok{ num\_people  }\CommentTok{\# Base price per person}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (transport\_type }\SpecialCharTok{==} \StringTok{"train"}\NormalTok{) \{}
\NormalTok{    transport\_cost }\OtherTok{\textless{}{-}} \DecValTok{150} \SpecialCharTok{*}\NormalTok{ num\_people  }\CommentTok{\# Base price per person}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    transport\_cost }\OtherTok{\textless{}{-}} \DecValTok{0}  \CommentTok{\# Assuming transport is by own car}
\NormalTok{  \}}
  
  \CommentTok{\# Calculate accommodation cost}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(hotel)) \{}
\NormalTok{    accommodation\_cost }\OtherTok{\textless{}{-}}\NormalTok{ hotel}\SpecialCharTok{$}\NormalTok{price }\SpecialCharTok{*}\NormalTok{ trip\_duration}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    accommodation\_cost }\OtherTok{\textless{}{-}} \DecValTok{0}  \CommentTok{\# Assuming staying not at a hotel}
\NormalTok{  \}}
  
  \CommentTok{\# Calculate other expenses}
\NormalTok{  other\_expenses }\OtherTok{\textless{}{-}}\NormalTok{ daily\_expenses }\SpecialCharTok{*}\NormalTok{ num\_people }\SpecialCharTok{*}\NormalTok{ trip\_duration}
  
  \CommentTok{\# Calculate total cost}
\NormalTok{  total\_cost }\OtherTok{\textless{}{-}}\NormalTok{ transport\_cost }\SpecialCharTok{+}\NormalTok{ accommodation\_cost }\SpecialCharTok{+}\NormalTok{ other\_expenses}
  
  \FunctionTok{return}\NormalTok{(total\_cost)}
\NormalTok{\}}

\CommentTok{\# Usage example}
\NormalTok{trip\_cost\_1 }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_trip\_cost}\NormalTok{(}\AttributeTok{origin\_city =} \StringTok{"Lima"}\NormalTok{, }
                                     \AttributeTok{destination\_city =} \StringTok{"New York"}\NormalTok{, }
                                     \AttributeTok{transport\_type =} \StringTok{"plane"}\NormalTok{, }
                                     \AttributeTok{num\_people =} \DecValTok{2}\NormalTok{)}

\NormalTok{trip\_cost\_2 }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_trip\_cost}\NormalTok{(}\AttributeTok{origin\_city =} \StringTok{"Lima"}\NormalTok{, }
                                     \AttributeTok{destination\_city =} \StringTok{"Los Angeles"}\NormalTok{, }
                                     \AttributeTok{transport\_type =} \StringTok{"train"}\NormalTok{, }
                                     \AttributeTok{num\_people =} \DecValTok{3}\NormalTok{, }
                                     \AttributeTok{hotel =} \FunctionTok{list}\NormalTok{(}\AttributeTok{price =} \DecValTok{150}\NormalTok{), }
                                     \AttributeTok{daily\_expenses =} \DecValTok{120}\NormalTok{, }
                                     \AttributeTok{trip\_duration =} \DecValTok{10}\NormalTok{)}

\NormalTok{trip\_cost\_1 }
\CommentTok{\#\textgreater{} [1] 2000}
\NormalTok{trip\_cost\_2 }
\CommentTok{\#\textgreater{} [1] 5550}
\end{Highlighting}
\end{Shaded}

\section{Higher-order functions}\label{higher-order-functions}

In previous sections, we explored how to create and use functions in R. Now, let's delve into a more advanced concept: \textbf{higher-order functions}.

Higher-order functions are those that can receive other functions as arguments or return a function as a result.

This type of function allows us to write more flexible and expressive code, and they are a powerful tool for data analysis.

\subsection{\texorpdfstring{\texttt{lapply()} and \texttt{sapply()}: applying a function to each element}{lapply() and sapply(): applying a function to each element}}\label{lapply-and-sapply-applying-a-function-to-each-element}

Imagine you have a list with information about several US cities, and you want to calculate the population density of each city. You could write a \texttt{for} loop to iterate through the list and calculate the density of each city separately. However, R offers a more efficient and elegant way to do this: the \texttt{lapply()} function.

\texttt{lapply()} (which stands for ``list apply'') takes two arguments:

\begin{itemize}
\tightlist
\item
  A list (or a vector).
\item
  A function to be applied to each element of the list.
\end{itemize}

\texttt{lapply()} applies the function to each element of the list and returns a new list with the results.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a list with information about cities}
\NormalTok{cities }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{New\_York =} \FunctionTok{list}\NormalTok{(}\AttributeTok{population =} \FloatTok{8.4e6}\NormalTok{, }\AttributeTok{area =} \FloatTok{783.8}\NormalTok{),}
  \AttributeTok{Los\_Angeles =} \FunctionTok{list}\NormalTok{(}\AttributeTok{population =} \FloatTok{3.9e6}\NormalTok{, }\AttributeTok{area =} \FloatTok{1302.0}\NormalTok{),}
  \AttributeTok{Chicago =} \FunctionTok{list}\NormalTok{(}\AttributeTok{population =} \FloatTok{2.7e6}\NormalTok{, }\AttributeTok{area =} \FloatTok{606.1}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# Function to calculate population density}
\NormalTok{calculate\_density }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(city) \{}
\NormalTok{  density }\OtherTok{\textless{}{-}}\NormalTok{ city}\SpecialCharTok{$}\NormalTok{population }\SpecialCharTok{/}\NormalTok{ city}\SpecialCharTok{$}\NormalTok{area}
  \FunctionTok{return}\NormalTok{(density)}
\NormalTok{\}}

\CommentTok{\# Calculate population density of each city}
\NormalTok{densities }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(cities, calculate\_density)}

\NormalTok{densities}
\CommentTok{\#\textgreater{} $New\_York}
\CommentTok{\#\textgreater{} [1] 10717.02}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $Los\_Angeles}
\CommentTok{\#\textgreater{} [1] 2995.392}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $Chicago}
\CommentTok{\#\textgreater{} [1] 4454.71}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{lapply()} applies the \texttt{calculate\_density} function to each element of the \texttt{cities} list and returns a new list \texttt{densities} with the population density of each city.

The \texttt{sapply()} function is similar to \texttt{lapply()}, but tries to simplify the result. If the result is a list of vectors of the same type and length, \texttt{sapply()} returns a vector or a matrix.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculate population density of each city with sapply()}
\NormalTok{densities }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(cities, calculate\_density)}

\NormalTok{densities}
\CommentTok{\#\textgreater{}    New\_York Los\_Angeles     Chicago }
\CommentTok{\#\textgreater{}   10717.020    2995.392    4454.710}
\end{Highlighting}
\end{Shaded}

In this case, \texttt{sapply()} returns a vector with population densities.

\subsection{\texorpdfstring{\texttt{apply()}: applying a function to rows or columns}{apply(): applying a function to rows or columns}}\label{apply-applying-a-function-to-rows-or-columns}

The \texttt{apply()} function allows us to apply a function to the rows or columns of a matrix or array. It's like having a tool that allows us to go through each row or column of our data table and perform a specific calculation on each one.

For example, if we have a matrix with the maximum and minimum temperatures of different cities, we can use \texttt{apply()} to calculate the average temperature of each city.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a matrix with temperatures}
\NormalTok{temperatures }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{28}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{3}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{,}
                       \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{),}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{"Maximum"}\NormalTok{, }\StringTok{"Minimum"}\NormalTok{)))}

\CommentTok{\# Calculate average temperature of each city}
\NormalTok{average\_temperatures }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(temperatures, }\DecValTok{1}\NormalTok{, mean)}

\NormalTok{average\_temperatures}
\CommentTok{\#\textgreater{}    New York Los Angeles     Chicago }
\CommentTok{\#\textgreater{}        23.5        26.5        29.0}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{apply()} applies the \texttt{mean()} function to each row of the \texttt{temperatures} matrix (the argument \texttt{1} indicates that the function should be applied to rows) and returns a vector with the average temperatures of each city.

If we wanted to calculate the maximum or minimum temperature among all cities, we could use \texttt{apply()} with the \texttt{max()} or \texttt{min()} function, respectively, and apply it to columns (using argument \texttt{2}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculate maximum temperature among all cities}
\NormalTok{maximum\_temperature }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(temperatures, }\DecValTok{2}\NormalTok{, max)}

\NormalTok{maximum\_temperature}
\CommentTok{\#\textgreater{} Maximum Minimum }
\CommentTok{\#\textgreater{}      30      35}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{\texttt{mapply()}: applying a function to multiple arguments}{mapply(): applying a function to multiple arguments}}\label{mapply-applying-a-function-to-multiple-arguments}

The \texttt{mapply()} function allows us to apply a function to multiple arguments in parallel. It's like having a tool that allows us to take several sets of data and apply the same operation to each corresponding set.

For example, imagine we have two vectors: one with the names of different US cities and another with their respective populations. We want to create a new vector containing the phrase ``The city of {[}city name{]} has a population of {[}population{]} inhabitants''. We could use \texttt{mapply()} to apply a function combining the city name and its population to each pair of elements from the vectors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create vectors with city names and populations}
\NormalTok{cities }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{)}
\NormalTok{populations }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{8.4e6}\NormalTok{, }\FloatTok{3.9e6}\NormalTok{, }\FloatTok{2.7e6}\NormalTok{)}

\CommentTok{\# Function to create the phrase}
\NormalTok{create\_phrase }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(city, population) \{}
\NormalTok{  phrase }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"The city of"}\NormalTok{, city, }\StringTok{"has a population of"}\NormalTok{, population, }\StringTok{"inhabitants."}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(phrase)}
\NormalTok{\}}

\CommentTok{\# Create vector with phrases}
\NormalTok{city\_phrases }\OtherTok{\textless{}{-}} \FunctionTok{mapply}\NormalTok{(create\_phrase, cities, populations)}

\NormalTok{city\_phrases}
\CommentTok{\#\textgreater{}                                                           New York }
\CommentTok{\#\textgreater{}    "The city of New York has a population of 8400000 inhabitants." }
\CommentTok{\#\textgreater{}                                                        Los Angeles }
\CommentTok{\#\textgreater{} "The city of Los Angeles has a population of 3900000 inhabitants." }
\CommentTok{\#\textgreater{}                                                            Chicago }
\CommentTok{\#\textgreater{}     "The city of Chicago has a population of 2700000 inhabitants."}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{mapply()} applies the \texttt{create\_phrase} function to the \texttt{cities} and \texttt{populations} vectors in parallel, taking one element from each vector at a time, and returns a vector with the resulting phrases.

Note that the \texttt{create\_phrase} function receives two arguments: \texttt{city} and \texttt{population}. \texttt{mapply()} is responsible for taking one element from each vector and passing them as arguments to the function. In the first iteration, it passes ``New York'' as \texttt{city} and 8.4e6 as \texttt{population}. In the second iteration, it passes ``Los Angeles'' and 3.9e6, and so on.

Another example of using \texttt{mapply()} would be if we have two vectors with maximum and minimum temperatures of different cities, and we want to calculate the temperature difference between maximum and minimum for each city.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create vectors with maximum and minimum temperatures}
\NormalTok{maxs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{35}\NormalTok{)}
\NormalTok{mins }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{28}\NormalTok{)}

\CommentTok{\# Calculate temperature difference for each city}
\NormalTok{temp\_difference }\OtherTok{\textless{}{-}} \FunctionTok{mapply}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(max, min) max }\SpecialCharTok{{-}}\NormalTok{ min, maxs, mins)}

\NormalTok{temp\_difference}
\CommentTok{\#\textgreater{} [1] 7 8 7}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{mapply()} applies the anonymous function \texttt{function(max,\ min)\ max\ -\ min} to the \texttt{maxs} and \texttt{mins} vectors in parallel, taking the first element of \texttt{maxs} and the first element of \texttt{mins}, then the second element of each vector, and so on. For each pair of elements, the anonymous function calculates the difference and returns a vector with the results.

\subsection{Examples: data analysis with higher-order functions}\label{examples-data-analysis-with-higher-order-functions}

Higher-order functions are a powerful tool for data analysis. They allow us to perform complex operations concisely and efficiently. Imagine you have a matrix with information about different states, where each row represents a state and each column a numeric variable, such as population or per capita income. You could use \texttt{apply()} to calculate the mean of each column.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a matrix with information about states}
\NormalTok{states }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{39.2e6}\NormalTok{, }\FloatTok{29.0e6}\NormalTok{, }\FloatTok{21.4e6}\NormalTok{, }\DecValTok{64500}\NormalTok{, }\DecValTok{56100}\NormalTok{, }\DecValTok{50800}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{3}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{,}
                 \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"California"}\NormalTok{, }\StringTok{"Texas"}\NormalTok{, }\StringTok{"Florida"}\NormalTok{),}
                                 \FunctionTok{c}\NormalTok{(}\StringTok{"population"}\NormalTok{, }\StringTok{"per\_capita\_income"}\NormalTok{)))}

\CommentTok{\# Calculate mean of each column}
\NormalTok{means }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(states, }\DecValTok{2}\NormalTok{, mean)}

\NormalTok{means}
\CommentTok{\#\textgreater{}        population per\_capita\_income }
\CommentTok{\#\textgreater{}       29866666.67          57133.33}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{apply()} applies the \texttt{mean()} function to each column of the states matrix and returns a vector with the means.

Another one would be if we have a list with prices of different hotels in several US cities. You could use \texttt{sapply()} to apply a function calculating the tax of each price, or \texttt{lapply()} to convert prices from dollars to euros.

You could also use \texttt{apply()} to calculate the average price of hotels in each city, or to find the most expensive and cheapest hotel in each city.

As we progress through the book, we will see more examples of how to use higher-order functions to solve real-world problems.

The possibilities are endless, and higher-order functions give you great flexibility to manipulate and analyze your data.

\section{Closures: functions with memory}\label{closures-functions-with-memory}

Until now, we have seen that functions in R receive arguments, execute a set of instructions, and return a result. However, functions can also have ``memory'', that is, they can remember information between calls. This is possible thanks to a concept called \textbf{closures}.

\subsection{Concept: functions that ``remember''}\label{concept-functions-that-remember}

A closure is a function that ``remembers'' the environment in which it was created. This means the function has access to variables that were defined at the time of its creation, even if those variables are no longer in the current scope.

To better understand this concept, let's see an example. Imagine we want to create a function that counts how many times it has been called. We can do this using a closure:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{create\_counter }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{  counter }\OtherTok{\textless{}{-}} \DecValTok{0}  \CommentTok{\# Initialize the counter}

  \CommentTok{\# Define the function that increments the counter}
\NormalTok{  increment\_counter }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{    counter }\OtherTok{\textless{}\textless{}{-}}\NormalTok{ counter }\SpecialCharTok{+} \DecValTok{1}
    \FunctionTok{return}\NormalTok{(counter)}
\NormalTok{  \}}

  \FunctionTok{return}\NormalTok{(increment\_counter)  }\CommentTok{\# Return the function}
\NormalTok{\}}

\CommentTok{\# Create a counter}
\NormalTok{my\_counter }\OtherTok{\textless{}{-}} \FunctionTok{create\_counter}\NormalTok{()}

\CommentTok{\# Call the counter several times}
\FunctionTok{my\_counter}\NormalTok{()  }
\CommentTok{\#\textgreater{} [1] 1}
\FunctionTok{my\_counter}\NormalTok{()  }
\CommentTok{\#\textgreater{} [1] 2}
\FunctionTok{my\_counter}\NormalTok{()  }
\CommentTok{\#\textgreater{} [1] 3}
\end{Highlighting}
\end{Shaded}

In this example, the \texttt{create\_counter()} function creates a \texttt{counter} variable and an \texttt{increment\_counter()} function. The \texttt{increment\_counter()} function has access to the \texttt{counter} variable and increments it by 1 each time it is called. The \texttt{create\_counter()} function returns the \texttt{increment\_counter()} function.

When we call \texttt{my\_counter()}, we are calling the \texttt{increment\_counter()} function that was created inside \texttt{create\_counter()}. This function ``remembers'' the value of the \texttt{counter} variable and increments it on each call.

It is important to note that the \texttt{counter} variable is not a global variable. It is only accessible within the \texttt{increment\_counter()} function. This is because \texttt{counter} was defined inside the \texttt{create\_counter()} function, so its scope is local to that function.

However, the \texttt{increment\_counter()} function ``captures'' the \texttt{counter} variable in its environment, allowing it to access it even after the \texttt{create\_counter()} function has finished executing.

\subsection{Applications: creating counters, functions with internal state}\label{applications-creating-counters-functions-with-internal-state}

Closures have many applications in programming. They are commonly used for \textbf{creating counters} that maintain an internal state between calls, \textbf{configuring parameters} where a generated function remembers specific settings (like a temperature scale), and \textbf{encapsulating data} to hide sensitive information or internal logic within the function scope.

\subsection{Examples: simulating a game, creating an operation history}\label{examples-simulating-a-game-creating-an-operation-history}

Let's see some more concrete examples of using closures:

\begin{itemize}
\item
  \textbf{Simulating a game:} We can use a closure to simulate a game where the player has to guess a secret number. The closure can ``remember'' the secret number and keep track of the player's attempts.
\item
  \textbf{Creating an operation history:} We can use a closure to create a function that records operations performed on a variable. The closure can ``remember'' the operation history and show it when requested.
\end{itemize}

Closures are a powerful tool that allows us to write more flexible and expressive code. As you become familiar with them, you will discover new ways to apply them in your data analysis.

\section{Debugging and error handling: solving the mysteries of your code}\label{debugging-and-error-handling-solving-the-mysteries-of-your-code}

So far, we have explored the fascinating world of functions in R. We have learned to create, use, and combine them to perform complex tasks. However, on the programming journey, encountering errors is inevitable. Sometimes, our code doesn't work as we expect, and we encounter cryptic error messages that leave us perplexed.

In this section, we will learn to identify, understand, and fix errors in our R code. We will also see how to handle errors gracefully, so our code is more robust and reliable.

\subsection{Identifying errors: common error messages in R}\label{identifying-errors-common-error-messages-in-r}

When our code contains an error, R will show us an error message in the console. These messages can seem intimidating at first, but with a little practice, we will learn to interpret them and use them to find the cause of the error.

Some common error messages in R include \texttt{Error:\ object\ \textquotesingle{}object\_name\textquotesingle{}\ not\ found}, which happens when you interpret a non-existent variable or function. Another is \texttt{invalid\ argument} when function inputs don't match the expected type, such as passing text to a numeric function. You might also encounter \texttt{argument\ is\ of\ length\ zero} in \texttt{if} conditions, often due to \texttt{NULL} or empty vectors, or \texttt{invalid\ \textquotesingle{}for\textquotesingle{}\ loop\ sequence} when the loop iterator definition is flawed.

It is important to read error messages carefully and try to understand what they are telling us. Often, the error message will give us a clue about the cause of the problem.

\subsection{\texorpdfstring{Debugging tools: \texttt{debug()}, \texttt{traceback()}}{Debugging tools: debug(), traceback()}}\label{debugging-tools-debug-traceback}

R offers several tools to debug our code and find the cause of errors. Two of the most useful tools are \texttt{debug()} and \texttt{traceback()}.

\begin{itemize}
\item
  \texttt{debug()}: This function allows us to execute a function step by step, allowing us to inspect the value of variables at each step and understand how the code is executing. To use \texttt{debug()}, we simply call the function with the name of the function we want to debug as an argument.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{debug}\NormalTok{(my\_function)}
\end{Highlighting}
\end{Shaded}

  Then, when we call \texttt{my\_function()}, R will enter debug mode and allow us to execute the code line by line.
\item
  \texttt{traceback()}: This function shows us the sequence of function calls that led to the error. This can be useful for understanding how the error was reached and which functions are involved. To use \texttt{traceback()}, simply call the function after an error has occurred.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{traceback}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

  R will show a list of the functions that were called, starting with the function where the error occurred and ending with the function that started the code execution.
\end{itemize}

\subsection{\texorpdfstring{Error handling: \texttt{tryCatch()}}{Error handling: tryCatch()}}\label{error-handling-trycatch}

Sometimes, we want our code to continue executing even if an error occurs. For this, we can use the \texttt{tryCatch()} function.

\texttt{tryCatch()} allows us to specify a block of code that will be executed if an error occurs. We can also specify a block of code that will be executed if no error occurs.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tryCatch}\NormalTok{(}
\NormalTok{  \{}
    \CommentTok{\# Code that might produce an error}
\NormalTok{  \},}
  \AttributeTok{error =} \ControlFlowTok{function}\NormalTok{(e) \{}
    \CommentTok{\# Code to be executed if an error occurs}
\NormalTok{  \},}
  \AttributeTok{finally =}\NormalTok{ \{}
    \CommentTok{\# Code to be executed always, whether or not there is an error}
\NormalTok{  \}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

For example, if we are reading data from a file and the file does not exist, we can use \texttt{tryCatch()} to show an error message and continue with code execution.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tryCatch}\NormalTok{(}
\NormalTok{  \{}
\NormalTok{    data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"my\_file.csv"}\NormalTok{)}
\NormalTok{  \},}
  \AttributeTok{error =} \ControlFlowTok{function}\NormalTok{(e) \{}
    \FunctionTok{print}\NormalTok{(}\StringTok{"Error reading file. Please verify the file exists."}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Examples: debugging functions with errors, handling exceptions}\label{examples-debugging-functions-with-errors-handling-exceptions}

Let's see some examples of how to use debugging tools and error handling in R:

\begin{itemize}
\item
  \textbf{Debugging a function with \texttt{debug()}:}

  Imagine we create a function to calculate a person's Body Mass Index (BMI), but when using it, we get an error. We can use \texttt{debug()} to analyze what happens inside the function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_bmi }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(weight, height) \{}
\NormalTok{  bmi }\OtherTok{\textless{}{-}}\NormalTok{ weight }\SpecialCharTok{/}\NormalTok{ (height }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{) }
  \FunctionTok{return}\NormalTok{(bmi)}
\NormalTok{\}}

\FunctionTok{debug}\NormalTok{(calculate\_bmi)}
\FunctionTok{calculate\_bmi}\NormalTok{(}\AttributeTok{weight =} \DecValTok{70}\NormalTok{, }\AttributeTok{height =} \FloatTok{1.75}\NormalTok{)  }\CommentTok{\# We call the function to start debugging}
\end{Highlighting}
\end{Shaded}

  When executing this code, R will enter debug mode. In the console, we will see a new prompt \texttt{Browse{[}1{]}\textgreater{}}. We can use commands like \texttt{n} (next) to execute the next line of code, \texttt{c} (continue) to continue normal execution, or \texttt{Q} to exit debug mode. We can also print the value of variables using their name (e.g.~\texttt{weight}, \texttt{height}, \texttt{bmi}).
\item
  \textbf{Handling an exception with \texttt{tryCatch()}:}

  Suppose we are creating a function to calculate the annual population growth rate of a city. If the initial population is 0, the division will produce an error. We can use \texttt{tryCatch()} to handle this situation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_growth\_rate }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(initial\_population, final\_population, years) \{}
  \FunctionTok{tryCatch}\NormalTok{(}
\NormalTok{    \{}
\NormalTok{      rate }\OtherTok{\textless{}{-}}\NormalTok{ ((final\_population }\SpecialCharTok{/}\NormalTok{ initial\_population)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ years) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \DecValTok{100}
      \FunctionTok{return}\NormalTok{(rate)}
\NormalTok{    \},}
    \AttributeTok{error =} \ControlFlowTok{function}\NormalTok{(e) \{}
      \FunctionTok{message}\NormalTok{(}\StringTok{"Error: Initial population cannot be zero."}\NormalTok{)}
      \FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  )}
\NormalTok{\}}

\FunctionTok{calculate\_growth\_rate}\NormalTok{(}\DecValTok{10000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# Output: 3.7137...}
\CommentTok{\#\textgreater{} [1] 3.713729}
\FunctionTok{calculate\_growth\_rate}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# Output: "Error: Initial population cannot be zero." }
\CommentTok{\#\textgreater{} [1] Inf}
\end{Highlighting}
\end{Shaded}

  In this example, if \texttt{initial\_population} is 0, \texttt{tryCatch()} captures the error and displays a message. Then, it returns \texttt{NA} to indicate that calculation could not be performed.
\end{itemize}

With practice, you will learn to use these tools to debug your code, handle errors, and write more robust and reliable programs.

\section{Exercises}\label{exercises-1}

It's time to test your skills with functions! Below, you will find a series of exercises with different levels of difficulty.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Create a function called \texttt{miles\_to\_kilometers()} converting miles to kilometers. The function should receive a \texttt{miles} argument and return the equivalent in kilometers. (Remember that 1 mile equals 1.60934 kilometers).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{miles\_to\_kilometers }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(miles) \{}
\NormalTok{  kilometers }\OtherTok{\textless{}{-}}\NormalTok{ miles }\SpecialCharTok{*} \FloatTok{1.60934}
  \FunctionTok{return}\NormalTok{(kilometers)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  Create a function called \texttt{triangle\_area()} calculating the area of a triangle. The function should receive two arguments: \texttt{base} and \texttt{height}, and return the triangle's area. (Remember that the area of a triangle is equal to (base * height) / 2).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{triangle\_area }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(base, height) \{}
\NormalTok{  area }\OtherTok{\textless{}{-}}\NormalTok{ (base }\SpecialCharTok{*}\NormalTok{ height) }\SpecialCharTok{/} \DecValTok{2}
  \FunctionTok{return}\NormalTok{(area)}
\NormalTok{    \}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{12}
\tightlist
\item
  Create a function called \texttt{price\_with\_vat()} calculating the price of a product including VAT. The function should receive two arguments: \texttt{price\_without\_vat} and \texttt{vat\_rate} (default, 0.16), and return the price with VAT.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{price\_with\_vat }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(price\_without\_vat, }\AttributeTok{vat\_rate =} \FloatTok{0.16}\NormalTok{) \{}
\NormalTok{  price\_with\_vat }\OtherTok{\textless{}{-}}\NormalTok{ price\_without\_vat }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ vat\_rate)}
  \FunctionTok{return}\NormalTok{(price\_with\_vat)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{13}
\tightlist
\item
  Create a function called \texttt{is\_even()} determining if a number is even. The function should receive a \texttt{number} argument and return \texttt{TRUE} if the number is even and \texttt{FALSE} if not. (Hint: use the modulo operator \texttt{\%\%}).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{    is\_even }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(number) \{}
      \FunctionTok{return}\NormalTok{(number }\SpecialCharTok{\%\%} \DecValTok{2} \SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\NormalTok{    \}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{14}
\tightlist
\item
  Create a function called \texttt{my\_factorial()} calculating the factorial of a number. The factorial of a positive integer \emph{n}, denoted by \emph{n!}, is the product of all positive integers less than or equal to \emph{n}. For example, 5! = 5 * 4 * 3 * 2 * 1 = 120. (Hint: use a recursive function). Note: We name it \texttt{my\_factorial()} to avoid shadowing R's built-in \texttt{factorial()} function.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_factorial }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
  \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
      \CommentTok{\# We use message() and return(NA) because we haven\textquotesingle{}t covered stop() yet}
      \FunctionTok{message}\NormalTok{(}\StringTok{"Factorial is not defined for negative numbers"}\NormalTok{)}
      \FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\NormalTok{    \}}
  \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{return}\NormalTok{(n }\SpecialCharTok{*} \FunctionTok{my\_factorial}\NormalTok{(n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{15}
\tightlist
\item
  Create a function called \texttt{fibonacci()} generating a Fibonacci sequence of a given length. The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones. The sequence typically starts with 0 and 1. For example, a Fibonacci sequence of length 10 would be: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fibonacci }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
  \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{\textless{}=} \DecValTok{0}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{numeric}\NormalTok{(}\DecValTok{0}\NormalTok{))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{==} \DecValTok{2}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    fib\_seq }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(n)}
\NormalTok{    fib\_seq[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{    fib\_seq[}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{3}\SpecialCharTok{:}\NormalTok{n) \{}
\NormalTok{      fib\_seq[i] }\OtherTok{\textless{}{-}}\NormalTok{ fib\_seq[i }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ fib\_seq[i }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{]}
\NormalTok{    \}}
    \FunctionTok{return}\NormalTok{(fib\_seq)}
\NormalTok{  \}}
\NormalTok{\}}

\FunctionTok{fibonacci}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1]  0  1  1  2  3  5  8 13 21 34}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{16}
\tightlist
\item
  Create a function called \texttt{gcd()} calculating the greatest common divisor (GCD) of two numbers. The GCD of two or more non-zero integers is the largest positive integer that divides them without a remainder. For example, the GCD of 12 and 18 is 6. (Hint: use the Euclidean algorithm).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gcd }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(a, b) \{}
  \ControlFlowTok{while}\NormalTok{ (b }\SpecialCharTok{!=} \DecValTok{0}\NormalTok{) \{}
\NormalTok{    temp }\OtherTok{\textless{}{-}}\NormalTok{ b}
\NormalTok{    b }\OtherTok{\textless{}{-}}\NormalTok{ a }\SpecialCharTok{\%\%}\NormalTok{ b}
\NormalTok{    a }\OtherTok{\textless{}{-}}\NormalTok{ temp}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(a)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{17}
\item
  Create a function called \texttt{validate\_password()} validating a password. The function should receive a \texttt{password} argument and return \texttt{TRUE} if the password meets the following conditions, and \texttt{FALSE} otherwise:

  \begin{itemize}
  \tightlist
  \item
    Has at least 8 characters.
  \item
    Contains at least one uppercase letter.
  \item
    Contains at least one lowercase letter.
  \item
    Contains at least one number.
  \item
    Contains at least one special character (!@\#\$\%\^{}\&*).
  \end{itemize}
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{validate\_password }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(password) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{nchar}\NormalTok{(password) }\SpecialCharTok{\textless{}} \DecValTok{8}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{grepl}\NormalTok{(}\StringTok{"[A{-}Z]"}\NormalTok{, password)) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{grepl}\NormalTok{(}\StringTok{"[a{-}z]"}\NormalTok{, password)) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{grepl}\NormalTok{(}\StringTok{"[0{-}9]"}\NormalTok{, password)) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{grepl}\NormalTok{(}\StringTok{"[!@\#$\%\^{}\&*]"}\NormalTok{, password)) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{18}
\tightlist
\item
  Create a function called \texttt{apply\_discount()} receiving a price calculation function and a discount as arguments. The \texttt{apply\_discount()} function should return a new function calculating the price with the discount applied.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{apply\_discount }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(price\_function, discount) \{}
  \ControlFlowTok{function}\NormalTok{(original\_price) \{}
\NormalTok{    discounted\_price }\OtherTok{\textless{}{-}} \FunctionTok{price\_function}\NormalTok{(original\_price) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ discount)}
    \FunctionTok{return}\NormalTok{(discounted\_price)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{19}
\tightlist
\item
  Create a function called \texttt{create\_temperature\_converter()} receiving a temperature scale as argument (``Celsius'', ``Fahrenheit'' or ``Kelvin''). The function should return a function converting temperatures to the specified scale.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{create\_temperature\_converter }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(scale) \{}
  \ControlFlowTok{if}\NormalTok{ (scale }\SpecialCharTok{==} \StringTok{"Celsius"}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(temp) (temp }\SpecialCharTok{{-}} \DecValTok{32}\NormalTok{) }\SpecialCharTok{*} \DecValTok{5} \SpecialCharTok{/} \DecValTok{9}\NormalTok{)  }\CommentTok{\# Fahrenheit to Celsius}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (scale }\SpecialCharTok{==} \StringTok{"Fahrenheit"}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(temp) (temp }\SpecialCharTok{*} \DecValTok{9} \SpecialCharTok{/} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+} \DecValTok{32}\NormalTok{)  }\CommentTok{\# Celsius to Fahrenheit}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (scale }\SpecialCharTok{==} \StringTok{"Kelvin"}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(temp) temp }\SpecialCharTok{+} \FloatTok{273.15}\NormalTok{)  }\CommentTok{\# Celsius to Kelvin}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
      \CommentTok{\# We use message() and return(NA) because we haven\textquotesingle{}t covered stop() yet}
      \FunctionTok{message}\NormalTok{(}\StringTok{"Invalid temperature scale."}\NormalTok{)}
      \FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{20}
\tightlist
\item
  Create a function called \texttt{guess\_number()} simulating a guess the number game. The function should generate a random number between 1 and 100 and ask the user to guess it. The function should give hints to the user (higher or lower) and count the number of attempts. (Hint: use a closure to store the secret number and the number of attempts).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{guess\_number }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{  secret\_number }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  attempts }\OtherTok{\textless{}{-}} \DecValTok{0}

\NormalTok{  guess }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{    attempts }\OtherTok{\textless{}\textless{}{-}}\NormalTok{ attempts }\SpecialCharTok{+} \DecValTok{1}
    \FunctionTok{cat}\NormalTok{(}\StringTok{"Attempt"}\NormalTok{, attempts, }\StringTok{": "}\NormalTok{)}
\NormalTok{    number }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{readline}\NormalTok{())}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.na}\NormalTok{(number)) \{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"Please enter a valid number.}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (number }\SpecialCharTok{\textless{}}\NormalTok{ secret\_number) \{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"The secret number is higher.}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (number }\SpecialCharTok{\textgreater{}}\NormalTok{ secret\_number) \{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"The secret number is lower.}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"You guessed it! The secret number was"}\NormalTok{, secret\_number, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"It took you"}\NormalTok{, attempts, }\StringTok{"attempts.}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  \}}

  \FunctionTok{return}\NormalTok{(guess)}
\NormalTok{\}}

\NormalTok{game }\OtherTok{\textless{}{-}} \FunctionTok{guess\_number}\NormalTok{()}

\FunctionTok{game}\NormalTok{()}
\CommentTok{\#\textgreater{} Attempt 1 : }
\CommentTok{\#\textgreater{} Please enter a valid number.}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{21}
\tightlist
\item
  Create a function that, given a vector of integers, finds the contiguous subsequence with the maximum sum. For example, for the vector \texttt{c(-2,\ 1,\ -3,\ 4,\ -1,\ 2,\ 1,\ -5,\ 4)}, the contiguous subsequence with the maximum sum is \texttt{c(4,\ -1,\ 2,\ 1)}, with a sum of 6.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max\_subsequence }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  current\_max }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{  global\_max }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{  start }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{  end }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{  temp\_start }\OtherTok{\textless{}{-}} \DecValTok{1}

  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(x)) \{}
\NormalTok{    current\_max }\OtherTok{\textless{}{-}}\NormalTok{ current\_max }\SpecialCharTok{+}\NormalTok{ x[i]}
    \ControlFlowTok{if}\NormalTok{ (current\_max }\SpecialCharTok{\textgreater{}}\NormalTok{ global\_max) \{}
\NormalTok{      global\_max }\OtherTok{\textless{}{-}}\NormalTok{ current\_max}
\NormalTok{      start }\OtherTok{\textless{}{-}}\NormalTok{ temp\_start}
\NormalTok{      end }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{    \}}
    \ControlFlowTok{if}\NormalTok{ (current\_max }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      current\_max }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{      temp\_start }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{    \}}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{subsequence =}\NormalTok{ x[start}\SpecialCharTok{:}\NormalTok{end], }\AttributeTok{sum =}\NormalTok{ global\_max))}
\NormalTok{\}}

\NormalTok{test }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\FunctionTok{max\_subsequence}\NormalTok{(test)}
\CommentTok{\#\textgreater{} $subsequence}
\CommentTok{\#\textgreater{} [1]  4 {-}1  2  1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $sum}
\CommentTok{\#\textgreater{} [1] 6}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{22}
\tightlist
\item
  Create a function that, given a character vector, determines if it is possible to obtain a palindrome by rearranging its letters. A palindrome is a word or phrase that reads the same left to right as right to left (e.g.~``radar'').
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{is\_palindrome\_possible }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(text) \{}
\NormalTok{  letters }\OtherTok{\textless{}{-}} \FunctionTok{strsplit}\NormalTok{(}\FunctionTok{tolower}\NormalTok{(text), }\StringTok{""}\NormalTok{)[[}\DecValTok{1}\NormalTok{]]}
\NormalTok{  frequencies }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(letters)}
\NormalTok{  odds }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(frequencies }\SpecialCharTok{\%\%} \DecValTok{2}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(odds }\SpecialCharTok{\textless{}=} \DecValTok{1}\NormalTok{)}
\NormalTok{\}}

\NormalTok{test }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"radar"}\NormalTok{, }\StringTok{"hello"}\NormalTok{, }\StringTok{"abb"}\NormalTok{)}
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(test, is\_palindrome\_possible)}
\NormalTok{result}
\CommentTok{\#\textgreater{} radar hello   abb }
\CommentTok{\#\textgreater{}  TRUE FALSE  TRUE}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{23}
\tightlist
\item
  Create a function that, given a positive integer, determines if it is a prime number. A prime number is a natural number greater than 1 that has no divisors other than 1 and itself.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{is\_prime }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
  \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{\textless{}=} \DecValTok{1}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{\textless{}=} \DecValTok{3}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{\%\%} \DecValTok{2} \SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{||}\NormalTok{ n }\SpecialCharTok{\%\%} \DecValTok{3} \SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  i }\OtherTok{\textless{}{-}} \DecValTok{5}
  \ControlFlowTok{while}\NormalTok{ (i }\SpecialCharTok{*}\NormalTok{ i }\SpecialCharTok{\textless{}=}\NormalTok{ n) \{}
    \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{\%\%}\NormalTok{ i }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{||}\NormalTok{ n }\SpecialCharTok{\%\%}\NormalTok{ (i }\SpecialCharTok{+} \DecValTok{2}\NormalTok{) }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{}
      \FunctionTok{return}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{    i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{6}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The condition \texttt{i\ *\ i\ \textless{}=\ n} in the \texttt{while} loop limits iterations to the square root of \texttt{n}. This optimizes the algorithm, as it is not necessary to check divisors greater than the square root of \texttt{n}.
The increment \texttt{i\ \textless{}-\ i\ +\ 6} is based on the observation that all prime numbers greater than 3 can be expressed in the form 6k ± 1. Therefore, only numbers of the form 6k ± 1 need to be checked as possible divisors.

\chapter{Data Frames}\label{data-frames}

\section{Introduction to Data Frames}\label{introduction-to-data-frames}

In previous chapters, we explored different types of objects in R, such as variables, vectors, lists, and matrices. These objects allow us to store information in more efficient ways. Now, in this chapter, we will delve into the world of \textbf{data frames}, an essential tool for organizing and analyzing information that will help you make the best decision about your move to the United States.

\subsection{What are data frames?}\label{what-are-data-frames}

Imagine a spreadsheet, with rows and columns organizing information in a tabular way. In R, a data frame is precisely that: a data structure that stores information in a tabular format, with rows representing \textbf{observations} (for example, every US city) and columns representing \textbf{variables} (such as population, cost of living, crime rate).

Each column of a data frame can contain a different data type: numeric, character, logical, factor, etc. This makes data frames very versatile for storing diverse information.

For example, a data frame about US cities could serve as a comprehensive record. It might contain a character column for the \texttt{city} name and another for the \texttt{state} it belongs to. Numeric columns could store the \texttt{population} and the \texttt{area} in square kilometers, while a logical column like \texttt{has\_beach} could indicate whether the city is coastal.

\subsection{Why data frames?}\label{why-data-frames}

In R, there are various structures for organizing data, such as vectors, lists, and matrices. However, data frames stand out as a fundamental tool in data analysis. Why?

Data frames offer a unique combination of features that make them ideal for representing and manipulating complex information:

Data frames are uniquely suited for data analysis because of their specific features. Their \textbf{tabular structure} organizes data into rows and columns, similar to a spreadsheet, making it intuitive to visualize. They offer \textbf{flexibility} by allowing each column to hold a different data type, such as numbers, text, or dates. this structure also ensures \textbf{efficiency}, as most R analysis packages are optimized to work directly with data frames.

In summary, data frames are a versatile and powerful data structure that adapts to the needs of modern data analysis.

\subsection{Data Frames in action: exploring information about the United States}\label{data-frames-in-action-exploring-information-about-the-united-states}

In the context of your move to the United States, data frames will be essential for organizing and analyzing the information you need to make the best decision. We can use data frames to store information about:

We can use data frames to store and correlate various aspects of your potential new home. You might track \textbf{crime rates} across different states, compare the \textbf{cost of living} (housing, food, transportation) in target cities, analyze \textbf{climate data} like temperature and precipitation, or study \textbf{demographics} such as population age and education levels.

With this information organized in data frames, you will be able to perform deeper analyses and make more informed decisions about your move.

\section{Creating Data Frames: Building your database for the move}\label{creating-data-frames-building-your-database-for-the-move}

Now that you know what data frames are and why they are so important in data analysis, it's time to learn how to create them. In R, we can create data frames in different ways: importing data from external files or creating them manually.

\subsection{Importing data from files: CSV, Excel}\label{importing-data-from-files-csv-excel}

A common way to create data frames is by importing data from external files, such as CSV (Comma Separated Values) files or Excel files. R offers us functions to read data from different formats.

One of the most common ways to create data frames is by importing data from external files. For \textbf{CSV (Comma Separated Values)} files, we rely on the \texttt{read\_csv()} function from the \texttt{readr} package (part of the tidyverse), which is faster and more robust than the base R equivalent. To import a file, you simply provide its URL or file path:

\begin{verbatim}
``` r
library(readr)
url <- "https://dparedesi.github.io/Data-Science-with-R-book/data/student-grades.csv"

# Import data from a CSV file called "student-grades.csv"
grades <- read_csv(url)
#> Rows: 21 Columns: 9
#> -- Column specification -----------------------------
#> Delimiter: ","
#> chr (3): start_date, gender, type
#> dbl (6): P1, P2, P3, P4, P5, P6
#> 
#> i Use `spec()` to retrieve the full column specification for this data.
#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.

grades
#> # A tibble: 21 x 9
#>    start_date gender type                 P1    P2    P3    P4    P5    P6
#>    <chr>      <chr>  <chr>             <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
#>  1 03/05/2020 female Individual Work 1     5     5     5     5     5     5
#>  2 03/05/2020 male   Individual Work 1     5     5     5     5     4     5
#>  3 03/05/2020 female Individual Work 1     5     5     4     5     5     5
#>  4 03/05/2020 male   Individual Work 1     5     5     5     5     5     5
#>  5 03/05/2020 male   Individual Work 1     2     5     5     5     5     5
#>  6 03/05/2020 male   Individual Work 1     5     4     5     1     5     5
#>  7 03/05/2020 male   Individual Work 1     2     1     5     5     2     5
#>  8 03/05/2020 male   Individual Work 1     5     5     5     5     5     5
#>  9 03/05/2020 male   Individual Work 1     4     5     5     5     5     5
#> 10 03/05/2020 male   Individual Work 1     3     4     5     5     5     5
#> # i 11 more rows
```
\end{verbatim}

The \texttt{read\_csv()} function offers several arguments to customize how files are read. The \texttt{header} argument allows you to specify if the first row contains column names, while \texttt{sep} defines the column separator (defaulting to a comma). You can also use \texttt{dec} to set the character used for decimal points.

For \textbf{Excel files}, we use the \texttt{read\_excel()} function from the \texttt{readxl} package. This function works similarly but includes specific arguments like \texttt{sheet} to specify which spreadsheet tab to import.

\begin{verbatim}
``` r
# Install the readxl package (if you don't have it installed)
install.packages("readxl")

# Load the readxl package
library(readxl)

# Import data from an Excel file called "states.xlsx"
states <- read_excel("states.xlsx")
```
\end{verbatim}

\subsection{Creating data frames manually}\label{creating-data-frames-manually}

We can also create data frames manually, combining vectors with the \texttt{data.frame()} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create vectors with information about cities}
\NormalTok{cities }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{)}
\NormalTok{states }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"California"}\NormalTok{, }\StringTok{"Illinois"}\NormalTok{)}
\NormalTok{population }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{8.4e6}\NormalTok{, }\FloatTok{3.9e6}\NormalTok{, }\FloatTok{2.7e6}\NormalTok{)}

\CommentTok{\# Create a data frame with city information}
\NormalTok{df\_cities\_simple }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{city =}\NormalTok{ cities, }\AttributeTok{state =}\NormalTok{ states, }\AttributeTok{population =}\NormalTok{ population)}

\NormalTok{df\_cities\_simple}
\CommentTok{\#\textgreater{}          city      state population}
\CommentTok{\#\textgreater{} 1    New York   New York    8400000}
\CommentTok{\#\textgreater{} 2 Los Angeles California    3900000}
\CommentTok{\#\textgreater{} 3     Chicago   Illinois    2700000}
\end{Highlighting}
\end{Shaded}

In this example, we create a data frame called \texttt{df\_cities\_simple} with three columns: \texttt{city}, \texttt{state}, and \texttt{population}. Each column is created from a vector. Note that the vectors must have the same length to be combined into a data frame.

\subsection{Examples}\label{examples}

We can use data frames to organize diverse information about our move to the United States. For example, we could create a data frame with information about different cities, including their cost of living, crime rate, and climate. We could also create a data frame with information about the different states, including their population, gross domestic product (GDP), and education system.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a data frame with information about cities}
\NormalTok{df\_cities }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{city =} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{, }\StringTok{"Houston"}\NormalTok{),}
  \AttributeTok{state =} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"California"}\NormalTok{, }\StringTok{"Illinois"}\NormalTok{, }\StringTok{"Texas"}\NormalTok{),}
  \AttributeTok{cost\_of\_living =} \FunctionTok{c}\NormalTok{(}\FloatTok{3.5}\NormalTok{, }\FloatTok{2.8}\NormalTok{, }\FloatTok{2.5}\NormalTok{, }\FloatTok{2.0}\NormalTok{),  }\CommentTok{\# In thousands of dollars}
  \AttributeTok{crime\_rate =} \FunctionTok{c}\NormalTok{(}\DecValTok{400}\NormalTok{, }\DecValTok{350}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{450}\NormalTok{),  }\CommentTok{\# Per 100,000 inhabitants}
  \AttributeTok{climate =} \FunctionTok{c}\NormalTok{(}\StringTok{"Temperate"}\NormalTok{, }\StringTok{"Mediterranean"}\NormalTok{, }\StringTok{"Continental"}\NormalTok{, }\StringTok{"Subtropical"}\NormalTok{)}
\NormalTok{)}

\NormalTok{df\_cities}
\CommentTok{\#\textgreater{}          city      state cost\_of\_living crime\_rate       climate}
\CommentTok{\#\textgreater{} 1    New York   New York            3.5        400     Temperate}
\CommentTok{\#\textgreater{} 2 Los Angeles California            2.8        350 Mediterranean}
\CommentTok{\#\textgreater{} 3     Chicago   Illinois            2.5        500   Continental}
\CommentTok{\#\textgreater{} 4     Houston      Texas            2.0        450   Subtropical}

\CommentTok{\# Create a data frame with information about states}
\NormalTok{df\_states }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{state =} \FunctionTok{c}\NormalTok{(}\StringTok{"California"}\NormalTok{, }\StringTok{"Texas"}\NormalTok{, }\StringTok{"Florida"}\NormalTok{, }\StringTok{"New York"}\NormalTok{),}
  \AttributeTok{population =} \FunctionTok{c}\NormalTok{(}\FloatTok{39.2e6}\NormalTok{, }\FloatTok{29.0e6}\NormalTok{, }\FloatTok{21.4e6}\NormalTok{, }\FloatTok{19.4e6}\NormalTok{),}
  \AttributeTok{gdp =} \FunctionTok{c}\NormalTok{(}\FloatTok{3.2e12}\NormalTok{, }\FloatTok{1.8e12}\NormalTok{, }\FloatTok{1.1e12}\NormalTok{, }\FloatTok{1.7e12}\NormalTok{),  }\CommentTok{\# In dollars}
  \AttributeTok{education\_system =} \FunctionTok{c}\NormalTok{(}\StringTok{"Good"}\NormalTok{, }\StringTok{"Regular"}\NormalTok{, }\StringTok{"Good"}\NormalTok{, }\StringTok{"Excellent"}\NormalTok{)}
\NormalTok{)}

\NormalTok{df\_states}
\CommentTok{\#\textgreater{}        state population     gdp education\_system}
\CommentTok{\#\textgreater{} 1 California   39200000 3.2e+12             Good}
\CommentTok{\#\textgreater{} 2      Texas   29000000 1.8e+12          Regular}
\CommentTok{\#\textgreater{} 3    Florida   21400000 1.1e+12             Good}
\CommentTok{\#\textgreater{} 4   New York   19400000 1.7e+12        Excellent}
\end{Highlighting}
\end{Shaded}

These data frames will allow us to analyze the information more efficiently and make more informed decisions about our move.

\section{Exploring Data Frames: Discovering the secrets of your data}\label{exploring-data-frames-discovering-the-secrets-of-your-data}

We have already learned to create data frames, now it is time to explore their content and discover the information they hide. R offers us various tools to examine and understand our data.

\subsection{Accessing rows, columns, and cells}\label{accessing-rows-columns-and-cells}

A data frame is like a map organized in rows and columns. To access the information we need, we must know how to navigate this map. R provides us with different ways to access rows, columns, and cells of a data frame.

There are several ways to access specific data within a dataframe. To retrieve a \textbf{column}, you can use the \texttt{\$} operator (e.g., \texttt{df\_cities\$state}) or bracket notation with the column name in quotes (e.g., \texttt{df\_states{[}"population"{]}}). To access a specific \textbf{row}, use brackets with the row number (e.g., \texttt{df\_cities{[}3,\ {]}}). For a precise \textbf{cell} at the intersection of a row and column, specify both indices (e.g., \texttt{df\_states{[}2,\ 3{]}}). You can also \textbf{filter rows} based on conditions, such as extracting all cities where the cost of living is less than 3 using a logical expression inside the brackets.

\subsection{Functions for exploring data frames}\label{functions-for-exploring-data-frames}

R offers several useful functions for exploring data frames:

R provides useful functions for a quick overview of your data. \texttt{head()} displays the first six rows, while \texttt{tail()} shows the last six. To understand the structure---such as column names and data types---you can use \texttt{str()}. For a statistical overview including mean, median, and quartiles, \texttt{summary()} is the go-to function. Additionally, \texttt{View()} opens an interactive spreadsheet-style window to browse the data.

\subsection{Examples: exploring data frames with move information}\label{examples-exploring-data-frames-with-move-information}

By exploring the data frames we created in the previous section, we can obtain valuable information about US cities and states. For example, we could use \texttt{summary()} to get descriptive statistics of the cost of living in different cities, or \texttt{View()} to examine information about each state in detail.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Get descriptive statistics of cost of living in different cities}
\FunctionTok{summary}\NormalTok{(df\_cities}\SpecialCharTok{$}\NormalTok{cost\_of\_living)}
\CommentTok{\#\textgreater{}    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. }
\CommentTok{\#\textgreater{}   2.000   2.375   2.650   2.700   2.975   3.500}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Examine detailed information about each state}
\FunctionTok{View}\NormalTok{(df\_states)}
\end{Highlighting}
\end{Shaded}

In addition to the mentioned functions, we can use other tools to explore our data frames. For example, we can use the \texttt{table()} function to get the frequency of each value in a categorical column, such as the \texttt{climate} column in the \texttt{df\_cities} data frame.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(df\_cities}\SpecialCharTok{$}\NormalTok{climate)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Continental Mediterranean   Subtropical     Temperate }
\CommentTok{\#\textgreater{}             1             1             1             1}
\end{Highlighting}
\end{Shaded}

We can also use the \texttt{hist()} function to create a histogram of a numeric column, such as the population column in the \texttt{df\_states} data frame.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(df\_states}\SpecialCharTok{$}\NormalTok{population)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-139-1} \end{center}

These are just some ideas of how we can explore our data frames. As you become familiar with R, you will discover new functions and techniques for analyzing and visualizing your data.

\section{Manipulating Data Frames: Transforming your data}\label{manipulating-data-frames-transforming-your-data}

In the previous section, we learned to explore data frames and access the information they contain. Now, we will go a step further and learn to \textbf{manipulate} data frames, transforming data to answer specific questions and obtain relevant information for our move.

\subsection{\texorpdfstring{Introduction to the pipeline operator (\texttt{\textbar{}\textgreater{}})}{Introduction to the pipeline operator (\textbar\textgreater)}}\label{introduction-to-the-pipeline-operator}

Before modifying data frames, we will introduce a tool to write more readable and efficient code: the \textbf{native pipeline operator} (\texttt{\textbar{}\textgreater{}}). This operator was introduced in R 4.1 (2021) as a built-in language feature, meaning it works without any additional packages.

\begin{quote}
\textbf{Note:} You may also encounter the \texttt{\%\textgreater{}\%} pipe operator from the \texttt{magrittr} package (part of the tidyverse). Both \texttt{\textbar{}\textgreater{}} and \texttt{\%\textgreater{}\%} work similarly for most data analysis tasks. We use the native \texttt{\textbar{}\textgreater{}} operator throughout this book as it is built into R, but \texttt{\%\textgreater{}\%} is still widely used in older codebases.
\end{quote}

The pipeline operator allows us to chain several operations sequentially. Instead of writing nested code, we can use the pipeline operator to ``pass'' the result of one operation to the next.

To use additional data manipulation functions, we'll load the \texttt{tidyverse} package, which includes \texttt{dplyr} - a package with many useful functions for working with data frames.

A package in R is like a toolbox with additional functions and data for performing specific tasks. To use a package's functions, we must first install it and then load it into our working environment.

To install the \texttt{tidyverse} package, we can use the following instruction in the R console:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"tidyverse"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This will install \texttt{tidyverse} and all the packages it contains, including \texttt{dplyr}. Once the package is installed, we can load it with the \texttt{library()} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Now we can use the pipeline operator \texttt{(\textbar{}\textgreater{})} and functions from \texttt{dplyr.}

For example, we'll use the \texttt{murders} dataset from the \texttt{dslabs} package. This dataset contains gun murder data by US state in 2010, including variables like state name, abbreviation, region, population, and total murders. Let's use a pipeline to view selected columns:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"dslabs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load library and dataset}
\FunctionTok{library}\NormalTok{(dslabs)}
\FunctionTok{data}\NormalTok{(murders)}

\CommentTok{\# Pipeline}
\NormalTok{murders }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(state, population, total)}
\CommentTok{\#\textgreater{}                   state population total}
\CommentTok{\#\textgreater{} 1               Alabama    4779736   135}
\CommentTok{\#\textgreater{} 2                Alaska     710231    19}
\CommentTok{\#\textgreater{} 3               Arizona    6392017   232}
\CommentTok{\#\textgreater{} 4              Arkansas    2915918    93}
\CommentTok{\#\textgreater{} 5            California   37253956  1257}
\CommentTok{\#\textgreater{} 6              Colorado    5029196    65}
\CommentTok{\#\textgreater{} 7           Connecticut    3574097    97}
\CommentTok{\#\textgreater{} 8              Delaware     897934    38}
\CommentTok{\#\textgreater{} 9  District of Columbia     601723    99}
\CommentTok{\#\textgreater{} 10              Florida   19687653   669}
\CommentTok{\#\textgreater{} 11              Georgia    9920000   376}
\CommentTok{\#\textgreater{} 12               Hawaii    1360301     7}
\CommentTok{\#\textgreater{} 13                Idaho    1567582    12}
\CommentTok{\#\textgreater{} 14             Illinois   12830632   364}
\CommentTok{\#\textgreater{} 15              Indiana    6483802   142}
\CommentTok{\#\textgreater{} 16                 Iowa    3046355    21}
\CommentTok{\#\textgreater{} 17               Kansas    2853118    63}
\CommentTok{\#\textgreater{} 18             Kentucky    4339367   116}
\CommentTok{\#\textgreater{} 19            Louisiana    4533372   351}
\CommentTok{\#\textgreater{} 20                Maine    1328361    11}
\CommentTok{\#\textgreater{} 21             Maryland    5773552   293}
\CommentTok{\#\textgreater{} 22        Massachusetts    6547629   118}
\CommentTok{\#\textgreater{} 23             Michigan    9883640   413}
\CommentTok{\#\textgreater{} 24            Minnesota    5303925    53}
\CommentTok{\#\textgreater{} 25          Mississippi    2967297   120}
\CommentTok{\#\textgreater{} 26             Missouri    5988927   321}
\CommentTok{\#\textgreater{} 27              Montana     989415    12}
\CommentTok{\#\textgreater{} 28             Nebraska    1826341    32}
\CommentTok{\#\textgreater{} 29               Nevada    2700551    84}
\CommentTok{\#\textgreater{} 30        New Hampshire    1316470     5}
\CommentTok{\#\textgreater{} 31           New Jersey    8791894   246}
\CommentTok{\#\textgreater{} 32           New Mexico    2059179    67}
\CommentTok{\#\textgreater{} 33             New York   19378102   517}
\CommentTok{\#\textgreater{} 34       North Carolina    9535483   286}
\CommentTok{\#\textgreater{} 35         North Dakota     672591     4}
\CommentTok{\#\textgreater{} 36                 Ohio   11536504   310}
\CommentTok{\#\textgreater{} 37             Oklahoma    3751351   111}
\CommentTok{\#\textgreater{} 38               Oregon    3831074    36}
\CommentTok{\#\textgreater{} 39         Pennsylvania   12702379   457}
\CommentTok{\#\textgreater{} 40         Rhode Island    1052567    16}
\CommentTok{\#\textgreater{} 41       South Carolina    4625364   207}
\CommentTok{\#\textgreater{} 42         South Dakota     814180     8}
\CommentTok{\#\textgreater{} 43            Tennessee    6346105   219}
\CommentTok{\#\textgreater{} 44                Texas   25145561   805}
\CommentTok{\#\textgreater{} 45                 Utah    2763885    22}
\CommentTok{\#\textgreater{} 46              Vermont     625741     2}
\CommentTok{\#\textgreater{} 47             Virginia    8001024   250}
\CommentTok{\#\textgreater{} 48           Washington    6724540    93}
\CommentTok{\#\textgreater{} 49        West Virginia    1852994    27}
\CommentTok{\#\textgreater{} 50            Wisconsin    5686986    97}
\CommentTok{\#\textgreater{} 51              Wyoming     563626     5}
\end{Highlighting}
\end{Shaded}

Code with pipeline is easier to read and understand, as it follows the natural flow of operations. Pipeline creates a view; we are not editing the \texttt{murders} data frame.

We can show the first rows using the \texttt{head()} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(murders }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(state, population, total))}
\CommentTok{\#\textgreater{}        state population total}
\CommentTok{\#\textgreater{} 1    Alabama    4779736   135}
\CommentTok{\#\textgreater{} 2     Alaska     710231    19}
\CommentTok{\#\textgreater{} 3    Arizona    6392017   232}
\CommentTok{\#\textgreater{} 4   Arkansas    2915918    93}
\CommentTok{\#\textgreater{} 5 California   37253956  1257}
\CommentTok{\#\textgreater{} 6   Colorado    5029196    65}
\end{Highlighting}
\end{Shaded}

We can also use the pipeline operator to show the first rows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(state, population, total) }\SpecialCharTok{|\textgreater{}} \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}        state population total}
\CommentTok{\#\textgreater{} 1    Alabama    4779736   135}
\CommentTok{\#\textgreater{} 2     Alaska     710231    19}
\CommentTok{\#\textgreater{} 3    Arizona    6392017   232}
\CommentTok{\#\textgreater{} 4   Arkansas    2915918    93}
\CommentTok{\#\textgreater{} 5 California   37253956  1257}
\CommentTok{\#\textgreater{} 6   Colorado    5029196    65}
\end{Highlighting}
\end{Shaded}

For better readability, we will use one function per line, obtaining the same result:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(state, population, total) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Select columns}
  \FunctionTok{head}\NormalTok{() }\CommentTok{\# Show first 6 rows}
\CommentTok{\#\textgreater{}        state population total}
\CommentTok{\#\textgreater{} 1    Alabama    4779736   135}
\CommentTok{\#\textgreater{} 2     Alaska     710231    19}
\CommentTok{\#\textgreater{} 3    Arizona    6392017   232}
\CommentTok{\#\textgreater{} 4   Arkansas    2915918    93}
\CommentTok{\#\textgreater{} 5 California   37253956  1257}
\CommentTok{\#\textgreater{} 6   Colorado    5029196    65}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Transforming a table with \texttt{mutate()}}{Transforming a table with mutate()}}\label{transforming-a-table-with-mutate}

We can create new columns or modify existing ones using the \texttt{mutate()} function. For example, to add a column with the homicide rate per 100,000 inhabitants to the \texttt{murders} data frame:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total }\SpecialCharTok{/}\NormalTok{ population }\SpecialCharTok{*} \DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}        state abb region population total    ratio}
\CommentTok{\#\textgreater{} 1    Alabama  AL  South    4779736   135 2.824424}
\CommentTok{\#\textgreater{} 2     Alaska  AK   West     710231    19 2.675186}
\CommentTok{\#\textgreater{} 3    Arizona  AZ   West    6392017   232 3.629527}
\CommentTok{\#\textgreater{} 4   Arkansas  AR  South    2915918    93 3.189390}
\CommentTok{\#\textgreater{} 5 California  CA   West   37253956  1257 3.374138}
\CommentTok{\#\textgreater{} 6   Colorado  CO   West    5029196    65 1.292453}
\end{Highlighting}
\end{Shaded}

This creates a view with the additional \texttt{ratio} column.

If we want to modify the \texttt{murders} data frame directly, we use the assignment operator \texttt{\textless{}-}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\OtherTok{\textless{}{-}}\NormalTok{ murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total }\SpecialCharTok{/}\NormalTok{ population }\SpecialCharTok{*} \DecValTok{100000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Filtering data: selecting cities that interest you}\label{filtering-data-selecting-cities-that-interest-you}

We can filter rows meeting a condition using the \texttt{filter()} function. For example, to get states with less than 1 homicide per 100,000 inhabitants:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load dataset}
\FunctionTok{data}\NormalTok{(murders)}

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total }\SpecialCharTok{/}\NormalTok{ population }\SpecialCharTok{*} \DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(ratio }\SpecialCharTok{\textless{}} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{}            state abb        region population total     ratio}
\CommentTok{\#\textgreater{} 1         Hawaii  HI          West    1360301     7 0.5145920}
\CommentTok{\#\textgreater{} 2          Idaho  ID          West    1567582    12 0.7655102}
\CommentTok{\#\textgreater{} 3           Iowa  IA North Central    3046355    21 0.6893484}
\CommentTok{\#\textgreater{} 4          Maine  ME     Northeast    1328361    11 0.8280881}
\CommentTok{\#\textgreater{} 5      Minnesota  MN North Central    5303925    53 0.9992600}
\CommentTok{\#\textgreater{} 6  New Hampshire  NH     Northeast    1316470     5 0.3798036}
\CommentTok{\#\textgreater{} 7   North Dakota  ND North Central     672591     4 0.5947151}
\CommentTok{\#\textgreater{} 8         Oregon  OR          West    3831074    36 0.9396843}
\CommentTok{\#\textgreater{} 9   South Dakota  SD North Central     814180     8 0.9825837}
\CommentTok{\#\textgreater{} 10          Utah  UT          West    2763885    22 0.7959810}
\CommentTok{\#\textgreater{} 11       Vermont  VT     Northeast     625741     2 0.3196211}
\CommentTok{\#\textgreater{} 12       Wyoming  WY          West     563626     5 0.8871131}
\end{Highlighting}
\end{Shaded}

We can use different operators to create our conditions:

R supports standard comparison operators to create conditions: greater than (\texttt{\textgreater{}}), less than (\texttt{\textless{}}), greater than or equal to (\texttt{\textgreater{}=}), less than or equal to (\texttt{\textless{}=}), equal to (\texttt{==}), and different from (\texttt{!=}). You can combine multiple conditions using logical operators: \texttt{\&} for AND, \texttt{\textbar{}} for OR, and \texttt{!} for NOT.

For example, to filter by ratio less than 1 and West region:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total }\SpecialCharTok{/}\NormalTok{ population }\SpecialCharTok{*} \DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(ratio }\SpecialCharTok{\textless{}} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ region }\SpecialCharTok{==} \StringTok{"West"}\NormalTok{)}
\CommentTok{\#\textgreater{}     state abb region population total     ratio}
\CommentTok{\#\textgreater{} 1  Hawaii  HI   West    1360301     7 0.5145920}
\CommentTok{\#\textgreater{} 2   Idaho  ID   West    1567582    12 0.7655102}
\CommentTok{\#\textgreater{} 3  Oregon  OR   West    3831074    36 0.9396843}
\CommentTok{\#\textgreater{} 4    Utah  UT   West    2763885    22 0.7959810}
\CommentTok{\#\textgreater{} 5 Wyoming  WY   West     563626     5 0.8871131}
\end{Highlighting}
\end{Shaded}

\subsection{Sorting data: finding the safest cities}\label{sorting-data-finding-the-safest-cities}

The \texttt{arrange()} function from the \texttt{dplyr} package allows us to order the rows of a data frame based on one or more columns. Imagine you have a data frame with information about different cities, and you want to order them from safest to least safe, based on their crime rate. Or perhaps you want to order them by cost of living, from cheapest to most expensive. \texttt{arrange()} allows you to do this easily.

For example, to order states by homicide rate (from lowest to highest):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total }\SpecialCharTok{/}\NormalTok{ population }\SpecialCharTok{*} \DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(ratio) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}           state abb        region population total     ratio}
\CommentTok{\#\textgreater{} 1       Vermont  VT     Northeast     625741     2 0.3196211}
\CommentTok{\#\textgreater{} 2 New Hampshire  NH     Northeast    1316470     5 0.3798036}
\CommentTok{\#\textgreater{} 3        Hawaii  HI          West    1360301     7 0.5145920}
\CommentTok{\#\textgreater{} 4  North Dakota  ND North Central     672591     4 0.5947151}
\CommentTok{\#\textgreater{} 5          Iowa  IA North Central    3046355    21 0.6893484}
\CommentTok{\#\textgreater{} 6         Idaho  ID          West    1567582    12 0.7655102}
\end{Highlighting}
\end{Shaded}

If we want to sort in descending order, we use the \texttt{desc()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total }\SpecialCharTok{/}\NormalTok{ population }\SpecialCharTok{*} \DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(ratio)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}                  state abb        region population total     ratio}
\CommentTok{\#\textgreater{} 1 District of Columbia  DC         South     601723    99 16.452753}
\CommentTok{\#\textgreater{} 2            Louisiana  LA         South    4533372   351  7.742581}
\CommentTok{\#\textgreater{} 3             Missouri  MO North Central    5988927   321  5.359892}
\CommentTok{\#\textgreater{} 4             Maryland  MD         South    5773552   293  5.074866}
\CommentTok{\#\textgreater{} 5       South Carolina  SC         South    4625364   207  4.475323}
\CommentTok{\#\textgreater{} 6             Delaware  DE         South     897934    38  4.231937}
\end{Highlighting}
\end{Shaded}

We can also sort by multiple columns. For example, if we want to sort first by \texttt{region} and then by \texttt{state} (in alphabetical order):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{arrange}\NormalTok{(region, state) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}           state abb    region population total}
\CommentTok{\#\textgreater{} 1   Connecticut  CT Northeast    3574097    97}
\CommentTok{\#\textgreater{} 2         Maine  ME Northeast    1328361    11}
\CommentTok{\#\textgreater{} 3 Massachusetts  MA Northeast    6547629   118}
\CommentTok{\#\textgreater{} 4 New Hampshire  NH Northeast    1316470     5}
\CommentTok{\#\textgreater{} 5    New Jersey  NJ Northeast    8791894   246}
\CommentTok{\#\textgreater{} 6      New York  NY Northeast   19378102   517}
\end{Highlighting}
\end{Shaded}

\subsection{Aggregating and summarizing data: obtaining general overview}\label{aggregating-and-summarizing-data-obtaining-general-overview}

The \texttt{summarize()} function from the \texttt{dplyr} package allows us to calculate descriptive statistics for one or more columns of a data frame. It's like summarizing information from our data frame into a single number or a set of numbers.

For example, to calculate the mean population of states:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean\_population =} \FunctionTok{mean}\NormalTok{(population))}
\CommentTok{\#\textgreater{}   mean\_population}
\CommentTok{\#\textgreater{} 1         6075769}
\end{Highlighting}
\end{Shaded}

We can combine \texttt{summarize()} with \texttt{group\_by()} to calculate statistics by groups. For example, to calculate average population by region:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(region) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean\_population =} \FunctionTok{mean}\NormalTok{(population))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 2}
\CommentTok{\#\textgreater{}   region        mean\_population}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}                   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Northeast            6146360 }
\CommentTok{\#\textgreater{} 2 South                6804378.}
\CommentTok{\#\textgreater{} 3 North Central        5577250.}
\CommentTok{\#\textgreater{} 4 West                 5534273.}
\end{Highlighting}
\end{Shaded}

\subsection{Joining data frames: combining information}\label{joining-data-frames-combining-information}

Imagine you have two data frames: one with information about cities (name, population, etc.) and another with information about the states those cities belong to (state name, governor, etc.). If you want to combine information from both data frames to have a single data frame with all information about cities and their states, you can use \texttt{dplyr} join functions.

\texttt{dplyr} offers several functions for joining data frames, such as \texttt{left\_join()}, \texttt{right\_join()}, \texttt{inner\_join()}, and \texttt{full\_join()}. Each function performs a different type of join, depending on how data frame rows are combined.

The \texttt{left\_join()} function joins two data frames keeping all rows from the first data frame (the one on the left) and adding columns from the second data frame that match the first data frame's rows. If a row from the first data frame has no match in the second data frame, new columns will have \texttt{NA} values.

For example, if we have a data frame with city information and another with state information, we can join them by the \texttt{state} column:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_cities\_states }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(df\_cities, df\_states, }\AttributeTok{by =} \StringTok{"state"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The resulting data frame \texttt{df\_cities\_states} will contain information from both data frames combined. If a city in \texttt{df\_cities} does not have a corresponding state in \texttt{df\_states}, columns from \texttt{df\_states} will have \texttt{NA} values for that city.

Let's see a concrete example. Suppose we have the following data frames:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_cities }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{city =} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{, }\StringTok{"Houston"}\NormalTok{),}
  \AttributeTok{state =} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"California"}\NormalTok{, }\StringTok{"Illinois"}\NormalTok{, }\StringTok{"Texas"}\NormalTok{)}
\NormalTok{)}

\NormalTok{df\_states }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{state =} \FunctionTok{c}\NormalTok{(}\StringTok{"California"}\NormalTok{, }\StringTok{"Texas"}\NormalTok{, }\StringTok{"Florida"}\NormalTok{),}
  \AttributeTok{governor =} \FunctionTok{c}\NormalTok{(}\StringTok{"Gavin Newsom"}\NormalTok{, }\StringTok{"Greg Abbott"}\NormalTok{, }\StringTok{"Ron DeSantis"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# Join data frames by "state" column}
\NormalTok{df\_cities\_states }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(df\_cities, df\_states, }\AttributeTok{by =} \StringTok{"state"}\NormalTok{)}

\NormalTok{df\_cities\_states}
\CommentTok{\#\textgreater{}          city      state     governor}
\CommentTok{\#\textgreater{} 1    New York   New York         \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 2 Los Angeles California Gavin Newsom}
\CommentTok{\#\textgreater{} 3     Chicago   Illinois         \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 4     Houston      Texas  Greg Abbott}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{left\_join()} combines \texttt{df\_cities} and \texttt{df\_states} data frames by the \texttt{state} column. Note that ``New York'' and ``Chicago'' cities have \texttt{NA} values in the \texttt{governor} column, since their states (``New York'' and ``Illinois'') are not present in the \texttt{df\_states} data frame.

The other join functions (\texttt{right\_join()}, \texttt{inner\_join()}, and \texttt{full\_join()}) work similarly, but with different criteria for combining data frame rows.

The other join functions work similarly but with different inclusion criteria. \texttt{right\_join()} does the opposite of \texttt{left\_join()}, keeping all rows from the right data frame and only matching rows from the left. \texttt{inner\_join()} is more restrictive, keeping only rows that have matches in both tables, while \texttt{full\_join()} is the most inclusive, retaining all rows from both data frames and filling in \texttt{NA} where no match exists.

You can consult \texttt{dplyr} documentation for more information about these functions.

\subsection{Examples}\label{examples-1}

The \texttt{dplyr} functions we have seen allow us to perform complex data transformations to answer specific questions about our move to the United States. Let's see some examples with R code:

\textbf{Examples of analysis questions}

We can combine these tools to answer specific questions. To find suitable locations, we might filtered for cities with a ``Good'' education system and a cost of living index below 2.5. Alternatively, to study economic prosperity, we could sort states by their GDP per capita (calculated as GDP divided by population) in descending order. For a more comprehensive climate analysis, we could join our city data with a separate climate table.

With these tools, you will be able to explore and analyze information about the United States to make the best decision about your move.

\section{Exercises}\label{exercises-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{24}
\tightlist
\item
  Report the state abbreviation \texttt{abb} and population \texttt{population} columns from the \texttt{murders} data frame
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(abb, population)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{25}
\tightlist
\item
  Report all data frame data that are not from the South region.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(region }\SpecialCharTok{!=} \StringTok{"South"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
If we want to filter all records that are from the South and West region we will use \texttt{\%in\%} instead of \texttt{==} to compare versus a vector
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{26}
\tightlist
\item
  Create the vector \texttt{south\_and\_west} containing values ``South'' and ``West''. Then filter records that are from those two regions.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{south\_and\_west }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"South"}\NormalTok{, }\StringTok{"West"}\NormalTok{)}
  
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(region }\SpecialCharTok{\%in\%}\NormalTok{ south\_and\_west)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{27}
\tightlist
\item
  Add the \texttt{ratio} column to the \texttt{murders} data frame with the murder ratio per 100,000 inhabitants. Then, filter those with a ratio less than 0.5 and are from ``South'' and ``West'' regions. Report \texttt{state}, \texttt{abb}, and \texttt{ratio} columns.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(murders)}

\NormalTok{south\_and\_west }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"South"}\NormalTok{, }\StringTok{"West"}\NormalTok{)}
  
\NormalTok{murders }\OtherTok{\textless{}{-}}\NormalTok{ murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{*}\DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(ratio }\SpecialCharTok{\textless{}} \FloatTok{0.5} \SpecialCharTok{\&}\NormalTok{ region }\SpecialCharTok{\%in\%}\NormalTok{ south\_and\_west) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(state, abb, ratio)}

\NormalTok{murders}
\end{Highlighting}
\end{Shaded}

\begin{quote}
To sort using pipeline we use the \texttt{arrange(x)} function, where \texttt{x} is the name of the column we want to take as reference which will sort in ascending order or \texttt{arrange(desc(x))} to sort in descending order.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{28}
\tightlist
\item
  Modify the code generated in the previous exercise to sort the result by the \texttt{ratio} field.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(murders)}

\NormalTok{south\_and\_west }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"South"}\NormalTok{, }\StringTok{"West"}\NormalTok{)}
  
\NormalTok{murders }\OtherTok{\textless{}{-}}\NormalTok{ murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{*}\DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(ratio }\SpecialCharTok{\textless{}} \FloatTok{0.5} \SpecialCharTok{\&}\NormalTok{ region }\SpecialCharTok{\%in\%}\NormalTok{ south\_and\_west) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(state, abb, ratio) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(ratio)}

\NormalTok{murders}
\end{Highlighting}
\end{Shaded}

So, finally we can know what state options we have to be able to move and solve the presented case.

\section{Data frames in plots}\label{data-frames-in-plots}

Now we will see some functions that allow us to visualize our data. Little by little we will build more complex and visually more aesthetic graphs to present. First let's see the most basic functions R presents us. In the next chapter we will see in more detail graph types and in which situations it is recommended to use one or another graph.

\subsection{Scatter plots}\label{scatter-plots}

One of the most used plots in R is the scatter plot, which is a type of mathematical diagram using Cartesian coordinates to show values for two variables for a set of data \citep[pp.~492]{jarrell1994}. By default we assume the variables to analyze are independent. Thus, the scatter plot will show the degree of correlation (not causality) between the two variables.

The simplest way to plot a scatter plot is with the \texttt{plot(x,y)} function, where \texttt{x} and \texttt{y} are vectors indicating the \emph{x-axis} coordinates and \emph{y-axis} coordinates of each point we want to plot. For example, let's see the relationship between population size and total murders.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Let\textquotesingle{}s store population data in the x\_axis object}
\NormalTok{x\_axis }\OtherTok{\textless{}{-}}\NormalTok{ murders}\SpecialCharTok{$}\NormalTok{population}

\CommentTok{\# Let\textquotesingle{}s store total murders data in the y\_axis object}
\NormalTok{y\_axis }\OtherTok{\textless{}{-}}\NormalTok{ murders}\SpecialCharTok{$}\NormalTok{total}

\CommentTok{\# With this code we create the scatter plot}
\FunctionTok{plot}\NormalTok{(x\_axis, y\_axis)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-168-1} \end{center}

We can see a correlation between population and number of cases. Let's transform the \texttt{x\_axis} dividing by one million (\({10}^6\)). Thus we will have the x axis expressed in millions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_axis }\OtherTok{\textless{}{-}}\NormalTok{ murders}\SpecialCharTok{$}\NormalTok{population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}
\NormalTok{y\_axis }\OtherTok{\textless{}{-}}\NormalTok{ murders}\SpecialCharTok{$}\NormalTok{total}

\FunctionTok{plot}\NormalTok{(x\_axis, y\_axis)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-169-1} \end{center}

\subsection{Histograms}\label{histograms}

We can also create histograms from a vector with the \texttt{hist} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(murders)}

\NormalTok{murders }\OtherTok{\textless{}{-}}\NormalTok{ murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{*}\DecValTok{100000}\NormalTok{)}

\FunctionTok{hist}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{ratio)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-170-1} \end{center}

The ease R gives us to create graphs will save us time for analysis. From here we can quickly see that most states have a \texttt{ratio\ \textless{}\ 5}.

\subsection{Box plot}\label{box-plot}

Finally, R allows us to create box plots easily with the \texttt{boxplot} function. So, if we wanted to analyze the distribution of \texttt{ratio} we would use the following code:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{ratio)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-171-1} \end{center}

\section{Data interpretation}\label{data-interpretation}

We have seen graphs that can be generated with a line of code, but we need to interpret them. To do so, we need to learn or remember some statistics. Throughout this book we will learn statistical concepts not going deep into the math part, but from the practical part and leveraging that functions already exist in R.

Let's remember our case/problem. We have a list of murders in each of the 51 states. If we order them by the total column we would have:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{arrange}\NormalTok{(total) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}           state abb        region population total     ratio}
\CommentTok{\#\textgreater{} 1       Vermont  VT     Northeast     625741     2 0.3196211}
\CommentTok{\#\textgreater{} 2  North Dakota  ND North Central     672591     4 0.5947151}
\CommentTok{\#\textgreater{} 3 New Hampshire  NH     Northeast    1316470     5 0.3798036}
\CommentTok{\#\textgreater{} 4       Wyoming  WY          West     563626     5 0.8871131}
\CommentTok{\#\textgreater{} 5        Hawaii  HI          West    1360301     7 0.5145920}
\CommentTok{\#\textgreater{} 6  South Dakota  SD North Central     814180     8 0.9825837}
\end{Highlighting}
\end{Shaded}

R provides us with the \texttt{summary()} function, which gives us a summary of a vector's data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}
\CommentTok{\#\textgreater{}    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. }
\CommentTok{\#\textgreater{}     2.0    24.5    97.0   184.4   268.0  1257.0}
\end{Highlighting}
\end{Shaded}

The summary provides key insights: the \textbf{Min} and \textbf{Max} show the range of the data; the \textbf{1st Qu} (first quartile) and \textbf{3rd Qu} (third quartile) indicate the 25th and 75th percentiles; the \textbf{Median} marks the exact middle of the distribution; and the \textbf{Mean} gives the arithmetic average.

\subsection{Quartiles}\label{quartiles}

To understand quartiles let's visualize total data in an ordered way. To only obtain a single column in pipeline we will use \texttt{.\$} before the variable name:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{arrange}\NormalTok{(total) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{(total)}
\CommentTok{\#\textgreater{}  [1]    2    4    5    5    7    8   11   12   12   16   19   21   22   27   32}
\CommentTok{\#\textgreater{} [16]   36   38   53   63   65   67   84   93   93   97   97   99  111  116  118}
\CommentTok{\#\textgreater{} [31]  120  135  142  207  219  232  246  250  286  293  310  321  351  364  376}
\CommentTok{\#\textgreater{} [46]  413  457  517  669  805 1257}
\end{Highlighting}
\end{Shaded}

Quartiles divide our vector into 4 parts with the same amount of data. Given we have 51 values, we would have groups of \texttt{51/4\ =\ 12.75}. We would have groups of 13 values (3 groups of 13 elements and one of 12 elements).

For example, the first group would be composed of these numbers:

\begin{verbatim}
#>  [1]  2  4  5  5  7  8 11 12 12 16 19 21 22
\end{verbatim}

The second group would be composed of these numbers:

\begin{verbatim}
#>  [1] 27 32 36 38 53 63 65 67 84 93 93 97 97
\end{verbatim}

And so on. In total 4 groups made up of 25\% of data each.

\subsubsection{First quartile}\label{first-quartile}

Therefore, when we see the 1st quartile, \texttt{1st\ Qu.}, let's think that is the cut indicating up to where I can find 25\% of the data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}
\CommentTok{\#\textgreater{}    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. }
\CommentTok{\#\textgreater{}     2.0    24.5    97.0   184.4   268.0  1257.0}
\end{Highlighting}
\end{Shaded}

In our example \texttt{24.5} indicates that every number less than or equal to that number will be within the first 25\% of data (25\% of 51 data points = 12.75, rounded to 13 data points).

If we list numbers less than or equal to 24.5 we will have this list:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(total) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(total }\SpecialCharTok{\textless{}=} \FloatTok{24.5}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{(total)}
\CommentTok{\#\textgreater{}  [1]  2  4  5  5  7  8 11 12 12 16 19 21 22}
\end{Highlighting}
\end{Shaded}

Which is exactly the same list we obtained previously for the first group.

\subsubsection{Second quartile or median}\label{second-quartile-or-median}

The second quartile, also called the median (\texttt{Median}), indicates the cut of the second group. The first group contains the first 25\% of data, the second group has additional 25\%. So this cut would give us exactly the value found in the middle.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}
\CommentTok{\#\textgreater{}    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. }
\CommentTok{\#\textgreater{}     2.0    24.5    97.0   184.4   268.0  1257.0}
\end{Highlighting}
\end{Shaded}

In our example \texttt{97} indicates that below that number we will find 50\% of total data (50\% of 51 data points = 25.5, rounded to 26 data points).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(total) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(total }\SpecialCharTok{\textless{}=} \DecValTok{97}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{(total)}
\CommentTok{\#\textgreater{}  [1]  2  4  5  5  7  8 11 12 12 16 19 21 22 27 32 36 38 53 63 65 67 84 93 93 97}
\CommentTok{\#\textgreater{} [26] 97}
\end{Highlighting}
\end{Shaded}

\subsubsection{Third quartile}\label{third-quartile}

The third quartile is the cut of the third group. Up to the median we already had 50\%, if we add another 25\% of data we would have 75\%.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}
\CommentTok{\#\textgreater{}    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. }
\CommentTok{\#\textgreater{}     2.0    24.5    97.0   184.4   268.0  1257.0}
\end{Highlighting}
\end{Shaded}

In our example \texttt{268} indicates that below that number we will find 75\% of total data (75\% of 51 data points = 38.25, rounded to 38 data points).

\subsection{Interpretation of box plot}\label{interpretation-of-box-plot}

We are now ready to create a box plot with total murders and interpret results.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-182-1} \end{center}

The box starts at value 24.5 (first quartile) and ends at value 268 (third quartile). The thick line represents the median (second quartile), 97 in our example.

Between the first quartile and third quartile (between 24.5 and 97 for our example) we will find 50\% of the data, also called interquartile range or \texttt{IQR}.

Outside the box we see a vertical line upwards and another downwards, showing the range of our data. Outside those lines we see dots which are atypical data very far from the mean, known as \textbf{outliers}.

We can quickly find to which states these extreme data belong if we sort the table descendingly using the \texttt{desc} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(total)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}          state abb        region population total    ratio}
\CommentTok{\#\textgreater{} 1   California  CA          West   37253956  1257 3.374138}
\CommentTok{\#\textgreater{} 2        Texas  TX         South   25145561   805 3.201360}
\CommentTok{\#\textgreater{} 3      Florida  FL         South   19687653   669 3.398069}
\CommentTok{\#\textgreater{} 4     New York  NY     Northeast   19378102   517 2.667960}
\CommentTok{\#\textgreater{} 5 Pennsylvania  PA     Northeast   12702379   457 3.597751}
\CommentTok{\#\textgreater{} 6     Michigan  MI North Central    9883640   413 4.178622}
\end{Highlighting}
\end{Shaded}

We see that in California \texttt{1257} cases were reported. That is one of the extreme data points we see in the box plot.

\subsection{Examples}\label{examples-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create variable \texttt{pop\_log10} and store log base 10 data of population (\texttt{log10()} function). Perform the same log base 10 transformation for total murders and store it in variable \texttt{tot\_log10}. Generate a scatter plot of these two variables.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pop\_log10 }\OtherTok{\textless{}{-}} \FunctionTok{log10}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{population)}
\NormalTok{tot\_log10 }\OtherTok{\textless{}{-}} \FunctionTok{log10}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}

\FunctionTok{plot}\NormalTok{(pop\_log10, tot\_log10)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-184-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a histogram of population in millions (divided by \({10}^6\)).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-185-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Create a box plot of population.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{population)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-186-1} \end{center}

\section{Exercises}\label{exercises-3}

Below, you will find a series of exercises with different levels of difficulty. It is time to put into practice what you have learned in this chapter. Remember you can use \texttt{dplyr} functions like \texttt{filter()}, \texttt{arrange()}, \texttt{mutate()}, \texttt{summarize()}, \texttt{group\_by()} and \texttt{left\_join()} to manipulate data frames.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{29}
\tightlist
\item
  Create a data frame called \texttt{my\_expenses}. It should contain a \texttt{category} factor with levels ``Housing'', ``Transport'', ``Food'', and ``Entertainment'', along with three numeric columns (\texttt{january}, \texttt{february}, \texttt{march}) recording expenses for each category.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_expenses }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{category =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Housing"}\NormalTok{, }\StringTok{"Transport"}\NormalTok{, }\StringTok{"Food"}\NormalTok{, }\StringTok{"Entertainment"}\NormalTok{)),}
  \AttributeTok{january =} \FunctionTok{c}\NormalTok{(}\DecValTok{1500}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{200}\NormalTok{),}
  \AttributeTok{february =} \FunctionTok{c}\NormalTok{(}\DecValTok{1500}\NormalTok{, }\DecValTok{250}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{150}\NormalTok{),}
  \AttributeTok{march =} \FunctionTok{c}\NormalTok{(}\DecValTok{1500}\NormalTok{, }\DecValTok{350}\NormalTok{, }\DecValTok{550}\NormalTok{, }\DecValTok{250}\NormalTok{)}
\NormalTok{)}

\NormalTok{my\_expenses}
\CommentTok{\#\textgreater{}        category january february march}
\CommentTok{\#\textgreater{} 1       Housing    1500     1500  1500}
\CommentTok{\#\textgreater{} 2     Transport     300      250   350}
\CommentTok{\#\textgreater{} 3          Food     500      400   550}
\CommentTok{\#\textgreater{} 4 Entertainment     200      150   250}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{30}
\tightlist
\item
  Use \texttt{head()}, \texttt{tail()}, \texttt{str()} and \texttt{summary()} functions to explore \texttt{my\_expenses} data frame.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(my\_expenses)}
\CommentTok{\#\textgreater{}        category january february march}
\CommentTok{\#\textgreater{} 1       Housing    1500     1500  1500}
\CommentTok{\#\textgreater{} 2     Transport     300      250   350}
\CommentTok{\#\textgreater{} 3          Food     500      400   550}
\CommentTok{\#\textgreater{} 4 Entertainment     200      150   250}
\FunctionTok{tail}\NormalTok{(my\_expenses)}
\CommentTok{\#\textgreater{}        category january february march}
\CommentTok{\#\textgreater{} 1       Housing    1500     1500  1500}
\CommentTok{\#\textgreater{} 2     Transport     300      250   350}
\CommentTok{\#\textgreater{} 3          Food     500      400   550}
\CommentTok{\#\textgreater{} 4 Entertainment     200      150   250}
\FunctionTok{str}\NormalTok{(my\_expenses)}
\CommentTok{\#\textgreater{} \textquotesingle{}data.frame\textquotesingle{}:    4 obs. of  4 variables:}
\CommentTok{\#\textgreater{}  $ category: Factor w/ 4 levels "Entertainment",..: 3 4 2 1}
\CommentTok{\#\textgreater{}  $ january : num  1500 300 500 200}
\CommentTok{\#\textgreater{}  $ february: num  1500 250 400 150}
\CommentTok{\#\textgreater{}  $ march   : num  1500 350 550 250}
\FunctionTok{summary}\NormalTok{(my\_expenses)}
\CommentTok{\#\textgreater{}           category    january        february        march       }
\CommentTok{\#\textgreater{}  Entertainment:1   Min.   : 200   Min.   : 150   Min.   : 250.0  }
\CommentTok{\#\textgreater{}  Food         :1   1st Qu.: 275   1st Qu.: 225   1st Qu.: 325.0  }
\CommentTok{\#\textgreater{}  Housing      :1   Median : 400   Median : 325   Median : 450.0  }
\CommentTok{\#\textgreater{}  Transport    :1   Mean   : 625   Mean   : 575   Mean   : 662.5  }
\CommentTok{\#\textgreater{}                    3rd Qu.: 750   3rd Qu.: 675   3rd Qu.: 787.5  }
\CommentTok{\#\textgreater{}                    Max.   :1500   Max.   :1500   Max.   :1500.0}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{31}
\tightlist
\item
  Access \texttt{february} column of \texttt{my\_expenses} data frame using \texttt{\$} operator. Then, access the second row of the data frame using brackets.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_expenses}\SpecialCharTok{$}\NormalTok{february}
\CommentTok{\#\textgreater{} [1] 1500  250  400  150}
\NormalTok{my\_expenses[}\DecValTok{2}\NormalTok{, ]}
\CommentTok{\#\textgreater{}    category january february march}
\CommentTok{\#\textgreater{} 2 Transport     300      250   350}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{32}
\tightlist
\item
  Filter \texttt{my\_expenses} data frame to get only rows where expenses in \texttt{january} are greater than 400.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_expenses }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(january }\SpecialCharTok{\textgreater{}} \DecValTok{400}\NormalTok{)}
\CommentTok{\#\textgreater{}   category january february march}
\CommentTok{\#\textgreater{} 1  Housing    1500     1500  1500}
\CommentTok{\#\textgreater{} 2     Food     500      400   550}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{33}
\tightlist
\item
  Sort \texttt{my\_expenses} data frame descendingly by expenses in \texttt{march}.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_expenses }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(march))}
\CommentTok{\#\textgreater{}        category january february march}
\CommentTok{\#\textgreater{} 1       Housing    1500     1500  1500}
\CommentTok{\#\textgreater{} 2          Food     500      400   550}
\CommentTok{\#\textgreater{} 3     Transport     300      250   350}
\CommentTok{\#\textgreater{} 4 Entertainment     200      150   250}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{34}
\tightlist
\item
  Add a column called \texttt{total} to \texttt{my\_expenses} data frame containing the sum of January, February, and March expenses for each category.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_expenses }\OtherTok{\textless{}{-}}\NormalTok{ my\_expenses }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{total =}\NormalTok{ january }\SpecialCharTok{+}\NormalTok{ february }\SpecialCharTok{+}\NormalTok{ march)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{35}
\tightlist
\item
  Calculate mean and standard deviation of total expenses for each category in \texttt{my\_expenses} data frame.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_expenses }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean\_total =} \FunctionTok{mean}\NormalTok{(total), }
            \AttributeTok{std\_total =} \FunctionTok{sd}\NormalTok{(total))}
\CommentTok{\#\textgreater{}   mean\_total std\_total}
\CommentTok{\#\textgreater{} 1     1862.5  1793.216}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{36}
\tightlist
\item
  Group \texttt{my\_expenses} data frame by category and calculate sum of expenses for each month.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_expenses }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(category) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sum\_january =} \FunctionTok{sum}\NormalTok{(january), }
            \AttributeTok{sum\_february =} \FunctionTok{sum}\NormalTok{(february), }
            \AttributeTok{sum\_march =} \FunctionTok{sum}\NormalTok{(march))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 4}
\CommentTok{\#\textgreater{}   category      sum\_january sum\_february sum\_march}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}               \textless{}dbl\textgreater{}        \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Entertainment         200          150       250}
\CommentTok{\#\textgreater{} 2 Food                  500          400       550}
\CommentTok{\#\textgreater{} 3 Housing              1500         1500      1500}
\CommentTok{\#\textgreater{} 4 Transport             300          250       350}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{37}
\tightlist
\item
  Visually analyze the following chart describing total murder distribution by regions. Just by visualizing it, could you point out which region has the smallest data range, ignoring outliers? Which region has the highest median?
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-204-1} \end{center}

Solution

West has the smallest data range and has two outliers. South has the highest median among all regions.

Analyzing solely by seeing a chart allows us to put ourselves in the final observer's shoes and understand if decisions can be made just with presented information.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{38}
\tightlist
\item
  Create \texttt{south} vector where you store filtered data of total murders occurred in South region. Then, create a histogram of \texttt{south} vector.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{south }\OtherTok{\textless{}{-}}\NormalTok{ murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(region }\SpecialCharTok{==} \StringTok{"South"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{(total)}

\FunctionTok{hist}\NormalTok{(south)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{39}
\tightlist
\item
  Create a new data frame called \texttt{df\_cities\_climate} combining information from \texttt{df\_cities} and \texttt{df\_climate} (you must create \texttt{df\_climate} data frame with city climate information). Ensure resulting data frame contains all cities from \texttt{df\_cities}, even if they don't have climate information in \texttt{df\_climate}.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_climate }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{city =} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"Los Angeles"}\NormalTok{, }\StringTok{"Chicago"}\NormalTok{),}
  \AttributeTok{average\_temperature =} \FunctionTok{c}\NormalTok{(}\FloatTok{12.8}\NormalTok{, }\FloatTok{17.7}\NormalTok{, }\FloatTok{10.7}\NormalTok{),  }\CommentTok{\# In degrees Celsius}
  \AttributeTok{annual\_precipitation =} \FunctionTok{c}\NormalTok{(}\DecValTok{1269}\NormalTok{, }\DecValTok{373}\NormalTok{, }\DecValTok{965}\NormalTok{)  }\CommentTok{\# In millimeters}
\NormalTok{)}

\NormalTok{df\_cities\_climate }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(df\_cities, df\_climate, }\AttributeTok{by =} \StringTok{"city"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{40}
\tightlist
\item
  Create a data frame with some missing values (\texttt{NA}). Then, replace missing values with mean of non-missing values in same column.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create data frame with missing values}
\NormalTok{df\_with\_na }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{),}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{)}

\NormalTok{df\_with\_na}
\CommentTok{\#\textgreater{}    x  y}
\CommentTok{\#\textgreater{} 1  1 NA}
\CommentTok{\#\textgreater{} 2  2  7}
\CommentTok{\#\textgreater{} 3 NA  8}
\CommentTok{\#\textgreater{} 4  4 NA}
\CommentTok{\#\textgreater{} 5  5 10}

\CommentTok{\# Replace missing values with mean}
\NormalTok{df\_with\_na }\OtherTok{\textless{}{-}}\NormalTok{ df\_with\_na }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{x =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(x), }\FunctionTok{mean}\NormalTok{(x, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{), x),}
         \AttributeTok{y =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(y), }\FunctionTok{mean}\NormalTok{(y, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{), y))}

\NormalTok{df\_with\_na}
\CommentTok{\#\textgreater{}   x         y}
\CommentTok{\#\textgreater{} 1 1  8.333333}
\CommentTok{\#\textgreater{} 2 2  7.000000}
\CommentTok{\#\textgreater{} 3 3  8.000000}
\CommentTok{\#\textgreater{} 4 4  8.333333}
\CommentTok{\#\textgreater{} 5 5 10.000000}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{41}
\tightlist
\item
  Create a function called \texttt{clean\_data\_frame()} receiving a data frame as argument and replacing missing values with mean of non-missing values in each column.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clean\_data\_frame }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df) \{}
  \ControlFlowTok{for}\NormalTok{ (col }\ControlFlowTok{in} \FunctionTok{names}\NormalTok{(df)) \{}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.numeric}\NormalTok{(df[[col]])) \{}
\NormalTok{      df[[col]] }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(df[[col]]), }\FunctionTok{mean}\NormalTok{(df[[col]], }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{), df[[col]])}
\NormalTok{    \}}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(df)}
\NormalTok{\}}

\DocumentationTok{\#\# Test created function}
\CommentTok{\# Create data frame with missing values to test function}
\NormalTok{df\_test }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{age =} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{30}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{35}\NormalTok{),}
  \AttributeTok{height =} \FunctionTok{c}\NormalTok{(}\FloatTok{1.75}\NormalTok{, }\FloatTok{1.80}\NormalTok{, }\FloatTok{1.65}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\FloatTok{1.70}\NormalTok{),}
  \AttributeTok{weight =} \FunctionTok{c}\NormalTok{(}\DecValTok{70}\NormalTok{, }\DecValTok{80}\NormalTok{, }\DecValTok{75}\NormalTok{, }\DecValTok{65}\NormalTok{, }\ConstantTok{NA}\NormalTok{)}
\NormalTok{)}

\NormalTok{df\_test}
\CommentTok{\#\textgreater{}   age height weight}
\CommentTok{\#\textgreater{} 1  25   1.75     70}
\CommentTok{\#\textgreater{} 2  30   1.80     80}
\CommentTok{\#\textgreater{} 3  NA   1.65     75}
\CommentTok{\#\textgreater{} 4  28     NA     65}
\CommentTok{\#\textgreater{} 5  35   1.70     NA}

\CommentTok{\# Apply function to test data frame}
\NormalTok{df\_clean }\OtherTok{\textless{}{-}} \FunctionTok{clean\_data\_frame}\NormalTok{(df\_test)}

\CommentTok{\# Show clean data frame}
\NormalTok{df\_clean}
\CommentTok{\#\textgreater{}    age height weight}
\CommentTok{\#\textgreater{} 1 25.0  1.750   70.0}
\CommentTok{\#\textgreater{} 2 30.0  1.800   80.0}
\CommentTok{\#\textgreater{} 3 29.5  1.650   75.0}
\CommentTok{\#\textgreater{} 4 28.0  1.725   65.0}
\CommentTok{\#\textgreater{} 5 35.0  1.700   72.5}
\end{Highlighting}
\end{Shaded}

\chapter{Advanced Techniques}\label{advanced-techniques}

\section{Metaprogramming: writing code that writes code}\label{metaprogramming-writing-code-that-writes-code}

In previous chapters, we explored different object types in R and how to use functions to manipulate them. Now, we are going to delve into a more advanced concept: \textbf{metaprogramming}.

Metaprogramming is a technique that allows us to write code that generates other code. It's like having a code factory where we can create new functions and expressions dynamically.

Why is this useful? Metaprogramming can be very useful for:

Metaprogramming is incredibly useful for \textbf{automating repetitive tasks}, allowing us to generate boilerplate code dynamically. It also enables us to create \textbf{more flexible functions} that adapt to different data structures, and facilitates \textbf{writing concise, expressive code} that captures complex logic simply.

In R, metaprogramming is based on the manipulation of \textbf{expressions}. An expression is a representation of R code as an object. We can create expressions, modify them, and evaluate them to generate new code.

\subsection{Manipulating expressions: The art of sculpting code}\label{manipulating-expressions-the-art-of-sculpting-code}

In R, metaprogramming relies on manipulating \textbf{expressions}. An expression is a representation of R code as an object. Instead of simply executing the code, we can manipulate it as if it were a block of clay, shaping and modifying it to create new expressions and functions.

Think of an expression like a cooking recipe. The recipe contains a set of instructions (ingredients and steps to follow) to create a dish. Similarly, an expression in R contains instructions to perform a task.

R offers us several tools to manipulate expressions, as if they were the hands of a sculptor shaping clay:

R provides a toolkit for sculpting expressions. The \texttt{quote()} function captures code as an expression without running it, like saving a recipe for later. \texttt{substitute()} allows you to inject values into an expression, replacing placeholders with actual variables. To execute these stored expressions, we use \texttt{eval()}, which runs the code and returns the result. Finally, \texttt{parse()} can turn text strings directly into executable expressions.

With these tools, we can manipulate expressions to create new functions, modify the behavior of existing functions, and generate code dynamically.

\subsection{Examples}\label{examples-3}

Metaprogramming might seem like an abstract concept at first, but its applications are very concrete and powerful. Let's look at some examples of how we can use metaprogramming in R to create dynamic functions and generate code automatically.

\textbf{Example 1: Creating a function that generates other functions}

Imagine you need to create several functions performing similar operations, but with some different parameters. For example, functions adding different constants to a number. Instead of writing each function separately, you can use metaprogramming to create a function that generates these functions dynamically.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{create\_sum\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
\NormalTok{  expression }\OtherTok{\textless{}{-}} \FunctionTok{substitute}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) x }\SpecialCharTok{+}\NormalTok{ n)}
  \FunctionTok{eval}\NormalTok{(expression)}
\NormalTok{\}}

\NormalTok{sum\_5 }\OtherTok{\textless{}{-}} \FunctionTok{create\_sum\_function}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\NormalTok{sum\_10 }\OtherTok{\textless{}{-}} \FunctionTok{create\_sum\_function}\NormalTok{(}\DecValTok{10}\NormalTok{)}

\FunctionTok{sum\_5}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 15}
\FunctionTok{sum\_10}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 20}
\end{Highlighting}
\end{Shaded}

In this example, the \texttt{create\_sum\_function()} function receives a number \texttt{n} as an argument and generates a new function adding \texttt{n} to its argument. The \texttt{substitute()} function is used to create an expression representing the function we want to generate, and the \texttt{eval()} function is used to evaluate the expression and create the function.

\textbf{Example 2: Generating code for data analysis}

Suppose you want to perform a data analysis involving several steps, such as filtering data, calculating statistics, and generating a plot. You can use metaprogramming to generate the code for this analysis dynamically, based on specified parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{analyze\_data }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, filter\_cond, column\_to\_analyze, statistic, plot\_type) \{}
  
  \CommentTok{\# Filter data}
\NormalTok{  filtered\_data }\OtherTok{\textless{}{-}} \FunctionTok{substitute}\NormalTok{(data[filter\_cond, ][[column\_to\_analyze]])}
  
\NormalTok{  filtered\_data }\OtherTok{\textless{}{-}} \FunctionTok{eval}\NormalTok{(filtered\_data)}
  
  \CommentTok{\# Calculate statistic}
\NormalTok{  calculated\_statistic }\OtherTok{\textless{}{-}} \FunctionTok{substitute}\NormalTok{(}\FunctionTok{statistic}\NormalTok{(filtered\_data))}
\NormalTok{  calculated\_statistic }\OtherTok{\textless{}{-}} \FunctionTok{eval}\NormalTok{(calculated\_statistic)}
  
  \CommentTok{\# Generate plot}
\NormalTok{  plot\_expression }\OtherTok{\textless{}{-}} \FunctionTok{substitute}\NormalTok{(}\FunctionTok{plot\_type}\NormalTok{(filtered\_data))}
  \FunctionTok{eval}\NormalTok{(plot\_expression)}
  
  \CommentTok{\# Return calculated statistic}
  \FunctionTok{return}\NormalTok{(calculated\_statistic)}
\NormalTok{\}}

\CommentTok{\# Usage example}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{5.5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\FloatTok{3.5}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{),}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{3.6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# We want to filter data where x \textgreater{} 5, calculate mean of y and generate a histogram}
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{analyze\_data}\NormalTok{(df, df}\SpecialCharTok{$}\NormalTok{x }\SpecialCharTok{\textgreater{}} \DecValTok{5}\NormalTok{, }\StringTok{"y"}\NormalTok{, mean, hist)}

\NormalTok{result}
\CommentTok{\#\textgreater{} [1] 3.32}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-215-1} \end{center}

\textbf{Example 3: Creating a function to generate plots with dynamic variable names and advanced options}

Imagine you need to create a function generating different types of plots (scatter, histograms, boxplots) with custom options like titles, labels, colors, and legends, and that can also handle different datasets and variables. In this case, metaprogramming can be very useful to create a flexible function adapting to these needs.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{create\_plot }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, plot\_type, var\_x, }\AttributeTok{var\_y =} \ConstantTok{NULL}\NormalTok{, }
                          \AttributeTok{title =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }
                          \AttributeTok{labels\_x =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{labels\_y =} \ConstantTok{NULL}\NormalTok{, }
                          \AttributeTok{legend =} \ConstantTok{NULL}\NormalTok{) \{}
  
  \CommentTok{\# Create base plot expression}
  \ControlFlowTok{if}\NormalTok{ (plot\_type }\SpecialCharTok{==} \StringTok{"scatter"}\NormalTok{) \{}
\NormalTok{    expression }\OtherTok{\textless{}{-}} \FunctionTok{substitute}\NormalTok{(}\FunctionTok{plot}\NormalTok{(data[[var\_x]], data[[var\_y]], }
                                 \AttributeTok{xlab =}\NormalTok{ labels\_x, }\AttributeTok{ylab =}\NormalTok{ labels\_y,}
                                 \AttributeTok{main =}\NormalTok{ title, }\AttributeTok{col =}\NormalTok{ color))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (plot\_type }\SpecialCharTok{==} \StringTok{"histogram"}\NormalTok{) \{}
\NormalTok{    expression }\OtherTok{\textless{}{-}} \FunctionTok{substitute}\NormalTok{(}\FunctionTok{hist}\NormalTok{(data[[var\_x]], }\AttributeTok{main =}\NormalTok{ title, }\AttributeTok{xlab =}\NormalTok{ labels\_x, }\AttributeTok{col =}\NormalTok{ color))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (plot\_type }\SpecialCharTok{==} \StringTok{"boxplot"}\NormalTok{) \{}
\NormalTok{    expression }\OtherTok{\textless{}{-}} \FunctionTok{substitute}\NormalTok{(}\FunctionTok{boxplot}\NormalTok{(data[[var\_x]], }\AttributeTok{main =}\NormalTok{ title, }\AttributeTok{ylab =}\NormalTok{ labels\_y, }\AttributeTok{col =}\NormalTok{ color))}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{stop}\NormalTok{(}\StringTok{"Invalid plot type."}\NormalTok{)}
\NormalTok{  \}}
  
  \CommentTok{\# Evaluate base expression}
  \FunctionTok{eval}\NormalTok{(expression)}
  
  \CommentTok{\# Add legend if specified}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(legend)) \{}
    \FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =}\NormalTok{ legend, }\AttributeTok{fill =}\NormalTok{ color)}
\NormalTok{  \}}
\NormalTok{\}}

\CommentTok{\# Usage example}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{5.5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\FloatTok{3.5}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{),}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{3.6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{)}

\FunctionTok{create\_plot}\NormalTok{(df, }\StringTok{"scatter"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }
              \AttributeTok{title =} \StringTok{"Scatter Plot"}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{, }
              \AttributeTok{labels\_x =} \StringTok{"Variable X"}\NormalTok{, }\AttributeTok{labels\_y =} \StringTok{"Variable Y"}\NormalTok{)}

\FunctionTok{create\_plot}\NormalTok{(df, }\StringTok{"histogram"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }
              \AttributeTok{title =} \StringTok{"Histogram of X"}\NormalTok{, }\AttributeTok{color =} \StringTok{"green"}\NormalTok{, }
              \AttributeTok{labels\_x =} \StringTok{"Variable X"}\NormalTok{)}

\FunctionTok{create\_plot}\NormalTok{(df, }\StringTok{"boxplot"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }
              \AttributeTok{title =} \StringTok{"Boxplot of Y"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }
              \AttributeTok{labels\_y =} \StringTok{"Variable X"}\NormalTok{, }
              \AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Group A"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-216-1} \includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-216-2} \includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-216-3} \end{center}

In this example, the \texttt{create\_plot()} function can generate different types of plots with custom options. The function uses \texttt{substitute()} to construct the base plot expression, and then \texttt{eval()} to evaluate the expression and generate the plot. Additionally, the function can add a legend to the plot if the legend argument is specified.

This example illustrates how metaprogramming can be useful for creating more flexible and complex functions that adapt to different needs.

\section{Functional programming: a new paradigm}\label{functional-programming-a-new-paradigm}

In previous chapters, we explored different object types in R and how to use functions to manipulate them. We have also seen how metaprogramming allows us to write code that generates other code. Now, we are going to delve into a different programming paradigm: \textbf{functional programming}.

Functional programming is a programming style based on the use of \textbf{pure functions} and data \textbf{immutability}.

Functional programming relies on two core concepts: \textbf{pure functions} and \textbf{immutability}. A pure function is consistent and side-effect-free, meaning it always produces the same output for the same input and does not modify any external state. \textbf{Immutability} ensures that data is not changed after creation; instead of modifying an existing object, we create a new one with the desired changes.

These principles make functional programming easier to reason about, debug, and maintain. It also facilitates writing concurrent and parallel code, as pure functions have no side effects that can interfere with other processes.

\subsection{Basic principles of functional programming}\label{basic-principles-of-functional-programming}

Functional programming rests on several pillars. First, \textbf{functions are first-class citizens}, meaning they can be assigned to variables and passed as arguments just like data. Second, it relies on \textbf{pure functions} that produce consistent outputs without side effects. Third, it emphasizes \textbf{immutability}, creating new data rather than modifying existing objects. Finally, it typically \textbf{rejects loops}, facilitating data processing through higher-order functions instead.

\subsection{Higher-order functions in R}\label{higher-order-functions-in-r}

R offers several higher-order functions that are especially useful for functional programming. These functions allow us to manipulate vectors, lists, and other objects concisely and efficiently, avoiding the use of \texttt{for} and \texttt{while} loops. The \texttt{purrr} package offers variants of \texttt{map()} for different types of results: \texttt{map\_dbl()} to get a numeric vector, \texttt{map\_chr()} to get a character vector, \texttt{map\_lgl()} to get a logical vector, etc.

The \texttt{purrr} package provides a robust suite of tools. \texttt{map()} applies a function to each element of a list or vector, returning a new list (or vector with variants like \texttt{map\_dbl}). \texttt{reduce()} performs a cumulative operation, combining elements one by one until a single result remains. \texttt{keep()} acts as a filter, retaining only those elements that satisfy a given condition.

The \texttt{\textasciitilde{}} symbol in higher-order functions is used to define an anonymous function. This means you are creating a function ``on the fly'', without needing to give it an explicit name. The part following \texttt{\textasciitilde{}} is the body of this function, specifying operations to be performed on each element of the vector or list to which the function is applied. The dot \texttt{.} is used as a placeholder to refer to the current element.

These functions, along with other higher-order functions like \texttt{map2()}, \texttt{pmap()}, \texttt{accumulate()}, and \texttt{every()}, give us great flexibility for processing data functionally in R.

\subsection{Examples}\label{examples-4}

Let's see some examples of how to apply functional programming in R:

Let's put these concepts into practice with some concrete examples. First, consider a scenario where we want to \textbf{calculate the sum of squares of even numbers} in a vector.

\begin{verbatim}
``` r
numbers <- c(1, 2, 3, 4, 5)
sum_squares_evens <- numbers |>
  keep(~. %% 2 == 0) |>
  map_dbl(~. ^2) |>
  reduce(`+`)

sum_squares_evens
#> [1] 20
```
\end{verbatim}

For a second example, let's filter a list of cities to find those with a \textbf{population greater than 5 million}.

\begin{verbatim}
``` r
cities <- list(
  list(name = "New York", population = 8.4e6),
  list(name = "Los Angeles", population = 3.9e6),
  list(name = "Chicago", population = 2.7e6)
)

big_cities <- cities |>
  keep(~.x$population > 5e6)

big_cities
#> [[1]]
#> [[1]]$name
#> [1] "New York"
#> 
#> [[1]]$population
#> [1] 8400000
```

In this example, "x" acts as a placeholder to represent each element of the `cities` list as it iterates over it. That is, in each iteration, "x" will take the value of one of the cities in the list.
\end{verbatim}

You might wonder why we use \texttt{.x} in these expressions. This placeholder serves three main purposes. First, it allows us to define an \textbf{anonymous function}---a quick, unnamed function (\texttt{\textasciitilde{}\ .x\$population\ \textgreater{}\ 5e6}) that evaluates whether a city meets our criteria. Second, it provides a way to \textbf{access elements}; the \texttt{.x} represents the current list item, allowing us to grab properties like \texttt{.x\$population}. Finally, it promotes \textbf{conciseness}, enabling us to write compact, readable code without formally defining a separate function for a simple operation. You can technically use other variable names, but \texttt{.x} is the standard convention in \texttt{purrr}.

Functional programming is a powerful paradigm that can help you write cleaner, more efficient, and maintainable code. As you become familiar with its principles and tools, you will be able to apply them to a wide variety of data analysis problems.

\section{R6: The future of OOP in R}\label{r6-the-future-of-oop-in-r}

For advanced Object-Oriented Programming (OOP) using the R6 package, please refer to \hyperref[r6-intro]{Appendix B}.

\section{Exercises}\label{exercises-4}

Below, you will find a series of exercises with different levels of difficulty. It is time to put into practice what you have learned in this chapter.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{42}
\tightlist
\item
  Formulate an expression that represents the sum of two variables, \texttt{a} and \texttt{b}.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{expression }\OtherTok{\textless{}{-}} \FunctionTok{quote}\NormalTok{(a }\SpecialCharTok{+}\NormalTok{ b)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{43}
\tightlist
\item
  Compose an expression for the multiplication of \texttt{x} and \texttt{y}, then execute it to find the result.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{expression }\OtherTok{\textless{}{-}} \FunctionTok{quote}\NormalTok{(x }\SpecialCharTok{*}\NormalTok{ y)}
\FunctionTok{eval}\NormalTok{(expression)}
\CommentTok{\#\textgreater{} [1] 50}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{44}
\tightlist
\item
  Generate a numeric vector and apply the \texttt{map()} function to compute the square of each element.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{squares }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(numbers, }\ControlFlowTok{function}\NormalTok{(x) x}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{squares}
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} [1] 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[2]]}
\CommentTok{\#\textgreater{} [1] 4}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[3]]}
\CommentTok{\#\textgreater{} [1] 9}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[4]]}
\CommentTok{\#\textgreater{} [1] 16}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[5]]}
\CommentTok{\#\textgreater{} [1] 25}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{45}
\tightlist
\item
  Define a vector of numbers and utilize \texttt{keep()} from the \texttt{purrr} package to retain only the even values.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{evens }\OtherTok{\textless{}{-}} \FunctionTok{keep}\NormalTok{(numbers, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{\%\%} \DecValTok{2} \SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\NormalTok{evens}
\CommentTok{\#\textgreater{} [1] 2 4}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{46}
\tightlist
\item
  Build a function named \texttt{create\_power\_function()} that takes a number \texttt{n} and returns a new function capable of raising its input to the power of \texttt{n}.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{create\_power\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
  \ControlFlowTok{function}\NormalTok{(x) x}\SpecialCharTok{\^{}}\NormalTok{n}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{47}
\tightlist
\item
  Construct a numeric vector and apply \texttt{reduce()} to calculate the product of all its elements.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{product }\OtherTok{\textless{}{-}} \FunctionTok{reduce}\NormalTok{(numbers, }\StringTok{\textasciigrave{}}\AttributeTok{*}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{product}
\CommentTok{\#\textgreater{} [1] 120}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{48}
\tightlist
\item
  Design a function \texttt{create\_flexible\_sum\_function()} that accepts a number \texttt{n} and yields a function that adds \texttt{n} to the sum of any arguments passed to it.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{create\_flexible\_sum\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
  \ControlFlowTok{function}\NormalTok{(...) \{}
    \FunctionTok{sum}\NormalTok{(}\FunctionTok{c}\NormalTok{(...)) }\SpecialCharTok{+}\NormalTok{ n}
\NormalTok{  \}}
\NormalTok{\}}

\CommentTok{\# Tests}
\CommentTok{\# Create a function adding 5 to any set of numbers}
\NormalTok{sum\_5 }\OtherTok{\textless{}{-}} \FunctionTok{create\_flexible\_sum\_function}\NormalTok{(}\DecValTok{5}\NormalTok{)}

\CommentTok{\# Usage examples and verification}
\FunctionTok{sum\_5}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 14}

\FunctionTok{sum\_5}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 35}

\FunctionTok{sum\_5}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] 5}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{49}
\tightlist
\item
  Develop a \texttt{create\_dynamic\_plot()} function that takes a data frame, a plot type (``scatter'', ``histogram'', or ``boxplot''), and a list of options (like title and color), generating the requested plot dynamically.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{create\_dynamic\_plot }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, plot\_type, options) \{}
  \CommentTok{\# Create base plot expression}
  \ControlFlowTok{if}\NormalTok{ (plot\_type }\SpecialCharTok{==} \StringTok{"scatter"}\NormalTok{) \{}
\NormalTok{    expression }\OtherTok{\textless{}{-}} \FunctionTok{quote}\NormalTok{(}\FunctionTok{plot}\NormalTok{(data[[options}\SpecialCharTok{$}\NormalTok{var\_x]], data[[options}\SpecialCharTok{$}\NormalTok{var\_y]],}
                            \AttributeTok{xlab =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{labels\_x, }\AttributeTok{ylab =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{labels\_y,}
                            \AttributeTok{main =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{title, }\AttributeTok{col =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{color))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (plot\_type }\SpecialCharTok{==} \StringTok{"histogram"}\NormalTok{) \{}
\NormalTok{    expression }\OtherTok{\textless{}{-}} \FunctionTok{quote}\NormalTok{(}\FunctionTok{hist}\NormalTok{(data[[options}\SpecialCharTok{$}\NormalTok{var\_x]], }
                            \AttributeTok{main =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{title, }
                            \AttributeTok{xlab =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{labels\_x, }\AttributeTok{col =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{color))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (plot\_type }\SpecialCharTok{==} \StringTok{"boxplot"}\NormalTok{) \{}
\NormalTok{    expression }\OtherTok{\textless{}{-}} \FunctionTok{quote}\NormalTok{(}\FunctionTok{boxplot}\NormalTok{(data[[options}\SpecialCharTok{$}\NormalTok{var\_x]], }
                               \AttributeTok{main =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{title, }
                               \AttributeTok{ylab =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{labels\_y, }\AttributeTok{col =}\NormalTok{ options}\SpecialCharTok{$}\NormalTok{color))}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{stop}\NormalTok{(}\StringTok{"Invalid plot type."}\NormalTok{)}
\NormalTok{  \}}
  
  \CommentTok{\# Evaluate base expression}
  \FunctionTok{eval}\NormalTok{(expression)}
\NormalTok{\}}

\CommentTok{\# Create sample data}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{), }\AttributeTok{y =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{))}

\CommentTok{\# Tests}
\CommentTok{\# Scatter plot}
\NormalTok{options\_scatter }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{var\_x =} \StringTok{"x"}\NormalTok{, }\AttributeTok{var\_y =} \StringTok{"y"}\NormalTok{,}
                            \AttributeTok{title =} \StringTok{"Scatter Plot"}\NormalTok{,}
                            \AttributeTok{labels\_x =} \StringTok{"Variable X"}\NormalTok{,}
                            \AttributeTok{labels\_y =} \StringTok{"Variable Y"}\NormalTok{,}
                            \AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}
\FunctionTok{create\_dynamic\_plot}\NormalTok{(data, }\StringTok{"scatter"}\NormalTok{, options\_scatter)}

\CommentTok{\# Histogram}
\NormalTok{options\_histogram }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{var\_x =} \StringTok{"x"}\NormalTok{,}
                            \AttributeTok{title =} \StringTok{"Histogram"}\NormalTok{,}
                            \AttributeTok{labels\_x =} \StringTok{"Values"}\NormalTok{,}
                            \AttributeTok{color =} \StringTok{"green"}\NormalTok{)}
\FunctionTok{create\_dynamic\_plot}\NormalTok{(data, }\StringTok{"histogram"}\NormalTok{, options\_histogram)}

\CommentTok{\# Boxplot}
\NormalTok{options\_boxplot }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{var\_x =} \StringTok{"y"}\NormalTok{,}
                         \AttributeTok{title =} \StringTok{"Boxplot"}\NormalTok{,}
                         \AttributeTok{labels\_y =} \StringTok{"Values"}\NormalTok{,}
                         \AttributeTok{color =} \StringTok{"red"}\NormalTok{)}
\FunctionTok{create\_dynamic\_plot}\NormalTok{(data, }\StringTok{"boxplot"}\NormalTok{, options\_boxplot)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-234-1} \includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-234-2} \includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-234-3} \end{center}

\part{Data Visualization and Summarization}\label{part-data-visualization-and-summarization}

\chapter{Ggplot and dplyr}\label{ggplot-and-dplyr}

\textbf{Learning Objectives:}

In this chapter, we will master the art of data storytelling. We will learn to create layered visualizations using \texttt{ggplot2}, customizing every aspect from aesthetics and scales to themes and labels. Additionally, we will gain proficiency in summarizing data with \texttt{dplyr} functions like \texttt{summarize()} and \texttt{group\_by()}, all while deepening our understanding of the grammar of graphics approach.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Building on the basic plotting skills from previous chapters, we'll now create more sophisticated and visually polished visualizations. The \texttt{ggplot2} package provides a powerful and consistent framework for building graphics layer by layer.

To get started, we'll use the \texttt{ggplot} object included in the \texttt{tidyverse} library (the \texttt{tidyverse} package includes \texttt{ggplot2} among its core packages). Since we've already installed \texttt{tidyverse} previously, we only need to load it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

We'll learn these visualization techniques using our previous case/problem, allowing us to build up our \texttt{ggplot} skills gradually with familiar data.

\section{Creating the ggplot object}\label{creating-the-ggplot-object}

We will start by creating the \texttt{ggplot} object from the \texttt{murders} data using the pipeline operator \texttt{\textbar{}\textgreater{}}. Let's also remember to have loaded the \texttt{murders} data from the \texttt{dslabs} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dslabs)}
\FunctionTok{data}\NormalTok{(murders)}

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-237-1} \end{center}

This code only shows us an empty box. This is because we haven't specified which variables to take from the data frame nor what type of plot we want.

To build our plot, we'll add components using \emph{layers}. The \texttt{ggplot} system allows us to add one layer at a time, each specifying a different aspect of the visualization. We connect layers using the \texttt{+} operator.

\section{Aesthetic mapping layer}\label{aesthetic-mapping-layer}

First we will focus on the basic aesthetics, that is: what goes on the \emph{\textbf{x-axis}} and what we put on the \emph{\textbf{y-axis}}. To do this we will use the aesthetic function which in R is \texttt{aes()}. For example, let's add the \texttt{population} data on the \emph{x-axis} and the \texttt{total} data on the \emph{y-axis}. We don't have to use the \texttt{\$} accessor because the \texttt{aes} function takes the \texttt{murders} table before the pipeline as a reference.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-238-1} \end{center}

Now we have a box with the axes marked, but still without any data inside the box.

\section{Geoms layer}\label{geoms-layer}

Let's add one more layer that indicates what type of plot we want. To do this we will use the so-called \textbf{geoms}. There are different types of geoms. For example, a scatter plot is shown with points, therefore we will use the \texttt{geom\_point()} function. For more detail we can see the documentation of \texttt{geom\_point()} \href{https://ggplot2.tidyverse.org/reference/geom_point.html}{here}.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-239-1} \end{center}

In the same way, we can show lines connecting the data instead of points with the \texttt{geom\_line()} function.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-240-1} \end{center}

Up to this point we have created the same scatter plot that we saw in the previous chapter. The power of ggplot lies in the ease of adding components. For example, to label each point with the state abbreviation (\texttt{abb}), we simply add it as a \texttt{label} attribute inside \texttt{aes} and include the \texttt{geom\_text()} layer.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-241-1} \end{center}

In this plot we can already see that the upper right point corresponds to \textbf{CA} which is the abbreviation for the state of \textbf{California}.

\subsection{Tweaking aes and geoms}\label{tweaking-aes-and-geoms}

We can tweak our plots in multiple ways by adding attributes to our functions.

For example, if we want to identify which region each point belongs to (if it is from the US North, South, etc.) we would have to edit \texttt{aes()} and make \texttt{color} take into account the \texttt{region} variable as follows:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-242-1} \end{center}

Then, we can also edit the attributes of the \texttt{geoms}. For example, let's make the size of the points larger. To do this we edit inside \texttt{geom\_points()}:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-243-1} \end{center}

Having increased the size of the points, we can no longer see the text of the state abbreviations well. We can nudge the text on the \emph{x-axis} or on the \emph{y-axis}. Since we are talking about several million people, let's nudge the letters 1.5 million to the right.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \DecValTok{1500000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-244-1} \end{center}

To avoid entering such large numbers we can transform the population on the x-axis in the \texttt{aes()} function. Thus, once we express the data without counting the millions we would have to nudge the text only 1.5 points to the right:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-245-1} \end{center}

This transformation gives us the same result as before and the \emph{x-axis} is now easier to understand now that we can see the numbers.

\section{Scale layer}\label{scale-layer}

Visually we can still improve our plot further. We see several data points concentrated in lower values and only a few extremes. In those cases it is better to have a view scaling the axes using logarithms. To do this, we will use the layers \texttt{scale\_x\_continuous()} and \texttt{scale\_y\_continuous()}. For example, if we want to transform the scale to base 2 logarithm we would have to add layers, but also change the value of \texttt{nudge\_x}, due to the scale change:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.23}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-246-1} \end{center}

In the same way, we could do the transformation to base 10 logarithm:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.075}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log10"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log10"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-247-1} \end{center}

The transformation of the scale to base 10 logarithm is widely used in statistics and R provides us with a faster function to proceed with this scale transformation, the function \texttt{scale\_x\_log10()}, which gives us the same result as the previous plot.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.075}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-248-1} \end{center}

\section{Label, title and legend layer}\label{label-title-and-legend-layer}

We can also \href{https://www.datanovia.com/en/blog/ggplot-legend-title-position-and-labels/}{change the labels} (\texttt{label} in English) of the plot. So far on the \emph{x-axis} we see that \textbf{population/10\^{}6} appears and we can change it with the function \texttt{xlab()}. In the same way we can change on the \emph{y-axis} using \texttt{ylab()}. To add a title to the plot we will use the function \texttt{ggtitle()}. To change the name of the legend we will use the function \texttt{scale\_color\_discrete()}.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.075}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Population expressed in millions (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Total number of murders (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Gun murders in the US in 2010"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Regions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-249-1} \end{center}

\begin{quote}
\textbf{Modern Alternative:} You can also use the \texttt{labs()} function to set multiple labels in a single layer: \texttt{labs(x\ =\ "...",\ y\ =\ "...",\ title\ =\ "...",\ color\ =\ "...")}. This is often cleaner for plots with many labels.
\end{quote}

\section{Reference lines}\label{reference-lines}

We can add reference lines, whether vertical with \texttt{geom\_vline(xintercept\ =\ )}, horizontal with \texttt{geom\_hline(yintercept\ =\ ...)} or diagonal with \texttt{geom\_abline(intercept\ =\ )}, the latter asks us at what point it cuts the \emph{y-axis} and draws a line with a default slope of 1.

For example, we could calculate the average of total murders and draw a horizontal reference line.

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\#Calculate the average of the total}
\NormalTok{avg\_total }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}

\CommentTok{\#And add the horizontal reference line}
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.075}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Population expressed in millions (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Total number of murders (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Gun murders in the US in 2010"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Regions"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =}\NormalTok{ avg\_total)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-250-1} \end{center}

Or we could calculate the murder rate per million inhabitants throughout the US and draw a reference diagonal. In the case of the diagonal we have to express it in the same scale of the axis, therefore we have to convert it to \texttt{log10}.

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# Calculate the average rate}
\NormalTok{ratio }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{total)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(murders}\SpecialCharTok{$}\NormalTok{population) }\SpecialCharTok{*} \DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}

\CommentTok{\# Calculate base 10 logarithm to obtain the intercept on the "y{-}axis"}
\NormalTok{ratio\_log10 }\OtherTok{\textless{}{-}} \FunctionTok{log10}\NormalTok{(ratio)}

\CommentTok{\#And add the diagonal reference line}
\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.075}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Population expressed in millions (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Total number of murders (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Gun murders in the US in 2010"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Regions"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{intercept =}\NormalTok{ ratio\_log10)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-251-1} \end{center}

We can improve this reference line by making it dashed and gray. To do this, simply edit the \texttt{geom\_abline()} function as follows:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.075}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Population expressed in millions (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Total number of murders (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Gun murders in the US in 2010"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Regions"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{intercept =}\NormalTok{ ratio\_log10, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkgrey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-252-1} \end{center}

\section{Changing the plot style}\label{changing-the-plot-style}

The plot style using \texttt{ggplot()} can be easily changed. There are multiple themes we can use by loading the \textbf{ggthemes} library. We can, for example, use a widely used theme: the economist theme by adding the \texttt{theme\_economist()} layer.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggthemes)}

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{0.075}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Population expressed in millions (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Total number of murders (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Gun murders in the US in 2010"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Regions"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{intercept =}\NormalTok{ ratio\_log10, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkgrey"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_economist}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-253-1} \end{center}

We still see overlapping abbreviations. We can make the names repel each other using the \texttt{geom\_text\_repel()} function instead of \texttt{geom\_text()} that we are currently using. To use this function we need to call the \textbf{ggrepel} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggthemes)}
\FunctionTok{library}\NormalTok{(ggrepel)}

\NormalTok{murders }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}\NormalTok{, }\AttributeTok{y =}\NormalTok{ total, }\AttributeTok{label=}\NormalTok{abb, }\AttributeTok{color=}\NormalTok{region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text\_repel}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Population expressed in millions (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Total number of murders (logarithmic scale)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Gun murders in the US in 2010"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Regions"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{intercept =}\NormalTok{ ratio\_log10, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkgrey"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_economist}\NormalTok{()}
\CommentTok{\#\textgreater{} Warning: ggrepel: 1 unlabeled data points (too many overlaps). Consider}
\CommentTok{\#\textgreater{} increasing max.overlaps}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-254-1} \end{center}

This plot is visually much easier to understand and aesthetically much better than the default plot we created in previous chapters. We can explore more examples at this \href{https://rstudio-pubs-static.s3.amazonaws.com/228019_f0c39e05758a4a51b435b19dbd321c23.html}{link}.

\section{Saving plots}\label{saving-plots}

Once you've created a plot, you'll often want to save it to a file. The \texttt{ggsave()} function makes this easy:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Save the last plot created}
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"my\_plot.png"}\NormalTok{, }\AttributeTok{width =} \DecValTok{8}\NormalTok{, }\AttributeTok{height =} \DecValTok{6}\NormalTok{)}

\CommentTok{\# Or save a specific plot object}
\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ murders }\SpecialCharTok{|\textgreater{}} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ population, }\AttributeTok{y =}\NormalTok{ total) }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{()}
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"murders\_plot.pdf"}\NormalTok{, }\AttributeTok{plot =}\NormalTok{ p)}
\end{Highlighting}
\end{Shaded}

The function automatically detects the file type from the extension (\texttt{.png}, \texttt{.pdf}, \texttt{.svg}, etc.).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Summarizing data with dplyr}\label{summarizing-data-with-dplyr}

Visualization and data summarization go hand in hand. While plots help us \emph{see} patterns in our data, summary statistics help us \emph{quantify} those patterns. The \texttt{dplyr} package provides powerful functions for calculating summaries.

The \texttt{tidyverse} package includes several packages, among them \texttt{dplyr} which makes it easier for us to summarize data from a variable. When we call the \texttt{tidyvere} library we are also calling all the functions of \texttt{dplyr}. To start using the functions of \texttt{dplyr} we are going to load the \texttt{heights} data frame which is in the \texttt{dslabs} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(dslabs)}
\end{Highlighting}
\end{Shaded}

First let's understand the \texttt{heights} data frame, we can apply pipeline and then use the \texttt{head()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}      sex height}
\CommentTok{\#\textgreater{} 1   Male     75}
\CommentTok{\#\textgreater{} 2   Male     70}
\CommentTok{\#\textgreater{} 3   Male     68}
\CommentTok{\#\textgreater{} 4   Male     74}
\CommentTok{\#\textgreater{} 5   Male     61}
\CommentTok{\#\textgreater{} 6 Female     65}
\end{Highlighting}
\end{Shaded}

This data frame corresponds to the list of attributes of students in a university, where the \texttt{height} column indicates the height of each one in inches.

Finally, let's add the column \texttt{height\_m} where we will transform the height to meters. Remember that a meter has 39.37 inches. Let's store the result in the variable \texttt{heights\_m}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_m }\OtherTok{\textless{}{-}}\NormalTok{ heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_m =}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{)}

\NormalTok{heights\_m }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}      sex height height\_m}
\CommentTok{\#\textgreater{} 1   Male     75 1.905004}
\CommentTok{\#\textgreater{} 2   Male     70 1.778004}
\CommentTok{\#\textgreater{} 3   Male     68 1.727203}
\CommentTok{\#\textgreater{} 4   Male     74 1.879604}
\CommentTok{\#\textgreater{} 5   Male     61 1.549403}
\CommentTok{\#\textgreater{} 6 Female     65 1.651003}
\end{Highlighting}
\end{Shaded}

The fastest way to summarize a list of data is indicating what the average is and how much its \href{https://support.minitab.com/en-us/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/data-concepts/what-is-the-standard-deviation/}{standard deviation}\footnote{What is the standard deviation?} is. If we wanted to obtain the average we would use the \texttt{mean()} function and \texttt{sd()} to obtain the standard deviation. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(heights\_m}\SpecialCharTok{$}\NormalTok{height\_m)}
\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(heights\_m}\SpecialCharTok{$}\NormalTok{height\_m)}
\end{Highlighting}
\end{Shaded}

However, this summarizes all students for us without considering whether men could be on average taller than women. If we wanted to calculate the average and std. dev. we would have to filter first, then store in a variable and finally calculate the average and standard deviation. This is impractical and for that \texttt{dplyr} grants us the \texttt{summarize()} function.

\subsection{Summarize function}\label{summarize-function}

We can use the \texttt{summarize} function using the pipeline operator. Thus, we could calculate the average and std. dev. in this way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_m }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{avg =} \FunctionTok{mean}\NormalTok{(height\_m), }\AttributeTok{std\_dev =} \FunctionTok{sd}\NormalTok{(height\_m))}
\CommentTok{\#\textgreater{}        avg    std\_dev}
\CommentTok{\#\textgreater{} 1 1.760598 0.09172018}
\end{Highlighting}
\end{Shaded}

This function also generates a data frame for us. We can validate it if we store the result in the variable \texttt{heights\_m\_male} and then report the \emph{class} of the variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_m\_male }\OtherTok{\textless{}{-}}\NormalTok{ heights\_m }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{avg =} \FunctionTok{mean}\NormalTok{(height\_m), }\AttributeTok{std\_dev =} \FunctionTok{sd}\NormalTok{(height\_m))}

\FunctionTok{class}\NormalTok{(heights\_m\_male)}
\CommentTok{\#\textgreater{} [1] "data.frame"}
\end{Highlighting}
\end{Shaded}

We can report the data frame \texttt{heights\_m\_male} and use it for future analyzes accessing with the accessor \texttt{\$}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_m\_male}
\CommentTok{\#\textgreater{}        avg    std\_dev}
\CommentTok{\#\textgreater{} 1 1.760598 0.09172018}
\end{Highlighting}
\end{Shaded}

We see that the average height of men is 1.76 meters with a standard deviation of 0.09 meters.

In the same way, we can use \texttt{summarize} to calculate other functions such as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_m }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{min\_val =} \FunctionTok{min}\NormalTok{(height\_m), }\AttributeTok{max\_val =} \FunctionTok{max}\NormalTok{(height\_m), }\AttributeTok{median\_val =} \FunctionTok{median}\NormalTok{(height\_m))}
\CommentTok{\#\textgreater{}    min\_val  max\_val median\_val}
\CommentTok{\#\textgreater{} 1 1.270003 2.100004   1.752604}
\end{Highlighting}
\end{Shaded}

The tallest student measures more than 2.1 meters. Half of the male students measure more than 1.75 meters.

However, we would now have to change to ``Female'' to calculate the data for women. We need to group and then summarize the data taking into account the grouping. For this there is the function \texttt{group\_by()}

\subsection{Group By Function}\label{group-by-function}

This function allows us to create grouped data frames which makes it easier for us to summarize the data. We would only have to select based on what we want to group and no longer filter by sex. In this case the grouping would be based on the \texttt{sex} column:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_m }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{group\_by}\NormalTok{(sex) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{avg =} \FunctionTok{mean}\NormalTok{(height\_m), }\AttributeTok{std\_dev =} \FunctionTok{sd}\NormalTok{(height\_m))}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 3}
\CommentTok{\#\textgreater{}   sex      avg std\_dev}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}  \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Female  1.65  0.0955}
\CommentTok{\#\textgreater{} 2 Male    1.76  0.0917}
\end{Highlighting}
\end{Shaded}

On average, women are shorter than men.

If we now remember our danger case in the US. We can calculate the ratio of total crimes regarding the population and then compare it by region in this way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{murders }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ total }\SpecialCharTok{/}\NormalTok{ population }\SpecialCharTok{*} \DecValTok{100000}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(region) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{avg\_ratio =} \FunctionTok{mean}\NormalTok{(ratio))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 2}
\CommentTok{\#\textgreater{}   region        avg\_ratio}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}             \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Northeast          1.85}
\CommentTok{\#\textgreater{} 2 South              4.42}
\CommentTok{\#\textgreater{} 3 North Central      2.18}
\CommentTok{\#\textgreater{} 4 West               1.83}
\end{Highlighting}
\end{Shaded}

On average, the South region is more dangerous.

\section{Exercises}\label{exercises-5}

This time we are going to perform exercises within the field of biology and for this we must remember the parts of a flower. This way we will give more sense to the problem:

\begin{center}\includegraphics[width=150pt,alt={Botanical diagram showing flower parts: sepal, petal, stamen, and pistil}]{assets/images/03-visualization/flower-parts} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{50}
\tightlist
\item
  Load the \texttt{iris} data frame (\texttt{data(iris)}), which details the characteristics of 150 flowers across 3 species. Create a scatter plot visualizing the relationship between sepal length and petal length.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Sepal.Length, }\AttributeTok{y =}\NormalTok{ Petal.Length) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{51}
\tightlist
\item
  Enhance the previous visualization by coloring the points to represent the species of each flower.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Sepal.Length, }\AttributeTok{y =}\NormalTok{ Petal.Length, }\AttributeTok{color =}\NormalTok{ Species) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{52}
\tightlist
\item
  Polish your plot by setting the title to ``Relationship between sepal and petal size of different flowers'', naming the x-axis ``Sepal length (in cm)'', the y-axis ``Petal length (in cm)'', and labeling the legend simply as ``Species''.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Sepal.Length, }\AttributeTok{y =}\NormalTok{ Petal.Length, }\AttributeTok{color =}\NormalTok{ Species) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Sepal length (in cm)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Petal length (in cm)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Relationship between sepal and petal size of different flowers"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Species"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{53}
\tightlist
\item
  Generate a statistical summary of the ratio between sepal length and petal length, reporting a data frame that includes the average, standard deviation, and median of this ratio.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ Sepal.Length }\SpecialCharTok{/}\NormalTok{ Petal.Length) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{avg =} \FunctionTok{mean}\NormalTok{(ratio), }\AttributeTok{std\_dev =} \FunctionTok{sd}\NormalTok{(ratio), }\AttributeTok{median\_val =} \FunctionTok{median}\NormalTok{(ratio))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{54}
\tightlist
\item
  Refine your previous ratio summary to show these statistics (average, standard deviation, and median) calculated separately for each species.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ratio =}\NormalTok{ Sepal.Length }\SpecialCharTok{/}\NormalTok{ Petal.Length) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(Species) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{avg =} \FunctionTok{mean}\NormalTok{(ratio), }\AttributeTok{std\_dev =} \FunctionTok{sd}\NormalTok{(ratio), }\AttributeTok{median\_val =} \FunctionTok{median}\NormalTok{(ratio))}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Key Takeaways}\label{key-takeaways}

This chapter emphasized a \textbf{layered approach} to visualization, building plots incrementally with aesthetics, geoms, and scales. We learned to map data to visual properties using \texttt{aes}, select the appropriate geometry (like \texttt{geom\_point} or \texttt{geom\_line}), and transform axes to reveal patterns in skewed data. Beyond the visuals, we explored how to customize themes and labels for clarity, and how to quantify insights using \texttt{dplyr} summarization tools before saving our work with \texttt{ggsave()}.

\chapter{Gapminder}\label{gapminder}

\href{https://www.gapminder.org/}{The Gapminder Foundation}\footnote{\url{https://www.gapminder.org/}} is a Swedish non-profit organization that promotes global development through the use of statistics that can help reduce common myths and sensationalist stories about global health and economics. An important selection of data is already loaded in the \texttt{dslabs} library in the \texttt{gapminder} data frame. Our case/problem now will be to answer these two questions:

\begin{quote}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Is it still reasonable to divide the world between Western countries* and developing countries?
\item
  Is it true that every day we are worse off and rich countries get richer while poor countries get poorer?
\end{enumerate}
\end{quote}

(*): Samuel Huntington in 1993 published an article called \href{https://web.archive.org/web/20100821191056/http://history.club.fatih.edu.tr/103\%20Huntington\%20Clash\%20of\%20Civilizations\%20full\%20text.htm}{Clash of Civilizations}\footnote{Full text of Huntington's article (in English)} where he defined Western countries as those located in the regions of North America, Northern/Southern/Western Europe and Australia and New Zealand.

To address these questions, we will follow a structured data science workflow. We'll start by \textbf{exploring the data} to understand its structure and content, then move to \textbf{in-depth analysis} to identify relevant variables. Finally, we will use \textbf{visualization and summarization} techniques to synthesize our findings and provide clear answers.

First let's explore the structure of the data frame with \texttt{str()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{str}\NormalTok{()}
\CommentTok{\#\textgreater{} \textquotesingle{}data.frame\textquotesingle{}:    10545 obs. of  9 variables:}
\CommentTok{\#\textgreater{}  $ country         : Factor w/ 185 levels "Albania","Algeria",..: 1 2 3 4 5 6 7 8 9 10 ...}
\CommentTok{\#\textgreater{}  $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...}
\CommentTok{\#\textgreater{}  $ infant\_mortality: num  115.4 148.2 208 NA 59.9 ...}
\CommentTok{\#\textgreater{}  $ life\_expectancy : num  62.9 47.5 36 63 65.4 ...}
\CommentTok{\#\textgreater{}  $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...}
\CommentTok{\#\textgreater{}  $ population      : num  1636054 11124892 5270844 54681 20619075 ...}
\CommentTok{\#\textgreater{}  $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...}
\CommentTok{\#\textgreater{}  $ continent       : Factor w/ 5 levels "Africa","Americas",..: 4 1 1 2 2 3 2 5 4 3 ...}
\CommentTok{\#\textgreater{}  $ region          : Factor w/ 22 levels "Australia and New Zealand",..: 19 11 10 2 15 21 2 1 22 21 ...}
\end{Highlighting}
\end{Shaded}

We have a data frame with more than 10 thousand data points and 9 variables.

Now let's take a look at the data with \texttt{head()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}               country year infant\_mortality life\_expectancy fertility}
\CommentTok{\#\textgreater{} 1             Albania 1960           115.40           62.87      6.19}
\CommentTok{\#\textgreater{} 2             Algeria 1960           148.20           47.50      7.65}
\CommentTok{\#\textgreater{} 3              Angola 1960           208.00           35.98      7.32}
\CommentTok{\#\textgreater{} 4 Antigua and Barbuda 1960               NA           62.97      4.43}
\CommentTok{\#\textgreater{} 5           Argentina 1960            59.87           65.39      3.11}
\CommentTok{\#\textgreater{} 6             Armenia 1960               NA           66.86      4.55}
\CommentTok{\#\textgreater{}   population          gdp continent          region}
\CommentTok{\#\textgreater{} 1    1636054           NA    Europe Southern Europe}
\CommentTok{\#\textgreater{} 2   11124892  13828152297    Africa Northern Africa}
\CommentTok{\#\textgreater{} 3    5270844           NA    Africa   Middle Africa}
\CommentTok{\#\textgreater{} 4      54681           NA  Americas       Caribbean}
\CommentTok{\#\textgreater{} 5   20619075 108322326649  Americas   South America}
\CommentTok{\#\textgreater{} 6    1867396           NA      Asia    Western Asia}
\end{Highlighting}
\end{Shaded}

Remember that for library data frames we can usually find the documentation and understand each attribute faster:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?gapminder}
\end{Highlighting}
\end{Shaded}

Going directly to the questions would be not leaving that curiosity free to see what else is in the data. Thus, we are going to start with other variables such as infant mortality, fertility or population.

We can filter all the data that are from Peru and select the column country, year, infant mortality and population:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{==} \StringTok{"Peru"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(country, year, infant\_mortality, population)}
\CommentTok{\#\textgreater{}    country year infant\_mortality population}
\CommentTok{\#\textgreater{} 1     Peru 1960            135.9   10061519}
\CommentTok{\#\textgreater{} 2     Peru 1961            132.6   10350239}
\CommentTok{\#\textgreater{} 3     Peru 1962            129.1   10650672}
\CommentTok{\#\textgreater{} 4     Peru 1963            125.4   10961539}
\CommentTok{\#\textgreater{} 5     Peru 1964            121.8   11281015}
\CommentTok{\#\textgreater{} 6     Peru 1965            118.2   11607684}
\CommentTok{\#\textgreater{} 7     Peru 1966            114.8   11941327}
\CommentTok{\#\textgreater{} 8     Peru 1967            111.6   12282081}
\CommentTok{\#\textgreater{} 9     Peru 1968            108.7   12629333}
\CommentTok{\#\textgreater{} 10    Peru 1969            106.0   12982444}
\CommentTok{\#\textgreater{} 11    Peru 1970            103.4   13341071}
\CommentTok{\#\textgreater{} 12    Peru 1971            100.9   13704333}
\CommentTok{\#\textgreater{} 13    Peru 1972             98.3   14072476}
\CommentTok{\#\textgreater{} 14    Peru 1973             95.8   14447649}
\CommentTok{\#\textgreater{} 15    Peru 1974             93.3   14832839}
\CommentTok{\#\textgreater{} 16    Peru 1975             91.0   15229951}
\CommentTok{\#\textgreater{} 17    Peru 1976             88.9   15639898}
\CommentTok{\#\textgreater{} 18    Peru 1977             87.0   16061327}
\CommentTok{\#\textgreater{} 19    Peru 1978             85.5   16491087}
\CommentTok{\#\textgreater{} 20    Peru 1979             83.9   16924758}
\CommentTok{\#\textgreater{} 21    Peru 1980             82.4   17359118}
\CommentTok{\#\textgreater{} 22    Peru 1981             80.7   17792551}
\CommentTok{\#\textgreater{} 23    Peru 1982             78.7   18225727}
\CommentTok{\#\textgreater{} 24    Peru 1983             76.3   18660443}
\CommentTok{\#\textgreater{} 25    Peru 1984             73.7   19099575}
\CommentTok{\#\textgreater{} 26    Peru 1985             70.7   19544950}
\CommentTok{\#\textgreater{} 27    Peru 1986             67.6   19996250}
\CommentTok{\#\textgreater{} 28    Peru 1987             64.6   20451712}
\CommentTok{\#\textgreater{} 29    Peru 1988             61.7   20909897}
\CommentTok{\#\textgreater{} 30    Peru 1989             58.9   21368856}
\CommentTok{\#\textgreater{} 31    Peru 1990             56.3   21826658}
\CommentTok{\#\textgreater{} 32    Peru 1991             53.7   22283130}
\CommentTok{\#\textgreater{} 33    Peru 1992             51.0   22737056}
\CommentTok{\#\textgreater{} 34    Peru 1993             48.2   23184222}
\CommentTok{\#\textgreater{} 35    Peru 1994             45.4   23619358}
\CommentTok{\#\textgreater{} 36    Peru 1995             42.5   24038761}
\CommentTok{\#\textgreater{} 37    Peru 1996             39.7   24441076}
\CommentTok{\#\textgreater{} 38    Peru 1997             36.9   24827409}
\CommentTok{\#\textgreater{} 39    Peru 1998             34.3   25199744}
\CommentTok{\#\textgreater{} 40    Peru 1999             31.8   25561297}
\CommentTok{\#\textgreater{} 41    Peru 2000             29.6   25914875}
\CommentTok{\#\textgreater{} 42    Peru 2001             27.6   26261363}
\CommentTok{\#\textgreater{} 43    Peru 2002             25.7   26601463}
\CommentTok{\#\textgreater{} 44    Peru 2003             24.1   26937737}
\CommentTok{\#\textgreater{} 45    Peru 2004             22.6   27273188}
\CommentTok{\#\textgreater{} 46    Peru 2005             21.3   27610406}
\CommentTok{\#\textgreater{} 47    Peru 2006             20.1   27949958}
\CommentTok{\#\textgreater{} 48    Peru 2007             19.0   28292768}
\CommentTok{\#\textgreater{} 49    Peru 2008             18.0   28642048}
\CommentTok{\#\textgreater{} 50    Peru 2009             17.1   29001563}
\CommentTok{\#\textgreater{} 51    Peru 2010             16.3   29373644}
\CommentTok{\#\textgreater{} 52    Peru 2011             15.6   29759891}
\CommentTok{\#\textgreater{} 53    Peru 2012             14.9   30158768}
\CommentTok{\#\textgreater{} 54    Peru 2013             14.2   30565461}
\CommentTok{\#\textgreater{} 55    Peru 2014             13.6   30973148}
\CommentTok{\#\textgreater{} 56    Peru 2015             13.1   31376670}
\CommentTok{\#\textgreater{} 57    Peru 2016               NA         NA}
\end{Highlighting}
\end{Shaded}

Let's add a filter to obtain only the data from 2015:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{==} \StringTok{"Peru"} \SpecialCharTok{\&}\NormalTok{ year }\SpecialCharTok{==} \DecValTok{2015}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(country, year, infant\_mortality, population)}
\CommentTok{\#\textgreater{}   country year infant\_mortality population}
\CommentTok{\#\textgreater{} 1    Peru 2015             13.1   31376670}
\end{Highlighting}
\end{Shaded}

We can make a comparison between Peru and Chile if we create a vector and instead of the \texttt{==} operator we use the \texttt{\%in\%} operator that allows evaluating that our data are \textbf{in} that vector.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_countries }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{"Peru"}\NormalTok{, }\StringTok{"Chile"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%}\NormalTok{ vector\_countries }\SpecialCharTok{\&}\NormalTok{ year }\SpecialCharTok{==} \DecValTok{2015}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(country, year, infant\_mortality, population)}
\CommentTok{\#\textgreater{}   country year infant\_mortality population}
\CommentTok{\#\textgreater{} 1   Chile 2015              7.0   17948141}
\CommentTok{\#\textgreater{} 2    Peru 2015             13.1   31376670}
\end{Highlighting}
\end{Shaded}

Infant mortality is measured in number of children who die per 1,000 infants. This means that it already takes into account the population. In 2015 Peru had a higher infant mortality rate than Chile.

\section{Initial gapminder plots}\label{initial-gapminder-plots}

However, if we want to analyze global data, comparing countries one by one would be impractical. Let's use \texttt{ggplot} to see if there is a relationship in our data.

Let's create a scatter plot with data from the \textbf{year 1990} of the fertility variable (\texttt{fertility}), which is the average number of children per woman, and the life expectancy variable (\texttt{life\_expectancy}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{1990}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-285-1} \end{center}

From this graph we can see that countries where families have 7.5 children have a lower life expectancy. On the other hand, in countries with high life expectancy the average number of children is less than 2 children per family.

As we have done previously, we can color the points according to some other variable. In this case, knowing which continent they belong to could give us a better idea of the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{1990}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-286-1} \end{center}

In this graph, groups begin to be seen. Several European countries are in the upper left quadrant, while several African countries are in the lower right quadrant.

\section{Facets}\label{facets}

Although the previous graph already shows us a correlation of variables, we cannot see how it has changed from one year to another. For this we will use the facet layer (\texttt{facet\_}).

In the layer \texttt{facet\_grid(row\_variable\ \textasciitilde{}\ column\_variable)} we replace ``row\_variable'' with the name of our variable or replace it with a \texttt{.} if we don't want any of them. For example, from the previous example let's compare how the distribution changed by comparing the year 1960 with the year 2013.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_years }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1960}\NormalTok{, }\DecValTok{2013}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%}\NormalTok{ vector\_years) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(year }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-287-1} \end{center}

We can make it even clearer which continent changed the most if we add the continent variable as a column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_years }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1960}\NormalTok{, }\DecValTok{2013}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%}\NormalTok{ vector\_years) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(year }\SpecialCharTok{\textasciitilde{}}\NormalTok{ continent)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-288-1} \end{center}

Having several columns for each continent makes it harder to understand because the columns become smaller. It is recommended to have few columns. So we invert the order between year and continent.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_years }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1960}\NormalTok{, }\DecValTok{2013}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%}\NormalTok{ vector\_years) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(continent }\SpecialCharTok{\textasciitilde{}}\NormalTok{ year)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-289-1} \end{center}

Here the change by regions is much more evident: the majority of countries have reduced fertility per family while increasing life expectancy. We are living longer than in the 1960s and having fewer children per family. These trends have occurred across all continents.

We don't always have to show all variables, in this case continents. We can continue applying filters so that it shows us a subset of continents that we want to compare. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_years }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1960}\NormalTok{, }\DecValTok{2013}\NormalTok{)}
\NormalTok{vector\_continents }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Europe"}\NormalTok{, }\StringTok{"Asia"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%}\NormalTok{ vector\_years }\SpecialCharTok{\&}\NormalTok{ continent }\SpecialCharTok{\%in\%}\NormalTok{ vector\_continents) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(continent }\SpecialCharTok{\textasciitilde{}}\NormalTok{ year)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-290-1} \end{center}

In this case it would be visually better if the continents were not in separate rows, but could still be appreciated in the graph. To do this, we will use the wrap facet (\texttt{facet\_wrap(\textasciitilde{}\ x)}), where \texttt{x} is the variable we want to wrap. In our case it would be the year, instead of appearing in separate rows we can join and transpose them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_years }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1960}\NormalTok{, }\DecValTok{2013}\NormalTok{)}
\NormalTok{vector\_continents }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Europe"}\NormalTok{, }\StringTok{"Asia"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%}\NormalTok{ vector\_years }\SpecialCharTok{\&}\NormalTok{ continent }\SpecialCharTok{\%in\%}\NormalTok{ vector\_continents) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{( }\SpecialCharTok{\textasciitilde{}}\NormalTok{ year)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-291-1} \end{center}

We can add more data by adding more data to the vectors. For example, let's add a cut in the middle between 1960 and 2013.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_years }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1960}\NormalTok{, }\DecValTok{1985}\NormalTok{, }\DecValTok{2013}\NormalTok{)}
\NormalTok{vector\_continents }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Europe"}\NormalTok{, }\StringTok{"Asia"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%}\NormalTok{ vector\_years }\SpecialCharTok{\&}\NormalTok{ continent }\SpecialCharTok{\%in\%}\NormalTok{ vector\_continents) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fertility, }\AttributeTok{y =}\NormalTok{ life\_expectancy, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{( }\SpecialCharTok{\textasciitilde{}}\NormalTok{ year)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-292-1} \end{center}

\section{Time series}\label{time-series}

Time series are sequences of data measured at determined moments and ordered chronologically. R allows us to easily plot time series, we only need our data frames to include some time variable.

\subsection{Individual time series}\label{individual-time-series}

In an individual time series we only analyze how a single variable has evolved, for example the evolution of the fertility rate in Peru. For this we can use a scatter plot with points or with lines.

As we will remember, we use \texttt{geom\_point()} for points:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{==} \StringTok{"Peru"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ year, }\AttributeTok{y =}\NormalTok{ fertility) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\CommentTok{\#\textgreater{} Warning: Removed 1 row containing missing values or values}
\CommentTok{\#\textgreater{} outside the scale range (\textasciigrave{}geom\_point()\textasciigrave{}).}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-293-1} \end{center}

We get a ``warning'' indicating that there are values that cannot be drawn because they are \texttt{NA} and are not available. This does not prevent showing the graph.

If we want a line graph, which is the most used in time series, we use \texttt{geom\_line()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{==} \StringTok{"Peru"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ year, }\AttributeTok{y =}\NormalTok{ fertility) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\CommentTok{\#\textgreater{} Warning: Removed 1 row containing missing values or values}
\CommentTok{\#\textgreater{} outside the scale range (\textasciigrave{}geom\_line()\textasciigrave{}).}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-294-1} \end{center}

\subsection{Multiple time series}\label{multiple-time-series}

In multiple time series we seek comparison to analyze in a time series how the data evolved. For example, this would be the time series if we compare Peru, Bolivia and Chile:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Peru"}\NormalTok{, }\StringTok{"Bolivia"}\NormalTok{, }\StringTok{"Chile"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%}\NormalTok{ countries) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ year, }\AttributeTok{y =}\NormalTok{ fertility, }\AttributeTok{color =}\NormalTok{ country) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\CommentTok{\#\textgreater{} Warning: Removed 3 rows containing missing values or values}
\CommentTok{\#\textgreater{} outside the scale range (\textasciigrave{}geom\_line()\textasciigrave{}).}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-295-1} \end{center}

We can also remove the legend and show the name of the countries as labels on the same graph. To do this we will first have to create a data frame using the function \texttt{data.frame()} that indicates the coordinates where we want each label to appear:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Peru"}\NormalTok{, }\StringTok{"Bolivia"}\NormalTok{, }\StringTok{"Chile"}\NormalTok{)}

\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{country\_names =}\NormalTok{ countries, }\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1975}\NormalTok{, }\DecValTok{1965}\NormalTok{, }\DecValTok{1962}\NormalTok{), }\AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{))}
  
\NormalTok{labels}
\CommentTok{\#\textgreater{}   country\_names    x y}
\CommentTok{\#\textgreater{} 1          Peru 1975 6}
\CommentTok{\#\textgreater{} 2       Bolivia 1965 7}
\CommentTok{\#\textgreater{} 3         Chile 1962 4}
\end{Highlighting}
\end{Shaded}

We will use this to indicate that we want, for example, Bolivia to be written at the intersection of the year 1972 and with a fertility rate of 6.8.

To use these labels in \texttt{ggplot} we will edit the arguments in the \texttt{geom\_text} layer. We will use the \texttt{data} attributes to indicate that we want to obtain the data from an external source, and we will include the \texttt{aes} layer inside \texttt{geom\_text} to correlate the data frame we have created with the graph. We must keep in mind that the column name in both data frames must be the same, in this case \texttt{country}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Peru"}\NormalTok{, }\StringTok{"Bolivia"}\NormalTok{, }\StringTok{"Chile"}\NormalTok{)}

\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{country =}\NormalTok{ countries, }\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1976}\NormalTok{, }\DecValTok{1972}\NormalTok{, }\DecValTok{1965}\NormalTok{), }\AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\FloatTok{5.2}\NormalTok{, }\FloatTok{6.8}\NormalTok{, }\FloatTok{5.5}\NormalTok{))}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%}\NormalTok{ countries) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(year, fertility, }\AttributeTok{col =}\NormalTok{ country) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{data =}\NormalTok{ labels, }\FunctionTok{aes}\NormalTok{(x, y, }\AttributeTok{label =}\NormalTok{ country)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning: Removed 3 rows containing missing values or values}
\CommentTok{\#\textgreater{} outside the scale range (\textasciigrave{}geom\_line()\textasciigrave{}).}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-297-1} \end{center}

\section{Exercises}\label{exercises-6}

For these exercises we will continue using the \texttt{gapminder} data frame.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{55}
\tightlist
\item
  Generate a scatter plot comparing fertility rates and life expectancy for the Americas in the year 2000. Use color to differentiate between the regions within the continent.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{( continent }\SpecialCharTok{==} \StringTok{"Americas"} \SpecialCharTok{\&}\NormalTok{ year }\SpecialCharTok{==} \DecValTok{2000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(fertility, life\_expectancy, }\AttributeTok{color =}\NormalTok{ region) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{quote}
To create a vector of sequences we can use \texttt{X:Y}. This creates a vector that goes from number X to number Y
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{56}
\tightlist
\item
  During the Vietnam War, both the US and Vietnam suffered significant losses. Create a line chart visualizing how life expectancy changed in both countries from 1955 to 1990 to observe the war's impact.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Vietnam"}\NormalTok{, }\StringTok{"United States"}\NormalTok{)}
\NormalTok{year\_sequence }\OtherTok{\textless{}{-}} \DecValTok{1955}\SpecialCharTok{:}\DecValTok{1990}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%}\NormalTok{ countries }\SpecialCharTok{\&}\NormalTok{ year }\SpecialCharTok{\%in\%}\NormalTok{ year\_sequence) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(year, life\_expectancy, }\AttributeTok{color =}\NormalTok{ country) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{57}
\tightlist
\item
  Expand the previous chart to include Cambodia, allowing us to visualize the devastating impact of the Khmer Rouge regime (1975-1979) on life expectancy alongside the Vietnam War data.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Vietnam"}\NormalTok{, }\StringTok{"United States"}\NormalTok{, }\StringTok{"Cambodia"}\NormalTok{)}
\NormalTok{year\_sequence }\OtherTok{\textless{}{-}} \DecValTok{1955}\SpecialCharTok{:}\DecValTok{1990}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%}\NormalTok{ countries }\SpecialCharTok{\&}\NormalTok{ year }\SpecialCharTok{\%in\%}\NormalTok{ year\_sequence) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(year, life\_expectancy, }\AttributeTok{color =}\NormalTok{ country) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\section{Histograms with ggplot}\label{histograms-with-ggplot}

We could continue exploring the data until we understand it much better. Eventually we would get to the GDP (\texttt{gdp}) data and in turn we would understand that comparing only GDP alone makes no sense since there are countries with much more population than others. Data transformation is not something new, but we will see that it is something recurrent in our analyzes.

We are going to use a transformation that allows us to obtain how much is the GDP per capita per day in each country in each year

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\OtherTok{\textless{}{-}}\NormalTok{ gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We could visualize this variable first by creating a histogram of it. A histogram in ggplot is nothing more than one of the \texttt{geoms} we have available, in this case it would be \texttt{geom\_histogram(binwidth\ =\ x)}, where \textbf{x} is the width of the bar. For example, let's calculate the distribution of our created variable in the year 2010:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning: Removed 9 rows containing non{-}finite outside the}
\CommentTok{\#\textgreater{} scale range (\textasciigrave{}stat\_bin()\textasciigrave{}).}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-305-1} \end{center}

We can filter out the \textbf{NA} so that we no longer get the low ``warnings'' with the function we saw previously \texttt{is.na()}. In this case since we don't want the \textbf{NA} we will negate the function by placing the symbol \texttt{!} at the beginning.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-306-1} \end{center}

At this point it should be quick to detect that there is a concentration of data from countries with low GDP per capita and we could be tempted to apply a scale transformation on the \emph{x-axis}. Let's try with logarithm in base 2:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\#Change the width to 0.5 due to logarithmic scale}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-307-1} \end{center}

Let's be careful interpreting this data. We cannot say that it is a symmetric distribution, even when with this scale we are tempted to do so. Remember the scale and use it appropriately.

\begin{quote}
\textbf{Tip:} For smooth distribution curves, you can also use \texttt{geom\_density()} instead of \texttt{geom\_histogram()}. Density plots are particularly useful when comparing multiple groups on the same plot.
\end{quote}

\section{Box plots with ggplot}\label{box-plots-with-ggplot}

In the same way, box plots are one more \texttt{geom} within the available ones, for this we will use the \texttt{geom\_boxplot()} layer.

For example, let's create a box plot to analyze GDP per capita per day by continent:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(continent, gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-308-1} \end{center}

Now let's zoom in. Within each continent we have regions, for example in the Americas we have South America, Central America, North America, and so on with each continent. Let's change the \texttt{continent} variable to \texttt{region}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-309-1} \end{center}

As we can verify: this visualization allows us to infer very little. Before discarding a graph let's think if we can change the configuration to improve the visualization.

The first thing we can improve is the names of the regions. They are in horizontal form, but we could rotate it 45 degrees using the \texttt{theme()} layer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{) )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-310-1} \end{center}

The names are understood, but if we want to find the top 3 (either by median or average) we would have to look for them one by one. Let's reorder it, but first let's be aware of some previous considerations:

The \texttt{region} column is a \texttt{Factor} type variable, it is not a character string. Even when visually we did not find a difference, factors are used to categorize data. For example, bronze, silver, platinum customers, etc.

Factors are useful because internally they are replaced by numbers and numbers, at a computational level, are faster to sort. The default sorting is alphabetical, as we can appreciate if we use the \texttt{levels} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{levels}\NormalTok{(gapminder}\SpecialCharTok{$}\NormalTok{region)}
\CommentTok{\#\textgreater{}  [1] "Australia and New Zealand" "Caribbean"                }
\CommentTok{\#\textgreater{}  [3] "Central America"           "Central Asia"             }
\CommentTok{\#\textgreater{}  [5] "Eastern Africa"            "Eastern Asia"             }
\CommentTok{\#\textgreater{}  [7] "Eastern Europe"            "Melanesia"                }
\CommentTok{\#\textgreater{}  [9] "Micronesia"                "Middle Africa"            }
\CommentTok{\#\textgreater{} [11] "Northern Africa"           "Northern America"         }
\CommentTok{\#\textgreater{} [13] "Northern Europe"           "Polynesia"                }
\CommentTok{\#\textgreater{} [15] "South America"             "South{-}Eastern Asia"       }
\CommentTok{\#\textgreater{} [17] "Southern Africa"           "Southern Asia"            }
\CommentTok{\#\textgreater{} [19] "Southern Europe"           "Western Africa"           }
\CommentTok{\#\textgreater{} [21] "Western Asia"              "Western Europe"}
\end{Highlighting}
\end{Shaded}

We will use the \texttt{reorder()} function to change the order of the factors and since we are altering the dataframe we would have to use it inside the \texttt{mutate()} function. The \texttt{reorder()} function asks us as the first attribute the factor to reorder, then the vector that we will take into account and finally a grouping function. For example, order based on the median of each region (visually remember that it is the thick line inside each box):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{region =} \FunctionTok{reorder}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{FUN =}\NormalTok{ median)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-312-1} \end{center}

Note that a \texttt{mutate} has been placed after filtering the data. This is to guarantee that we are removing the \textbf{NA}. Otherwise, we risk that all values are \textbf{NA} and the reordering is not performed and remains default.

We see at the far left some regions in Africa, and at the far right Europe and USA. Remember that we can add color according to some variable. In this case let's add color based on the continent:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{region =} \FunctionTok{reorder}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{FUN =}\NormalTok{ median)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{color =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-313-1} \end{center}

Although we can already differentiate it, in a box plot it is usually the fill (\texttt{fill} in English) of the box that is painted. So, let's change the \texttt{color} attribute to the \texttt{fill} attribute. And let's remove the legend on the \emph{x-axis}. It is not necessary in this case where the regions are self-explanatory.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{region =} \FunctionTok{reorder}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{FUN =}\NormalTok{ median)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{fill =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-314-1} \end{center}

This graph helps us see the top 5, but since there are several regions concentrated in small values of GDP per capita we visually lose those regions. We need a scale transformation.

If you are thinking of adding a logarithmic scale layer for the \emph{y-axis} you are on the right track. Let's try:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{region =} \FunctionTok{reorder}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{FUN =}\NormalTok{ median)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{fill =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-315-1} \end{center}

Sometimes it is necessary not only to show the boxes, but also where each of the data points is located. For this we can add the \texttt{geom\_point()} layer that we had previously used to show the points of each data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{region =} \FunctionTok{reorder}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{FUN =}\NormalTok{ median)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{fill =}\NormalTok{ continent) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-316-1} \end{center}

\section{Comparison of distributions}\label{comparison-of-distributions}

To be able to solve the first question of the case we would have to compare the distributions of the ``Western'' countries versus the developing countries.

For this, since we do not have a column that indicates which are from the West, we are going to create a \texttt{western\_countries} with the list of regions that fall into this category:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{western\_countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Western Europe"}\NormalTok{, }\StringTok{"Northern Europe"}\NormalTok{, }\StringTok{"Southern Europe"}\NormalTok{, }\StringTok{"Northern America"}\NormalTok{, }\StringTok{"Australia and New Zealand"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
We will also use the \texttt{ifelse(test,\ yes,\ no)} function to create a new column such that if the region is in the West it stores a value, and if it is not in the West it stores another value. It is recommended to read the documentation in \texttt{?ifelse}.
\end{quote}

Let's add the column for the group each country belongs to:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{western\_countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Western Europe"}\NormalTok{, }\StringTok{"Northern Europe"}\NormalTok{, }\StringTok{"Southern Europe"}\NormalTok{, }\StringTok{"Northern America"}\NormalTok{, }\StringTok{"Australia and New Zealand"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{group =} \FunctionTok{ifelse}\NormalTok{(region }\SpecialCharTok{\%in\%}\NormalTok{ western\_countries, }\StringTok{"Western"}\NormalTok{, }\StringTok{"Developing"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{()}
\CommentTok{\#\textgreater{}               country year infant\_mortality life\_expectancy fertility}
\CommentTok{\#\textgreater{} 1             Albania 2010             14.8            77.2      1.74}
\CommentTok{\#\textgreater{} 2             Algeria 2010             23.5            76.0      2.82}
\CommentTok{\#\textgreater{} 3              Angola 2010            109.6            57.6      6.22}
\CommentTok{\#\textgreater{} 4 Antigua and Barbuda 2010              7.7            75.8      2.13}
\CommentTok{\#\textgreater{} 5           Argentina 2010             13.0            75.8      2.22}
\CommentTok{\#\textgreater{} 6             Armenia 2010             16.1            73.0      1.55}
\CommentTok{\#\textgreater{}   population          gdp continent          region gdp\_per\_capita\_per\_day}
\CommentTok{\#\textgreater{} 1    2901883   6137563946    Europe Southern Europe               5.794597}
\CommentTok{\#\textgreater{} 2   36036159  79164339611    Africa Northern Africa               6.018638}
\CommentTok{\#\textgreater{} 3   21219954  26125663270    Africa   Middle Africa               3.373106}
\CommentTok{\#\textgreater{} 4      87233    836686777  Americas       Caribbean              26.277814}
\CommentTok{\#\textgreater{} 5   41222875 434405530244  Americas   South America              28.871158}
\CommentTok{\#\textgreater{} 6    2963496   4102285513      Asia    Western Asia               3.792527}
\CommentTok{\#\textgreater{}        group}
\CommentTok{\#\textgreater{} 1    Western}
\CommentTok{\#\textgreater{} 2 Developing}
\CommentTok{\#\textgreater{} 3 Developing}
\CommentTok{\#\textgreater{} 4 Developing}
\CommentTok{\#\textgreater{} 5 Developing}
\CommentTok{\#\textgreater{} 6 Developing}
\end{Highlighting}
\end{Shaded}

Now that we have how to differentiate the countries we can see their distribution until we find how to answer our question. We start by creating a histogram with logarithmic scale in the \emph{x-axis} and separate it using \texttt{facet\_grid} based on the group it belongs to:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{western\_countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Western Europe"}\NormalTok{, }\StringTok{"Northern Europe"}\NormalTok{, }\StringTok{"Southern Europe"}\NormalTok{, }\StringTok{"Northern America"}\NormalTok{, }\StringTok{"Australia and New Zealand"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2010} \SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{group =} \FunctionTok{ifelse}\NormalTok{(region }\SpecialCharTok{\%in\%}\NormalTok{ western\_countries, }\StringTok{"Western"}\NormalTok{, }\StringTok{"Developing"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(. }\SpecialCharTok{\textasciitilde{}}\NormalTok{ group)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-319-1} \end{center}

We see that the daily GDP per capita has a distribution with higher values compared to developing countries. However, the picture in one year is not everything. We are ready to see if the separation was the same 40 years back from the date in the example (2010). We are also going to add the \texttt{geom\_histogram()} layer the color attribute to see the border of the bars which by default are grey.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{western\_countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Western Europe"}\NormalTok{, }\StringTok{"Northern Europe"}\NormalTok{, }\StringTok{"Southern Europe"}\NormalTok{, }\StringTok{"Northern America"}\NormalTok{, }\StringTok{"Australia and New Zealand"}\NormalTok{)}

\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{1970}\NormalTok{, }\DecValTok{2010}\NormalTok{) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{group =} \FunctionTok{ifelse}\NormalTok{(region }\SpecialCharTok{\%in\%}\NormalTok{ western\_countries, }\StringTok{"Western"}\NormalTok{, }\StringTok{"Developing"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(year }\SpecialCharTok{\textasciitilde{}}\NormalTok{ group)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-320-1} \end{center}

Both groups, both ``Western'' and ``Developing'' have improved in that 40-year span, but developing countries have advanced more than Western countries.

So far we have assumed something: that all countries that reported in 2010 also reported data in 1970. To make the comparison finer we have to look for the distribution of countries that have data reported both in 1970 and in 2010.

To do this, we are going to create a vector that lists the countries with data in 1970 and another of those that have data in 2010 and then look for the intersection. Remember that to extract a column we use the \texttt{pull()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{western\_countries }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Western Europe"}\NormalTok{, }\StringTok{"Northern Europe"}\NormalTok{, }\StringTok{"Southern Europe"}\NormalTok{, }\StringTok{"Northern America"}\NormalTok{, }\StringTok{"Australia and New Zealand"}\NormalTok{)}

\NormalTok{list\_1 }\OtherTok{\textless{}{-}}\NormalTok{ gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{1970}\NormalTok{) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(country)}

\NormalTok{list\_2 }\OtherTok{\textless{}{-}}\NormalTok{ gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{2010}\NormalTok{) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(country)}
\end{Highlighting}
\end{Shaded}

To find the intersection of these two vectors we will use the function \texttt{intersect(vector\_1,\ vector\_2)}, which will give us the vector we are looking for.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{intersection\_vector }\OtherTok{\textless{}{-}} \FunctionTok{intersect}\NormalTok{(list\_1, list\_2)}
\end{Highlighting}
\end{Shaded}

So, we recreate our histogram including only the countries on this list.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{1970}\NormalTok{, }\DecValTok{2010}\NormalTok{) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%}\NormalTok{ intersection\_vector) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{group =} \FunctionTok{ifelse}\NormalTok{(region }\SpecialCharTok{\%in\%}\NormalTok{ western\_countries, }\StringTok{"Western"}\NormalTok{, }\StringTok{"Developing"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(year }\SpecialCharTok{\textasciitilde{}}\NormalTok{ group)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-323-1} \end{center}

We see now more clearly with comparable data how there are more countries within the developing region that increased per capita GDP, and by a larger margin than Western countries. But this first inference is still visual, we need to compare how the median, range, etc. changed. For this we will use a box plot very similar to the previous one, but this time we will edit \texttt{geom\_boxplot()} so that it shows us in a single graph how each region has changed from 1970 to 2010.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp\_per\_capita\_per\_day =}\NormalTok{ gdp}\SpecialCharTok{/}\NormalTok{population}\SpecialCharTok{/}\DecValTok{365}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{1970}\NormalTok{, }\DecValTok{2010}\NormalTok{) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(gdp\_per\_capita\_per\_day)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%}\NormalTok{ intersection\_vector) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{region =} \FunctionTok{reorder}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{FUN =}\NormalTok{ median)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(region, gdp\_per\_capita\_per\_day, }\AttributeTok{fill=}\FunctionTok{factor}\NormalTok{(year))) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-324-1} \end{center}

We see how there are regions within Asia that have grown substantially. As we know from general culture, some countries in Asia are already powers, but today with these graphs we can understand well how much each region has changed until becoming a power.

Therefore, we can now answer both questions of the case:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  It is not reasonable to continue using the categorization of ``Western'' and ``developing'' since there are more and more regions that are poorly represented by those categories, such as East Asia.
\item
  It is not true that rich countries get richer while poor countries get poorer. We have seen that developing countries have even higher growth than the growth that Western countries have.
\end{enumerate}

\section{Exercises}\label{exercises-7}

For this series of exercises we will use the \texttt{stars} data frame from the \texttt{dslabs} library. This dataset contains attributes of stars including their temperature, spectral type, and magnitude. The \texttt{magnitude} column represents absolute magnitude---a measure of intrinsic brightness where more negative values indicate greater luminosity.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dslabs)}
\FunctionTok{data}\NormalTok{(stars)}
\FunctionTok{head}\NormalTok{(stars)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{58}
\tightlist
\item
  The temperature data is currently in Kelvin. Create a new column \texttt{temp\_celsius} using the formula \(C = K - 273.15\), then visualize the relationship between temperature and magnitude. Color the points by star type and use a base-10 logarithmic scale for the x-axis to better display the wide range of temperatures.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stars }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{temp\_celsius =}\NormalTok{ temp }\SpecialCharTok{{-}} \FloatTok{273.15}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(temp\_celsius, magnitude, }\AttributeTok{color =}\NormalTok{ type) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{59}
\tightlist
\item
  Since lower magnitude values correspond to higher brightness, reverse the y-axis scale using \texttt{scale\_y\_reverse()} to make the plot more intuitive (brighter stars at the top).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stars }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{temp\_celsius =}\NormalTok{ temp }\SpecialCharTok{{-}} \FloatTok{273.15}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(temp\_celsius, magnitude, }\AttributeTok{color =}\NormalTok{ type) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_reverse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{60}
\tightlist
\item
  The Sun is a G-type star. To determine if these are the most luminous, create a box plot comparing the magnitude distributions across different star types.
\end{enumerate}

No, G-type stars are not the most luminous. For this we can elaborate this graph:

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stars }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(type, magnitude) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_reverse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Key Takeaways}\label{key-takeaways-1}

In this chapter, we followed a complete \textbf{data exploration process}, starting with understanding the data structure before diving into visualization. We utilized \textbf{faceting} to reveal trends across categories and time, and used \textbf{time series} plots to track specific country trajectories. We also explored distributions using \textbf{histograms} and \textbf{box plots}, applying \textbf{scale transformations} to handle skewed economic data. Finally, we practiced \textbf{iterative refinement}, adjusting our plots step-by-step to tell a clearer story.

\part{Statistics}\label{part-statistics}

\chapter*{Introduction to Probabilities}\label{introduction-to-probabilities}


Understanding probability theory is indispensable for every Data Scientist.

In the following chapters we are going to learn how to apply probability theory in R. It is expected that the reader has basic knowledge in statistics given that we will not go into depth in each of the statistical concepts.

For example, we are not going to explain formulas for calculating probabilities of independent or dependent events. Instead, we are going to apply directly probabilities of independent or dependent events in R.

\chapter{Discrete Probabilities}\label{discrete-probabilities}

We will start with some basic principles of categorical data. Probabilities of this type are called discrete probabilities. Understanding the basic principles of discrete probabilities will help us understand continuous probabilities which are the most common in data science applications.

In this chapter, we will master the foundations of discrete probability. We will start by calculating probabilities using mathematical definitions and then learn to estimate them using Monte Carlo simulations. We will leverage R functions like \texttt{sample()}, \texttt{replicate()}, and \texttt{mean()} to model random events, and use the \texttt{gtools} package to solve problems involving permutations and combinations. Finally, we will determine how to choose an adequate sample size to ensure our simulations yield reliable results.

Recall that a discrete variable is a variable that cannot take some values within a minimum countable set, that is, it does not accept any value, only those that belong to the set.

For example, if we have 4 women and 6 men seated in a room and we were to raffle 1 prize, intuitively we would know that the probability that the winner is a man is 60\%.

\section{Calculation using the mathematical definition}\label{calculation-using-the-mathematical-definition}

The probability we obtained by intuition in the previous example can be expressed as follows:

\(P(A) = probability\ of\ event\ A = \frac{Times\ event\ A\ can\ occur}{Total\ possible\ outcomes}\)

\(P(Winner\ is\ man) = \frac{6}{10} = 60\%\)

\section{Monte Carlo Simulation for Discrete Variables}\label{monte-carlo-simulation-for-discrete-variables}

Monte Carlo simulation or method is a statistical method used to solve complex mathematical problems through the generation of random variables. In this case the problem is not complex, but Monte Carlo can be used to familiarize ourselves with a method that we will use constantly.

We will use Monte Carlo simulation to estimate the proportion we would obtain if we repeated this experiment randomly a determined number of times. That is, the probability of the event using this estimation would be the proportion of times that event occurred in our simulation.

In R we can easily create random samples using the \texttt{sample()} function. For example, let's create a vector of students and then use the \texttt{sample()} function to choose one at random.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{students }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"woman"}\NormalTok{, }\StringTok{"woman"}\NormalTok{, }\StringTok{"woman"}\NormalTok{, }\StringTok{"woman"}\NormalTok{, }\StringTok{"man"}\NormalTok{, }
                 \StringTok{"man"}\NormalTok{, }\StringTok{"man"}\NormalTok{, }\StringTok{"man"}\NormalTok{, }\StringTok{"man"}\NormalTok{, }\StringTok{"man"}\NormalTok{)}

\FunctionTok{sample}\NormalTok{(students, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We could also use the \texttt{rep()} function to create the \texttt{students} vector faster. To do this we would enter as the first argument a vector and as the second another vector indicating how many times we want them to be created. Thus, we would create the students vector faster.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{students }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"woman"}\NormalTok{, }\StringTok{"man"}\NormalTok{), }\AttributeTok{times =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{))}

\NormalTok{students}
\CommentTok{\#\textgreater{}  [1] "woman" "woman" "woman" "woman" "man"   "man"   "man"   "man"   "man"  }
\CommentTok{\#\textgreater{} [10] "man"}
\end{Highlighting}
\end{Shaded}

Now we have to simulate a determined number of times the experiment of picking a random element. For this we will use the \texttt{replicate()} function. Let's replicate this experiment 100 times:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{students }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"woman"}\NormalTok{, }\StringTok{"man"}\NormalTok{), }\AttributeTok{times =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{))}

\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
  \FunctionTok{sample}\NormalTok{(students, }\DecValTok{1}\NormalTok{)}
\NormalTok{  \})}

\NormalTok{results}
\CommentTok{\#\textgreater{}   [1] "man"   "man"   "man"   "man"   "man"   "man"   "man"   "man"   "man"  }
\CommentTok{\#\textgreater{}  [10] "man"   "woman" "woman" "woman" "man"   "woman" "man"   "man"   "man"  }
\CommentTok{\#\textgreater{}  [19] "man"   "man"   "man"   "man"   "woman" "man"   "woman" "woman" "man"  }
\CommentTok{\#\textgreater{}  [28] "man"   "man"   "woman" "man"   "man"   "man"   "man"   "man"   "woman"}
\CommentTok{\#\textgreater{}  [37] "man"   "woman" "man"   "man"   "man"   "woman" "woman" "woman" "man"  }
\CommentTok{\#\textgreater{}  [46] "woman" "woman" "man"   "woman" "woman" "man"   "woman" "woman" "man"  }
\CommentTok{\#\textgreater{}  [55] "woman" "man"   "man"   "woman" "man"   "woman" "man"   "woman" "woman"}
\CommentTok{\#\textgreater{}  [64] "man"   "woman" "man"   "man"   "man"   "woman" "woman" "woman" "woman"}
\CommentTok{\#\textgreater{}  [73] "woman" "man"   "woman" "woman" "man"   "man"   "man"   "man"   "man"  }
\CommentTok{\#\textgreater{}  [82] "woman" "man"   "man"   "man"   "woman" "woman" "man"   "woman" "man"  }
\CommentTok{\#\textgreater{}  [91] "man"   "man"   "man"   "man"   "man"   "man"   "woman" "man"   "woman"}
\CommentTok{\#\textgreater{} [100] "man"}
\end{Highlighting}
\end{Shaded}

We can see what the result was for each of the 100 draws we simulated.

Now we will use the \texttt{table()} function to transform our \texttt{results} vector into a summary table that shows us how many times each value appeared.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(results)}
\CommentTok{\#\textgreater{} results}
\CommentTok{\#\textgreater{}   man woman }
\CommentTok{\#\textgreater{}    62    38}
\end{Highlighting}
\end{Shaded}

If we store this result in a vector \texttt{results\_table}, we can then use the \texttt{prop.table()} function to know the proportion of each value:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results\_table }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(results)}

\FunctionTok{prop.table}\NormalTok{(results\_table)}
\CommentTok{\#\textgreater{} results}
\CommentTok{\#\textgreater{}   man woman }
\CommentTok{\#\textgreater{}  0.62  0.38}
\end{Highlighting}
\end{Shaded}

We should not worry if the probability that it is a man has not come out exactly 60\%. Recall that we are estimating the probability using a method that depends on the number of times we simulate the experiment. The more times we repeat the experiment the closer we will be to the value. For example, let's replicate this experiment now 10,000 times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{students }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"woman"}\NormalTok{, }\StringTok{"man"}\NormalTok{), }\AttributeTok{times =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{))}

\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
  
  \FunctionTok{sample}\NormalTok{(students, }\DecValTok{1}\NormalTok{)}

\NormalTok{  \})}

\NormalTok{results\_table }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(results)}

\FunctionTok{prop.table}\NormalTok{(results\_table)}
\CommentTok{\#\textgreater{} results}
\CommentTok{\#\textgreater{}    man  woman }
\CommentTok{\#\textgreater{} 0.5898 0.4102}
\end{Highlighting}
\end{Shaded}

We see how the value converges to 60\%. We should not worry if the value varies by a few digits from the one presented in this book given that we are simulating a random event.

Finally, for this simple example we could also have used the \texttt{mean()} function. Although this calculates the average of a set of numbers, we could convert our \texttt{students} vector to numerical values, where each value is converted to 1 or 0 depending on some condition.

To do this, R makes the conversion of vectors to 1 and 0 very simple using the comparator operator \texttt{==}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{students }\SpecialCharTok{==} \StringTok{"man"}
\CommentTok{\#\textgreater{}  [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE}
\end{Highlighting}
\end{Shaded}

When we apply the \texttt{mean()} function to this result, it coerces \texttt{TRUE} values to \texttt{1} and \texttt{FALSE} values to \texttt{0}. Thus, if we apply the average of this list, we would have the percentage of men and with it the probability that when choosing a person it is a man:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(students }\SpecialCharTok{==} \StringTok{"man"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.6}
\end{Highlighting}
\end{Shaded}

\subsection{Other functions to create vectors}\label{other-functions-to-create-vectors}

We have already learned the \texttt{rep()} function to create vectors faster. Another function we find in R is the \texttt{expand.grid(x,\ y)} function which creates a data frame of all combinations between vectors \texttt{x} and \texttt{y}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{greetings }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Hello"}\NormalTok{, }\StringTok{"Goodbye"}\NormalTok{)}
\NormalTok{names\_list }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Andrew"}\NormalTok{, }\StringTok{"Joseph"}\NormalTok{, }\StringTok{"John"}\NormalTok{, }\StringTok{"Emily"}\NormalTok{, }\StringTok{"Cesar"}\NormalTok{, }\StringTok{"Jeremy"}\NormalTok{)}

\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{greeting =}\NormalTok{ greetings, }\AttributeTok{name =}\NormalTok{ names\_list)}
\NormalTok{result}
\CommentTok{\#\textgreater{}    greeting   name}
\CommentTok{\#\textgreater{} 1     Hello Andrew}
\CommentTok{\#\textgreater{} 2   Goodbye Andrew}
\CommentTok{\#\textgreater{} 3     Hello Joseph}
\CommentTok{\#\textgreater{} 4   Goodbye Joseph}
\CommentTok{\#\textgreater{} 5     Hello   John}
\CommentTok{\#\textgreater{} 6   Goodbye   John}
\CommentTok{\#\textgreater{} 7     Hello  Emily}
\CommentTok{\#\textgreater{} 8   Goodbye  Emily}
\CommentTok{\#\textgreater{} 9     Hello  Cesar}
\CommentTok{\#\textgreater{} 10  Goodbye  Cesar}
\CommentTok{\#\textgreater{} 11    Hello Jeremy}
\CommentTok{\#\textgreater{} 12  Goodbye Jeremy}
\end{Highlighting}
\end{Shaded}

Finally, we have the \texttt{paste(x,y)} function, which concatenates two strings or vectors of strings adding a space in the middle.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{paste}\NormalTok{(result}\SpecialCharTok{$}\NormalTok{greeting, result}\SpecialCharTok{$}\NormalTok{name)}
\CommentTok{\#\textgreater{}  [1] "Hello Andrew"   "Goodbye Andrew" "Hello Joseph"   "Goodbye Joseph"}
\CommentTok{\#\textgreater{}  [5] "Hello John"     "Goodbye John"   "Hello Emily"    "Goodbye Emily" }
\CommentTok{\#\textgreater{}  [9] "Hello Cesar"    "Goodbye Cesar"  "Hello Jeremy"   "Goodbye Jeremy"}
\end{Highlighting}
\end{Shaded}

Thus, we can easily generate, for example, a deck of cards distributed in 4 suits: hearts, diamonds, spades, and clubs. The cards of each suit are numbered from 1 to 10, where 1 is the Ace, and followed by Jack, Queen, and King.

To do this, we would have to create a vector of suits and a vector of numbers to then create the combinationl and have the complete deck.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numbers }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Ace"}\NormalTok{, }\StringTok{"Two"}\NormalTok{, }\StringTok{"Three"}\NormalTok{, }\StringTok{"Four"}\NormalTok{, }\StringTok{"Five"}\NormalTok{, }\StringTok{"Six"}\NormalTok{, }\StringTok{"Seven"}\NormalTok{, }
             \StringTok{"Eight"}\NormalTok{, }\StringTok{"Nine"}\NormalTok{, }\StringTok{"Ten"}\NormalTok{, }\StringTok{"Jack"}\NormalTok{, }\StringTok{"Queen"}\NormalTok{, }\StringTok{"King"}\NormalTok{)}
\NormalTok{suits }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"of Hearts"}\NormalTok{, }\StringTok{"of Diamonds"}\NormalTok{, }\StringTok{"of Spades"}\NormalTok{, }\StringTok{"of Clubs"}\NormalTok{)}

\CommentTok{\# Create card combinations}
\NormalTok{combination }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{number =}\NormalTok{ numbers, }\AttributeTok{suit =}\NormalTok{ suits)}

\CommentTok{\# Concatenate vectors to have our final combination}
\FunctionTok{paste}\NormalTok{(combination}\SpecialCharTok{$}\NormalTok{number, combination}\SpecialCharTok{$}\NormalTok{suit)}
\CommentTok{\#\textgreater{}  [1] "Ace of Hearts"     "Two of Hearts"     "Three of Hearts"  }
\CommentTok{\#\textgreater{}  [4] "Four of Hearts"    "Five of Hearts"    "Six of Hearts"    }
\CommentTok{\#\textgreater{}  [7] "Seven of Hearts"   "Eight of Hearts"   "Nine of Hearts"   }
\CommentTok{\#\textgreater{} [10] "Ten of Hearts"     "Jack of Hearts"    "Queen of Hearts"  }
\CommentTok{\#\textgreater{} [13] "King of Hearts"    "Ace of Diamonds"   "Two of Diamonds"  }
\CommentTok{\#\textgreater{} [16] "Three of Diamonds" "Four of Diamonds"  "Five of Diamonds" }
\CommentTok{\#\textgreater{} [19] "Six of Diamonds"   "Seven of Diamonds" "Eight of Diamonds"}
\CommentTok{\#\textgreater{} [22] "Nine of Diamonds"  "Ten of Diamonds"   "Jack of Diamonds" }
\CommentTok{\#\textgreater{} [25] "Queen of Diamonds" "King of Diamonds"  "Ace of Spades"    }
\CommentTok{\#\textgreater{} [28] "Two of Spades"     "Three of Spades"   "Four of Spades"   }
\CommentTok{\#\textgreater{} [31] "Five of Spades"    "Six of Spades"     "Seven of Spades"  }
\CommentTok{\#\textgreater{} [34] "Eight of Spades"   "Nine of Spades"    "Ten of Spades"    }
\CommentTok{\#\textgreater{} [37] "Jack of Spades"    "Queen of Spades"   "King of Spades"   }
\CommentTok{\#\textgreater{} [40] "Ace of Clubs"      "Two of Clubs"      "Three of Clubs"   }
\CommentTok{\#\textgreater{} [43] "Four of Clubs"     "Five of Clubs"     "Six of Clubs"     }
\CommentTok{\#\textgreater{} [46] "Seven of Clubs"    "Eight of Clubs"    "Nine of Clubs"    }
\CommentTok{\#\textgreater{} [49] "Ten of Clubs"      "Jack of Clubs"     "Queen of Clubs"   }
\CommentTok{\#\textgreater{} [52] "King of Clubs"}
\end{Highlighting}
\end{Shaded}

Once our deck is created we can inquire some probabilities easily with the created vector.

Let's calculate the probability that when choosing a card it is ``King of Diamonds'':

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Store the combinationl in the variable deck}
\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(combination}\SpecialCharTok{$}\NormalTok{number, combination}\SpecialCharTok{$}\NormalTok{suit)}

\FunctionTok{mean}\NormalTok{(deck }\SpecialCharTok{==} \StringTok{"King of Diamonds"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.01923077}
\end{Highlighting}
\end{Shaded}

Or we can also calculate the probability that when choosing a card it is some Queen:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First create the vector of "Queen of..."}
\NormalTok{queens }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"Queen"}\NormalTok{, suits)}

\CommentTok{\# Probability calculation}
\FunctionTok{mean}\NormalTok{(deck }\SpecialCharTok{\%in\%}\NormalTok{ queens)}
\CommentTok{\#\textgreater{} [1] 0.07692308}
\end{Highlighting}
\end{Shaded}

This chapter highlighted two complementary approaches to probability. The \textbf{mathematical definition} (\(P(A) = \frac{\text{favorable outcomes}}{\text{total outcomes}}\)) gives us exact answers for simple problems. However, for more complex scenarios, \textbf{Monte Carlo simulation} allows us to estimate probabilities by replicating experiments thousands of times using \texttt{sample()} and \texttt{replicate()}. We learned that \texttt{mean(condition)} is an efficient way to calculate proportions in R, and that increasing the number of repetitions brings our simulation estimates closer to the true theoretical probability.

\section{Exercises}\label{exercises-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{61}
\tightlist
\item
  Calculate the probability of \textbf{not} rolling a 1 on a single die roll and store it in a variable named \texttt{prob}. Then, use this variable to determine the probability that the number 1 does not appear in three consecutive rolls.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob }\OtherTok{\textless{}{-}} \DecValTok{5} \SpecialCharTok{/} \DecValTok{6}

\NormalTok{prob }\SpecialCharTok{*}\NormalTok{ prob }\SpecialCharTok{*}\NormalTok{ prob}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{62}
\tightlist
\item
  Imagine a container holding 5 blue, 3 yellow, and 4 gray marbles. Determine the probability that a marble chosen at random is blue.
\end{enumerate}

\begin{center}\includegraphics[width=200pt,alt={Container with colored marbles: 5 blue, 3 yellow, and 4 gray}]{assets/images/04-statistics/probabilities-marbles} \end{center}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{marbles }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"yellow"}\NormalTok{, }\StringTok{"gray"}\NormalTok{), }\AttributeTok{times =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{))}

\CommentTok{\# Solution using monte carlo simulation, repeating the event 10,000 times:}
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{10000}\NormalTok{, \{}
  
  \FunctionTok{sample}\NormalTok{(marbles, }\DecValTok{1}\NormalTok{)}
  
\NormalTok{  \})}

\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(results))}

\CommentTok{\# Solution using the \textasciigrave{}mean()\textasciigrave{} function:}
\FunctionTok{mean}\NormalTok{(marbles }\SpecialCharTok{==} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Mathematically it would be:

Given the event: \(X = chosen\ marble\ is\ blue\):

\(P(X)=\frac{5}{5+3+4}=\frac{5}{12}=41.67\%\)

The probability that the marble is blue is 41.67\%.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{63}
\tightlist
\item
  Using the same container of marbles, calculate the probability that a randomly chosen marble is \textbf{not} blue.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{marbles }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"yellow"}\NormalTok{, }\StringTok{"gray"}\NormalTok{), }\AttributeTok{times =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{))}

\FunctionTok{mean}\NormalTok{(marbles }\SpecialCharTok{!=} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The probability is 58.33\%.

Mathematically it would be:

Given the event \(X = chosen\ marble\ is\ blue\):

\(P(\sim~X)=1-P(X)=1-\frac{5}{12}=1-41.67\%=58.33\%\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{64}
\tightlist
\item
  Consider drawing two marbles from the container in sequence without replacing the first one. Calculate the probability that the first marble is blue and the second is \textbf{not} blue. Create numeric variables for each color count to perform this calculation.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create variables}
\NormalTok{blue }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{yellow }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{gray }\OtherTok{\textless{}{-}} \DecValTok{4}

\CommentTok{\# Calculate probability that the first marble is blue:}
\NormalTok{p\_1 }\OtherTok{\textless{}{-}}\NormalTok{ blue }\SpecialCharTok{/}\NormalTok{ (blue }\SpecialCharTok{+}\NormalTok{ yellow }\SpecialCharTok{+}\NormalTok{ gray)}

\CommentTok{\# First calculate the probability that the second is blue:}
\NormalTok{p\_aux }\OtherTok{\textless{}{-}}\NormalTok{ (blue }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (blue }\SpecialCharTok{{-}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ yellow }\SpecialCharTok{+}\NormalTok{ gray)}

\CommentTok{\# Calculate the complement because they ask that the second is NOT blue:}
\NormalTok{p\_2 }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_aux}

\CommentTok{\# Calculate what is asked:}
\NormalTok{p\_1 }\SpecialCharTok{*}\NormalTok{ p\_2}
\end{Highlighting}
\end{Shaded}

This is called \textbf{sampling without replacement}. We have two events, we are taking out two marbles. The second event depends on the first. These two events are not independent of each other.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{65}
\tightlist
\item
  Repeat the previous experiment, but this time \textbf{replace} the first marble before drawing the second one. Update your R code to calculate the probability that the first marble is blue and the second is \textbf{not} blue under these conditions.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create variables}
\NormalTok{blue }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{yellow }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{gray }\OtherTok{\textless{}{-}} \DecValTok{4}

\CommentTok{\# Calculate probability that the first marble is blue:}
\NormalTok{p\_1 }\OtherTok{\textless{}{-}}\NormalTok{ blue }\SpecialCharTok{/}\NormalTok{ (blue }\SpecialCharTok{+}\NormalTok{ yellow }\SpecialCharTok{+}\NormalTok{ gray)}

\CommentTok{\# First calculate the probability that the second is blue:}
\NormalTok{p\_aux }\OtherTok{\textless{}{-}}\NormalTok{ blue }\SpecialCharTok{/}\NormalTok{ (blue }\SpecialCharTok{+}\NormalTok{ yellow }\SpecialCharTok{+}\NormalTok{ gray)}

\CommentTok{\# Calculate the complement because they ask that the second is NOT blue:}
\NormalTok{p\_2 }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_aux}

\CommentTok{\# Calculate what is asked:}
\NormalTok{p\_1 }\SpecialCharTok{*}\NormalTok{ p\_2}
\end{Highlighting}
\end{Shaded}

This is called \textbf{sampling with replacement}. We have two events, we are taking out two marbles again. The second event does \textbf{not} depend on the first. These two events are independent.

\section{Combinations and Permutations}\label{combinations-and-permutations}

Some probability situations involve multiple events. When one of the events affects others, they are called dependent events. For example, when objects are chosen from a list or group and are not returned, the first choice reduces the options for future choices.

There are two ways to order or combine results of dependent events. \textbf{Permutations} are groupings in which the order of objects matters. \textbf{Combinations} are groupings in which the content matters but the order does not.

For this we will use the \texttt{gtools} package, which includes libraries like \texttt{gtools} that provide us with intuitive functionalities to work with permutations and combinations.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First install the gtools package}
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"gtools"}\NormalTok{)}

\CommentTok{\# To start using it, load the gtools library}
\FunctionTok{library}\NormalTok{(gtools)}
\end{Highlighting}
\end{Shaded}

\subsection{Permutations}\label{permutations}

The order matters when we calculate, for example, the winners of a competition. Suppose we have 10 students who are competing on equal terms for who builds the most accurate machine learning model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_scientists }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Jenny"}\NormalTok{, }\StringTok{"Freddy"}\NormalTok{, }\StringTok{"Yasan"}\NormalTok{, }\StringTok{"Iver"}\NormalTok{, }\StringTok{"Pamela"}\NormalTok{, }\StringTok{"Alexandra"}\NormalTok{, }
                     \StringTok{"Bladimir"}\NormalTok{, }\StringTok{"Enrique"}\NormalTok{, }\StringTok{"Karen"}\NormalTok{, }\StringTok{"Christiam"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Only the top 3 will receive the prize. In this case the order matters, so we will use the function \texttt{permutations(total,\ selection,\ data)} where \texttt{total} indicates the size of the vector, \texttt{selection} indicates the size of the result I want, and finally \texttt{data} is my source vector.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{permutations}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{, }\AttributeTok{v =}\NormalTok{ data\_scientists)}
\end{Highlighting}
\end{Shaded}

We have already calculated all possible results. We can calculate on this result the probability that Freddy wins the competition and that Pamela is in second place.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{permutations}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{, }\AttributeTok{v =}\NormalTok{ data\_scientists)}

\CommentTok{\# Total results: nrow(results)}
\NormalTok{total }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(results)}

\CommentTok{\# Probability that Freddy wins:}
\FunctionTok{mean}\NormalTok{(results[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Freddy"} \SpecialCharTok{\&}\NormalTok{ results[, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Pamela"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.01111111}
\end{Highlighting}
\end{Shaded}

\subsection{Combinations}\label{combinations}

The order does not matter when, for example, we form groups of 2 to participate in the competition.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{combinations}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{, }\AttributeTok{v =}\NormalTok{ data\_scientists)}
\end{Highlighting}
\end{Shaded}

If now only one team is going to win the prize, we could calculate the probability that the team made up of Pamela and Enrique are the ones who win.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{combinations}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{, }\AttributeTok{v =}\NormalTok{ data\_scientists)}

\CommentTok{\# Total results:}
\FunctionTok{nrow}\NormalTok{(results)}
\CommentTok{\#\textgreater{} [1] 45}

\CommentTok{\# Probability:}
\FunctionTok{mean}\NormalTok{((results[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Pamela"} \SpecialCharTok{\&}\NormalTok{ results[, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Enrique"}\NormalTok{) }\SpecialCharTok{|} 
\NormalTok{     (results[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Enrique"} \SpecialCharTok{\&}\NormalTok{ results[, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Pamela"}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 0.02222222}
\end{Highlighting}
\end{Shaded}

Although we can obtain the probability by calculating all combinations, in R it will be very frequent to use Monte Carlo to estimate the probability by simulation. For the previous case we would not have to generate all combinations, but simply take a sample of two people who would be the members of the winning team. Recall that we have assumed that everyone has equal chances of winning.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(data\_scientists, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Then, we would have to replicate this experiment over and over again, store the sampling results and calculate the proportion of how many times the winning team was composed of Pamela and Enrique.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10000}

\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n, \{}
\NormalTok{      team }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(data\_scientists, }\DecValTok{2}\NormalTok{)}
      
\NormalTok{      meets\_condition }\OtherTok{\textless{}{-}}\NormalTok{ (team[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Pamela"} \SpecialCharTok{\&}\NormalTok{ team[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Enrique"}\NormalTok{) }\SpecialCharTok{|} 
\NormalTok{                          (team[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Pamela"} \SpecialCharTok{\&}\NormalTok{ team[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Enrique"}\NormalTok{)}
      
\NormalTok{      meets\_condition}
\NormalTok{\})}

\FunctionTok{mean}\NormalTok{(result)}
\CommentTok{\#\textgreater{} [1] 0.022}
\end{Highlighting}
\end{Shaded}

Note that, as we saw previously, the value converges as we increase the number of times we repeat the experiment \texttt{n}. We have simulated repeating the experiment 10 thousand times. However, how many times would it be necessary to replicate the experiment to trust the results of the simulation?

\section{Sufficient Experiments with Monte Carlo Simulation}\label{sufficient-experiments-with-monte-carlo-simulation}

Intuitively we can indicate that the greater the number of experiments the more precise the estimated probability. We can, thus, do several simulations with different number of experiments for each simulation. In this way we could find a reasonable number of experiments for our simulation. To do this, first we create a numerical vector where the number of times we are going to simulate the experiment is indicated. Our vector will contain the following values: 10, 20, 40, 80, 160,\ldots, etc. This means that the first time we will simulate the experiment 10 times, the second 20 times and so on.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10}\SpecialCharTok{*}\DecValTok{2}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{17}\NormalTok{)}
\NormalTok{n\_times}
\CommentTok{\#\textgreater{}  [1]      20      40      80     160     320     640    1280    2560    5120}
\CommentTok{\#\textgreater{} [10]   10240   20480   40960   81920  163840  327680  655360 1310720}
\end{Highlighting}
\end{Shaded}

Then, we use the code we created to replicate the experiment to create a function called \texttt{probability\_by\_sample}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probability\_by\_sample }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
\NormalTok{  result }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n, \{}
\NormalTok{    team }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(data\_scientists, }\DecValTok{2}\NormalTok{)}
    
\NormalTok{    meets\_condition }\OtherTok{\textless{}{-}}\NormalTok{ (team[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Pamela"} \SpecialCharTok{\&}\NormalTok{ team[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Enrique"}\NormalTok{) }\SpecialCharTok{|} 
\NormalTok{                        (team[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Pamela"} \SpecialCharTok{\&}\NormalTok{ team[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==} \StringTok{"Enrique"}\NormalTok{)}
    
\NormalTok{    meets\_condition}
\NormalTok{  \})}
  
  \FunctionTok{mean}\NormalTok{(result)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We already have a function that allows us to replicate the experiment as many times as we want. For example, in the previous section we simulated 10 thousand experiments. Now that we have created the function we would do:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Probability using functions:}
\FunctionTok{probability\_by\_sample}\NormalTok{(}\DecValTok{10000}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.0229}
\end{Highlighting}
\end{Shaded}

Again, this is a simulation. So every time we execute that function the probability will vary as it is a random sample.

To apply a function on each of the values of a vector we use the function \texttt{sapply(vector,\ function)} where \texttt{vector} is the vector where the data on which I want to apply the function is and \texttt{function} is the function I want to apply.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(n\_times, probability\_by\_sample)}

\NormalTok{prob}
\CommentTok{\#\textgreater{}  [1] 0.00000000 0.05000000 0.03750000 0.02500000 0.02812500 0.02812500}
\CommentTok{\#\textgreater{}  [7] 0.02187500 0.02382812 0.02402344 0.02148438 0.02011719 0.02253418}
\CommentTok{\#\textgreater{} [13] 0.02163086 0.02171631 0.02195129 0.02239075 0.02221298}
\end{Highlighting}
\end{Shaded}

This gives us the probabilities depending on the number of times we repeat the experiment. Now let's place these results in a scatter plot to see how it converges

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probabilities }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{n =}\NormalTok{ n\_times,}
  \AttributeTok{probability =}\NormalTok{ prob}
\NormalTok{)}

\NormalTok{probabilities }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(n, probability) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"\# of times of the experiment"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-369-1} \end{center}

We can also change the scale to zoom in on the probabilities for smaller experiment number values and add a reference line with the theoretical probability value calculated previously:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probabilities }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(n, probability) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"\# of times of the experiment"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{trans =} \StringTok{"log2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \FloatTok{0.022222}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-370-1} \end{center}

We observe that, for this experiment, repeating the experiment 10 thousand times (x-axis = 3 because it is \(10^3\)) already gives us a good approximation to the real value.

\section{Case: Birthdays in Classrooms}\label{case-birthdays-in-classrooms}

Let's review the concepts learned with another example. In a \emph{Data Science for Managers} class there are 50 students. Using Monte Carlo simulation, let's estimate what is the probability that there are at least two people who have birthdays on the same day. (Let's ignore those who have birthdays on February 29).

First let's list all the days of the year available for birthdays:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{days }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{365}
\end{Highlighting}
\end{Shaded}

Let's generate a random sample of 50 numbers from the \texttt{days} vector, but this time with replacement because a person could have the same day, and store it in the \texttt{colleagues} variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colleagues }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(days, }\DecValTok{50}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To validate if any of the values are repeated we will use the \texttt{duplicated()} function which validates if there are duplicate values within the vector:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{duplicated}\NormalTok{(colleagues)}
\CommentTok{\#\textgreater{}  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE}
\CommentTok{\#\textgreater{} [13] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE}
\CommentTok{\#\textgreater{} [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE}
\CommentTok{\#\textgreater{} [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE}
\CommentTok{\#\textgreater{} [49] FALSE FALSE}
\end{Highlighting}
\end{Shaded}

Finally, to determine if there was any \texttt{TRUE} value we use the \texttt{any()} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{any}\NormalTok{(}\FunctionTok{duplicated}\NormalTok{(colleagues))}
\CommentTok{\#\textgreater{} [1] TRUE}
\end{Highlighting}
\end{Shaded}

The result tells us whether it is true or not that there are at least two people who have birthdays on the same day. To estimate by Monte Carlo simulation what the probability is, we have to repeat the experiment many times and take the proportion of how many times we get \texttt{TRUE} as a result.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Monte Carlo simulation with 10 thousand repetitions}
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{    }
    
\NormalTok{    colleagues }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(days, }\DecValTok{50}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
    
    \CommentTok{\# Returns a logical value of whether there are duplicates}
    \FunctionTok{any}\NormalTok{(}\FunctionTok{duplicated}\NormalTok{(colleagues))}
\NormalTok{\})}

\CommentTok{\# Probability:}
\FunctionTok{mean}\NormalTok{(results) }
\CommentTok{\#\textgreater{} [1] 0.9723}
\end{Highlighting}
\end{Shaded}

We see that the estimated probability is very high, above 95\%. What would happen if I have a room of 25 people?

To do this, we modify the previous code and create the variable \texttt{classroom} which will indicate the number of students in that class:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Monte Carlo simulation with 10 thousand repetitions}
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{classroom }\OtherTok{\textless{}{-}} \DecValTok{25}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{    }\CommentTok{\# Returns a logical vector}
\NormalTok{    colleagues }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(days, classroom, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
    \FunctionTok{any}\NormalTok{(}\FunctionTok{duplicated}\NormalTok{(colleagues))}
\NormalTok{\})}

\CommentTok{\# Probability:}
\FunctionTok{mean}\NormalTok{(results) }
\CommentTok{\#\textgreater{} [1] 0.5685}
\end{Highlighting}
\end{Shaded}

Let's now create the function \texttt{estimate\_probability} and estimate using this function the probability of finding at least two people with the same birthday in a room of 25 people. This time we have to specify that the sampling is with ``replacement'' because by default the \texttt{sample()} function is ``without replacement''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create the function}
\NormalTok{estimate\_probability }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(classroom, }\AttributeTok{n\_times =} \DecValTok{10000}\NormalTok{)\{}
\NormalTok{    results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{    }\CommentTok{\# Returns a logical vector}
\NormalTok{        colleagues }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(days, classroom, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
        \FunctionTok{any}\NormalTok{(}\FunctionTok{duplicated}\NormalTok{(colleagues))}
\NormalTok{    \})}

    \CommentTok{\# Probability:}
    \FunctionTok{mean}\NormalTok{(results) }
\NormalTok{\}}

\FunctionTok{estimate\_probability}\NormalTok{(}\DecValTok{25}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.5627}
\end{Highlighting}
\end{Shaded}

Finally, if we already have a function that calculates based on the number of people in a room we can create a numerical vector with the total number of people from different rooms and then apply the function we have created. The result can be stored in the variable \texttt{prob}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create 80 different classrooms}
\CommentTok{\# The first room with 1 person, the last room with 80 people}
\NormalTok{classrooms }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{80}

\CommentTok{\# Estimate probability depending on the number of students per room}
\NormalTok{prob }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(classrooms, estimate\_probability)}

\NormalTok{prob}
\CommentTok{\#\textgreater{}  [1] 0.0000 0.0024 0.0092 0.0173 0.0270 0.0400 0.0557 0.0689 0.0937 0.1158}
\CommentTok{\#\textgreater{} [11] 0.1389 0.1697 0.2015 0.2266 0.2554 0.2855 0.3120 0.3508 0.3739 0.4134}
\CommentTok{\#\textgreater{} [21] 0.4394 0.4832 0.5113 0.5348 0.5654 0.5975 0.6256 0.6533 0.6796 0.6991}
\CommentTok{\#\textgreater{} [31] 0.7223 0.7498 0.7672 0.7900 0.8092 0.8303 0.8479 0.8663 0.8760 0.8911}
\CommentTok{\#\textgreater{} [41] 0.9048 0.9140 0.9229 0.9327 0.9355 0.9482 0.9577 0.9596 0.9627 0.9703}
\CommentTok{\#\textgreater{} [51] 0.9753 0.9762 0.9804 0.9835 0.9859 0.9889 0.9895 0.9923 0.9927 0.9947}
\CommentTok{\#\textgreater{} [61] 0.9938 0.9949 0.9952 0.9969 0.9970 0.9980 0.9985 0.9987 0.9992 0.9992}
\CommentTok{\#\textgreater{} [71] 0.9995 0.9991 0.9997 0.9997 0.9999 0.9997 0.9996 1.0000 1.0000 0.9999}
\end{Highlighting}
\end{Shaded}

Thus, if we place it in a scatter plot we can see how the probability increases as there are more students:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probabilities }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{n =}\NormalTok{ classrooms,}
  \AttributeTok{probability =}\NormalTok{ prob}
\NormalTok{)}

\NormalTok{probabilities }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(n, probability) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Number of students in each class"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-379-1} \end{center}

We can now impress our friends from different groups by telling them that, if they are in a room of 60 people, ``you can bet them'' that there are two people in that room who have birthdays on the same day. It is not definitive, but the chances are very much in our favor.

\section{Exercises}\label{exercises-9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{66}
\tightlist
\item
  Alonso and Georgina play chess, and Georgina has a 60\% chance of winning any given game. \textbf{Without using a simulation}, calculate the probability that Alonso wins at least one game out of four played.
\end{enumerate}

Solution

Calculating the probability that Alonso has won at least once is the complement of the probability that Georgina has won all 4 times. Thus, we will first calculate the probability that Georgina has always won and then calculate the complement.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Probability that Georgina wins all 4 games}
\NormalTok{prob }\OtherTok{\textless{}{-}} \FloatTok{0.6}\SpecialCharTok{\^{}}\DecValTok{4}

\CommentTok{\# Probability that Alonso wins at least once}
\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{67}
\tightlist
\item
  Now, estimate the probability of Alonso winning at least one of four games using a Monte Carlo simulation. Assume Alonso has a 40\% chance of winning each individual match.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{game\_results }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"loses"}\NormalTok{,}\StringTok{"wins"}\NormalTok{), }\DecValTok{4}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Times I run the simulation}
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}

\CommentTok{\# Generate result of experiments that Alonso wins}
\NormalTok{alonso\_wins }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{    game\_results }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"loses"}\NormalTok{,}\StringTok{"wins"}\NormalTok{), }\DecValTok{4}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.4}\NormalTok{))}
    \FunctionTok{any}\NormalTok{(game\_results }\SpecialCharTok{==} \StringTok{"wins"}\NormalTok{)}
\NormalTok{\})}

\CommentTok{\# Estimate probability}
\FunctionTok{mean}\NormalTok{(alonso\_wins)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{68}
\tightlist
\item
  Generalize the previous simulation by creating a function \texttt{probability\_of\_winning} that accepts Alonso's win probability \texttt{p} as an argument. Use this function to simulate outcomes for a sequence of win probabilities from 0.4 to 0.95 (steps of 0.025) and visualize the results in a scatter plot.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create function}
\NormalTok{probability\_of\_winning }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(p)\{}
\NormalTok{  n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}
  
\NormalTok{  alonso\_wins }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{      game\_results }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"loses"}\NormalTok{,}\StringTok{"wins"}\NormalTok{), }\DecValTok{4}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p, p))}
      \FunctionTok{any}\NormalTok{(game\_results }\SpecialCharTok{==} \StringTok{"wins"}\NormalTok{)}
\NormalTok{  \})}
  
  \FunctionTok{mean}\NormalTok{(alonso\_wins)}

\NormalTok{\}}

\CommentTok{\# Create vector with different probabilities}
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.95}\NormalTok{, }\FloatTok{0.025}\NormalTok{)}

\NormalTok{prob }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(p, probability\_of\_winning)}

\FunctionTok{plot}\NormalTok{(p, prob, }\AttributeTok{xlab=}\StringTok{"p: probability that Alonso wins in each game"}\NormalTok{, }
     \AttributeTok{ylab=}\StringTok{"prob: prob. that Alonso wins at least one game"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Integrative Exercise}\label{integrative-exercise}

Let's solve together this exercise that integrates everything we have learned in this chapter, called the Monty Hall problem.

\subsection{Monty Hall Problem}\label{monty-hall-problem}

Monty Hall was a TV presenter who made famous a contest in his show which we are going to replicate below. We have three doors in front of us:

\begin{center}\includegraphics[width=400pt,alt={Three closed doors labeled 1, 2, and 3 in the Monty Hall problem}]{assets/images/04-statistics/monty-hall-closed} \end{center}

Behind one of these doors is a zero-kilometer car, while in the other two there is a goat. We, as contest participants, have to choose together which door to open. Whatever is behind it will be ours.

Suppose we have chosen door number 2. Once you announce our choice, Monty Hall tells us that he is going to help us and opens a door for us right now. He opens one of the other doors and it turns out there is a goat in door 3 that he opened.

\begin{center}\includegraphics[width=400pt,alt={Monty Hall problem with door 3 open showing a goat, doors 1 and 2 remain closed}]{assets/images/04-statistics/monty-hall-open} \end{center}

Monty Hall asks us:

\begin{quote}
I am going to give you a chance to change doors and that will be your final choice, Would you change doors or stick with the door chosen at the beginning?
\end{quote}

Intuitively we knew that, when all doors were closed, the car is in one of 3 doors. The probability of winning would be \(\frac{1}{3} = 0.3333\) so it didn't matter which door to choose. But when he opens door number three he gives us information and the first thing we should ask ourselves is whether the probabilities have been affected or not. Although this is an advanced math exercise using change of variable, we can execute a Monte Carlo simulation to estimate the probabilities and solve it without using almost any mathematical formula.

Let's start by simulating the experiment. At the beginning we had three doors, door 1, 2 and 3. We will create the variable \texttt{doors}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{doors }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"door 1"}\NormalTok{, }\StringTok{"door 2"}\NormalTok{, }\StringTok{"door 3"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Then, we know that behind the doors there is a car and two goats distributed randomly. We will use the function \texttt{sample} to order them randomly.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prizes }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"car"}\NormalTok{, }\StringTok{"goat"}\NormalTok{, }\StringTok{"goat"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Since Monty Hall knows where the prize is. We are going to create a variable \texttt{prize\_door} where we will store where the car is.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prize\_door }\OtherTok{\textless{}{-}}\NormalTok{ doors[prizes }\SpecialCharTok{==} \StringTok{"car"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Now we choose a door randomly and store our result in the variable \texttt{choice}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{choice }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Given that we already have the chosen door shown we will simulate Monty Hall choosing the door to open. Since he is the presenter he will choose any door that is not the door where the prize is or your door.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{door\_opened }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors[}\SpecialCharTok{!}\NormalTok{doors }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(choice, prize\_door)],}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Finally, we are going to put all the code together and in the last line add the comparison of whether the prize door matches our choice. This time we are going to choose not to change doors, so our choice does not vary.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{doors }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"door 1"}\NormalTok{, }\StringTok{"door 2"}\NormalTok{, }\StringTok{"door 3"}\NormalTok{)}
\NormalTok{prizes }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"car"}\NormalTok{, }\StringTok{"goat"}\NormalTok{, }\StringTok{"goat"}\NormalTok{))}
\NormalTok{prize\_door }\OtherTok{\textless{}{-}}\NormalTok{ doors[prizes }\SpecialCharTok{==} \StringTok{"car"}\NormalTok{]}
\NormalTok{choice }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors, }\DecValTok{1}\NormalTok{)}
\NormalTok{door\_opened }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors[}\SpecialCharTok{!}\NormalTok{doors }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(choice, prize\_door)],}\DecValTok{1}\NormalTok{)}

\NormalTok{choice }\SpecialCharTok{==}\NormalTok{ prize\_door}
\end{Highlighting}
\end{Shaded}

With our experiment created we are going to simulate what would happen if we stick with the choice and what would happen if we change it.

\subsubsection{Stick with the chosen door}\label{stick-with-the-chosen-door}

Let's replicate about 10 thousand times to see the proportion of times we would win if we stick with our door.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{      doors }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"door 1"}\NormalTok{, }\StringTok{"door 2"}\NormalTok{, }\StringTok{"door 3"}\NormalTok{)}
\NormalTok{      prizes }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"car"}\NormalTok{, }\StringTok{"goat"}\NormalTok{, }\StringTok{"goat"}\NormalTok{))}
\NormalTok{      prize\_door }\OtherTok{\textless{}{-}}\NormalTok{ doors[prizes }\SpecialCharTok{==} \StringTok{"car"}\NormalTok{]}
\NormalTok{      choice }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors, }\DecValTok{1}\NormalTok{)}
\NormalTok{      door\_opened }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors[}\SpecialCharTok{!}\NormalTok{doors }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(choice, prize\_door)],}\DecValTok{1}\NormalTok{)}
      
\NormalTok{      choice }\SpecialCharTok{==}\NormalTok{ prize\_door}
\NormalTok{\})}

\FunctionTok{mean}\NormalTok{(results)}
\CommentTok{\#\textgreater{} [1] 0.334}
\end{Highlighting}
\end{Shaded}

We see that the probability obtained by Monte Carlo simulation is an estimation very close to the probability that we had intuitively calculated. That is, if we keep our choice of the door we chose we have a 33.33\% probability of winning.

But, what happens if we change doors? Is the probability of winning the same?

\subsubsection{Change door}\label{change-door}

We are going to use the code and modify it by creating the variable \texttt{new\_choice} to make the door change.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{      doors }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"door 1"}\NormalTok{, }\StringTok{"door 2"}\NormalTok{, }\StringTok{"door 3"}\NormalTok{)}
\NormalTok{      prizes }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"car"}\NormalTok{, }\StringTok{"goat"}\NormalTok{, }\StringTok{"goat"}\NormalTok{))}
\NormalTok{      prize\_door }\OtherTok{\textless{}{-}}\NormalTok{ doors[prizes }\SpecialCharTok{==} \StringTok{"car"}\NormalTok{]}
\NormalTok{      choice }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors, }\DecValTok{1}\NormalTok{)}
\NormalTok{      door\_opened }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(doors[}\SpecialCharTok{!}\NormalTok{doors }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(choice, prize\_door)],}\DecValTok{1}\NormalTok{)}
      
\NormalTok{      new\_choice }\OtherTok{\textless{}{-}}\NormalTok{ doors[}\SpecialCharTok{!}\NormalTok{doors }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(choice, door\_opened)]}
      
\NormalTok{      new\_choice }\SpecialCharTok{==}\NormalTok{ prize\_door}
\NormalTok{\})}

\FunctionTok{mean}\NormalTok{(results)}
\CommentTok{\#\textgreater{} [1] 0.664}
\end{Highlighting}
\end{Shaded}

As we see, changing the door in this show gave us a probability of 66.66\% of winning, while keeping our choice only 33.33\%.

It may sound counterintuitive, but statistically speaking it is better to change doors instead of trusting our luck and keeping the initial choice.

\chapter{Continuous Probabilities}\label{continuous-probabilities}

Recall that a continuous variable is a variable that takes values along a continuum, that is, over an entire interval of values. An essential attribute of a continuous variable is that, unlike a discrete variable, it can never be measured exactly; the observed value depends largely on the precision of the measuring instruments. With a continuous variable, there is inevitably a measurement error. As an example, the height of a person (1.72m, 1.719m, 1.7186m\ldots.). Another example could be the time it takes an athlete to run 100 meters flat, since this time can take values such as 9.623 seconds; 10.456485 seconds; 12.456412 seconds; that is, an interval of values.

\section{Learning Objectives}\label{learning-objectives}

After completing this chapter, you will be able to:

In this chapter, we will learn how to handle data that can take any value within a range. We will distinguish between empirical distributions, based on real data, and theoretical distributions, which model ideal behavior. We will use the Cumulative Distribution Function (CDF) to calculate probabilities for intervals and apply the normal distribution to model real-world continuous data. Additionally, we will learn to assess whether data fits a normal distribution using Q-Q plots and the Shapiro-Wilk test, and perform Monte Carlo simulations for continuous variables using \texttt{rnorm()}.

For example, recall that in the \texttt{heights} data frame we have the heights of a group of university students.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Filter only males}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_m =}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Convert to meters}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(sex, height\_m, }\AttributeTok{color =}\NormalTok{ height\_m) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{position =} \FunctionTok{position\_jitterdodge}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-398-1} \end{center}

When graphing the data distribution, we intuitively realize that it does not make sense to calculate the proportion of people who measure exactly 1.73m because it would also serve us if a person measures 1.731, 1.729, or any close value that is not exactly 1.73, whether due to how it was measured or any other type of error.

It makes more sense to analyze the data by intervals, as can be seen in this histogram that groups by intervals of 0.05 meters = 5 cm.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Filter only males}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_m =}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Convert to meters}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(height\_m) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-399-1} \end{center}

It is much more practical to define a function that operates on intervals instead of unique values. For this we use the Cumulative Distribution Function (CDF).

\section{Empirical Distribution}\label{empirical-distribution}

When we use data to analyze its distribution, we speak of an empirical distribution. It is the actual distribution of a subject or an option, and measures the real and individual possibilities, regarding the measurement of the subject's direct score, or of an option of which the frequency of occurrence has been measured.

For example, for our case we can create the vector \texttt{men} (men) made up of all the values of the heights of men:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{men }\OtherTok{\textless{}{-}}\NormalTok{ heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_m =}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(height\_m)}
\end{Highlighting}
\end{Shaded}

Then, we can create the function \texttt{empirical\_cdf} (CDF) that takes \texttt{x} as a variable and calculates the proportion of men who measure less than or equal to \texttt{x} within the data found in the \texttt{men} vector.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{empirical\_cdf }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x)\{}
  \FunctionTok{mean}\NormalTok{(men }\SpecialCharTok{\textless{}=}\NormalTok{ x)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Thus, if we want to calculate what the proportion of students who measure 1.73m or less would be.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.73}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.3768473}
\end{Highlighting}
\end{Shaded}

On the other hand, recall that the median is the value that divides our data into two equal parts. So, if we calculate the median:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{median}\NormalTok{(men)}
\CommentTok{\#\textgreater{} [1] 1.752604}
\end{Highlighting}
\end{Shaded}

And then we enter the value 1.7526035 into our function to ask what is the proportion of students who measure 1.7526035 or less, we should get a value very close to 50\% by definition of the median.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{median\_val }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(men)}
\FunctionTok{empirical\_cdf}\NormalTok{(median\_val)}
\CommentTok{\#\textgreater{} [1] 0.5073892}
\end{Highlighting}
\end{Shaded}

So far we have calculated proportions with the cumulative distribution function. However, if we want to know what is the \textbf{probability} that when choosing a man at random they measure 1.9m or less, we could use the same \texttt{empirical\_cdf}. Since each student has the same chance of being chosen, the answer to the question would be the proportion of students who measure 1.9 or less.

\(F(1.9) = P(x \le 1.9)\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.9}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9396552}
\end{Highlighting}
\end{Shaded}

We observe that the probability is approximately 93.97\%.

If we now want to calculate the probability that someone chosen at random is taller than 1.80m, we first calculate the CDF for 1.8 and then obtain the complement.

\(P(x > 1.8) = 1 - P(x \le 1.8)\)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Probability of measuring 1.80m or less}
\NormalTok{prob }\OtherTok{\textless{}{-}} \FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.8}\NormalTok{)}

\CommentTok{\# Probability of measuring more than 1.80m}
\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob}
\CommentTok{\#\textgreater{} [1] 0.3583744}
\end{Highlighting}
\end{Shaded}

The probability is approximately 35.8\%.

If we now wanted to know the probability that when choosing someone at random they measure more than 1.6m, but not more than 1.95m, we would have.

\(P(x > 1.6\ \cap\ x \le 1.95) = P(x \le 1.95) - P(x \le 1.6)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob\_1 }\OtherTok{\textless{}{-}} \FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.95}\NormalTok{)}

\NormalTok{prob\_2 }\OtherTok{\textless{}{-}} \FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.6}\NormalTok{)}

\NormalTok{prob\_1 }\SpecialCharTok{{-}}\NormalTok{ prob\_2}
\CommentTok{\#\textgreater{} [1] 0.9445813}
\end{Highlighting}
\end{Shaded}

\section{Theoretical Distribution}\label{theoretical-distribution}

On the other hand, a theoretical distribution is a distribution that is derived from certain principles or assumptions by logical and mathematical reasoning, as opposed to one derived from real-world data obtained by empirical research. Among them we have the normal distribution, the binomial distribution, and the Poisson distribution.

For example, if we draw an approximate line of our data on men's heights we would have this graph:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_m =}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(height\_m) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =} \FunctionTok{after\_stat}\NormalTok{(count)}\SpecialCharTok{*}\FloatTok{0.05}\NormalTok{), }\AttributeTok{colour =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-408-1} \end{center}

We see that the distribution has an approximately symmetric, bell shape. This distribution could be modeled using a \href{https://support.minitab.com/en-us/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/normality/what-is-the-normal-distribution/}{normal distribution} (also called Gaussian distribution, Gauss curve, or Gauss bell). To do this, in R we will use the function \texttt{pnorm(x,\ average,\ std\_dev)} to estimate the probability but using a normal distribution function with an average \texttt{average} and a standard deviation \texttt{std\_dev}. In this way, we can estimate what is the probability that if we choose a value at random it is less than or equal to \texttt{x}.

For example, let's calculate again the probability that when choosing a man at random he measures 1.65m or less, we could use the same FDA and now the \texttt{pnorm()} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Using the empirical distribution (real data):}
\FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.9}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9396552}

\CommentTok{\# Using the theoretical normal distribution (approx. data):}
\NormalTok{avg }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(men)}
\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(men)}

\NormalTok{probability }\OtherTok{\textless{}{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.9}\NormalTok{, avg, std\_dev)}
\NormalTok{probability}
\CommentTok{\#\textgreater{} [1] 0.9357267}
\end{Highlighting}
\end{Shaded}

We obtain approximately the same results. Using a normal distribution facilitates our work when our data has a normal behavior.

Mathematically we are calculating the area under the curve which is seen in blue:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sec }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\AttributeTok{length =} \DecValTok{100}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ std\_dev }\SpecialCharTok{+}\NormalTok{ avg}
\NormalTok{normal }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(sec, avg, std\_dev)}

\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{value =}\NormalTok{ normal) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(sec, value) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Height (meters)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Normal Distribution"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_area}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{ifelse}\NormalTok{(sec }\SpecialCharTok{\textless{}} \FloatTok{1.9}\NormalTok{, sec, }\DecValTok{0}\NormalTok{)), }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{min}\NormalTok{(sec), }\FunctionTok{max}\NormalTok{(sec)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \FunctionTok{paste}\NormalTok{(}\StringTok{"P(x \textless{}= 1.9) ="}\NormalTok{, probability))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-410-1} \end{center}

In the same way, we could estimate the probability that a person chosen at random measures more than 1.8m.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Using the empirical distribution (real data):}
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.8}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.3583744}

\CommentTok{\# Using the theoretical normal distribution (approx. data):}
\NormalTok{avg }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(men)}
\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(men)}

\NormalTok{probability }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.8}\NormalTok{, avg, std\_dev)}
\NormalTok{probability}
\CommentTok{\#\textgreater{} [1] 0.3337484}
\end{Highlighting}
\end{Shaded}

Mathematically we are calculating the area under the curve which is seen in blue:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sec }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\AttributeTok{length =} \DecValTok{100}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ std\_dev }\SpecialCharTok{+}\NormalTok{ avg}
\NormalTok{normal }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(sec, avg, std\_dev)}

\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{value =}\NormalTok{ normal) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(sec, value) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Height (meters)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Normal Distribution"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_area}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{ifelse}\NormalTok{(sec }\SpecialCharTok{\textgreater{}} \FloatTok{1.8}\NormalTok{, sec, }\DecValTok{0}\NormalTok{)), }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{min}\NormalTok{(sec), }\FunctionTok{max}\NormalTok{(sec)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \FunctionTok{paste}\NormalTok{(}\StringTok{"P(x \textgreater{} 1.8) ="}\NormalTok{, probability))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-412-1} \end{center}

Finally, let's recalculate the probability that when choosing someone at random they measure more than 1.6m, but not more than 1.95m, we would have.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Using the empirical distribution (real data):}
\NormalTok{prob\_1 }\OtherTok{\textless{}{-}} \FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.95}\NormalTok{)}
\NormalTok{prob\_2 }\OtherTok{\textless{}{-}} \FunctionTok{empirical\_cdf}\NormalTok{(}\FloatTok{1.6}\NormalTok{)}
\NormalTok{prob\_1 }\SpecialCharTok{{-}}\NormalTok{ prob\_2}
\CommentTok{\#\textgreater{} [1] 0.9445813}

\CommentTok{\# Using the theoretical normal distribution (approx. data):}
\NormalTok{avg }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(men)}
\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(men)}

\NormalTok{probability }\OtherTok{\textless{}{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.95}\NormalTok{, avg, std\_dev) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.6}\NormalTok{, avg, std\_dev)}
\NormalTok{probability}
\CommentTok{\#\textgreater{} [1] 0.9405618}
\end{Highlighting}
\end{Shaded}

Mathematically we are calculating the area under the curve which is seen in blue:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sec }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\AttributeTok{length =} \DecValTok{100}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ std\_dev }\SpecialCharTok{+}\NormalTok{ avg}
\NormalTok{normal }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(sec, avg, std\_dev)}

\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{value =}\NormalTok{ normal) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(sec, value) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Height (meters)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Normal Distribution"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_area}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{ifelse}\NormalTok{(sec }\SpecialCharTok{\textgreater{}} \FloatTok{1.6} \SpecialCharTok{\&}\NormalTok{ sec }\SpecialCharTok{\textless{}=} \FloatTok{1.95}\NormalTok{, sec, }\DecValTok{0}\NormalTok{)), }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{min}\NormalTok{(sec), }\FunctionTok{max}\NormalTok{(sec)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \FunctionTok{paste}\NormalTok{(}\StringTok{"P(1.6 \textless{} x \textless{}= 1.95) ="}\NormalTok{, probability))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-414-1} \end{center}

We can plot a Q-Q plot, which is a scatter plot created by plotting two sets of quantiles against each other. The function \texttt{stat\_qq(x)} creates a normal Q-Q plot. This function plots the data in sorted order against the quantiles of a standard Normal distribution. The function \texttt{stat\_qq\_line()} adds a reference line. Although understanding this requires advanced statistics, we can interpret it that if when using this function the correlation is very close to the line then our data is very likely to follow a normal distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_m =}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ height\_m) }\SpecialCharTok{+} 
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-415-1} \end{center}

The points seem to fall on a straight line. This gives us a good indication that assuming our height data comes from a population that is normally distributed is reasonable. Observe that the \emph{y-axis} plots the empirical quantiles and \emph{x-axis} plots the theoretical quantiles. The latter are the quantiles of the standard Normal distribution with mean 0 and standard deviation 1.

Visual inspection is not always reliable. It is possible to use a significance test that compares the sample distribution with a normal one to determine whether or not the data shows a serious deviation from normality. The most used test for these tests is the Shapiro-Wilk normality test.

For this we will use the function \texttt{shapiro.test()}, which performs a normality test and gives us a \href{https://www.investopedia.com/terms/p/p-value.asp}{p-value}\^{}(\url{https://www.investopedia.com/terms/p/p-value.asp}). It is based on the correlation between the data and the corresponding normal scores. If the \texttt{p-value\ \textgreater{}\ 0.05} then the data distribution is not significantly different from the normal distribution. In other words, we can assume normality.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{(men)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}  Shapiro{-}Wilk normality test}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} data:  men}
\CommentTok{\#\textgreater{} W = 0.96374, p{-}value = 2.623e{-}13}
\end{Highlighting}
\end{Shaded}

The p-value is less than 0.05 so, although our distribution resembles a normal one, it does not pass the significance test.

\section{Key Takeaways}\label{key-takeaways-2}

We have explored the differences between \textbf{empirical distributions}, derived directly from observed data using functions like \texttt{empirical\_cdf()}, and \textbf{theoretical distributions}, which rely on mathematical models such as the normal distribution. We learned to use \texttt{pnorm(x,\ mean,\ sd)} to calculate cumulative probabilities, providing a powerful tool for analyzing continuous variables. Finally, we introduced \textbf{Q-Q plots} and the \textbf{Shapiro-Wilk test} as method to verify if our data follows a normal distribution, with a p-value greater than 0.05 indicating that the assumption of normality is reasonable.

\section{Exercises}\label{exercises-10}

For the following exercises assume that the distribution of ages of students in the \emph{Data Science with R} course approximates a normal distribution with an average of 24 years and a standard deviation of 3. If we select a student at random:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{69}
\tightlist
\item
  Given the parameters of our student age distribution, calculate the probability that a randomly chosen student is \textbf{at most} 23 years old.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg\_e }\OtherTok{\textless{}{-}} \DecValTok{24}
\NormalTok{std\_dev\_e }\OtherTok{\textless{}{-}} \DecValTok{3}

\FunctionTok{pnorm}\NormalTok{(}\DecValTok{23}\NormalTok{, avg\_e, std\_dev\_e)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{70}
\tightlist
\item
  Determine the probability that a selected student is \textbf{older than} 28 years.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg\_e }\OtherTok{\textless{}{-}} \DecValTok{24}
\NormalTok{std\_dev\_e }\OtherTok{\textless{}{-}} \DecValTok{3}

\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{28}\NormalTok{, avg\_e, std\_dev\_e )}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{71}
\tightlist
\item
  Calculate the probability that a student is between 22 and 27 years old (older than 22 but at most 27).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg\_e }\OtherTok{\textless{}{-}} \DecValTok{24}
\NormalTok{std\_dev\_e }\OtherTok{\textless{}{-}} \DecValTok{3}

\FunctionTok{pnorm}\NormalTok{(}\DecValTok{27}\NormalTok{, avg\_e, std\_dev\_e ) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{22}\NormalTok{, avg\_e, std\_dev\_e )}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{72}
\tightlist
\item
  Find the probability that a student's age falls within one standard deviation of the average (i.e., between \texttt{average\ -\ sd} and \texttt{average\ +\ sd}).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg\_e }\OtherTok{\textless{}{-}} \DecValTok{24}
\NormalTok{std\_dev\_e }\OtherTok{\textless{}{-}} \DecValTok{3}

\NormalTok{max }\OtherTok{\textless{}{-}}\NormalTok{ avg\_e }\SpecialCharTok{+}\NormalTok{ std\_dev\_e}
\NormalTok{min }\OtherTok{\textless{}{-}}\NormalTok{ avg\_e }\SpecialCharTok{{-}}\NormalTok{ std\_dev\_e}

\FunctionTok{pnorm}\NormalTok{(max, avg\_e, std\_dev\_e ) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(min, avg\_e, std\_dev\_e )}
\end{Highlighting}
\end{Shaded}

\section{Monte Carlo Simulation for Continuous Variables}\label{monte-carlo-simulation-for-continuous-variables}

Although we have used a normal function to calculate the approximate probability, we can create more than one normal function with that average and that standard deviation. We will use the function \texttt{rnorm(n,\ average,\ std\_dev)} to create a vector of \texttt{n} random data, such that they are normally distributed with an average \texttt{avg} and a standard deviation \texttt{std\_dev}.

Recall that our original data has the following characteristics:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(men)}
\NormalTok{avg}
\CommentTok{\#\textgreater{} [1] 1.760598}

\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(men)}
\NormalTok{std\_dev}
\CommentTok{\#\textgreater{} [1] 0.09172018}

\NormalTok{length\_val }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(men)}
\NormalTok{length\_val}
\CommentTok{\#\textgreater{} [1] 812}
\end{Highlighting}
\end{Shaded}

If we want to generate a random normal distribution we will use \texttt{rnorm()}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Creation of the normally distributed random vector:}
\NormalTok{random\_normal }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(length\_val, avg, std\_dev)}

\CommentTok{\# We create a histogram to visualize it better}
\FunctionTok{hist}\NormalTok{(random\_normal)}
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"Sample:"}\NormalTok{, length\_val, }\StringTok{". Average:"}\NormalTok{, }
                \FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(random\_normal), }\DecValTok{3}\NormalTok{), }\StringTok{". Std. dev.:"}\NormalTok{, }
                \FunctionTok{round}\NormalTok{(}\FunctionTok{sd}\NormalTok{(random\_normal), }\DecValTok{3}\NormalTok{)}
\NormalTok{                )}
\FunctionTok{mtext}\NormalTok{(result,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-426-1} \end{center}

We can execute the code again to verify that it generates another distribution for us:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Creation of the normally distributed random vector:}
\NormalTok{random\_normal }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(length\_val, avg, std\_dev)}

\CommentTok{\# We create a histogram to visualize it better}
\FunctionTok{hist}\NormalTok{(random\_normal)}
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"Sample:"}\NormalTok{, length\_val, }\StringTok{". Average:"}\NormalTok{, }
                \FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(random\_normal), }\DecValTok{3}\NormalTok{), }\StringTok{". Std. dev.:"}\NormalTok{, }
                \FunctionTok{round}\NormalTok{(}\FunctionTok{sd}\NormalTok{(random\_normal), }\DecValTok{3}\NormalTok{)}
\NormalTok{                )}
\FunctionTok{mtext}\NormalTok{(result,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-427-1} \end{center}

We can repeat this experiment of obtaining \texttt{n} random data that have approximately the same \texttt{average} and the same \texttt{std\_dev} about 10 thousand times to calculate the proportion of times that a man measures more than 1.8m.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}

\NormalTok{simulation\_results }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{  random\_normal }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(length\_val, avg, std\_dev)}
\NormalTok{  random\_normal }\SpecialCharTok{\textgreater{}} \FloatTok{1.8}
\NormalTok{\})}

\FunctionTok{mean}\NormalTok{(simulation\_results)}
\CommentTok{\#\textgreater{} [1] 0.3338422}
\end{Highlighting}
\end{Shaded}

Thus, we have obtained practically the same value that we achieved in the previous section, but this time estimating using the Monte Carlo simulation.

\section{Exercises}\label{exercises-11}

The distribution of the admission exam grades of the Univ. UNISM is distributed approximately normally. The average is 14.5 and the standard deviation is 1. We want to know the distribution of the first place. It is known that 5 thousand people apply once a year per exam and take a single exam.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{73}
\tightlist
\item
  Generate 5 thousand grades about 1,000 times using Monte Carlo simulation and perform a histogram of the result.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{avg }\OtherTok{\textless{}{-}} \FloatTok{14.5}
\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{max\_grades }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{  exam\_simulation }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{5000}\NormalTok{, avg, std\_dev)}
  \FunctionTok{max}\NormalTok{(exam\_simulation)}
\NormalTok{\})}

\FunctionTok{hist}\NormalTok{(max\_grades)}
\FunctionTok{shapiro.test}\NormalTok{(max\_grades)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{74}
\tightlist
\item
  Now, modify your simulation to analyze the \textbf{distribution of the yearly averages}. Generate the sample average for each of the 1,000 simulations and plot the histogram.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{avg }\OtherTok{\textless{}{-}} \FloatTok{14.5}
\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{notas\_avg }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{  exam\_simulation }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{5000}\NormalTok{, avg, std\_dev)}
  \FunctionTok{mean}\NormalTok{(exam\_simulation)}
\NormalTok{\})}

\FunctionTok{hist}\NormalTok{(notas\_avg)}
\FunctionTok{shapiro.test}\NormalTok{(notas\_avg)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{75}
\tightlist
\item
  Using the results from your first simulation (distribution of maximum grades), estimate the probability that the highest grade in a given year exceeds 18.5.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{avg }\OtherTok{\textless{}{-}} \FloatTok{14.5}
\NormalTok{std\_dev }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{max\_grades }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{  exam\_simulation }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{5000}\NormalTok{, avg, std\_dev)}
  \FunctionTok{max}\NormalTok{(exam\_simulation)}
\NormalTok{\})}

\FunctionTok{mean}\NormalTok{(max\_grades }\SpecialCharTok{\textgreater{}} \FloatTok{18.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\chapter{Statistical Inference}\label{statistical-inference}

To infer means to draw a conclusion from general or particular facts. Statistical inference is a set of methods and techniques that allow deducing characteristics of a population using data from a random sample. The method we are going to use most to infer is the parameter estimation method.

We estimate parameters of a population from a sample because very rarely we will be able to have access to all the data of the population. Such is the case of election polls, disease studies, etc.

\section{Learning Objectives}\label{learning-objectives-1}

After completing this chapter, you will be able to:

In this chapter, we will build the foundation for making valid conclusions from data. We will start by mastering the calculation of expected values and standard errors, which are critical for characterizing random variables. Then, we will explore the Central Limit Theorem to understand how sampling distributions behave. Finally, we will apply these concepts to estimate population parameters from sample data, calculating confidence intervals and margins of error to analyze real-world scenarios like election polling.

We will introduce fundamental concepts such as \textbf{expected value} and \textbf{standard error}, which will be useful to us to make inferences.

\section{Expected Value}\label{expected-value}

Let's use the following case to understand this concept intuitively.

\begin{quote}
We have been hired in a casino to analyze if it is reasonable to install a roulette with 37 values ranging from 0 to 36. The house wants to open the game with a special offer if the ball lands on 0 or 21 paying 10 to 1. This means that if a player plays and wins we pay them 10 dollars and if they lose they would pay us 1 dollar.
\end{quote}

\begin{center}\includegraphics[width=300pt,alt={Casino roulette wheel with numbered red and black pockets}]{assets/images/04-statistics/roulette-casino} \end{center}

With what we have learned so far we can simulate our game with the case data. We have 37 values, of which in 2 of them give a player a profit of +10 or a loss -1. Let's also define \texttt{prob\_win} as the probability that a player wins.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Total times played}
\NormalTok{plays }\OtherTok{\textless{}{-}} \DecValTok{1}

\CommentTok{\# Probability that a player wins each time}
\NormalTok{prob\_win }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{/}\DecValTok{37}
\NormalTok{prob\_lose }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob\_win}

\CommentTok{\# Random sample}
\NormalTok{sample\_vec }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{), plays, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(prob\_win, prob\_lose))}

\NormalTok{sample\_vec}
\CommentTok{\#\textgreater{} [1] {-}1}
\end{Highlighting}
\end{Shaded}

The distribution of this variable is simple given that it can only take two values: 10 or -1. When we simulate a very large number of games it can be seen how it is distributed according to the indicated probability of winning and losing.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plays }\OtherTok{\textless{}{-}} \DecValTok{100000}

\NormalTok{prob\_win }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{/}\DecValTok{37}
\NormalTok{prob\_lose }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob\_win}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{outcome =}\NormalTok{ sample\_vec) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(outcome))) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Outcome ($)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Distribution of Roulette Outcomes"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-438-1} \end{center}

We have been using Monte Carlo simulation to estimate what the \textbf{mean} of the game results would be in real life.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimation of the mean by Monte Carlo simulation}
\FunctionTok{mean}\NormalTok{(sample\_vec)}
\CommentTok{\#\textgreater{} [1] {-}1}
\end{Highlighting}
\end{Shaded}

In addition, we have seen that, the more the sample grows, our \textbf{mean} in the Monte Carlo simulation converges to a value, in this case the probability of winning mainly in the roulette. That value to which it converges we will call \textbf{expected value}, which as its name indicates will be the value we expect to obtain in reality. The more the sample size grows the more our sample mean converges to this expected value. The notation we will use will be \(E[X]\).

When there are only two possible results \(a\) and \(b\) with proportions \(p\) and \(1-p\) respectively, the expected value will be calculated using this formula:

\(E[X] = ap + b(1-p)\)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Expected Value:}
\NormalTok{(}\DecValTok{10}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ prob\_win }\SpecialCharTok{+}\NormalTok{ (}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ prob\_lose}
\CommentTok{\#\textgreater{} [1] {-}0.4054054}
\end{Highlighting}
\end{Shaded}

Previously we had calculated the mean using Monte Carlo simulation. If we compare it with the expected value we see how both numbers are approximately the same, as the theory predicts.

Returning to the simulation of roulette games, a single person does not play so many times. Each person plays about 40 times a day at roulette. Thus, we can generate 40 games that a random player could play and find how much he would win:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plays }\OtherTok{\textless{}{-}} \DecValTok{40}

\NormalTok{prob\_win }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{/}\DecValTok{37}
\NormalTok{prob\_lose }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob\_win}

\NormalTok{sample\_vec }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{), plays, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(prob\_win, prob\_lose))}

\FunctionTok{sum}\NormalTok{(sample\_vec)}
\CommentTok{\#\textgreater{} [1] {-}18}
\end{Highlighting}
\end{Shaded}

Finally, not only one person will play. Let's replicate this sample about 100,000 times to simulate the number of players we would have in a quarter.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{players }\OtherTok{\textless{}{-}} \DecValTok{100000}
\NormalTok{plays }\OtherTok{\textless{}{-}} \DecValTok{40}

\NormalTok{prob\_win }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{/}\DecValTok{37}
\NormalTok{prob\_lose }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob\_win}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2025}\NormalTok{)}
\NormalTok{winnings\_simulation }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(players, \{}
  
\NormalTok{  sample\_vec }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{), plays, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(prob\_win, prob\_lose))}

  \FunctionTok{sum}\NormalTok{(sample\_vec)  }
  
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

So far we have done the same as we have learned in previous chapters. However, we could also see how the players' winnings are distributed. And for that it is enough to create a histogram of the result.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{winnings =}\NormalTok{ winnings\_simulation) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ winnings)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{bins =} \DecValTok{30}\NormalTok{, }\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{, }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Total Winnings ($)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Distribution of Player Winnings"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-444-1} \end{center}

It is not a coincidence that if we create a histogram with all the winnings of all the players the result looks like a normal distribution. In fact, that was the main approach that George Pólya made in 1920 when he presented his \textbf{Central Limit Theorem}.

\section{Central Limit Theorem}\label{central-limit-theorem}

The Central Limit Theorem tells us that if we take several samples of the same size \(n\) and in each sample we sum the values within each sample we will obtain a value \(S\) (the sum) then we will find that its distribution approximates well to a normal curve.

If we replicate this language to our example it would be: The central limit theorem tells us that if we take samples of 40 games for each player and then calculate for each player the total they won, then we will find that the distribution of the amount won by many players approximates a normal distribution.

Since it is a new distribution, we can calculate its mean and standard deviation. Being samples we will use the learned term \textbf{expected value} of the sum to refer to the sample mean and we will add the term of \textbf{standard error} of the sum to refer to the sample standard deviation

This would be the formula to calculate the expected value of the sum:

\(E[S_n] = n (ap+b(1-p))\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plays }\OtherTok{\textless{}{-}} \DecValTok{40}

\NormalTok{prob\_win }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{/}\DecValTok{37}
\NormalTok{prob\_lose }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob\_win}

\CommentTok{\# Expected value of the sum}
\NormalTok{E\_sum }\OtherTok{\textless{}{-}}\NormalTok{ plays }\SpecialCharTok{*}\NormalTok{ ( (}\DecValTok{10}\NormalTok{)}\SpecialCharTok{*}\NormalTok{prob\_win }\SpecialCharTok{+}\NormalTok{ (}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{prob\_lose )}
\NormalTok{E\_sum}
\CommentTok{\#\textgreater{} [1] {-}16.21622}
\end{Highlighting}
\end{Shaded}

And to calculate the standard error of the sum we will use the following formula:

\(SE[S_n]=\sqrt{n}\ |a-b|\ \sqrt{p(1-p)}\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plays }\OtherTok{\textless{}{-}} \DecValTok{40}

\NormalTok{prob\_win }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{/}\DecValTok{37}
\NormalTok{prob\_lose }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob\_win}

\CommentTok{\# Standard error of the sum}
\NormalTok{SE\_sum }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(plays) }\SpecialCharTok{*} \FunctionTok{abs}\NormalTok{(}\DecValTok{10} \SpecialCharTok{{-}} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(prob\_win}\SpecialCharTok{*}\NormalTok{prob\_lose)}
\NormalTok{SE\_sum}
\CommentTok{\#\textgreater{} [1] 15.73149}
\end{Highlighting}
\end{Shaded}

With these two theoretical data, the expected value and the standard error, we can graph the normal curve of the sum of winnings of our game.

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-447-1} \end{center}

What does this mean? That if theoretically we can already graph the normal curve then we can also calculate the probability that the sum is greater or less than some value. This is the main advantage of the Central Limit Theorem since we can calculate probabilities of the population using this approximation and the data of a single sample.

For example, if we want to know what is the probability that a player wins money after playing 40 times in roulette we would have to calculate the probability that \(S\) is greater than \textbf{zero}, represented by the blue shaded area:

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-448-1} \end{center}

To perform this calculation in R we would use the \texttt{pnorm} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Probability of getting more than 0 dollars having played 40 games:}
\DecValTok{1}\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{0}\NormalTok{, E\_sum, SE\_sum)}
\CommentTok{\#\textgreater{} [1] 0.1513144}
\end{Highlighting}
\end{Shaded}

Let's validate that the Monte Carlo simulation approximates this theoretical value we just calculated:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Probability of getting more than 0 dollars having played 40 games:}
\FunctionTok{mean}\NormalTok{(winnings\_simulation }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.16813}
\end{Highlighting}
\end{Shaded}

We have used two ways to estimate the probability, the theoretical estimation using the central limit theorem and the Monte Carlo simulation. These two numbers are quite close to the real probability. In both cases, the larger the sample, the more reasonable our estimation will be.

On the other hand, the same happens if we wanted to analyze the average and not the sum of the winnings. But for the average case we will use the following formulas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Expected value of the average: \(E[\overline{X}]=ap+b(1-p)\).
\item
  Standard error of the average: \(SE[\overline{X}]=|a-b|\sqrt{\frac{p(1-p) }{n}}\).
\end{enumerate}

\section{Key Takeaways}\label{key-takeaways-3}

This chapter provided the tools to quantify uncertainty. We learned that the \textbf{Expected Value}, \(E[X]\), represents the long-term average outcome of a random variable. The \textbf{Central Limit Theorem} is the bridge that allows us to approximate the sum of independent samples using a normal distribution, regardless of the original population's shape. This theorem enables us to calculate the \textbf{Expected Value of the Sum} (\(E[S_n] = n \cdot E[X]\)) and the \textbf{Standard Error of the Sum} (\(SE[S_n] = \sqrt{n} \cdot SE[X]\)), empowering us to estimate probabilities and make inferences about a population without needing to measure every single individual.

\section{Exercises}\label{exercises-12}

The admission exam of the National Univ. of San Marcos consists of 100 multiple choice questions (A, B, C, D, E) with a value of 20 points for each correct question and 1.125 for each wrong answer. We want to analyze what would happen if a student answers all 100 questions randomly and if there are chances of getting a vacancy knowing that minimum 900 points are needed to enter some career.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{76}
\tightlist
\item
  Consider a multiple-choice exam with 100 questions, where each correct answer awards 20 points and each wrong answer deducts 1.125 points. Determine the expected value of points a student would receive for a single question if they guessed randomly among the 5 options.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{points\_correct }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{points\_wrong }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FloatTok{1.125}
  
\NormalTok{prob\_correct }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\DecValTok{5}
\NormalTok{prob\_wrong }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob\_correct}

\CommentTok{\# Expected value of guessing a question:}
\NormalTok{E }\OtherTok{\textless{}{-}}\NormalTok{ points\_correct }\SpecialCharTok{*}\NormalTok{ prob\_correct }\SpecialCharTok{+}\NormalTok{ points\_wrong }\SpecialCharTok{*}\NormalTok{ prob\_wrong}

\NormalTok{E}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{77}
\tightlist
\item
  Based on the expected value for a single question, calculate the total expected value if a student guesses on all 100 questions of the exam.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Total questions:}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}

\CommentTok{\# Expected value of the sum}
\NormalTok{E\_sum }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*}\NormalTok{ E}

\NormalTok{E\_sum}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{78}
\tightlist
\item
  Calculate the standard error associated with the total score if a student guesses on all 100 questions.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Standard error of the sum}
\NormalTok{SE\_sum }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(n)}\SpecialCharTok{*}\FunctionTok{abs}\NormalTok{(points\_correct }\SpecialCharTok{{-}}\NormalTok{ points\_wrong) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(prob\_correct}\SpecialCharTok{*}\NormalTok{prob\_wrong)}

\NormalTok{SE\_sum}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{79}
\tightlist
\item
  Using the Central Limit Theorem and the values calculated previously, determine the probability that a student guessing on all questions would achieve a score higher than 900 points.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{min\_score }\OtherTok{\textless{}{-}} \DecValTok{900}

\CommentTok{\# Probability of obtaining less than the minimum:}
\NormalTok{prob }\OtherTok{\textless{}{-}} \FunctionTok{pnorm}\NormalTok{(min\_score, E\_sum, SE\_sum)}

\CommentTok{\# Probability of obtaining more than the minimum:}
\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prob}
\end{Highlighting}
\end{Shaded}

This means that the probability that a student obtains the minimum score by guessing all the questions is: \texttt{0.0000000000014525}.

Conclusion: let's study before taking the exam. It is not reasonable to take the exam randomly and mark randomly.

\begin{quote}
Recall that \texttt{e-n} is the representation of \(10^{-n}\).
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{80}
\tightlist
\item
  Validate your theoretical calculation by running a Monte Carlo simulation. Simulate the exam scores for 22,000 applicants guessing randomly and calculate the proportion who score above 900 points.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{total }\OtherTok{\textless{}{-}} \DecValTok{22000}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2025}\NormalTok{)}
\NormalTok{admission\_simulation }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(total, \{}
\NormalTok{  exam\_score }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(points\_correct, points\_wrong), n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(prob\_correct, prob\_wrong) )}

  \FunctionTok{sum}\NormalTok{(exam\_score)  }
\NormalTok{\})}

\CommentTok{\# Probability of obtaining more than 900 points:}
\FunctionTok{mean}\NormalTok{(admission\_simulation }\SpecialCharTok{\textgreater{}} \DecValTok{900}\NormalTok{)}

\CommentTok{\# Histogram if we want to see the distribution of points obtained:}
\FunctionTok{hist}\NormalTok{(admission\_simulation)}
\end{Highlighting}
\end{Shaded}

We see that the simulation gives us practically the same result. Practically there are no possibilities of entering UNMSM by guessing the answers.

\section{Parameter Estimation Method}\label{parameter-estimation-method}

So far, using Monte Carlo simulation we have built samples randomly, but knowing the probability of occurrence. However, we will not always know the proportion previously. If we have, for example, a population and we want to know how many have been infected by Covid-19, we cannot test everyone. Or if we have the total voters for an election, we cannot survey everyone to know who would win. Not only is it very expensive, but it would take us a lot of time.

The \textbf{parameter estimation method} is the procedure used to know the characteristics of a population parameter, from the knowledge of a sample of \(n\) respondents

We will analyze this following case.

\begin{quote}
We have two political parties: Blue and Red. We do not know how much the total population is, nor the proportion that will vote for one or the other party. The only thing we can do is conduct voting intention polls.
\end{quote}

For example, these would be the results of the poll of a random sample of 10 people:

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-461-1} \end{center}

Intuitively we know that we cannot deduce which party will win given that the sample is very small. To know which party will win we need to estimate as precisely as possible the parameter \(p\) that represents the proportion of voters of the Blue Party in the population and the parameter \(1-p\) that represents the proportion of voters of the Red party.

Making some mathematical transformations to our theoretical estimates seen previously and defining \(a=1\) as value if they vote Blue and \(b=0\) if they do not vote for Blue, we can obtain the following theoretical estimates for this case:

By defining a vote for Blue as \(a=1\) and a vote for others as \(b=0\), we can derive theoretical estimates that link our sample data to the unknown population parameter \(p\).

First, consider the \textbf{expected value of a single vote}. Mathematically, \(E[X]=p\). This confirms that the value we expect to obtain from a single random voter matches the proportion \(p\) we are trying to find.

Next, we look at the \textbf{expected value of the average} across multiple surveys. If we were to conduct many surveys of \(n\) respondents each, the average of these sample means, denoted as \(E[\overline{X}]\), would also equal \(p\). This reinforces that our sample mean is an unbiased estimator of the population proportion.

Finally, we must account for variability using the \textbf{standard error of the average}, defined as \(SE[\overline{X}]=\sqrt{\frac{p(1-p) }{n}}\). This metric tells us how much the results of our multiple surveys would fluctuate around the true parameter \(p\), taking into account the sample size \(n\).

The expected value of the average \(E[\overline{X}]\), formula 2, is theoretically equal to the parameter \(p\) that we are looking to estimate. However, without knowing how much \(p\) is we would have to have multiple samples of \(n\) respondents, then calculate the mean for each case \(\overline{X}\) and finally calculate the average of these values. This is very expensive, so we will look for another way to estimate \(E[\overline{X}]\).

Given that we do not have so far how to estimate \(E[\overline{X}]\), and given that we know that \(E[\overline{X}]=p\) then we could give several values to \(p\) and see the impact on the standard error of the average that we know also depends on \(p\).

Let's generate, first, a sequence of parameter \(p\), from 0\% to 100\%, 100 different values:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length=}\DecValTok{100}\NormalTok{)}

\NormalTok{p}
\CommentTok{\#\textgreater{}   [1] 0.00000000 0.01010101 0.02020202 0.03030303 0.04040404 0.05050505}
\CommentTok{\#\textgreater{}   [7] 0.06060606 0.07070707 0.08080808 0.09090909 0.10101010 0.11111111}
\CommentTok{\#\textgreater{}  [13] 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717}
\CommentTok{\#\textgreater{}  [19] 0.18181818 0.19191919 0.20202020 0.21212121 0.22222222 0.23232323}
\CommentTok{\#\textgreater{}  [25] 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929}
\CommentTok{\#\textgreater{}  [31] 0.30303030 0.31313131 0.32323232 0.33333333 0.34343434 0.35353535}
\CommentTok{\#\textgreater{}  [37] 0.36363636 0.37373737 0.38383838 0.39393939 0.40404040 0.41414141}
\CommentTok{\#\textgreater{}  [43] 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747}
\CommentTok{\#\textgreater{}  [49] 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354}
\CommentTok{\#\textgreater{}  [55] 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.59595960}
\CommentTok{\#\textgreater{}  [61] 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566}
\CommentTok{\#\textgreater{}  [67] 0.66666667 0.67676768 0.68686869 0.69696970 0.70707071 0.71717172}
\CommentTok{\#\textgreater{}  [73] 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778}
\CommentTok{\#\textgreater{}  [79] 0.78787879 0.79797980 0.80808081 0.81818182 0.82828283 0.83838384}
\CommentTok{\#\textgreater{}  [85] 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.89898990}
\CommentTok{\#\textgreater{}  [91] 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596}
\CommentTok{\#\textgreater{}  [97] 0.96969697 0.97979798 0.98989899 1.00000000}
\end{Highlighting}
\end{Shaded}

Thinking of 100 different values of \(p\) would be like thinking of 100 different elections where the Blue party and the red one have participation, like the election for mayors nationwide. In some districts the candidate of the Blue party loses with 0\%, in others ties at 50\% and in others wins clearly with 100\% of the votes.

Intuitively we know that if our real proportion was \(p=80\%\) for the Blue party, that is that 8 out of every 10 will vote Blue, then it is very likely that in each survey we take we will find that in that district the Blue party has the majority of votes. This is predicted with the formula seen before and also includes the size of the survey \(n\) as part of the calculation:

\(SE[\overline{X}]=\sqrt{\frac{p(1-p) }{n}}\)

That said, let's return to our vector \texttt{p} that contains several values of parameter \(p\). On those values we can calculate what would happen if we survey groups of 20 people. Knowing the sample size we can calculate the standard error of the average for each of the values of \(p\):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Total people in each survey:}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{20}

\CommentTok{\# Standard error of the average:}
\NormalTok{SE\_avg }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p))}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)}

\NormalTok{SE\_avg  }
\CommentTok{\#\textgreater{}   [1] 0.00000000 0.02235954 0.03145942 0.03833064 0.04402928 0.04896646}
\CommentTok{\#\textgreater{}   [7] 0.05335399 0.05731823 0.06094183 0.06428243 0.06738214 0.07027284}
\CommentTok{\#\textgreater{}  [13] 0.07297936 0.07552152 0.07791540 0.08017428 0.08230929 0.08432982}
\CommentTok{\#\textgreater{}  [19] 0.08624394 0.08805856 0.08977974 0.09141275 0.09296223 0.09443229}
\CommentTok{\#\textgreater{}  [25] 0.09582660 0.09714840 0.09840064 0.09958592 0.10070661 0.10176486}
\CommentTok{\#\textgreater{}  [31] 0.10276258 0.10370152 0.10458327 0.10540926 0.10618079 0.10689904}
\CommentTok{\#\textgreater{}  [37] 0.10756509 0.10817988 0.10874431 0.10925913 0.10972506 0.11014270}
\CommentTok{\#\textgreater{}  [43] 0.11051262 0.11083529 0.11111111 0.11134044 0.11152357 0.11166072}
\CommentTok{\#\textgreater{}  [49] 0.11175205 0.11179770 0.11179770 0.11175205 0.11166072 0.11152357}
\CommentTok{\#\textgreater{}  [55] 0.11134044 0.11111111 0.11083529 0.11051262 0.11014270 0.10972506}
\CommentTok{\#\textgreater{}  [61] 0.10925913 0.10874431 0.10817988 0.10756509 0.10689904 0.10618079}
\CommentTok{\#\textgreater{}  [67] 0.10540926 0.10458327 0.10370152 0.10276258 0.10176486 0.10070661}
\CommentTok{\#\textgreater{}  [73] 0.09958592 0.09840064 0.09714840 0.09582660 0.09443229 0.09296223}
\CommentTok{\#\textgreater{}  [79] 0.09141275 0.08977974 0.08805856 0.08624394 0.08432982 0.08230929}
\CommentTok{\#\textgreater{}  [85] 0.08017428 0.07791540 0.07552152 0.07297936 0.07027284 0.06738214}
\CommentTok{\#\textgreater{}  [91] 0.06428243 0.06094183 0.05731823 0.05335399 0.04896646 0.04402928}
\CommentTok{\#\textgreater{}  [97] 0.03833064 0.03145942 0.02235954 0.00000000}
\end{Highlighting}
\end{Shaded}

Now let's generate a scatter plot of both the different values of \(p\) and the standard errors for each \(p\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p, }\AttributeTok{SE\_avg =}\NormalTok{ SE\_avg) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p, }\AttributeTok{y =}\NormalTok{ SE\_avg)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.12}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Proportion (p)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Standard Error"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Standard Error vs. Proportion"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-464-1} \end{center}

Thus, we see how we can obtain different standard errors of the average for different values of \(p\).

Intuitively we had the notion of what would happen given a \(p=80\%\). Now in the graph we see it better. If the real intention of vote was 80\% in that district then when taking several surveys and seeing the results of each survey we would obtain as expected value 80\% and as standard error 8.8\% or 0.088 as seen in the graph highlighted in blue:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coord\_x }\OtherTok{\textless{}{-}} \FloatTok{0.8}
\NormalTok{coord\_y }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(coord\_x }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ coord\_x)) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p, }\AttributeTok{SE\_avg =}\NormalTok{ SE\_avg) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p, }\AttributeTok{y =}\NormalTok{ SE\_avg)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =}\NormalTok{ coord\_y, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ coord\_x, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.12}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Proportion (p)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Standard Error"}\NormalTok{, }\AttributeTok{title =} \StringTok{"SE at p = 80\%"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-465-1} \end{center}

With these values of \(E[\overline{X}]=p=80\%\) and \(SE[\overline{X}]=8.8\%\) of standard error we can calculate a range of one standard error around \(80\%\), which would go from \(71.2\%\) to \(88.8\%\) and then calculate what would be the probability that the mean \(\overline{X}\) found in one of the surveys falls in this range. Visually it would be:

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-466-1} \end{center}

In R, calculating the probability that a data point falls in the range of 1 standard error would be:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculation of probability that dat is between {-}1 and 1 standard error:}
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.6826895}
\end{Highlighting}
\end{Shaded}

We can expand to have a greater range of \textbf{2 standard errors} around \(80\%\) and increase our probability:

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-468-1} \end{center}

In R it would be:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculation of probability that dat is between {-}2 and 2 standard errors:}
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9544997}
\end{Highlighting}
\end{Shaded}

The probability increases to 95\%, however how do we interpret this?. We haven't even calculated the real value of the mean \(\overline{X}\) of some survey.

Simple, this means that, theoretically, there is a 95\% probability that the mean \(\overline{X}\) that we find in each survey is in the range of 62\% to 98\%, two standard errors around \(80\%\). 95\% of the time in the worst case, in a survey of 20 people, the Blue party would obtain 62\% and in the best case 98\%, so we could predict that the Blue party will win. Or not?

Several things should make noise to us so far. First, the range so large, from 62\% to 98\%. Second, we have assumed a scenario: that the Blue voting intention was known and was 80\%. That is, we have assumed \(p=80\%\) which allowed us to calculate \(E[\overline{X}]=80\%\) and place that value at the center of the normal. However, \(p\) is unknown and is precisely what we are trying to estimate.

If, on the contrary, the result was tighter, for example \(p=55\%\), such a wide range would not serve us. Let's see how it would be:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coord\_x }\OtherTok{\textless{}{-}} \FloatTok{0.55}
\NormalTok{coord\_y }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(coord\_x }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ coord\_x)) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p, }\AttributeTok{SE\_avg =}\NormalTok{ SE\_avg) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p, }\AttributeTok{y =}\NormalTok{ SE\_avg)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =}\NormalTok{ coord\_y, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ coord\_x, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.12}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Proportion (p)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Standard Error"}\NormalTok{, }\AttributeTok{title =} \StringTok{"SE at p = 55\%"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-470-1} \end{center}

If the real voting intention was \(55\%\) we would have an expected value of the average \(E[\overline{X}]=p=55\%\) and a corresponding standard error of the average \(SE[\overline{X}]=11\%\). Again, by Central Limit Theorem we can calculate a range of \textbf{two standard errors} around \(55\%\):

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-471-1} \end{center}

The calculation of the probability of being in that range in R would be the same because we continue in the range of 2 standard errors. Therefore the probability would be the same.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculation of probability that dat is between {-}2 and 2 standard errors:}
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9544997}
\end{Highlighting}
\end{Shaded}

However, what does change is the range. Now the range goes from 32.8\% to 77.2\%, two standard errors around the expected value of the average \(E[\overline{X}]\). Although the probability is still 95\%, that does not help us at all this time because there is 95\% that what we find in our sample is a value between 33\% and 77\%. Some survey samples will give us 33\% of votes for Blue and other samples 77\%.

And the problem lies in the number of samples taken \(n\). If we see again the formula we see how \(n\) influences the result.

\(SE[\overline{X}]=\sqrt{\frac{p(1-p) }{n}}\)

Let's increment then our number of respondents to 500:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{500}

\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length =} \DecValTok{100}\NormalTok{)}
\NormalTok{SE\_avg }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p))}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p, }\AttributeTok{SE\_avg =}\NormalTok{ SE\_avg) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p, }\AttributeTok{y =}\NormalTok{ SE\_avg)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.12}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Proportion (p)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Standard Error"}\NormalTok{, }\AttributeTok{title =} \StringTok{"SE vs Proportion (n = 500)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-473-1} \end{center}

This sample gives us smaller standard errors. For example, if the real proportion of voters of the Blue party was \(p=55\%\) we would have \(E[\overline{X}]=p=55\%\) and a \(SE[\overline{X}]=2.2\%\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coord\_x }\OtherTok{\textless{}{-}} \FloatTok{0.55}
\NormalTok{coord\_y }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(coord\_x }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ coord\_x)) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p, }\AttributeTok{SE\_avg =}\NormalTok{ SE\_avg) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p, }\AttributeTok{y =}\NormalTok{ SE\_avg)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =}\NormalTok{ coord\_y, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ coord\_x, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.12}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Proportion (p)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Standard Error"}\NormalTok{, }\AttributeTok{title =} \StringTok{"SE at p = 55\% (n = 500)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-474-1} \end{center}

If we now calculate a range of two standard errors around \(55\%\) we would have a range that goes from \(50.6\%\) to \(59.4\%\). Again, interpretation is that the mean that we find in our random survey has a 95\% probability of being in that range.

We see then that this theoretical prediction, the standard error, becomes smaller as the sample size \(n\) increases and in turn depends on the probability of the population \(p\) that we do not know. Moreover, with a real value of \(p=0.5\), (50\%), we have the maximum value of the standard error that we can obtain. Thus, if we correct \(p\) at 50\%, which would be the extreme of cases, a tie, we can calculate how the value of the standard error of the average changes according to the sample size:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{5000}\NormalTok{, }\DecValTok{20}\NormalTok{)}
\NormalTok{SE\_avg }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{/}\NormalTok{n)}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{SE\_avg =}\NormalTok{ SE\_avg) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ n, }\AttributeTok{y =}\NormalTok{ SE\_avg)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \FloatTok{0.015}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \DecValTok{1000}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Sample Size (n)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Standard Error"}\NormalTok{, }\AttributeTok{title =} \StringTok{"SE vs Sample Size (p = 50\%)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-475-1} \end{center}

A sample of 1,000 people, for example, generates us a maximum standard error of 0.015 or 1.5\%.

\subsection{Margin of Error}\label{margin-of-error}

As we have already seen, we could consider a range of 1 standard error or 2 standard errors around \(E[\overline{X}]\) and calculate the probability that our sample mean \(\overline{X}\) is in that range. Or what is mathematically the same, we could say that if we build a range of 1 or 2 standard errors around our sample mean \(\overline{X}\) there is a determined probability that in that range is included the expected value \(E[\overline{X}]\) which is, by formula equal to \(p\), the value we want to estimate.

It is crucial then to calculate the standard error of the average \(SE[\overline{X}]\), but we see ourselves limited because it depends on \(p\).

There is another way to calculate \(SE[\overline{X}]\) without using \(p\) and is known as the standard error of estimation \(\hat{SE}[\overline{X}]\). For this we will use the following formula:

\(\hat{SE}[\overline{X}]=\sqrt{\frac{\overline{X}(1-\overline{X})}{n}}\)

Where, as we already know, \(\overline{X}\) is the mean of our sample or sample mean. For our example case, it is the percentage that the Blue party obtained in the survey we conducted.

Now that we have the sample mean \(\overline{X}\) and we can already calculate the standard error of estimation \(\hat{SE}[\overline{X}]\) we can start building ranges around \(\overline{X}\) that increase the probability of finding \(p\).

To make communication simpler, we will use by convention the notation \textbf{margin of error} to indicate that we are going to take a \textbf{range of 2 standard errors of estimation}.

For example, we have a sample of 1100 people and after reviewing the survey results we have a sample mean of \(\overline{X}=56\%\) for the Blue party. With this we can estimate the standard error of estimation \(\hat{SE}[\overline{X}]\) with the formula we just described and finally calculate the margin of error.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Total respondents}
\NormalTok{total }\OtherTok{\textless{}{-}} \DecValTok{1100}

\CommentTok{\# Survey results, 56\% indicated Blue:}
\NormalTok{X\_avg }\OtherTok{\textless{}{-}} \FloatTok{0.56}

\CommentTok{\# Standard error estimation}
\NormalTok{SE\_est }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(X\_avg }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ X\_avg)}\SpecialCharTok{/}\NormalTok{total)}
\NormalTok{SE\_est}
\CommentTok{\#\textgreater{} [1] 0.01496663}

\CommentTok{\# Margin of error, MoE}
\NormalTok{MoE }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ SE\_est}
\NormalTok{MoE}
\CommentTok{\#\textgreater{} [1] 0.02993326}
\end{Highlighting}
\end{Shaded}

With this we would have that from a sample of 1100 people, we have estimated 56\% voting intention for the Blue party with a margin of error of \(+- 2.99\%\).

Finally, let's see examples of the different surveys conducted in April and early May 2020 to measure voting intentions in the US.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Table of US election polls from April-May 2020 showing sample sizes, margins of error, and candidate percentages}]{assets/images/04-statistics/polls-us} \end{center}

We see as columns:

The table columns provide key details about each survey. The \textbf{Poll} column identifies the surveying company, while \textbf{Date} indicates when the survey was conducted. \textbf{Sample} shows the number of respondents, which varies by pollster, and \textbf{MoE} represents the margin of error. The \textbf{Candidates} columns display the backing for each presidential contender (note that percentages may not sum to 100\% due to checking for blank or null votes). Finally, \textbf{Spread} estimates the lead one candidate holds over the other.

If, on the other hand, we ask ourselves why larger surveys are not done, for example 50,000 people, the reason is that:

You might wonder why we rely on smaller samples instead of surveying, say, 50,000 people. The primary constraint is cost; reaching such a large audience is prohibitively expensive. Furthermore, parameter estimation is inherently theoretical---providing a razor-thin margin of error implies a false sense of absolute certainty. In reality, voter opinions are fluid, no survey is perfectly random (often missing rural populations), and respondents who claim they will vote might ultimately stay home.

\subsection{Confidence Intervals}\label{confidence-intervals}

Confidence intervals are a very useful concept widely used by Data Scientists. However, it is nothing more than another way of expressing what we have already learned so far.

And it is that a \textbf{confidence interval} of 95\% tells us that there is a 95\% probability that the interval we generate includes the parameter \(p\) that we want to estimate. This is nothing more than another way of indicating that we have to build an interval considering the margin of error, that is two standard errors around our sample mean.

For the sample of 1100 people we saw in the previous section, we reported an estimate of 56\% with a margin of error of \(+- 2.99\%\).

If we now want to use \textbf{confidence intervals} in our language we would say: We estimate 56\% for the Blue party with a confidence interval of 95\%. This confidence interval goes from 53\% to 59\%.

\section{Spread Estimation}\label{spread-estimation}

Although we are interested in estimating the proportion that the Blue party would obtain \(p\), sometimes it is more useful to know the difference (by how much it wins/loses). For example, when we have two parties in the second round of elections not only do we have votes for Blue and Red, but also blank/spoiled. Also, in regular elections we have more than one pollster doing several surveys. So one could give 45\% for Blue, 41\% for Red. While another can give 41\% for Blue and 38\% for Red, etc. If we compare surveys, rather than knowing the exact percentage it is more useful to know by how much the blue party wins, since if we see that in all, for example it wins by 4\%, with a tiny standard error, then \(p\) would not matter much. Only with the difference data we could take get an idea of who will win.

This difference is called \emph{spread}. We had defined that the voting intention for the Blue party was \(p\) and for the red party \(1-p\). So what we would expect to obtain for the difference would be \(p - (1-p)\), that is \(2p - 1\).

Standard error of the \emph{spread}:

\(SE[spread]=2\sqrt{\frac{p(1-p) }{n}}\)

We see that the standard error is twice the standard error of the average, which depends on \(p\), and we have already found previously an estimation to not depend on \(p\) but on the mean of our sample. So we will use:

\(\hat{SE[spread]}=2\sqrt{\frac{\overline{X}(1-\overline{X}) }{n}}\)

Let's see with an example these concepts. Let's study the 2016 US elections. In this case we have multiple pollsters, conducting multiple surveys months prior to elections, and mainly two parties competing for president.

We are going to use the \texttt{polls\_us\_election\_2016} data frame included in the \texttt{dslabs} library which includes data from multiple surveys conducted for the 2016 US elections between Hillary Clinton and Donald Trump. The first thing we will do is explore the data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dslabs)}
\FunctionTok{head}\NormalTok{(polls\_us\_election\_2016)}
\end{Highlighting}
\end{Shaded}

As we see, we do not have the standard error, nor the confidence interval. So we will proceed to make some mutations applying the formulas learned so far focusing on the voting intention for Hillary Clinton.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{surveys }\OtherTok{\textless{}{-}}\NormalTok{ polls\_us\_election\_2016 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(state }\SpecialCharTok{==} \StringTok{"U.S."}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{X\_avg =}\NormalTok{ rawpoll\_clinton}\SpecialCharTok{/}\DecValTok{100}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{SE\_prom =} \FunctionTok{sqrt}\NormalTok{((X\_avg}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{X\_avg))}\SpecialCharTok{/}\NormalTok{samplesize)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{inferior =}\NormalTok{ X\_avg }\SpecialCharTok{{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{SE\_prom,}
         \AttributeTok{superior =}\NormalTok{ X\_avg }\SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{SE\_prom) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(pollster, enddate, X\_avg, SE\_prom, inferior, superior)}

\CommentTok{\# First 5 rows}
\NormalTok{surveys }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{}                   pollster    enddate  X\_avg     SE\_prom  inferior  superior}
\CommentTok{\#\textgreater{} 1 ABC News/Washington Post 2016{-}11{-}06 0.4700 0.010592790 0.4488144 0.4911856}
\CommentTok{\#\textgreater{} 2  Google Consumer Surveys 2016{-}11{-}07 0.3803 0.002978005 0.3743440 0.3862560}
\CommentTok{\#\textgreater{} 3                    Ipsos 2016{-}11{-}06 0.4200 0.010534681 0.3989306 0.4410694}
\CommentTok{\#\textgreater{} 4                   YouGov 2016{-}11{-}07 0.4500 0.008204286 0.4335914 0.4664086}
\CommentTok{\#\textgreater{} 5         Gravis Marketing 2016{-}11{-}06 0.4700 0.003869218 0.4622616 0.4777384}
\end{Highlighting}
\end{Shaded}

For example, IPSOS in a survey published on 11/06/16 estimated 42\% voting intention for Clinton with a 95\% confidence interval in a range going from 39.89\% to 44.10\%.

Does this data mean that they estimated she would lose? No, given that in this case we are using real data the proportion of votes for Clinton with those for Trump will not sum 100\%. In fact, on actual election day Clinton obtained 48.2\% and Trump 46.1\% of total votes cast. That is real \(p\) was 48.2\%.

What we could calculate is how many of these pollsters guessed right in their estimation. That is, if in their confidence intervals is the \(p=48.2\%\) that Clinton finally obtained. To do this, we will add a column \texttt{guessed\_right} (guessed\_right) with the validation of whether it is in the confidence interval and then use \texttt{summarize()} to calculate the percentage of surveys that guessed right.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{surveys }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{guessed\_right =}\NormalTok{ inferior }\SpecialCharTok{\textless{}=} \FloatTok{0.482} \SpecialCharTok{\&} \FloatTok{0.482} \SpecialCharTok{\textless{}=}\NormalTok{ superior) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarize}\NormalTok{(}\FunctionTok{mean}\NormalTok{(guessed\_right))}
\CommentTok{\#\textgreater{}   mean(guessed\_right)}
\CommentTok{\#\textgreater{} 1           0.2802893}
\end{Highlighting}
\end{Shaded}

Only 28\% of published surveys published confidence intervals that included \(p\). This, among many other reasons, because at the beginning there are many more undecided who finally decide in the last weeks.

Let's analyze now how many guessed right in the spread. It could be that even though they did not estimate exact \(p\) the difference did remain over time. To do this, let's add to our surveys the column \texttt{spread} with the difference of votes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{surveys\_spread }\OtherTok{\textless{}{-}}\NormalTok{ polls\_us\_election\_2016 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(state }\SpecialCharTok{==} \StringTok{"U.S."}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{spread =}\NormalTok{ (rawpoll\_clinton }\SpecialCharTok{{-}}\NormalTok{ rawpoll\_trump)}\SpecialCharTok{/}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

And now we are going to do a trick calculating the spread of our sample:

\(spread=2*\overline{X}-1\)

We can transform this formula:

\(spread-1=2*\overline{X}\)

\(\frac{spread-1}{2}=\overline{X}\)

Or what is the same:

\(\overline{X}=\frac{spread-1}{2}\)

This formula gives us an approximation of how much \(\overline{X}\) would be transformed to a scale of 0 to 100\%. With it, let's calculate the standard error and the confidence interval:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{surveys\_spread }\OtherTok{\textless{}{-}}\NormalTok{ surveys\_spread }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{X\_avg =}\NormalTok{ (spread }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{SE\_spread =} \DecValTok{2}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{((X\_avg}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{X\_avg))}\SpecialCharTok{/}\NormalTok{samplesize)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{inferior =}\NormalTok{ spread }\SpecialCharTok{{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{SE\_spread,}
         \AttributeTok{superior =}\NormalTok{ spread }\SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{SE\_spread) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(pollster, enddate, spread, SE\_spread, inferior, superior)}

\CommentTok{\# First 5 rows}
\NormalTok{surveys\_spread }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{}                   pollster    enddate spread   SE\_spread     inferior}
\CommentTok{\#\textgreater{} 1 ABC News/Washington Post 2016{-}11{-}06 0.0400 0.021206832 {-}0.002413664}
\CommentTok{\#\textgreater{} 2  Google Consumer Surveys 2016{-}11{-}07 0.0234 0.006132712  0.011134575}
\CommentTok{\#\textgreater{} 3                    Ipsos 2016{-}11{-}06 0.0300 0.021334733 {-}0.012669466}
\CommentTok{\#\textgreater{} 4                   YouGov 2016{-}11{-}07 0.0400 0.016478037  0.007043926}
\CommentTok{\#\textgreater{} 5         Gravis Marketing 2016{-}11{-}06 0.0400 0.007746199  0.024507601}
\CommentTok{\#\textgreater{}     superior}
\CommentTok{\#\textgreater{} 1 0.08241366}
\CommentTok{\#\textgreater{} 2 0.03566542}
\CommentTok{\#\textgreater{} 3 0.07266947}
\CommentTok{\#\textgreater{} 4 0.07295607}
\CommentTok{\#\textgreater{} 5 0.05549240}
\end{Highlighting}
\end{Shaded}

Now let's calculate how many of these pollsters guessed right in their estimation. That is, if in their confidence intervals is the real value of \(spread=48.2\%-46.1\%=2.1\%\) that Clinton finally obtained spread. To do this, we will add the column \texttt{guessed\_right} and then \texttt{summarize()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{surveys\_spread }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{guessed\_right =}\NormalTok{ inferior }\SpecialCharTok{\textless{}=} \FloatTok{0.021} \SpecialCharTok{\&} \FloatTok{0.021} \SpecialCharTok{\textless{}=}\NormalTok{ superior) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarize}\NormalTok{(}\FunctionTok{mean}\NormalTok{(guessed\_right))}
\CommentTok{\#\textgreater{}   mean(guessed\_right)}
\CommentTok{\#\textgreater{} 1           0.6735986}
\end{Highlighting}
\end{Shaded}

In this case we see how 67.3\% of the time, surveys correctly estimated the difference in votes favorable to Clinton.

As a clarification, final reminder of this case, even though Clinton obtained more votes she did not win the elections because the US system is different and not necessarily if you win in votes you obtain the presidency.

\section{Estimates Outside Election Polls}\label{estimates-outside-election-polls}

We have used election polls to understand statistical inference concepts. However, most Data Scientists are not related to voting intention estimation calculations. That does not mean we will not use those concepts. The central limit theorem not only works in election polls. What it means is that we will use some slightly different formulas that apply to more daily life cases.

From what we have learned so far the main change is the formula to calculate the standard error. We will use instead the standard deviation \(\sigma\) of the sample to calculate the standard error:

\(SE[\overline{X}]=\frac{\sigma}{\sqrt{n}}\)

Where \(\overline{X}\) is the average of our random sample and \(n\) is the sample size.

\subsection{Example: Estimating Average Height}\label{example-estimating-average-height}

Let's apply this to a real-world scenario. Suppose we want to estimate the average height of adult males in a population, but we can only measure a sample of 50 people.

Using the \texttt{heights} dataset from \texttt{dslabs}, let's simulate this process:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load the heights data}
\FunctionTok{data}\NormalTok{(heights)}

\CommentTok{\# Our "population" (in reality, we wouldn\textquotesingle{}t have access to this)}
\NormalTok{population }\OtherTok{\textless{}{-}}\NormalTok{ heights }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_cm =}\NormalTok{ height }\SpecialCharTok{*} \FloatTok{2.54}\NormalTok{) }\SpecialCharTok{|\textgreater{}}  \CommentTok{\# Convert to cm}
  \FunctionTok{pull}\NormalTok{(height\_cm)}

\CommentTok{\# True population parameters (unknown in real life)}
\NormalTok{true\_mean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(population)}
\NormalTok{true\_sd }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(population)}

\FunctionTok{cat}\NormalTok{(}\StringTok{"True population mean:"}\NormalTok{, }\FunctionTok{round}\NormalTok{(true\_mean, }\DecValTok{2}\NormalTok{), }\StringTok{"cm}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} True population mean: 176.06 cm}
\FunctionTok{cat}\NormalTok{(}\StringTok{"True population SD:"}\NormalTok{, }\FunctionTok{round}\NormalTok{(true\_sd, }\DecValTok{2}\NormalTok{), }\StringTok{"cm}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} True population SD: 9.17 cm}
\end{Highlighting}
\end{Shaded}

Now let's take a random sample and build a 95\% confidence interval:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{42}\NormalTok{)  }\CommentTok{\# For reproducibility}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}  \CommentTok{\# Sample size}

\CommentTok{\# Take a random sample}
\NormalTok{sample\_heights }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(population, n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Sample statistics}
\NormalTok{sample\_mean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(sample\_heights)}
\NormalTok{sample\_sd }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(sample\_heights)}

\CommentTok{\# Standard error of the mean}
\NormalTok{SE }\OtherTok{\textless{}{-}}\NormalTok{ sample\_sd }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}

\CommentTok{\# 95\% Confidence interval (2 standard errors)}
\NormalTok{ci\_lower }\OtherTok{\textless{}{-}}\NormalTok{ sample\_mean }\SpecialCharTok{{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ SE}
\NormalTok{ci\_upper }\OtherTok{\textless{}{-}}\NormalTok{ sample\_mean }\SpecialCharTok{+} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ SE}

\FunctionTok{cat}\NormalTok{(}\StringTok{"Sample mean:"}\NormalTok{, }\FunctionTok{round}\NormalTok{(sample\_mean, }\DecValTok{2}\NormalTok{), }\StringTok{"cm}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Sample mean: 176.97 cm}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Standard error:"}\NormalTok{, }\FunctionTok{round}\NormalTok{(SE, }\DecValTok{2}\NormalTok{), }\StringTok{"cm}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Standard error: 1.44 cm}
\FunctionTok{cat}\NormalTok{(}\StringTok{"95\% CI: ["}\NormalTok{, }\FunctionTok{round}\NormalTok{(ci\_lower, }\DecValTok{2}\NormalTok{), }\StringTok{","}\NormalTok{, }\FunctionTok{round}\NormalTok{(ci\_upper, }\DecValTok{2}\NormalTok{), }\StringTok{"] cm}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} 95\% CI: [ 174.09 , 179.84 ] cm}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Does CI contain true mean?"}\NormalTok{, ci\_lower }\SpecialCharTok{\textless{}=}\NormalTok{ true\_mean }\SpecialCharTok{\&}\NormalTok{ true\_mean }\SpecialCharTok{\textless{}=}\NormalTok{ ci\_upper, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Does CI contain true mean? TRUE}
\end{Highlighting}
\end{Shaded}

Let's visualize this with a Monte Carlo simulation to verify that our confidence intervals work as expected:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{n\_simulations }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{sim\_id =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n\_simulations}
\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{sample\_data =} \FunctionTok{map}\NormalTok{(sim\_id, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{sample}\NormalTok{(population, n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)),}
    \AttributeTok{sample\_mean =} \FunctionTok{map\_dbl}\NormalTok{(sample\_data, mean),}
    \AttributeTok{sample\_sd =} \FunctionTok{map\_dbl}\NormalTok{(sample\_data, sd),}
    \AttributeTok{SE =}\NormalTok{ sample\_sd }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n),}
    \AttributeTok{ci\_lower =}\NormalTok{ sample\_mean }\SpecialCharTok{{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ SE,}
    \AttributeTok{ci\_upper =}\NormalTok{ sample\_mean }\SpecialCharTok{+} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ SE,}
    \AttributeTok{contains\_true =}\NormalTok{ ci\_lower }\SpecialCharTok{\textless{}=}\NormalTok{ true\_mean }\SpecialCharTok{\&}\NormalTok{ true\_mean }\SpecialCharTok{\textless{}=}\NormalTok{ ci\_upper}
\NormalTok{  )}

\CommentTok{\# Proportion of CIs that contain the true mean}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Proportion of 95\% CIs containing true mean:"}\NormalTok{, }
    \FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(results}\SpecialCharTok{$}\NormalTok{contains\_true), }\DecValTok{3}\NormalTok{), }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} Proportion of 95\% CIs containing true mean: 0.956}
\end{Highlighting}
\end{Shaded}

This confirms that approximately 95\% of our confidence intervals capture the true population mean---exactly as the theory predicts!

\section{Exercises}\label{exercises-13}

The most common data a Data Scientist manages comes from people, some attribute/characteristic of them. In these exercises we are going to use the heights data frame that we already used for other purposes in previous chapters.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dslabs)}
\FunctionTok{data}\NormalTok{(heights)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{81}
\tightlist
\item
  Create a vector named \texttt{x} to extract the height data for all individuals in the dataset. Then, report the population's average and standard deviation, ensuring you convert the heights to meters first.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"Male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height\_m =}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(height\_m)}

\CommentTok{\# Average of the population}
\FunctionTok{mean}\NormalTok{(x)}

\CommentTok{\# Standard deviation}
\FunctionTok{sd}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Mathematically we use \texttt{x} in lowercase to refer to our total population and \texttt{X} to refer to a random sample. We will denote the population mean as \(\mu\) and the population standard deviation as \(\sigma\)
\end{quote}

\begin{quote}
Most of the time we will not have access to the mean and standard deviation of the population because it is very large and highly expensive.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{82}
\tightlist
\item
  Assume we cannot access the entire population and can only obtain a random sample of 100 people. Simulate this by creating a random sample with replacement from \texttt{x}, storing the values in a vector called \texttt{X}. Using this sample data, construct a 95\% confidence interval to estimate the population average.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(x, N, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# Expected value}
\FunctionTok{mean}\NormalTok{(X)}

\CommentTok{\# Standard error}
\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(X)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(N)}

\CommentTok{\# 95\% confidence interval is approx. 2 se}
\NormalTok{ic }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{mean}\NormalTok{(X) }\SpecialCharTok{{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{se, }\FunctionTok{mean}\NormalTok{(X) }\SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{se)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{83}
\tightlist
\item
  Validate your estimation method using a Monte Carlo simulation. Repeat the sampling process 10,000 times and calculate the percentage of expected confidence intervals that successfully capture the true population mean.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{true\_mean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(x)}

\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{n\_times }\OtherTok{\textless{}{-}} \DecValTok{10000}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2025}\NormalTok{)}
\NormalTok{simulation }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(n\_times, \{}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(x, N, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  se }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(X)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(N)}
\NormalTok{  lower }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(X) }\SpecialCharTok{{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{se}
\NormalTok{  upper }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(X) }\SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{se}
  \FunctionTok{between}\NormalTok{(true\_mean, lower, upper)}
\NormalTok{\})}

\FunctionTok{mean}\NormalTok{(simulation)}
\end{Highlighting}
\end{Shaded}

\part{Data Wrangling}\label{part-data-wrangling}

\chapter*{Introduction}\label{introduction-1}


A frequent error in Data Science projects is thinking that they start with analysis. In fact, when a data analyst is asked where they spend most of their time, the answer remains the same: \href{https://www.infoworld.com/article/3228245/the-80-20-data-science-dilemma.html}{80\% in Data Wrangling}\footnote{\url{https://www.infoworld.com/article/3228245/the-80-20-data-science-dilemma.html}}.

Data in its natural form (Raw Data), usually contain registration errors that make exact analysis impossible. Being recorded by different systems and people, it is normal to end up with a file in which the same value is expressed in different ways (for example, a date can be recorded as June 28, or as 28/06), there may be blank records, and of course, grammatical errors.

When analyzing this data, all these records have to be pre-processed. That is, the data must be cleaned, unified, consolidated, and normalized so that it can be used to extract valuable information. Data Wrangling is the process of preparing data to be leveraged.

In the following chapters, we will see several common steps of the Data Wrangling process such as Importing data into R from files, converting data to tidy type, string processing, html processing, date and time formatting, and text mining.

In this section, we will master the essential skills for getting data into R and reshaping it for analysis. We will start by learning how to \textbf{import data} from diverse sources, including CSV files, Excel spreadsheets, and web pages. Once loaded, we will explore how to \textbf{transform} data between ``wide'' and ``tidy'' (long) formats using \texttt{pivot\_longer()} and \texttt{pivot\_wider()}, ensuring our data is structured correctly for visualization and modeling. We will also cover how to \textbf{combine multiple datasets} using the powerful family of join functions (\texttt{left\_join()}, \texttt{inner\_join()}, etc.). Finally, we will delve into specialized processing techniques, including \textbf{web scraping}, \textbf{string manipulation} with regular expressions, \textbf{date conversion} with \texttt{lubridate}, and the fundamentals of \textbf{text mining} to extract insights from unstructured text.

\chapter{Data import and consolidation}\label{data-import-and-consolidation}

\section{Importing from files}\label{importing-from-files}

For importing files, whether they are text types or spreadsheets, we need to know where we are going to import the data from.

\subsection{Working Directory}\label{working-directory}

By default, when we import files, R will search in the working directory. To find out the path of our working directory we will use the \texttt{getwd()} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{getwd}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] "c:/Documents/dparedesi/git{-}repository/DS"}
\end{Highlighting}
\end{Shaded}

This is the path where we can place our files to load them. If we want to load data from another folder we can change the working directory using \texttt{setwd()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{setwd}\NormalTok{(}\StringTok{"c:/Documents/Projects/R Files"}\NormalTok{)}

\FunctionTok{getwd}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] "c:/Documents/Projects/R Files"}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Note}: While \texttt{setwd()} works, it is generally discouraged in reproducible workflows because it creates absolute paths that break when code is shared or moved. Consider using \textbf{RStudio Projects} combined with the \texttt{here} package, which provides \texttt{here::here()} to construct relative paths that work across different systems.
\end{quote}

For practical purposes, we are going to use a file already available in one of the previously installed packages, \texttt{dslabs}, when we analyzed the danger level to decide which US state to travel to. To do this, we can use the \texttt{system.file()} function and determine the path where the \texttt{dslabs} package was installed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dslabs\_path }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\AttributeTok{package=}\StringTok{"dslabs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Likewise, we can list the files and folders within that path using the \texttt{list.files()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dslabs\_path }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\AttributeTok{package=}\StringTok{"dslabs"}\NormalTok{)}
\FunctionTok{list.files}\NormalTok{(dslabs\_path)}
\CommentTok{\#\textgreater{}  [1] "data"        "DESCRIPTION" "extdata"     "help"        "html"       }
\CommentTok{\#\textgreater{}  [6] "INDEX"       "Meta"        "NAMESPACE"   "R"           "script"}
\end{Highlighting}
\end{Shaded}

The folder we will use is \textbf{extdata}. We can access the path of this folder if we modify the parameters of the \texttt{system.file()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dslabs\_path }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata"}\NormalTok{, }\AttributeTok{package=}\StringTok{"dslabs"}\NormalTok{)}
\FunctionTok{list.files}\NormalTok{(dslabs\_path)}
\CommentTok{\#\textgreater{}  [1] "2010\_bigfive\_regents.xls"                               }
\CommentTok{\#\textgreater{}  [2] "calificaciones.csv"                                     }
\CommentTok{\#\textgreater{}  [3] "carbon\_emissions.csv"                                   }
\CommentTok{\#\textgreater{}  [4] "fertility{-}two{-}countries{-}example.csv"                    }
\CommentTok{\#\textgreater{}  [5] "HRlist2.txt"                                            }
\CommentTok{\#\textgreater{}  [6] "life{-}expectancy{-}and{-}fertility{-}two{-}countries{-}example.csv"}
\CommentTok{\#\textgreater{}  [7] "murders.csv"                                            }
\CommentTok{\#\textgreater{}  [8] "olive.csv"                                              }
\CommentTok{\#\textgreater{}  [9] "RD{-}Mortality{-}Report\_2015{-}18{-}180531.pdf"                 }
\CommentTok{\#\textgreater{} [10] "ssa{-}death{-}probability.csv"}
\end{Highlighting}
\end{Shaded}

The file we will use is \textbf{murders.csv}. To build the complete path of this file we can concatenate the strings or we can also directly use the \texttt{file.path(path,\ file\_name)} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{csv\_example\_path }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(dslabs\_path, }\StringTok{"murders.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Finally, we will copy the file to our working directory with the \texttt{file.copy(source\_path,\ destination\_path)} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{file.copy}\NormalTok{(csv\_example\_path, }\FunctionTok{getwd}\NormalTok{())}
\CommentTok{\#\textgreater{} [1] TRUE}
\end{Highlighting}
\end{Shaded}

We can validate the copy with the \texttt{file.exists(file\_name)} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{file.exists}\NormalTok{(}\StringTok{"murders.csv"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] TRUE}
\end{Highlighting}
\end{Shaded}

It is recommended to check the documentation of the file manipulation functions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?files}
\end{Highlighting}
\end{Shaded}

\subsection{readr and readxl packages}\label{readr-and-readxl-packages}

Now that we have the file in our working directory, we will use functions within the \textbf{readr} and \textbf{readxl} packages to import files into R. Both are included in the \textbf{tidyverse} package that we previously installed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse) }\CommentTok{\# Here readr is included automatically}
\FunctionTok{library}\NormalTok{(readxl)}
\end{Highlighting}
\end{Shaded}

The functions we will use the most will be \texttt{read\_csv()} and \texttt{read\_excel()}. The latter supports .xls and .xlsx extensions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_df }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"murders.csv"}\NormalTok{, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Once imported we can remove the file if we wish}
\FunctionTok{file.remove}\NormalTok{(}\StringTok{"murders.csv"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] TRUE}
\end{Highlighting}
\end{Shaded}

We see how by default it detects the headers in the first row and assigns them a default data type. Let's now explore our \texttt{data\_df} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_df}
\CommentTok{\#\textgreater{} \# A tibble: 51 x 5}
\CommentTok{\#\textgreater{}    state                abb   region    population total}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}                \textless{}chr\textgreater{} \textless{}chr\textgreater{}          \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Alabama              AL    South        4779736   135}
\CommentTok{\#\textgreater{}  2 Alaska               AK    West          710231    19}
\CommentTok{\#\textgreater{}  3 Arizona              AZ    West         6392017   232}
\CommentTok{\#\textgreater{}  4 Arkansas             AR    South        2915918    93}
\CommentTok{\#\textgreater{}  5 California           CA    West        37253956  1257}
\CommentTok{\#\textgreater{}  6 Colorado             CO    West         5029196    65}
\CommentTok{\#\textgreater{}  7 Connecticut          CT    Northeast    3574097    97}
\CommentTok{\#\textgreater{}  8 Delaware             DE    South         897934    38}
\CommentTok{\#\textgreater{}  9 District of Columbia DC    South         601723    99}
\CommentTok{\#\textgreater{} 10 Florida              FL    South       19687653   669}
\CommentTok{\#\textgreater{} \# i 41 more rows}
\end{Highlighting}
\end{Shaded}

The first thing it indicates is that the object is of type \textbf{tibble}. This object is very similar to a data frame, but with improved features such as, for example, the number of rows and columns in the console, the data type under the header, the default report of only the first 10 records automatically, among many others that we will discover in this chapter.

The same syntax and logic would apply for importing an excel file. In this case we are importing directly from the package path and not from our working directory.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{excel\_example\_path }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(dslabs\_path, }\StringTok{"2010\_bigfive\_regents.xls"}\NormalTok{)}
\NormalTok{data\_df\_from\_excel }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(excel\_example\_path)}
\end{Highlighting}
\end{Shaded}

\textbf{readr} gives us 7 different types of functions for importing flat files:

The \texttt{readr} package provides a versatile suite of functions for importing flat files, each tailored to a specific delimiter or format. The most common is \textbf{\texttt{read\_csv()}}, designed for comma-separated values. For tab-separated files, we use \textbf{\texttt{read\_tsv()}}, while \textbf{\texttt{read\_delim()}} offers a general-purpose solution for files with custom delimiters (like semicolons or pipes). Other specialized functions include \textbf{\texttt{read\_fwf()}} for fixed-width files, \textbf{\texttt{read\_table()}} for whitespace-separated columns, and \textbf{\texttt{read\_log()}} for parsing standard web server logs.

\begin{quote}
\textbf{Tip}: For files that use semicolons as delimiters (common in European locales), use \texttt{read\_csv2()} or \texttt{read\_delim()} with \texttt{delim\ =\ ";"}. Also, if you encounter import issues, use \texttt{problems(data\_df)} after importing to diagnose parsing errors.
\end{quote}

\begin{quote}
{[}!TIP{]}
\textbf{Clean Column Names}: Interpreted data often has column names with spaces or capital letters (e.g., ``Customer ID''). We highly recommend piping your data into \texttt{janitor::clean\_names()} immediately after reading it to standardize everything to \texttt{snake\_case} (e.g., ``customer\_id'').
\end{quote}

\subsection{Importing files from the internet}\label{importing-files-from-the-internet}

We have seen how we can enter the full path to load a file directly from another source different from our working directory. In the same way, if we have a file in an internet path we can pass it directly to R since \texttt{read\_csv()} and the other \textbf{readr} import functions support URL input as a parameter.

Here we see the import of grades from students of the Data Science with R course.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\# Example 1:}
\CommentTok{\# Historical grades data}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/student{-}grades.csv"}
\NormalTok{grades }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grades }\OtherTok{\textless{}{-}}\NormalTok{ grades }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{total =}\NormalTok{ (P1 }\SpecialCharTok{+}\NormalTok{ P2 }\SpecialCharTok{+}\NormalTok{ P3 }\SpecialCharTok{+}\NormalTok{ P4 }\SpecialCharTok{+}\NormalTok{ P5 }\SpecialCharTok{+}\NormalTok{ P6)}\SpecialCharTok{/}\DecValTok{30}\SpecialCharTok{*}\DecValTok{20}\NormalTok{)}

\NormalTok{grades }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(P1, P2, P3, P4, P5, total) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summary}\NormalTok{()}
\CommentTok{\#\textgreater{}        P1              P2             P3              P4              P5       }
\CommentTok{\#\textgreater{}  Min.   :1.000   Min.   :1.00   Min.   :4.000   Min.   :1.000   Min.   :1.000  }
\CommentTok{\#\textgreater{}  1st Qu.:3.000   1st Qu.:4.00   1st Qu.:5.000   1st Qu.:5.000   1st Qu.:5.000  }
\CommentTok{\#\textgreater{}  Median :4.000   Median :5.00   Median :5.000   Median :5.000   Median :5.000  }
\CommentTok{\#\textgreater{}  Mean   :3.762   Mean   :4.19   Mean   :4.905   Mean   :4.571   Mean   :4.429  }
\CommentTok{\#\textgreater{}  3rd Qu.:5.000   3rd Qu.:5.00   3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:5.000  }
\CommentTok{\#\textgreater{}  Max.   :5.000   Max.   :5.00   Max.   :5.000   Max.   :5.000   Max.   :5.000  }
\CommentTok{\#\textgreater{}      total      }
\CommentTok{\#\textgreater{}  Min.   :10.67  }
\CommentTok{\#\textgreater{}  1st Qu.:16.67  }
\CommentTok{\#\textgreater{}  Median :18.67  }
\CommentTok{\#\textgreater{}  Mean   :17.43  }
\CommentTok{\#\textgreater{}  3rd Qu.:19.33  }
\CommentTok{\#\textgreater{}  Max.   :20.00}
\end{Highlighting}
\end{Shaded}

From this we could visualize a histogram:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(grades}\SpecialCharTok{$}\NormalTok{total)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-510-1} \end{center}

Or we could compare between genders which one has the highest median:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grades }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(gender, total) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}
  
\end{Highlighting}
\end{Shaded}

We could also extract updated Covid-19 information.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\# Example 2:}
\CommentTok{\# Covid{-}19 Data}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://covid.ourworldindata.org/data/owid{-}covid{-}data.csv"}
\NormalTok{internet\_data }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\NormalTok{internet\_data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(date)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Tidy data}\label{tidy-data}

Ordered data or \emph{tidy data} are those obtained from a process called \emph{data tidying}. It is one of the important cleaning processes during processing of large data or `big data' and is a very used step in Data Science. The main characteristics are that each different observation of that variable has to be in a different row and that each variable you measure has to be in a column \citep{leek2015}.

As we may have noticed, we have been using \emph{tidy data} since the first chapters. However, not all our data comes ordered. Most of it comes in what we call wide data or \emph{wide data}.

For example, we have previously used data from Gapminder. Let's filter the data from Germany and South Korea to remember how we had our data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"South Korea"}\NormalTok{, }\StringTok{"Germany"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}        country year infant\_mortality life\_expectancy fertility population}
\CommentTok{\#\textgreater{} 1      Germany 1960             34.0           69.26      2.41   73179665}
\CommentTok{\#\textgreater{} 2  South Korea 1960             80.2           53.02      6.16   25074028}
\CommentTok{\#\textgreater{} 3      Germany 1961               NA           69.85      2.44   73686490}
\CommentTok{\#\textgreater{} 4  South Korea 1961             76.1           53.75      5.99   25808542}
\CommentTok{\#\textgreater{} 5      Germany 1962               NA           70.01      2.47   74238494}
\CommentTok{\#\textgreater{} 6  South Korea 1962             72.4           54.51      5.79   26495107}
\CommentTok{\#\textgreater{} 7      Germany 1963               NA           70.10      2.49   74820389}
\CommentTok{\#\textgreater{} 8  South Korea 1963             68.8           55.27      5.57   27143075}
\CommentTok{\#\textgreater{} 9      Germany 1964               NA           70.66      2.49   75410766}
\CommentTok{\#\textgreater{} 10 South Korea 1964             65.3           56.04      5.36   27770874}
\CommentTok{\#\textgreater{}            gdp continent         region}
\CommentTok{\#\textgreater{} 1           NA    Europe Western Europe}
\CommentTok{\#\textgreater{} 2  28928298962      Asia   Eastern Asia}
\CommentTok{\#\textgreater{} 3           NA    Europe Western Europe}
\CommentTok{\#\textgreater{} 4  30356298714      Asia   Eastern Asia}
\CommentTok{\#\textgreater{} 5           NA    Europe Western Europe}
\CommentTok{\#\textgreater{} 6  31102566019      Asia   Eastern Asia}
\CommentTok{\#\textgreater{} 7           NA    Europe Western Europe}
\CommentTok{\#\textgreater{} 8  34067175844      Asia   Eastern Asia}
\CommentTok{\#\textgreater{} 9           NA    Europe Western Europe}
\CommentTok{\#\textgreater{} 10 36643076469      Asia   Eastern Asia}
\end{Highlighting}
\end{Shaded}

We notice that each row is an observation and each column represents a variable. It is ordered data, \emph{tidy data}. On the other hand, we can see what the data was like for these two countries if we access the source in the \texttt{dslabs} package.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fertility\_path }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(dslabs\_path, }\StringTok{"fertility{-}two{-}countries{-}example.csv"}\NormalTok{)}

\NormalTok{wide\_data }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(fertility\_path, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\NormalTok{wide\_data}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 57}
\CommentTok{\#\textgreater{}   country  \textasciigrave{}1960\textasciigrave{} \textasciigrave{}1961\textasciigrave{} \textasciigrave{}1962\textasciigrave{} \textasciigrave{}1963\textasciigrave{} \textasciigrave{}1964\textasciigrave{} \textasciigrave{}1965\textasciigrave{} \textasciigrave{}1966\textasciigrave{} \textasciigrave{}1967\textasciigrave{} \textasciigrave{}1968\textasciigrave{} \textasciigrave{}1969\textasciigrave{}}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Germany    2.41   2.44   2.47   2.49   2.49   2.48   2.44   2.37   2.28   2.17}
\CommentTok{\#\textgreater{} 2 South K\textasciitilde{}   6.16   5.99   5.79   5.57   5.36   5.16   4.99   4.85   4.73   4.62}
\CommentTok{\#\textgreater{} \# i 46 more variables: \textasciigrave{}1970\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1971\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1972\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1973\textasciigrave{} \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   \textasciigrave{}1974\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1975\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1976\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1977\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1978\textasciigrave{} \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   \textasciigrave{}1979\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1980\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1981\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1982\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1983\textasciigrave{} \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   \textasciigrave{}1984\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1985\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1986\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1987\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1988\textasciigrave{} \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   \textasciigrave{}1989\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1990\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1991\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1992\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1993\textasciigrave{} \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   \textasciigrave{}1994\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1995\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1996\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1997\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}1998\textasciigrave{} \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   \textasciigrave{}1999\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}2000\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}2001\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}2002\textasciigrave{} \textless{}dbl\textgreater{}, \textasciigrave{}2003\textasciigrave{} \textless{}dbl\textgreater{}, ...}
\end{Highlighting}
\end{Shaded}

We see that the original data had two rows, one per country and then each column represented a year. This is what we call wide data or \emph{wide data}. Normally we will have \emph{wide data} that we first have to convert to \emph{tidy data} to later be able to perform our analyses.

\subsection{Transforming to tidy data}\label{transforming-to-tidy-data}

The \texttt{tidyverse} library provides two functions to reshape data between \emph{wide} and \emph{long} (tidy) formats. We use \texttt{pivot\_longer()} to convert from \emph{wide data} to \emph{tidy data} and \texttt{pivot\_wider()} to convert from \emph{tidy data} to \emph{wide data}.

\subsubsection{pivot\_longer function}\label{pivot_longer-function}

Let's see the utility with the \texttt{wide\_data} object that we created in the previous section as a result of importing data from the csv. First apply the \texttt{pivot\_longer()} function to explore the conversion that is performed by default.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_data }\OtherTok{\textless{}{-}}\NormalTok{ wide\_data }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{country, }\AttributeTok{names\_to =} \StringTok{"key"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"value"}\NormalTok{)}

\NormalTok{tidy\_data}
\CommentTok{\#\textgreater{} \# A tibble: 112 x 3}
\CommentTok{\#\textgreater{}    country key   value}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}   \textless{}chr\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Germany 1960   2.41}
\CommentTok{\#\textgreater{}  2 Germany 1961   2.44}
\CommentTok{\#\textgreater{}  3 Germany 1962   2.47}
\CommentTok{\#\textgreater{}  4 Germany 1963   2.49}
\CommentTok{\#\textgreater{}  5 Germany 1964   2.49}
\CommentTok{\#\textgreater{}  6 Germany 1965   2.48}
\CommentTok{\#\textgreater{}  7 Germany 1966   2.44}
\CommentTok{\#\textgreater{}  8 Germany 1967   2.37}
\CommentTok{\#\textgreater{}  9 Germany 1968   2.28}
\CommentTok{\#\textgreater{} 10 Germany 1969   2.17}
\CommentTok{\#\textgreater{} \# i 102 more rows}
\end{Highlighting}
\end{Shaded}

We see how the \texttt{pivot\_longer()} function has collected the columns into two, the names column (``key'') and the values column (``value''). We can change the title of these new columns, for example ``year'' and ``fertility''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_data }\OtherTok{\textless{}{-}}\NormalTok{ wide\_data }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{country, }\AttributeTok{names\_to =} \StringTok{"year"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"fertility"}\NormalTok{)}

\NormalTok{tidy\_data}
\CommentTok{\#\textgreater{} \# A tibble: 112 x 3}
\CommentTok{\#\textgreater{}    country year  fertility}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Germany 1960       2.41}
\CommentTok{\#\textgreater{}  2 Germany 1961       2.44}
\CommentTok{\#\textgreater{}  3 Germany 1962       2.47}
\CommentTok{\#\textgreater{}  4 Germany 1963       2.49}
\CommentTok{\#\textgreater{}  5 Germany 1964       2.49}
\CommentTok{\#\textgreater{}  6 Germany 1965       2.48}
\CommentTok{\#\textgreater{}  7 Germany 1966       2.44}
\CommentTok{\#\textgreater{}  8 Germany 1967       2.37}
\CommentTok{\#\textgreater{}  9 Germany 1968       2.28}
\CommentTok{\#\textgreater{} 10 Germany 1969       2.17}
\CommentTok{\#\textgreater{} \# i 102 more rows}
\end{Highlighting}
\end{Shaded}

We use \texttt{cols\ =\ -country} to exclude the country column from being pivoted. By default the column names are collected as text. To convert them to numbers we use the \texttt{names\_transform} argument.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_data }\OtherTok{\textless{}{-}}\NormalTok{ wide\_data }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{country, }\AttributeTok{names\_to =} \StringTok{"year"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"fertility"}\NormalTok{,}
               \AttributeTok{names\_transform =} \FunctionTok{list}\NormalTok{(}\AttributeTok{year =}\NormalTok{ as.integer))}

\NormalTok{tidy\_data}
\CommentTok{\#\textgreater{} \# A tibble: 112 x 3}
\CommentTok{\#\textgreater{}    country  year fertility}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}   \textless{}int\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Germany  1960      2.41}
\CommentTok{\#\textgreater{}  2 Germany  1961      2.44}
\CommentTok{\#\textgreater{}  3 Germany  1962      2.47}
\CommentTok{\#\textgreater{}  4 Germany  1963      2.49}
\CommentTok{\#\textgreater{}  5 Germany  1964      2.49}
\CommentTok{\#\textgreater{}  6 Germany  1965      2.48}
\CommentTok{\#\textgreater{}  7 Germany  1966      2.44}
\CommentTok{\#\textgreater{}  8 Germany  1967      2.37}
\CommentTok{\#\textgreater{}  9 Germany  1968      2.28}
\CommentTok{\#\textgreater{} 10 Germany  1969      2.17}
\CommentTok{\#\textgreater{} \# i 102 more rows}
\end{Highlighting}
\end{Shaded}

This data would now be ready to create graphs using \texttt{ggplot()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_data }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(year, fertility, }\AttributeTok{color =}\NormalTok{ country) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-518-1} \end{center}

\subsubsection{pivot\_wider function}\label{pivot_wider-function}

Sometimes, as we will see in the following section, it will be useful to go back from rows to columns. For this we will use the \texttt{pivot\_wider()} function, where we specify \texttt{names\_from} (the column containing the new column names) and \texttt{values\_from} (the column containing the values). Additionally, we can use the \texttt{:} operator to indicate from which column to which column we want to select.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ year, }\AttributeTok{values\_from =}\NormalTok{ fertility) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(country, }\StringTok{\textasciigrave{}}\AttributeTok{1965}\StringTok{\textasciigrave{}}\SpecialCharTok{:}\StringTok{\textasciigrave{}}\AttributeTok{1970}\StringTok{\textasciigrave{}}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 7}
\CommentTok{\#\textgreater{}   country     \textasciigrave{}1965\textasciigrave{} \textasciigrave{}1966\textasciigrave{} \textasciigrave{}1967\textasciigrave{} \textasciigrave{}1968\textasciigrave{} \textasciigrave{}1969\textasciigrave{} \textasciigrave{}1970\textasciigrave{}}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}        \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Germany       2.48   2.44   2.37   2.28   2.17   2.04}
\CommentTok{\#\textgreater{} 2 South Korea   5.16   4.99   4.85   4.73   4.62   4.53}
\end{Highlighting}
\end{Shaded}

\subsection{separate function}\label{separate-function}

In the cases described above we had a situation with relatively ordered data. We only had to do a collection transformation and converted to \emph{tidy data}. However, the data is not always stored in such an easily interpretable way. Sometimes we have data like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{path }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(dslabs\_path, }\StringTok{"life{-}expectancy{-}and{-}fertility{-}two{-}countries{-}example.csv"}\NormalTok{)}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(path, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\NormalTok{data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{) }\CommentTok{\#Report first 5 columns}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 5}
\CommentTok{\#\textgreater{}   country     \textasciigrave{}1960\_fertility\textasciigrave{} \textasciigrave{}1960\_life\_expectancy\textasciigrave{} \textasciigrave{}1961\_fertility\textasciigrave{}}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}                  \textless{}dbl\textgreater{}                  \textless{}dbl\textgreater{}            \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Germany                 2.41                   69.3             2.44}
\CommentTok{\#\textgreater{} 2 South Korea             6.16                   53.0             5.99}
\CommentTok{\#\textgreater{} \# i 1 more variable: \textasciigrave{}1961\_life\_expectancy\textasciigrave{} \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

If we apply \texttt{pivot\_longer()} directly we would not have our data ordered yet. Let's see:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{country, }\AttributeTok{names\_to =} \StringTok{"key\_col"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"value\_col"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 224 x 3}
\CommentTok{\#\textgreater{}    country key\_col              value\_col}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}   \textless{}chr\textgreater{}                    \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Germany 1960\_fertility            2.41}
\CommentTok{\#\textgreater{}  2 Germany 1960\_life\_expectancy     69.3 }
\CommentTok{\#\textgreater{}  3 Germany 1961\_fertility            2.44}
\CommentTok{\#\textgreater{}  4 Germany 1961\_life\_expectancy     69.8 }
\CommentTok{\#\textgreater{}  5 Germany 1962\_fertility            2.47}
\CommentTok{\#\textgreater{}  6 Germany 1962\_life\_expectancy     70.0 }
\CommentTok{\#\textgreater{}  7 Germany 1963\_fertility            2.49}
\CommentTok{\#\textgreater{}  8 Germany 1963\_life\_expectancy     70.1 }
\CommentTok{\#\textgreater{}  9 Germany 1964\_fertility            2.49}
\CommentTok{\#\textgreater{} 10 Germany 1964\_life\_expectancy     70.7 }
\CommentTok{\#\textgreater{} \# i 214 more rows}
\end{Highlighting}
\end{Shaded}

We will use the \texttt{separate()} function to separate a column into multiple columns using a specific separator. In this case our separator would be the character \texttt{\_}. Also, we will add the attribute \texttt{extra="merge"} to indicate that if there is more than one separator character, do not separate them and keep them joined.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{country, }\AttributeTok{names\_to =} \StringTok{"key\_col"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"value\_col"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{separate}\NormalTok{(key\_col, }\FunctionTok{c}\NormalTok{(}\StringTok{"year"}\NormalTok{, }\StringTok{"other\_var"}\NormalTok{), }\AttributeTok{sep=}\StringTok{"\_"}\NormalTok{, }\AttributeTok{extra =} \StringTok{"merge"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 224 x 4}
\CommentTok{\#\textgreater{}    country year  other\_var       value\_col}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}   \textless{}chr\textgreater{} \textless{}chr\textgreater{}               \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Germany 1960  fertility            2.41}
\CommentTok{\#\textgreater{}  2 Germany 1960  life\_expectancy     69.3 }
\CommentTok{\#\textgreater{}  3 Germany 1961  fertility            2.44}
\CommentTok{\#\textgreater{}  4 Germany 1961  life\_expectancy     69.8 }
\CommentTok{\#\textgreater{}  5 Germany 1962  fertility            2.47}
\CommentTok{\#\textgreater{}  6 Germany 1962  life\_expectancy     70.0 }
\CommentTok{\#\textgreater{}  7 Germany 1963  fertility            2.49}
\CommentTok{\#\textgreater{}  8 Germany 1963  life\_expectancy     70.1 }
\CommentTok{\#\textgreater{}  9 Germany 1964  fertility            2.49}
\CommentTok{\#\textgreater{} 10 Germany 1964  life\_expectancy     70.7 }
\CommentTok{\#\textgreater{} \# i 214 more rows}
\end{Highlighting}
\end{Shaded}

We already have the year separated, but this data is still not \emph{tidy data} since there is a row for fertility and a row for life expectancy for each country. We have to pass these values from row to columns. And for that we already learned that we can use the \texttt{pivot\_wider()} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{country, }\AttributeTok{names\_to =} \StringTok{"key\_col"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"value\_col"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{separate}\NormalTok{(key\_col, }\FunctionTok{c}\NormalTok{(}\StringTok{"year"}\NormalTok{, }\StringTok{"other\_var"}\NormalTok{), }\AttributeTok{sep=}\StringTok{"\_"}\NormalTok{, }\AttributeTok{extra =} \StringTok{"merge"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ other\_var, }\AttributeTok{values\_from =}\NormalTok{ value\_col)}
\CommentTok{\#\textgreater{} \# A tibble: 112 x 4}
\CommentTok{\#\textgreater{}    country year  fertility life\_expectancy}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}           \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Germany 1960       2.41            69.3}
\CommentTok{\#\textgreater{}  2 Germany 1961       2.44            69.8}
\CommentTok{\#\textgreater{}  3 Germany 1962       2.47            70.0}
\CommentTok{\#\textgreater{}  4 Germany 1963       2.49            70.1}
\CommentTok{\#\textgreater{}  5 Germany 1964       2.49            70.7}
\CommentTok{\#\textgreater{}  6 Germany 1965       2.48            70.6}
\CommentTok{\#\textgreater{}  7 Germany 1966       2.44            70.8}
\CommentTok{\#\textgreater{}  8 Germany 1967       2.37            71.0}
\CommentTok{\#\textgreater{}  9 Germany 1968       2.28            70.6}
\CommentTok{\#\textgreater{} 10 Germany 1969       2.17            70.5}
\CommentTok{\#\textgreater{} \# i 102 more rows}
\end{Highlighting}
\end{Shaded}

In other cases, instead of separating a column we will want to join them. In future cases we will see how the \texttt{unite(column\_1,\ column2)} function can also be useful.

\section{Exercises}\label{exercises-14}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{84}
\tightlist
\item
  Access the \textbf{Uber Peru 2010} dataset from \href{https://dparedesi.github.io/Data-Science-with-R-book/data/uber-peru-2010.csv}{this link} and attempt to import it into an object named \texttt{uber\_peru\_2010}. Pay attention to the delimiters used in the file.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/uber{-}peru{-}2010.csv"}

\CommentTok{\# We will use read\_csv since it is separated by commas}
\NormalTok{uber\_peru\_2010 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Upon importing it we realize it is separated by ";"}
\NormalTok{uber\_peru\_2010 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{()}

\CommentTok{\# Therefore we import again using read\_delim}
\NormalTok{uber\_peru\_2010 }\OtherTok{\textless{}{-}} \FunctionTok{read\_delim}\NormalTok{(}\StringTok{"external/uber{-}peru{-}2010.csv"}\NormalTok{, }
                             \AttributeTok{delim =} \StringTok{";"}\NormalTok{, }
                             \AttributeTok{col\_types =} \FunctionTok{cols}\NormalTok{(}\AttributeTok{.default =} \StringTok{"c"}\NormalTok{)}
\NormalTok{                             )}

\NormalTok{uber\_peru\_2010 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{85}
\tightlist
\item
  Import the \textbf{SINADEF} deaths registry from \href{https://www.datosabiertos.gob.pe/sites/default/files/sinadef-deaths.csv}{this source} into an object called \texttt{deaths}. Ensure you handle the file encoding correctly to avoid character issues.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://www.datosabiertos.gob.pe/sites/default/files/sinadef{-}deaths.csv"}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/sinadef{-}deaths.csv"}

\CommentTok{\# We will use read\_delim because it is delimited by ";" and not by ","}
\CommentTok{\# Also we change the encoding to avoid error in loading}
\NormalTok{deaths }\OtherTok{\textless{}{-}} \FunctionTok{read\_delim}\NormalTok{(url, }\StringTok{";"}\NormalTok{,}
                          \AttributeTok{local =} \FunctionTok{locale}\NormalTok{(}\AttributeTok{encoding =} \StringTok{"latin1"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{86}
\tightlist
\item
  Download the resource file from \href{https://dparedesi.github.io/Data-Science-with-R-book/data/resources-other-idd.xlsx}{this link} to a temporary location. Validating that the file exists, load the specific sheet named ``Deflators'' into an object named \texttt{data}.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Store the url}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/resources{-}other{-}idd.xlsx"}

\CommentTok{\# Create a temporary name \& path for our file. See: ?tempfile}
\NormalTok{temp\_file }\OtherTok{\textless{}{-}} \FunctionTok{tempfile}\NormalTok{()}

\CommentTok{\# Download the file to our temp}
\FunctionTok{download.file}\NormalTok{(url, temp\_file)}

\CommentTok{\# Import the excel}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(temp\_file, }\AttributeTok{sheet =} \StringTok{"Deflators"}\NormalTok{)}

\CommentTok{\# Remove the temporary file}
\FunctionTok{file.remove}\NormalTok{(temp\_file)}
\end{Highlighting}
\end{Shaded}

For the following files run the following code so that you have access to the objects referred to in the problems:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# GDP by countries}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/gdp.csv"}
\NormalTok{gdp }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Diseases by years by countries}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/diseases{-}evolution.csv"}
\NormalTok{diseases\_wide }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Number of female mayors}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/female{-}mayors.csv"}
\NormalTok{female\_mayors }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Evolution of a university}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/university.csv"}
\NormalTok{university }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{87}
\tightlist
\item
  Examine the structure of the \texttt{gdp} dataset. Transform it into a \emph{tidy} format suitable for analysis, and then create a line plot visualizing the evolution of GDP over time for each country.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# To tidy data}
\NormalTok{gdp }\OtherTok{\textless{}{-}}\NormalTok{ gdp }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{country, }\AttributeTok{names\_to =} \StringTok{"year"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"gdp"}\NormalTok{,}
               \AttributeTok{names\_transform =} \FunctionTok{list}\NormalTok{(}\AttributeTok{year =}\NormalTok{ as.integer))}

\NormalTok{gdp}

\CommentTok{\# Visualization}
\NormalTok{gdp }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(year, gdp, }\AttributeTok{color=}\NormalTok{country) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{88}
\tightlist
\item
  The \texttt{diseases\_wide} object contains disease counts in a wide format. Reshape this dataframe into a \emph{tidy} structure where the specific diseases are consolidated into a single column.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Solution}
\NormalTok{diseases\_1 }\OtherTok{\textless{}{-}}\NormalTok{ diseases\_wide }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{country, }\SpecialCharTok{{-}}\NormalTok{year, }\SpecialCharTok{{-}}\NormalTok{population), }\AttributeTok{names\_to =} \StringTok{"disease"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"count"}\NormalTok{)}

\NormalTok{diseases\_1}

\CommentTok{\# Alternative solution. Instead of indicating what to omit, we indicate what to take into account}
\NormalTok{diseases\_2 }\OtherTok{\textless{}{-}}\NormalTok{ diseases\_wide }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =}\NormalTok{ HepatitisA}\SpecialCharTok{:}\NormalTok{Rubella, }\AttributeTok{names\_to =} \StringTok{"disease"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"count"}\NormalTok{)}

\NormalTok{diseases\_2}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{89}
\tightlist
\item
  Convert the \texttt{female\_mayors} dataset, which is currently in a long format, into a \emph{wide} format where the variables are spread across columns.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{female\_mayors }\OtherTok{\textless{}{-}}\NormalTok{ female\_mayors }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ variable, }\AttributeTok{values\_from =}\NormalTok{ total)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{90}
\tightlist
\item
  The \texttt{university} dataset is untidy. Reshape it by first pivoting longer to gather variables, separating the combined variable names, and then pivoting wider to achieve a final tidy structure.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{university }\OtherTok{\textless{}{-}}\NormalTok{ university }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{semester, }\AttributeTok{names\_to =} \StringTok{"variable"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"value"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{separate}\NormalTok{(variable, }\FunctionTok{c}\NormalTok{(}\StringTok{"name"}\NormalTok{, }\StringTok{"variable2"}\NormalTok{), }\AttributeTok{sep=}\StringTok{"\_"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ variable2, }\AttributeTok{values\_from =}\NormalTok{ value)}

\NormalTok{university}
\end{Highlighting}
\end{Shaded}

\section{Joining tables}\label{joining-tables}

Regularly we will have data from different sources that we then have to combine to be able to perform our analyses. For this we will learn different groups of functions that will allow us to combine multiple objects.

\subsection{Join functions}\label{join-functions}

Join functions are the most used in table crossing. To use them we have to make sure we have the \texttt{dplyr} library installed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\end{Highlighting}
\end{Shaded}

This library includes a variety of functions to combine tables.

The \texttt{dplyr} package offers a family of join functions to combine tables based on common keys. The most frequently used is \textbf{\texttt{left\_join()}}, which preserves all rows from the first (left) table and appends matching data from the second. Conversely, \textbf{\texttt{right\_join()}} keeps all rows from the second table. \textbf{\texttt{inner\_join()}} is more restrictive, retaining only the rows that have matching keys in \emph{both} tables, effectively filtering for the intersection. \textbf{\texttt{full\_join()}} does the opposite, keeping \emph{all} rows from both tables and filling missing values with \texttt{NA}. Finally, filtering joins like \textbf{\texttt{semi\_join()}} (keeps rows in the first table that match the second) and \textbf{\texttt{anti\_join()}} (keeps rows in the first table that do \emph{not} match the second) are excellent for data validation and filtering without adding new columns.

To see the join functions with examples we will use the following files:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url\_1 }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/join{-}card.csv"}
\NormalTok{url\_2 }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/join{-}customer.csv"}

\NormalTok{card\_data\_1 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url\_1, }\AttributeTok{col\_types =} \FunctionTok{cols}\NormalTok{(}\AttributeTok{id =} \FunctionTok{col\_character}\NormalTok{()))}
\NormalTok{customer\_data\_2 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url\_2, }\AttributeTok{col\_types =} \FunctionTok{cols}\NormalTok{(}\AttributeTok{id =} \FunctionTok{col\_character}\NormalTok{()))}

\NormalTok{card\_data\_1}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 3}
\CommentTok{\#\textgreater{}   id       customer\_type card            }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}         \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 45860518 premium       VISA gold       }
\CommentTok{\#\textgreater{} 2 46534312 bronze        Mastercard Black}
\CommentTok{\#\textgreater{} 3 47564535 silver        VISA platinum   }
\CommentTok{\#\textgreater{} 4 48987654 bronze        American Express}
\CommentTok{\#\textgreater{} 5 78765434 gold          VISA Signature  }
\CommentTok{\#\textgreater{} 6 41346556 premium       Diners Club}

\NormalTok{customer\_data\_2}
\CommentTok{\#\textgreater{} \# A tibble: 8 x 4}
\CommentTok{\#\textgreater{}   id       first\_name last\_name mother\_last\_name}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}      \textless{}chr\textgreater{}     \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 49321442 Iver       Castro    Rivera          }
\CommentTok{\#\textgreater{} 2 47564535 Enrique    Gutierrez Rivasplata      }
\CommentTok{\#\textgreater{} 3 48987654 Alexandra  Cupe      Gaspar          }
\CommentTok{\#\textgreater{} 4 47542345 Christiam  Olortegui Roca            }
\CommentTok{\#\textgreater{} 5 41346556 Karen      Jara      Mory            }
\CommentTok{\#\textgreater{} 6 45860518 Hebert     Lopez     Chavez          }
\CommentTok{\#\textgreater{} 7 71234321 Jesus      Valle     Mariños         }
\CommentTok{\#\textgreater{} 8 73231243 Jenny      Sosa      Sosa}
\end{Highlighting}
\end{Shaded}

\subsubsection{Left join}\label{left-join}

Given two tables with the same identifier (in our case our identifier consists only of a single column: ID), the left join function maintains the information of the first table and completes it with the data that crosses in the second table

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{left\_join}\NormalTok{(card\_data\_1, customer\_data\_2, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 6}
\CommentTok{\#\textgreater{}   id       customer\_type card             first\_name last\_name mother\_last\_name}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}         \textless{}chr\textgreater{}            \textless{}chr\textgreater{}      \textless{}chr\textgreater{}     \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 45860518 premium       VISA gold        Hebert     Lopez     Chavez          }
\CommentTok{\#\textgreater{} 2 46534312 bronze        Mastercard Black \textless{}NA\textgreater{}       \textless{}NA\textgreater{}      \textless{}NA\textgreater{}            }
\CommentTok{\#\textgreater{} 3 47564535 silver        VISA platinum    Enrique    Gutierrez Rivasplata      }
\CommentTok{\#\textgreater{} 4 48987654 bronze        American Express Alexandra  Cupe      Gaspar          }
\CommentTok{\#\textgreater{} 5 78765434 gold          VISA Signature   \textless{}NA\textgreater{}       \textless{}NA\textgreater{}      \textless{}NA\textgreater{}            }
\CommentTok{\#\textgreater{} 6 41346556 premium       Diners Club      Karen      Jara      Mory}
\end{Highlighting}
\end{Shaded}

As we can see, the first three columns are exactly the same as we initially had and to the right of those columns we see the columns of the other table for the values \hspace{0pt}\hspace{0pt}that did cross the data. In this case we are facing a data inconsistency since all customers of \texttt{card\_data\_1} should be in \texttt{customer\_data\_2}. This inconsistency could lead us to have to map the data loss process, etc.

\subsubsection{Right join}\label{right-join}

Given two tables with the same identifier, the right join function maintains the information of the second table and completes it with the data that crosses in the first table

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{right\_join}\NormalTok{(card\_data\_1, customer\_data\_2, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 8 x 6}
\CommentTok{\#\textgreater{}   id       customer\_type card             first\_name last\_name mother\_last\_name}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}         \textless{}chr\textgreater{}            \textless{}chr\textgreater{}      \textless{}chr\textgreater{}     \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 45860518 premium       VISA gold        Hebert     Lopez     Chavez          }
\CommentTok{\#\textgreater{} 2 47564535 silver        VISA platinum    Enrique    Gutierrez Rivasplata      }
\CommentTok{\#\textgreater{} 3 48987654 bronze        American Express Alexandra  Cupe      Gaspar          }
\CommentTok{\#\textgreater{} 4 41346556 premium       Diners Club      Karen      Jara      Mory            }
\CommentTok{\#\textgreater{} 5 49321442 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Iver       Castro    Rivera          }
\CommentTok{\#\textgreater{} 6 47542345 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Christiam  Olortegui Roca            }
\CommentTok{\#\textgreater{} 7 71234321 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Jesus      Valle     Mariños         }
\CommentTok{\#\textgreater{} 8 73231243 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Jenny      Sosa      Sosa}
\end{Highlighting}
\end{Shaded}

The idea is the same as in \texttt{left\_join}, only this time the \texttt{NA} are in the first two columns.

\subsubsection{Inner join}\label{inner-join}

In this case we will only have the intersection of the tables. Only the result of the data that are in both tables will be shown.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{inner\_join}\NormalTok{(card\_data\_1, customer\_data\_2, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 6}
\CommentTok{\#\textgreater{}   id       customer\_type card             first\_name last\_name mother\_last\_name}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}         \textless{}chr\textgreater{}            \textless{}chr\textgreater{}      \textless{}chr\textgreater{}     \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 45860518 premium       VISA gold        Hebert     Lopez     Chavez          }
\CommentTok{\#\textgreater{} 2 47564535 silver        VISA platinum    Enrique    Gutierrez Rivasplata      }
\CommentTok{\#\textgreater{} 3 48987654 bronze        American Express Alexandra  Cupe      Gaspar          }
\CommentTok{\#\textgreater{} 4 41346556 premium       Diners Club      Karen      Jara      Mory}
\end{Highlighting}
\end{Shaded}

\subsubsection{Full join}\label{full-join}

Full join is a total crossing of both. It shows us all the data that are in both the first and the second table.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{full\_join}\NormalTok{(card\_data\_1, customer\_data\_2, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 6}
\CommentTok{\#\textgreater{}    id       customer\_type card             first\_name last\_name mother\_last\_name}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}    \textless{}chr\textgreater{}         \textless{}chr\textgreater{}            \textless{}chr\textgreater{}      \textless{}chr\textgreater{}     \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{}  1 45860518 premium       VISA gold        Hebert     Lopez     Chavez          }
\CommentTok{\#\textgreater{}  2 46534312 bronze        Mastercard Black \textless{}NA\textgreater{}       \textless{}NA\textgreater{}      \textless{}NA\textgreater{}            }
\CommentTok{\#\textgreater{}  3 47564535 silver        VISA platinum    Enrique    Gutierrez Rivasplata      }
\CommentTok{\#\textgreater{}  4 48987654 bronze        American Express Alexandra  Cupe      Gaspar          }
\CommentTok{\#\textgreater{}  5 78765434 gold          VISA Signature   \textless{}NA\textgreater{}       \textless{}NA\textgreater{}      \textless{}NA\textgreater{}            }
\CommentTok{\#\textgreater{}  6 41346556 premium       Diners Club      Karen      Jara      Mory            }
\CommentTok{\#\textgreater{}  7 49321442 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Iver       Castro    Rivera          }
\CommentTok{\#\textgreater{}  8 47542345 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Christiam  Olortegui Roca            }
\CommentTok{\#\textgreater{}  9 71234321 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Jesus      Valle     Mariños         }
\CommentTok{\#\textgreater{} 10 73231243 \textless{}NA\textgreater{}          \textless{}NA\textgreater{}             Jenny      Sosa      Sosa}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Tip}: To join on multiple columns, use a vector: \texttt{by\ =\ c("col1",\ "col2")}. To join on columns with different names, use named vectors: \texttt{by\ =\ c("left\_col"\ =\ "right\_col")}.
\end{quote}

\subsubsection{Semi join}\label{semi-join}

The case of the semi join is very similar to \texttt{left\_join} with the difference that it only shows us the columns of the first table and eliminates the data that did not manage to cross (what in \texttt{left\_join} comes out as NA). Also, none of the columns of table 2 appear. This is like doing a filter requesting the following: show me only the data from table 1 that is also in table 2.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semi\_join}\NormalTok{(card\_data\_1, customer\_data\_2, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 3}
\CommentTok{\#\textgreater{}   id       customer\_type card            }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}         \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 45860518 premium       VISA gold       }
\CommentTok{\#\textgreater{} 2 47564535 silver        VISA platinum   }
\CommentTok{\#\textgreater{} 3 48987654 bronze        American Express}
\CommentTok{\#\textgreater{} 4 41346556 premium       Diners Club}
\end{Highlighting}
\end{Shaded}

\subsubsection{Anti join}\label{anti-join}

In the case of \texttt{anti\_join} we have the opposite of \texttt{semi\_join} since it shows the data from table 1 that are \textbf{not} in table 2.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anti\_join}\NormalTok{(card\_data\_1, customer\_data\_2, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 3}
\CommentTok{\#\textgreater{}   id       customer\_type card            }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}         \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 46534312 bronze        Mastercard Black}
\CommentTok{\#\textgreater{} 2 78765434 gold          VISA Signature}
\end{Highlighting}
\end{Shaded}

\subsection{Joining without a common identifier}\label{joining-without-a-common-identifier}

Likewise, we will have some moments when we need to combine only two objects, without using any type of intersection. For this we will use the \texttt{bind} functions. These functions allow us to put together two vectors or tables either in rows or columns.

\subsubsection{Union of vectors}\label{union-of-vectors}

If we have two or more vectors of the same size we can create the union of the columns to create a table using the \texttt{bind\_cols()} function. Let's see with an example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector\_1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"hello"}\NormalTok{, }\StringTok{"Have you seen"}\NormalTok{, }\StringTok{"the"}\NormalTok{)}
\NormalTok{vector\_2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Julian"}\NormalTok{, }\StringTok{"Carla"}\NormalTok{, }\StringTok{"Wednesday"}\NormalTok{)}

\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(}\AttributeTok{greeting =}\NormalTok{ vector\_1, }\AttributeTok{nouns =}\NormalTok{ vector\_2)}

\NormalTok{result}
\CommentTok{\#\textgreater{} \# A tibble: 3 x 2}
\CommentTok{\#\textgreater{}   greeting      nouns    }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}         \textless{}chr\textgreater{}    }
\CommentTok{\#\textgreater{} 1 hello         Julian   }
\CommentTok{\#\textgreater{} 2 Have you seen Carla    }
\CommentTok{\#\textgreater{} 3 the           Wednesday}
\end{Highlighting}
\end{Shaded}

\subsubsection{Union of tables}\label{union-of-tables}

In the case of tables the use is the same. Likewise, we can also join the rows of two or more tables. To see its application let's first create some example tables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table\_1 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{name =} \FunctionTok{c}\NormalTok{(}\StringTok{"Jhasury"}\NormalTok{, }\StringTok{"Thomas"}\NormalTok{, }\StringTok{"Andres"}\NormalTok{, }\StringTok{"Josep"}\NormalTok{),}
  \AttributeTok{surname =} \FunctionTok{c}\NormalTok{(}\StringTok{"Campos"}\NormalTok{, }\StringTok{"Gonzales"}\NormalTok{, }\StringTok{"Santiago"}\NormalTok{, }\StringTok{"Villaverde"}\NormalTok{),}
  \AttributeTok{address =} \FunctionTok{c}\NormalTok{(}\StringTok{"Jr. los campos 471"}\NormalTok{, }\StringTok{"Av. Casuarinas 142"}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\StringTok{"Av. Tupac Amaru 164"}\NormalTok{),}
  \AttributeTok{phone =} \FunctionTok{c}\NormalTok{(}\StringTok{"976567325"}\NormalTok{, }\StringTok{"956732587"}\NormalTok{, }\StringTok{"961445664"}\NormalTok{, }\StringTok{"987786453"}\NormalTok{)}
\NormalTok{)}

\NormalTok{table\_2 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{age =} \FunctionTok{c}\NormalTok{(}\DecValTok{21}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{12}\NormalTok{),}
  \AttributeTok{sign =} \FunctionTok{c}\NormalTok{(}\StringTok{"Aries"}\NormalTok{, }\StringTok{"Capricorn"}\NormalTok{, }\StringTok{"Sagittarius"}\NormalTok{, }\StringTok{"Libra"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# Create a table from row 2 to 3 of table\_1}
\NormalTok{table\_3 }\OtherTok{\textless{}{-}}\NormalTok{ table\_1[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

Once we have our tables let's proceed to join them. We see that they do not have a common identifier.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(table\_1, table\_2)}
\NormalTok{result}
\CommentTok{\#\textgreater{}      name    surname             address     phone age        sign}
\CommentTok{\#\textgreater{} 1 Jhasury     Campos  Jr. los campos 471 976567325  21       Aries}
\CommentTok{\#\textgreater{} 2  Thomas   Gonzales  Av. Casuarinas 142 956732587  24   Capricorn}
\CommentTok{\#\textgreater{} 3  Andres   Santiago                \textless{}NA\textgreater{} 961445664  19 Sagittarius}
\CommentTok{\#\textgreater{} 4   Josep Villaverde Av. Tupac Amaru 164 987786453  12       Libra}
\end{Highlighting}
\end{Shaded}

or joining by rows like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(table\_1, table\_3)}
\NormalTok{result}
\CommentTok{\#\textgreater{}      name    surname             address     phone}
\CommentTok{\#\textgreater{} 1 Jhasury     Campos  Jr. los campos 471 976567325}
\CommentTok{\#\textgreater{} 2  Thomas   Gonzales  Av. Casuarinas 142 956732587}
\CommentTok{\#\textgreater{} 3  Andres   Santiago                \textless{}NA\textgreater{} 961445664}
\CommentTok{\#\textgreater{} 4   Josep Villaverde Av. Tupac Amaru 164 987786453}
\CommentTok{\#\textgreater{} 5  Thomas   Gonzales  Av. Casuarinas 142 956732587}
\CommentTok{\#\textgreater{} 6  Andres   Santiago                \textless{}NA\textgreater{} 961445664}
\end{Highlighting}
\end{Shaded}

\section{Web Scraping}\label{web-scraping}

Web Scraping is the process of extracting data from a website. We will use it when we need to extract data directly from tables that are presented on websites. For this we will use the \texttt{rvest} library, included in the \texttt{tidyverse} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(rvest)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Important}: When scraping websites, always respect the site's \texttt{robots.txt} file and terms of service. Avoid making excessive requests that could overload servers. For commercial use, consider whether the data is licensed or requires permission.
\end{quote}

The function we will use the most will be \texttt{read\_html()} and as an argument we will place the url of the web from where we want to extract the data. We are not talking about a url that downloads a text file but a web page like this:

\begin{center}\includegraphics[width=0.8\linewidth,alt={Wikipedia table of Hispanic countries by population}]{assets/images/05-wrangling/hispanic-countries} \end{center}

Thus, we will use \texttt{read\_html()} to store all the web html and then little by little access the table data in R.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{html\_data }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(}\StringTok{"https://es.wikipedia.org/wiki/Anexo:Pa\%C3\%ADses\_hispanos\_por\_poblaci\%C3\%B3n"}\NormalTok{)}

\NormalTok{html\_data}
\CommentTok{\#\textgreater{} \{html\_document\}}
\CommentTok{\#\textgreater{} \textless{}html class="client{-}nojs vector{-}feature{-}language{-}in{-}header{-}enabled vector{-}feature{-}language{-}in{-}main{-}page{-}header{-}disabled vector{-}feature{-}page{-}tools{-}pinned{-}disabled vector{-}feature{-}toc{-}pinned{-}clientpref{-}1 vector{-}feature{-}main{-}menu{-}pinned{-}disabled vector{-}feature{-}limited{-}width{-}clientpref{-}1 vector{-}feature{-}limited{-}width{-}content{-}enabled vector{-}feature{-}custom{-}font{-}size{-}clientpref{-}1 vector{-}feature{-}appearance{-}pinned{-}clientpref{-}1 vector{-}feature{-}night{-}mode{-}enabled skin{-}theme{-}clientpref{-}day vector{-}sticky{-}header{-}enabled vector{-}toc{-}available" lang="es" dir="ltr"\textgreater{}}
\CommentTok{\#\textgreater{} [1] \textless{}head\textgreater{}\textbackslash{}n\textless{}meta http{-}equiv="Content{-}Type" content="text/html; charset=UTF{-}8 ...}
\CommentTok{\#\textgreater{} [2] \textless{}body class="skin{-}{-}responsive skin{-}vector skin{-}vector{-}search{-}vue mediawik ...}
\end{Highlighting}
\end{Shaded}

Now that we have the data stored in the object we have to go looking for the data, doing scraping. For this we will use the \texttt{html\_nodes("table")} function to access the ``table'' node.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{web\_tables }\OtherTok{\textless{}{-}}\NormalTok{ html\_data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{html\_elements}\NormalTok{(}\StringTok{"table"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Finally, we have to go index by index looking for the table that interests us. To give it table format we will use \texttt{html\_table}. In this case we will use double brackets because it is a list of lists and the \texttt{setNames()} function to change the name of the columns.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We format as table and store in raw\_table}
\NormalTok{raw\_table }\OtherTok{\textless{}{-}}\NormalTok{ web\_tables[[}\DecValTok{1}\NormalTok{]] }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{html\_table}\NormalTok{()}

\CommentTok{\# Change header names}
\NormalTok{raw\_table }\OtherTok{\textless{}{-}}\NormalTok{ raw\_table }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{setNames}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\StringTok{"N"}\NormalTok{, }\StringTok{"country"}\NormalTok{, }\StringTok{"population"}\NormalTok{, }\StringTok{"pop\_prop"}\NormalTok{, }\StringTok{"avg\_change"}\NormalTok{, }\StringTok{"link"}\NormalTok{)}
\NormalTok{  )}

\CommentTok{\# Convert to tibble}
\NormalTok{raw\_table }\OtherTok{\textless{}{-}}\NormalTok{ raw\_table }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{as\_tibble}\NormalTok{()}

\CommentTok{\# Report first rows}
\NormalTok{raw\_table }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 2}
\CommentTok{\#\textgreater{}   N     country                                                                 }
\CommentTok{\#\textgreater{}   \textless{}lgl\textgreater{} \textless{}chr\textgreater{}                                                                   }
\CommentTok{\#\textgreater{} 1 NA    Este artículo o sección se encuentra desactualizado.La información sumi\textasciitilde{}}
\end{Highlighting}
\end{Shaded}

We already have our data imported and we could already start exploring its content in detail.

\section{Exercises}\label{exercises-15}

For the following exercises we will use objects from the \textbf{Lahman} library, which contains US baseball player data. Run the following Script before starting to solve the exercises.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"Lahman"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(Lahman)}

\CommentTok{\# Top 10 players of the year 2016}
\NormalTok{top\_players }\OtherTok{\textless{}{-}}\NormalTok{ Batting }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(yearID }\SpecialCharTok{==} \DecValTok{2016}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(HR)) }\SpecialCharTok{|\textgreater{}}    \CommentTok{\# sorted by number of "Home run"}
  \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{)    }\CommentTok{\# Take from row 1 to 10}

\NormalTok{top\_players }\OtherTok{\textless{}{-}}\NormalTok{ top\_players }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_tibble}\NormalTok{()}

\CommentTok{\# List of all baseball players from recent years}
\NormalTok{master }\OtherTok{\textless{}{-}}\NormalTok{ Master }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_tibble}\NormalTok{()}

\CommentTok{\# Awards won by players}
\NormalTok{awards }\OtherTok{\textless{}{-}}\NormalTok{ AwardsPlayers }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(yearID }\SpecialCharTok{==} \DecValTok{2016}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{as\_tibble}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{91}
\tightlist
\item
  Using the \texttt{top\_players} and \texttt{Master} datasets, join them to retrieve the \texttt{playerID}, first name, last name, and home runs (\texttt{HR}) for the top 10 players of 2016.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top\_10 }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(top\_players, master, }\AttributeTok{by =} \StringTok{"playerID"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(playerID, nameFirst, nameLast, HR)}

\NormalTok{top\_10}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{92}
\tightlist
\item
  Identify the \textbf{intersection} of top players and award winners. List the ID and names of the top 10 players from 2016 who also won at least one award that year.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semi\_join}\NormalTok{(top\_10, awards, }\AttributeTok{by =} \StringTok{"playerID"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{93}
\tightlist
\item
  Find the players who won awards in 2016 but did \textbf{not} make it into the top 10 list. Report their IDs and names.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First we calculate all prizes of those who are not top 10:}
\NormalTok{non\_top\_award\_ids }\OtherTok{\textless{}{-}} \FunctionTok{anti\_join}\NormalTok{(awards, top\_10, }\AttributeTok{by =} \StringTok{"playerID"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(playerID)}

\CommentTok{\# As a player could have obtained several prizes we obtain unique values}
\NormalTok{non\_top\_award\_ids }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(non\_top\_award\_ids)}

\CommentTok{\# Then we cross with the master to obtain the names}
\NormalTok{other\_names }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(non\_top\_award\_ids, master, }\AttributeTok{by =} \StringTok{"playerID"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(playerID, nameFirst, nameLast)}

\NormalTok{other\_names}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{94}
\tightlist
\item
  Scrape the MLB payroll data from \texttt{http://www.stevetheump.com/Payrolls.htm}. Store the entire page html, extract the tables, and specifically isolate the fourth table (\texttt{node\ 4}), formatting it as a data frame.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"http://www.stevetheump.com/Payrolls.htm"}
\NormalTok{html }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(url)}

\NormalTok{nodes }\OtherTok{\textless{}{-}}\NormalTok{ html }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{html\_elements}\NormalTok{(}\StringTok{"table"}\NormalTok{)}

\NormalTok{nodes[[}\DecValTok{4}\NormalTok{]] }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{html\_table}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{95}
\tightlist
\item
  Using the scraped tables, prepare the 2019 payroll (node 4) and 2018 payroll (node 5) data. Standardize the column names to \texttt{team}, \texttt{payroll\_2019}, and \texttt{payroll\_2018} respectively. Finally, perform a \textbf{full join} to combine these datasets by team name.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{payroll\_2019 }\OtherTok{\textless{}{-}}\NormalTok{ nodes[[}\DecValTok{4}\NormalTok{]] }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{html\_table}\NormalTok{()}

\NormalTok{payroll\_2018 }\OtherTok{\textless{}{-}}\NormalTok{ nodes[[}\DecValTok{5}\NormalTok{]] }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{html\_table}\NormalTok{()}

\DocumentationTok{\#\#\#\#\#\#\# Payroll 2019: \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#We eliminate row 15 which is the league average:}
\NormalTok{payroll\_2019 }\OtherTok{\textless{}{-}}\NormalTok{ payroll\_2019[}\SpecialCharTok{{-}}\DecValTok{15}\NormalTok{, ]}

\CommentTok{\#We filter the requested columns:}
\NormalTok{payroll\_2019 }\OtherTok{\textless{}{-}}\NormalTok{ payroll\_2019 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(X2, X4) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{team =}\NormalTok{ X2, }\AttributeTok{payroll\_2019 =}\NormalTok{ X4)}

\CommentTok{\# We eliminate row 1 since it is the source header}
\NormalTok{payroll\_2019 }\OtherTok{\textless{}{-}}\NormalTok{ payroll\_2019[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,]}

\DocumentationTok{\#\#\#\#\#\#\# Payroll 2018: \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\# We select the two columns that interest us and }
\CommentTok{\#change name to headers}
\NormalTok{payroll\_2018 }\OtherTok{\textless{}{-}}\NormalTok{ payroll\_2018 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(Team, Payroll) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{team =}\NormalTok{ Team, }\AttributeTok{payroll\_2018 =}\NormalTok{ Payroll)}

\DocumentationTok{\#\#\#\#\#\#\# Full join: \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\FunctionTok{full\_join}\NormalTok{(payroll\_2018, payroll\_2019, }\AttributeTok{by =} \StringTok{"team"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\part{Machine learning}\label{part-machine-learning}

\chapter*{Introduction}\label{introduction-2}


We have seen so far how to work with data: importing, cleaning, and visualizing it. Performing analysis of what has happened allows us to take a determined action to change the course of a business. However, the true power of data science lies in using this data to \textbf{predict} the future.

Predictive analysis is a technique that every Data Scientist must master, and \emph{Machine learning} provides us with robust algorithms to make these predictions.

\emph{Machine learning} is the study of computer algorithms that improve automatically through experience. It is a subset of artificial intelligence where algorithms create mathematical models based on sample data, known as ``training data'', to make predictions or decisions without being explicitly programmed to do so. Applications range from recommendation engines (like Netflix or Spotify) to fraud detection and self-driving cars \citep{mitchell1997}.

A good \emph{data scientist} knows how to build prediction algorithms using \emph{machine learning}. In this book, we will focus on the two main approaches:

We will explore two primary approaches to machine learning. \textbf{Supervised Learning} involves training models on labeled data where we know the correct answer, allowing us to predict outcomes for new, unseen data---either as numbers (regression) or categories (classification). In contrast, \textbf{Unsupervised Learning} deals with unlabeled data, where the goal is to discover hidden patterns, structures, or groupings (clustering) without a pre-defined answer key.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Machine learning diagram showing supervised vs unsupervised learning branches}]{assets/images/06-machine-learning/ML} \end{center}

Keep in mind that there are also other approaches, such as semi-supervised learning or \textbf{reinforcement learning} where the algorithm learns from a real or synthetic environment. These approaches will not be covered in this book, which focuses on the foundational techniques for starting out as a \emph{data scientist}.

\section{Learning Objectives}\label{learning-objectives-2}

By the end of this chapter, you will be able to:

In this chapter, we will learn to distinguish between \textbf{supervised} and \textbf{unsupervised} learning approaches. We will implement core algorithms such as \textbf{k-Nearest Neighbors (kNN)}, \textbf{Logistic Regression}, and \textbf{Random Forest} for classification tasks, and build \textbf{regression models} to predict continuous variables. Additionally, we will evaluate model performance using essential metrics like \textbf{confusion matrices} and \textbf{ROC curves}, apply \textbf{clustering techniques} to segment data, and select the optimal model using the modern \texttt{tidymodels} framework.

\section{Chapter Structure}\label{chapter-structure}

We will cover the two main approaches to machine learning:

Our journey covers these two fundamental pillars. We begin with \textbf{Supervised Learning}, focusing on models that learn from historical data to predict future outcomes, covering both classification and regression problems. We then move to \textbf{Unsupervised Learning}, techniques designed to find structure in unlabeled data, such as grouping similar customers or reducing complex datasets to their essential features.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Machine learning diagram showing supervised vs unsupervised learning branches}]{assets/images/06-machine-learning/ML} \end{center}

Keep in mind that there are also other approaches, such as semi-supervised learning or \textbf{reinforcement learning} where the algorithm learns from a real or synthetic environment. These approaches will not be covered in this book, which focuses on the most commonly used approaches for starting out as a \emph{data scientist}.

\chapter{Supervised Learning}\label{supervised-learning}

To understand supervised learning intuitively, we can compare it to how humans learn from examples.

Consider a doctor diagnosing patients. The doctor has \textbf{trained} for years using textbooks and case studies where the symptoms (inputs) and the correct diagnosis (output) were known. During their residency, they \textbf{test} their knowledge under the supervision of experienced mentors. Finally, once licensed, they \textbf{apply} this knowledge to diagnose new patients where the outcome is unknown.

This is an example of \textbf{supervised learning}.
This process mirrors \textbf{supervised learning}. First, the model undergoes a \textbf{Training} phase, learning from labeled data (like symptoms and their corresponding diagnoses). Next, during \textbf{Testing}, it is evaluated on new, unseen cases where the outcome is already known to verify its accuracy. finally, the model enters the \textbf{Prediction} phase, where it applies its learned knowledge to real-world data to generate diagnoses (predictions) for unknown cases.

In machine learning terms:
In machine learning terms, we have \textbf{Inputs} (features or predictors) which are the data points used to make a prediction, and \textbf{Outputs} (target or response), which are the values we aim to predict. The ultimate \textbf{Goal} is to learn the mathematical relationship between these inputs and outputs to accurately forecast outcomes for future data.

\begin{quote}
{[}!TIP{]}
\textbf{Key Terminology}
\textbf{Key Terminology}
In supervised learning, the \textbf{Input} (or Feature/Independent Variable) refers to the data used to make a prediction, such as patient symptoms or house characteristics. The \textbf{Output} (or Target/Dependent Variable) is the value we want to predict, like a medical diagnosis or a house price. We rely on \textbf{Labels}, which are the known ``answers'' in our training data, to teach the model.
\end{quote}

Common applications include:
Common applications of these techniques include \textbf{Spam Detection} (classifying emails as ``Spam'' or ``Not Spam''), \textbf{Credit Scoring} (predicting the likelihood of a customer repaying a loan), and \textbf{House Price Prediction} (estimating a property's value based on its location and size).

\section{Classification and Regression}\label{classification-and-regression}

We divide supervised learning into two main types based on the target variable:

We divide supervised learning into two main types based on the nature of the target variable. \textbf{Classification} is used when the target is a discrete category, such as determining if an email is spam (Yes/No) or predicting which product a customer will buy (A, B, or C). \textbf{Regression}, on the other hand, is used when the target is a continuous number, like estimating the price of a house or forecasting the number of units to be sold next month.

In the following sections, we will learn algorithms for both tasks.

\section{kNN: k-Nearest Neighbors}\label{knn-k-nearest-neighbors}

Let's start with a simple but very useful \textbf{classification} algorithm, the k-Nearest Neighbors algorithm (\emph{kNN}).

\subsection{Two variables as input}\label{two-variables-as-input}

Let's start by understanding it visually. Imagine that we have two variables as \emph{input} and as \emph{output} it gives us whether it is Red Class or Blue Class. This data is our training data.

\begin{quote}
{[}!NOTE{]}
\textbf{When to use kNN?}
kNN is excellent for small datasets with few dimensions (variables) because it is simple and explains non-linear patterns well. However, it becomes very slow and less accurate as the dataset grows in size or number of variables (the ``curse of dimensionality'').
\end{quote}

\begin{center}\includegraphics[width=0.8\linewidth,alt={Training data points on a 2D plane with red and blue class labels}]{assets/images/06-machine-learning/kNN-train} \end{center}

Now that we have our training data, we will start using the test data. As we want to predict the class, the \emph{output}, we will see how one of these data points would look visually and paint it yellow. Next, we calculate the distance between this point and the other data points.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Test point shown in yellow with distance lines to nearby training data points}]{assets/images/06-machine-learning/kNN-test} \end{center}

We have traced only some distances, but we could do it with all of them. For this example, we will take the \textbf{k = 3} nearest neighbors. Why 3? It is common to pick an odd number to avoid ties (where the vote is 50/50).

\begin{center}\includegraphics[width=0.8\linewidth,alt={k-NN classification showing 3 nearest neighbors (2 red, 1 blue), classifying test point as red}]{assets/images/06-machine-learning/kNN-classify} \end{center}

We notice that if we focus only on the 3 nearest neighbors, there are more reds than blues, so our prediction will be that this point must be Class R (red).

Calculating the distance on a Cartesian plane is relatively simple, we only have variables as input: on the x-axis and y-axis. However, the same logic can be taken to more variables.

\subsection{Multiple variables as input}\label{multiple-variables-as-input}

Let's see how it would be with 4 variables as input. We are going to work again with the \texttt{iris} data frame, which, as we will recall, has 4 attributes of a plant and the last column is the species to which it belongs.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(iris)}

\NormalTok{iris }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}    Sepal.Length Sepal.Width Petal.Length Petal.Width Species}
\CommentTok{\#\textgreater{} 1           5.1         3.5          1.4         0.2  setosa}
\CommentTok{\#\textgreater{} 2           4.9         3.0          1.4         0.2  setosa}
\CommentTok{\#\textgreater{} 3           4.7         3.2          1.3         0.2  setosa}
\CommentTok{\#\textgreater{} 4           4.6         3.1          1.5         0.2  setosa}
\CommentTok{\#\textgreater{} 5           5.0         3.6          1.4         0.2  setosa}
\CommentTok{\#\textgreater{} 6           5.4         3.9          1.7         0.4  setosa}
\CommentTok{\#\textgreater{} 7           4.6         3.4          1.4         0.3  setosa}
\CommentTok{\#\textgreater{} 8           5.0         3.4          1.5         0.2  setosa}
\CommentTok{\#\textgreater{} 9           4.4         2.9          1.4         0.2  setosa}
\CommentTok{\#\textgreater{} 10          4.9         3.1          1.5         0.1  setosa}
\end{Highlighting}
\end{Shaded}

The idea is as follows, we will take training data, 50 data points. From this data, we have the 4 input attributes and the last column is the output, the species. We will use the kNN algorithm taking this training data as input to create our model. Then, with testing data, another 50 data points, we will test our model.

Let's start by taking a random sample of 100 records and separate half for training and half for testing. Since we have 150 data points in our data frame, let's take a sample of the indices. In this case, we are going to use the \texttt{set.seed(n)} function to force the random sample values to be the same always. Thus, we can all obtain the same results and the explanation in the book in these chapters is consistent with the results that each reader obtains. For a real exercise, we should not include that line. It is recommended to read the documentation \texttt{?set.seed()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 28 is the author\textquotesingle{}s birthday}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}

\NormalTok{sample\_idx }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{150}\NormalTok{, }\DecValTok{100}\NormalTok{)}

\NormalTok{train\_idx }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(sample\_idx, }\DecValTok{50}\NormalTok{)}

\NormalTok{test\_idx }\OtherTok{\textless{}{-}}\NormalTok{ sample\_idx[}\SpecialCharTok{!}\NormalTok{sample\_idx }\SpecialCharTok{\%in\%}\NormalTok{ train\_idx]}
\end{Highlighting}
\end{Shaded}

Now that we have the indices we can build our training data and our test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_train }\OtherTok{\textless{}{-}}\NormalTok{ iris[train\_idx, ]}
\NormalTok{iris\_test }\OtherTok{\textless{}{-}}\NormalTok{ iris[test\_idx, ]}

\NormalTok{iris\_train\_input }\OtherTok{\textless{}{-}}\NormalTok{ iris\_train[, }\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{]}
\NormalTok{iris\_train\_output }\OtherTok{\textless{}{-}}\NormalTok{ iris\_train[, }\DecValTok{5}\NormalTok{]}

\NormalTok{iris\_test\_input }\OtherTok{\textless{}{-}}\NormalTok{ iris\_test[, }\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{]}
\NormalTok{iris\_test\_output }\OtherTok{\textless{}{-}}\NormalTok{ iris\_test[, }\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Although we could build the algorithms to calculate the minimum distances for each point, R provides us with libraries that facilitate the creation of these models. To do this, we will load the \texttt{class} library, which will allow us to execute kNN quickly.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"class"}\NormalTok{)}

\FunctionTok{library}\NormalTok{(class)}
\end{Highlighting}
\end{Shaded}

This library provides us with the \texttt{knn()} function, which will take the training data to create the model and once the model is created it will take the test data to predict the \emph{output} for our test data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_test\_output\_kNN }\OtherTok{\textless{}{-}} \FunctionTok{knn}\NormalTok{(}\AttributeTok{train =}\NormalTok{ iris\_train\_input, }
                       \AttributeTok{cl =}\NormalTok{ iris\_train\_output, }
                       \AttributeTok{test =}\NormalTok{ iris\_test\_input, }
                       \AttributeTok{k =} \DecValTok{3}\NormalTok{)}

\NormalTok{iris\_test\_output\_kNN}
\CommentTok{\#\textgreater{}  [1] versicolor versicolor versicolor versicolor setosa     versicolor}
\CommentTok{\#\textgreater{}  [7] virginica  virginica  virginica  virginica  versicolor versicolor}
\CommentTok{\#\textgreater{} [13] virginica  versicolor versicolor versicolor setosa     versicolor}
\CommentTok{\#\textgreater{} [19] versicolor virginica  virginica  setosa     versicolor versicolor}
\CommentTok{\#\textgreater{} [25] versicolor virginica  setosa     setosa     versicolor versicolor}
\CommentTok{\#\textgreater{} [31] virginica  setosa     setosa     virginica  virginica  setosa    }
\CommentTok{\#\textgreater{} [37] setosa     virginica  setosa     versicolor setosa     virginica }
\CommentTok{\#\textgreater{} [43] setosa     setosa     setosa     virginica  virginica  versicolor}
\CommentTok{\#\textgreater{} [49] virginica  versicolor}
\CommentTok{\#\textgreater{} Levels: setosa versicolor virginica}
\end{Highlighting}
\end{Shaded}

Thus, the knn function throws us the prediction just by entering the training data as attributes, the test inputs, and how many nearest neighbors it will look for (k). And not only that, we can compare our prediction with the test \emph{output} to see how \textbf{accurate} (\emph{accuracy}) our model is. To do this, we calculate the percentage of correct predictions regarding the test \emph{output}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(iris\_test\_output\_kNN }\SpecialCharTok{==}\NormalTok{ iris\_test\_output)}
\CommentTok{\#\textgreater{} [1] 0.94}
\end{Highlighting}
\end{Shaded}

In addition, we can place a summary in a table, also known as a \textbf{confusion matrix}, to see how many predicted values were equal to the real ones using the \texttt{table()} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(iris\_test\_output\_kNN, iris\_test\_output)}
\CommentTok{\#\textgreater{}                     iris\_test\_output}
\CommentTok{\#\textgreater{} iris\_test\_output\_kNN setosa versicolor virginica}
\CommentTok{\#\textgreater{}           setosa         14          0         0}
\CommentTok{\#\textgreater{}           versicolor      0         18         2}
\CommentTok{\#\textgreater{}           virginica       0          1        15}
\end{Highlighting}
\end{Shaded}

Let's interpret this result cell by cell:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Our kNN model predicted 14 values as species ``setosa'' and it turns out that in our test the real value, \emph{output}, was also setosa.
\item
  Our model predicted 20 as species versicolor. However, in the real-test data, of those 20, only 18 are versicolor and 2 are virginica.
\item
  Our model predicted 16 as species virginica. However, in the real-test data, of those 16, only 15 are virginica.
\end{enumerate}

\subsection{Diverse values of k}\label{diverse-values-of-k}

So far we have only used a single value for k, 3 nearest neighbors. However, we could see the accuracy for different values of k. Since we have 50 values in our training data, we will see the hits taking a maximum of 50 nearest neighbors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{50}
\NormalTok{result\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(k, }\AttributeTok{precision =} \DecValTok{0}\NormalTok{)}

\ControlFlowTok{for}\NormalTok{(n }\ControlFlowTok{in}\NormalTok{ k)\{}
\NormalTok{  iris\_test\_output\_kNN }\OtherTok{\textless{}{-}} \FunctionTok{knn}\NormalTok{(}\AttributeTok{train =}\NormalTok{ iris\_train\_input, }
                              \AttributeTok{cl =}\NormalTok{ iris\_train\_output, }
                              \AttributeTok{test =}\NormalTok{ iris\_test\_input, }
                              \AttributeTok{k =}\NormalTok{ n)}
  
\NormalTok{  result\_df}\SpecialCharTok{$}\NormalTok{precision[n] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(iris\_test\_output\_kNN }\SpecialCharTok{==}\NormalTok{ iris\_test\_output)}
\NormalTok{\}}

\NormalTok{result\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(k, precision) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-581-1} \end{center}

As we can see, the accuracy (precision) changes with \texttt{k}. This illustrates a fundamental concept in Machine Learning:

\begin{itemize}
\tightlist
\item
  \textbf{Overfitting (Low k):} When \texttt{k} is too low (e.g., \texttt{k=1}), the model pays excessive attention to individual data points, including noise. It effectively ``memorizes'' the training data but fails to generalize to new, unseen examples.
\item
  \textbf{Underfitting (High k):} Conversely, if \texttt{k} is too high (e.g., \texttt{k=50}), the model becomes overly simple, averaging out the signal and missing the distinct patterns that differentiate the classes.
\end{itemize}

Finding the sweet spot between these two extremes is the goal of \textbf{Hyperparameter Tuning}. It will depend on each case to choose the best ``k'' for our model to balance this trade-off (often called the \textbf{Bias-Variance Tradeoff}).

We have thus built our first machine learning model.

\section{tidymodels Framework}\label{tidymodels-framework}

Now that we have created our first machine learning model, we have seen ourselves with many lines of code. For example, to split the sample into training and test, to calculate the optimal ``k'', etc. To make the work easier, we will use the \texttt{tidymodels} framework. \href{https://www.tidymodels.org/}{tidymodels}\footnote{\url{https://www.tidymodels.org/}} is a collection of packages for modeling and machine learning using tidyverse principles. It provides a unified, modern interface for:

It provides a unified, modern interface via a suite of specialized packages: \textbf{rsample} for data splitting and resampling, \textbf{recipes} for feature engineering and preprocessing, \textbf{parsnip} for specifying models, \textbf{tune} for hyperparameter optimization, \textbf{yardstick} for metrics and model evaluation, and \textbf{workflows} to bundle everything together.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{\textquotesingle{}tidymodels\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidymodels)}
\CommentTok{\#\textgreater{} {-}{-} Attaching packages {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} tidymodels 1.4.1 {-}{-}}
\CommentTok{\#\textgreater{} v broom        1.0.11     v tailor       0.1.0 }
\CommentTok{\#\textgreater{} v dials        1.4.2      v tune         2.0.1 }
\CommentTok{\#\textgreater{} v infer        1.1.0      v workflows    1.3.0 }
\CommentTok{\#\textgreater{} v parsnip      1.4.0      v workflowsets 1.1.1 }
\CommentTok{\#\textgreater{} v recipes      1.3.1      v yardstick    1.3.2 }
\CommentTok{\#\textgreater{} v rsample      1.3.1}
\CommentTok{\#\textgreater{} {-}{-} Conflicts {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} tidymodels\_conflicts() {-}{-}}
\CommentTok{\#\textgreater{} x NLP::annotate()         masks ggplot2::annotate()}
\CommentTok{\#\textgreater{} x scales::discard()       masks purrr::discard()}
\CommentTok{\#\textgreater{} x Matrix::expand()        masks tidyr::expand()}
\CommentTok{\#\textgreater{} x dplyr::filter()         masks stats::filter()}
\CommentTok{\#\textgreater{} x recipes::fixed()        masks stringr::fixed()}
\CommentTok{\#\textgreater{} x dplyr::lag()            masks stats::lag()}
\CommentTok{\#\textgreater{} x Matrix::pack()          masks tidyr::pack()}
\CommentTok{\#\textgreater{} x rsample::permutations() masks gtools::permutations()}
\CommentTok{\#\textgreater{} x dials::prune()          masks dendextend::prune()}
\CommentTok{\#\textgreater{} x yardstick::spec()       masks readr::spec()}
\CommentTok{\#\textgreater{} x recipes::step()         masks stats::step()}
\CommentTok{\#\textgreater{} x Matrix::unpack()        masks tidyr::unpack()}
\CommentTok{\#\textgreater{} x recipes::update()       masks Matrix::update(), stats::update()}
\end{Highlighting}
\end{Shaded}

We are going to do another example with k-nearest neighbors, but this time using the functions of the \textbf{tidymodels} framework. The data for this example will be obtained from the \texttt{ISLR} library, which contains the daily percentage returns for the S\&P 500 stock index between 2001 and 2005. This data frame has 8 columns that we will use as \emph{input} and the last column that has two classes (whether the index goes up or down) that we will use as \emph{output} (See \texttt{?Smarket}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"ISLR"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ISLR)}
\FunctionTok{data}\NormalTok{(Smarket)}
\CommentTok{\# Data frame that we will use}
\NormalTok{Smarket }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}    Year   Lag1   Lag2   Lag3   Lag4   Lag5 Volume  Today Direction}
\CommentTok{\#\textgreater{} 1  2001  0.381 {-}0.192 {-}2.624 {-}1.055  5.010 1.1913  0.959        Up}
\CommentTok{\#\textgreater{} 2  2001  0.959  0.381 {-}0.192 {-}2.624 {-}1.055 1.2965  1.032        Up}
\CommentTok{\#\textgreater{} 3  2001  1.032  0.959  0.381 {-}0.192 {-}2.624 1.4112 {-}0.623      Down}
\CommentTok{\#\textgreater{} 4  2001 {-}0.623  1.032  0.959  0.381 {-}0.192 1.2760  0.614        Up}
\CommentTok{\#\textgreater{} 5  2001  0.614 {-}0.623  1.032  0.959  0.381 1.2057  0.213        Up}
\CommentTok{\#\textgreater{} 6  2001  0.213  0.614 {-}0.623  1.032  0.959 1.3491  1.392        Up}
\CommentTok{\#\textgreater{} 7  2001  1.392  0.213  0.614 {-}0.623  1.032 1.4450 {-}0.403      Down}
\CommentTok{\#\textgreater{} 8  2001 {-}0.403  1.392  0.213  0.614 {-}0.623 1.4078  0.027        Up}
\CommentTok{\#\textgreater{} 9  2001  0.027 {-}0.403  1.392  0.213  0.614 1.1640  1.303        Up}
\CommentTok{\#\textgreater{} 10 2001  1.303  0.027 {-}0.403  1.392  0.213 1.2326  0.287        Up}

\CommentTok{\# We make some translations for ease of analysis}
\NormalTok{Smarket }\OtherTok{\textless{}{-}}\NormalTok{ Smarket }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{Direction =}\NormalTok{ Direction) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Direction =} \FunctionTok{ifelse}\NormalTok{(Direction }\SpecialCharTok{==} \StringTok{"Up"}\NormalTok{, }\StringTok{"Up"}\NormalTok{, }\StringTok{"Down"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Direction"}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{as.factor}\NormalTok{(.)))}
\end{Highlighting}
\end{Shaded}

\subsection{Creation of training and test data}\label{creation-of-training-and-test-data}

From the total of our data frame, we will split a part of the data for training and the other to do the tests. tidymodels provides the \texttt{initial\_split()} function from the \texttt{rsample} package which creates a clean split object. We allocate 75\% of the data for training using the \texttt{prop} argument, and we can use \texttt{strata} to ensure balanced class distribution.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}
\NormalTok{data\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(Smarket, }\AttributeTok{prop =} \FloatTok{0.75}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ Direction)}

\NormalTok{SP\_train }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(data\_split)}
\NormalTok{SP\_test }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(data\_split)}

\CommentTok{\# Check the split}
\FunctionTok{nrow}\NormalTok{(SP\_train)}
\CommentTok{\#\textgreater{} [1] 937}
\FunctionTok{nrow}\NormalTok{(SP\_test)}
\CommentTok{\#\textgreater{} [1] 313}
\end{Highlighting}
\end{Shaded}

This function makes sampling data much simpler and returns a split object that we can use with \texttt{training()} and \texttt{testing()} accessor functions.

\subsection{Training our prediction algorithm}\label{training-our-prediction-algorithm}

In tidymodels, we build models in a structured way using three key components:
In \texttt{tidymodels}, we build models in a structured way using three key components: \textbf{Model Specification} (via \texttt{parsnip}) to define the algorithm, \textbf{Recipes} (via \texttt{recipes}) to define preprocessing steps, and \textbf{Workflows} (via \texttt{workflows}) to bundle the model and recipe together into a single execution unit.

Let's break down these components:

Let's break down these components. The \textbf{Model Specification (\texttt{parsnip})} tells R \emph{what} kind of model we want (e.g., ``nearest neighbor'') and \emph{which} computational engine to use (e.g., ``kknn''), decoupling intent from implementation. The \textbf{Recipe (\texttt{recipes})} acts as a blueprint for data processing, handling tasks like normalization (scaling variables) and converting categorical variables. Finally, the \textbf{Workflow (\texttt{workflows})} container holds the model and recipe together, ensuring that the exact same preprocessing steps are applied automatically when predicting on new data.

Let's start by specifying our k-nearest neighbors model. We use \texttt{tune()} as a placeholder for the \texttt{neighbors} parameter to indicate we want to find the optimal value.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Model specification}
\NormalTok{knn\_spec }\OtherTok{\textless{}{-}} \FunctionTok{nearest\_neighbor}\NormalTok{(}\AttributeTok{neighbors =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"kknn"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\NormalTok{knn\_spec}
\CommentTok{\#\textgreater{} K{-}Nearest Neighbor Model Specification (classification)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Main Arguments:}
\CommentTok{\#\textgreater{}   neighbors = tune()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computational engine: kknn}
\end{Highlighting}
\end{Shaded}

\subsection{Data Pre-processing with Recipes}\label{data-pre-processing-with-recipes}

tidymodels uses \texttt{recipes} for preprocessing. The \texttt{scale} method (division by standard deviation) and \texttt{centering} (subtraction of the mean) are implemented with \texttt{step\_normalize()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define preprocessing recipe}
\NormalTok{knn\_recipe }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(Direction }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ SP\_train) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{step\_normalize}\NormalTok{(}\FunctionTok{all\_numeric\_predictors}\NormalTok{())}

\NormalTok{knn\_recipe}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Recipe {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Inputs}
\CommentTok{\#\textgreater{} Number of variables by role}
\CommentTok{\#\textgreater{} outcome:   1}
\CommentTok{\#\textgreater{} predictor: 8}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Operations}
\CommentTok{\#\textgreater{} * Centering and scaling for:}
\CommentTok{\#\textgreater{}   all\_numeric\_predictors()}
\end{Highlighting}
\end{Shaded}

\subsection{Creating a Workflow}\label{creating-a-workflow}

A workflow bundles the recipe and model specification together for easy training and prediction.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Bundle into workflow}
\NormalTok{knn\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(knn\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(knn\_spec)}

\NormalTok{knn\_workflow}
\CommentTok{\#\textgreater{} == Workflow =========================================}
\CommentTok{\#\textgreater{} Preprocessor: Recipe}
\CommentTok{\#\textgreater{} Model: nearest\_neighbor()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Preprocessor {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} 1 Recipe Step}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} * step\_normalize()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} K{-}Nearest Neighbor Model Specification (classification)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Main Arguments:}
\CommentTok{\#\textgreater{}   neighbors = tune()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computational engine: kknn}
\end{Highlighting}
\end{Shaded}

\subsection{Parameter Tuning with Cross-Validation}\label{parameter-tuning-with-cross-validation}

One of the most important parts of training machine learning models is tuning the parameters. We use \texttt{vfold\_cv()} to create cross-validation folds and \texttt{tune\_grid()} to search for the best hyperparameters.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}

\CommentTok{\# Create 5{-}fold cross{-}validation}
\NormalTok{folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(SP\_train, }\AttributeTok{v =} \DecValTok{5}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ Direction)}

\CommentTok{\# Create a grid of k values to try}
\NormalTok{k\_grid }\OtherTok{\textless{}{-}} \FunctionTok{grid\_regular}\NormalTok{(}\FunctionTok{neighbors}\NormalTok{(}\AttributeTok{range =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{50}\NormalTok{)), }\AttributeTok{levels =} \DecValTok{20}\NormalTok{)}

\CommentTok{\# Tune the model}
\NormalTok{knn\_tune\_results }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  knn\_workflow,}
  \AttributeTok{resamples =}\NormalTok{ folds,}
  \AttributeTok{grid =}\NormalTok{ k\_grid}
\NormalTok{)}

\NormalTok{knn\_tune\_results}
\CommentTok{\#\textgreater{} \# Tuning results}
\CommentTok{\#\textgreater{} \# 5{-}fold cross{-}validation using stratification }
\CommentTok{\#\textgreater{} \# A tibble: 5 x 4}
\CommentTok{\#\textgreater{}   splits            id    .metrics          .notes          }
\CommentTok{\#\textgreater{}   \textless{}list\textgreater{}            \textless{}chr\textgreater{} \textless{}list\textgreater{}            \textless{}list\textgreater{}          }
\CommentTok{\#\textgreater{} 1 \textless{}split [748/189]\textgreater{} Fold1 \textless{}tibble [60 x 5]\textgreater{} \textless{}tibble [0 x 4]\textgreater{}}
\CommentTok{\#\textgreater{} 2 \textless{}split [750/187]\textgreater{} Fold2 \textless{}tibble [60 x 5]\textgreater{} \textless{}tibble [0 x 4]\textgreater{}}
\CommentTok{\#\textgreater{} 3 \textless{}split [750/187]\textgreater{} Fold3 \textless{}tibble [60 x 5]\textgreater{} \textless{}tibble [0 x 4]\textgreater{}}
\CommentTok{\#\textgreater{} 4 \textless{}split [750/187]\textgreater{} Fold4 \textless{}tibble [60 x 5]\textgreater{} \textless{}tibble [0 x 4]\textgreater{}}
\CommentTok{\#\textgreater{} 5 \textless{}split [750/187]\textgreater{} Fold5 \textless{}tibble [60 x 5]\textgreater{} \textless{}tibble [0 x 4]\textgreater{}}
\end{Highlighting}
\end{Shaded}

We can visualize the tuning results using \texttt{autoplot()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{(knn\_tune\_results)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-591-1} \end{center}

We can see the accuracy for each value of ``k''. The \texttt{show\_best()} function shows us the top performing values:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{show\_best}\NormalTok{(knn\_tune\_results, }\AttributeTok{metric =} \StringTok{"accuracy"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 7}
\CommentTok{\#\textgreater{}   neighbors .metric  .estimator  mean     n std\_err .config         }
\CommentTok{\#\textgreater{}       \textless{}int\textgreater{} \textless{}chr\textgreater{}    \textless{}chr\textgreater{}      \textless{}dbl\textgreater{} \textless{}int\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1        44 accuracy binary     0.905     5  0.0114 pre0\_mod18\_post0}
\CommentTok{\#\textgreater{} 2        42 accuracy binary     0.904     5  0.0116 pre0\_mod17\_post0}
\CommentTok{\#\textgreater{} 3        37 accuracy binary     0.902     5  0.0115 pre0\_mod15\_post0}
\CommentTok{\#\textgreater{} 4        31 accuracy binary     0.902     5  0.0112 pre0\_mod13\_post0}
\CommentTok{\#\textgreater{} 5        47 accuracy binary     0.901     5  0.0119 pre0\_mod19\_post0}
\end{Highlighting}
\end{Shaded}

\subsection{Finalizing the Model}\label{finalizing-the-model}

Once we've found the best hyperparameters, we finalize our workflow with those values:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Select the best k value}
\NormalTok{best\_k }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(knn\_tune\_results, }\AttributeTok{metric =} \StringTok{"accuracy"}\NormalTok{)}
\NormalTok{best\_k}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 2}
\CommentTok{\#\textgreater{}   neighbors .config         }
\CommentTok{\#\textgreater{}       \textless{}int\textgreater{} \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1        44 pre0\_mod18\_post0}

\CommentTok{\# Finalize the workflow with the best parameters}
\NormalTok{final\_knn\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(knn\_workflow, best\_k)}

\CommentTok{\# Fit the final model on the entire training set}
\NormalTok{SP\_knn\_trained }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(final\_knn\_workflow, }\AttributeTok{data =}\NormalTok{ SP\_train)}

\NormalTok{SP\_knn\_trained}
\CommentTok{\#\textgreater{} == Workflow [trained] ===============================}
\CommentTok{\#\textgreater{} Preprocessor: Recipe}
\CommentTok{\#\textgreater{} Model: nearest\_neighbor()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Preprocessor {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} 1 Recipe Step}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} * step\_normalize()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} kknn::train.kknn(formula = ..y \textasciitilde{} ., data = data, ks = min\_rows(44L,     data, 5))}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Type of response variable: nominal}
\CommentTok{\#\textgreater{} Minimal misclassification: 0.0864461}
\CommentTok{\#\textgreater{} Best kernel: optimal}
\CommentTok{\#\textgreater{} Best k: 44}
\end{Highlighting}
\end{Shaded}

We see the substantial improvement now that we have adjusted some parameters and made it reprocess first. Note that each time we adjust parameters, the value of ``k'' can change until the most optimal one is found. In this case, it changed to k = 29. This does not mean that the lower the ``k'', the better the algorithm, only that it is the most optimal for this particular case with these adjustments made.

\subsection{Testing the prediction model}\label{testing-the-prediction-model}

We already have our model trained and ready to test it. tidymodels makes it easy to make predictions using the \texttt{augment()} function which adds predictions directly to our test data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Make predictions on test data}
\NormalTok{SP\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(SP\_knn\_trained, }\AttributeTok{new\_data =}\NormalTok{ SP\_test)}

\CommentTok{\# View predictions}
\NormalTok{SP\_predictions }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(Direction, .pred\_class, .pred\_Down, .pred\_Up) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 4}
\CommentTok{\#\textgreater{}    Direction .pred\_class .pred\_Down .pred\_Up}
\CommentTok{\#\textgreater{}    \textless{}fct\textgreater{}     \textless{}fct\textgreater{}            \textless{}dbl\textgreater{}    \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Up        Up              0.243    0.757 }
\CommentTok{\#\textgreater{}  2 Up        Up              0.404    0.596 }
\CommentTok{\#\textgreater{}  3 Down      Down            0.611    0.389 }
\CommentTok{\#\textgreater{}  4 Down      Down            0.977    0.0231}
\CommentTok{\#\textgreater{}  5 Up        Up              0.230    0.770 }
\CommentTok{\#\textgreater{}  6 Down      Up              0.472    0.528 }
\CommentTok{\#\textgreater{}  7 Down      Down            0.955    0.0447}
\CommentTok{\#\textgreater{}  8 Up        Up              0.0361   0.964 }
\CommentTok{\#\textgreater{}  9 Down      Down            0.522    0.478 }
\CommentTok{\#\textgreater{} 10 Down      Down            1        0}
\end{Highlighting}
\end{Shaded}

The \texttt{augment()} function adds three columns: \texttt{.pred\_class} (the predicted class), and probability columns for each class (\texttt{.pred\_Down} and \texttt{.pred\_Up}). This makes it very easy to compare predictions with actual values.

As we can see, for each test value the model calculates the estimated probability for each class. The algorithm assigns the class with the highest probability.

\subsection{Model Evaluation with yardstick}\label{model-evaluation-with-yardstick}

To evaluate our model, we use the \texttt{yardstick} package. The \texttt{conf\_mat()} function creates a confusion matrix, and we can calculate various metrics like accuracy, sensitivity, and specificity.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Confusion matrix}
\NormalTok{SP\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Direction, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\CommentTok{\#\textgreater{}           Truth}
\CommentTok{\#\textgreater{} Prediction Down  Up}
\CommentTok{\#\textgreater{}       Down  132   4}
\CommentTok{\#\textgreater{}       Up     19 158}

\CommentTok{\# Calculate accuracy}
\NormalTok{SP\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Direction, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 3}
\CommentTok{\#\textgreater{}   .metric  .estimator .estimate}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 accuracy binary         0.927}

\CommentTok{\# Calculate multiple metrics at once}
\NormalTok{SP\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{metrics}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Direction, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 3}
\CommentTok{\#\textgreater{}   .metric  .estimator .estimate}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 accuracy binary         0.927}
\CommentTok{\#\textgreater{} 2 kap      binary         0.852}
\end{Highlighting}
\end{Shaded}

We obtain the accuracy as well as other metrics. The yardstick package provides many evaluation functions including \texttt{sens()} (sensitivity), \texttt{spec()} (specificity), \texttt{precision()}, \texttt{recall()}, and more.

\section{Confusion Matrix}\label{confusion-matrix}

We have already used confusion matrices in our two previous examples. Now it is our turn to properly understand its definition as well as some of the evaluation metrics of this matrix.

A confusion matrix, also known as an error matrix, allows us to visualize the performance of an algorithm, generally a supervised learning one (in unsupervised learning it is generally called a matching matrix). Each row of the matrix represents the instances in a predicted class, while each column represents the instances in a real class (or vice versa). The name derives from the fact that it makes it easy to see if the system confuses two classes (i.e., commonly mislabeling one as another).

Binary classifications, when the \emph{outcome} can take only two classes, yield this following confusion matrix.

\begin{center}\includegraphics[width=0.8\linewidth,alt={2x2 confusion matrix with True Positive, False Positive, True Negative, False Negative cells}]{assets/images/06-machine-learning/confusion-matrix} \end{center}

\subsection{Accuracy}\label{accuracy}

We have already been using this term in our examples. The accuracy of the model can be calculated from the confusion matrix:

\(Accuracy=\frac{TP+TN}{TP+TN+FP+FN}\)

The \emph{accuracy} of the model is the proportion of times the algorithm predicted correctly, regarding the total data evaluated.

\subsection{Sensitivity}\label{sensitivity}

Sensitivity (also called true positive rate, recall, or probability of detection in some fields) measures the proportion of real positives that are correctly identified as such (for example, the percentage of sick people who are correctly identified as having the condition).

\(Sensitivity=\frac{TP}{TP+FN}\)

\subsection{Specificity}\label{specificity}

Specificity (also called true negative rate) measures the proportion of real negatives that are correctly identified as such (for example, the percentage of healthy people who are correctly identified as not having the condition).

\(Specificity=\frac{TN}{TN+FP}\)

\section{Exercises}\label{exercises-16}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{96}
\tightlist
\item
  Using the tidymodels library, partition the \texttt{iris} data frame in such a way as to have 70\% training data and 30\% test data.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(iris, }\AttributeTok{prop =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ Species)}

\NormalTok{iris\_train }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(iris\_split)}
\NormalTok{iris\_test }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(iris\_split)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{97}
\tightlist
\item
  Using tidymodels and the training data obtained in the previous exercise, create a k-nearest neighbor model with tuning. Plot the result.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Model specification}
\NormalTok{iris\_knn\_spec }\OtherTok{\textless{}{-}} \FunctionTok{nearest\_neighbor}\NormalTok{(}\AttributeTok{neighbors =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"kknn"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Recipe with preprocessing}
\NormalTok{iris\_recipe }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(Species }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ iris\_train) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{step\_normalize}\NormalTok{(}\FunctionTok{all\_numeric\_predictors}\NormalTok{())}

\CommentTok{\# Workflow}
\NormalTok{iris\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(iris\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(iris\_knn\_spec)}

\CommentTok{\# Cross{-}validation and tuning}
\NormalTok{iris\_folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(iris\_train, }\AttributeTok{v =} \DecValTok{5}\NormalTok{)}
\NormalTok{iris\_tune }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(iris\_workflow, }\AttributeTok{resamples =}\NormalTok{ iris\_folds, }\AttributeTok{grid =} \DecValTok{20}\NormalTok{)}

\FunctionTok{autoplot}\NormalTok{(iris\_tune)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{98}
\tightlist
\item
  Use the model created in the previous exercise to predict the \emph{outputs} of the \texttt{test} object. Report the confusion matrix.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Finalize model with best k}
\NormalTok{best\_k }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(iris\_tune, }\AttributeTok{metric =} \StringTok{"accuracy"}\NormalTok{)}
\NormalTok{final\_iris\_wf }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(iris\_workflow, best\_k)}
\NormalTok{iris\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(final\_iris\_wf, }\AttributeTok{data =}\NormalTok{ iris\_train)}

\CommentTok{\# Predict and evaluate}
\NormalTok{iris\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(iris\_fit, }\AttributeTok{new\_data =}\NormalTok{ iris\_test)}
\NormalTok{iris\_predictions }\SpecialCharTok{|\textgreater{}} \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Species, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\end{Highlighting}
\end{Shaded}

\section{Simple Linear Regression}\label{simple-linear-regression}

Now we have to predict on continuous variables, the supervision algorithms for these cases are called \textbf{regression}.

To understand linear regression we are going to start with an example with a single variable as \emph{input}, this is known as Simple Linear Regression. To do this we are going to use data from the \texttt{HistData} library where we will find a dataset that enumerates the individual observations of 934 children in 205 families stored in the object \texttt{GaltonFamilies}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"HistData"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(HistData)}
\FunctionTok{data}\NormalTok{(GaltonFamilies)}

\CommentTok{\# We make some filters to have one dad and one son per family}
\NormalTok{heights\_df }\OtherTok{\textless{}{-}}\NormalTok{ GaltonFamilies }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(gender }\SpecialCharTok{==} \StringTok{"male"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(family) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# random sample of 1 son per family}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(father, childHeight) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{son =}\NormalTok{ childHeight) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{father =}\NormalTok{ father}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# From inches to meters}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{son =}\NormalTok{ son}\SpecialCharTok{/}\FloatTok{39.37}\NormalTok{) }\CommentTok{\# From inches to meters}
\end{Highlighting}
\end{Shaded}

Visually we could see if there is a relationship between the heights of dad and son:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(father, son) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-605-1} \end{center}

As we can see, there is a positive correlation, such that the taller the father, the son grows to be taller as an adult. This line, however, is nothing more than a default line. The challenge lies in finding which line minimizes the distance of the points to this line, known as error minimization.

We could try to predict the height the son will have from the father's height using the equation of this line:

\(Y = \beta_0+\beta_1X\)

Where \(X\) is an independent, explanatory variable, in this case the dad's height. \(\beta_1\) is a parameter that measures the influence that the explanatory variable has on the dependent variable \(Y\) and \(\beta_0\) is the intercept or constant term. In our case, the son's height.

In statistics, \textbf{linear regression} or linear adjustment is a mathematical model used to approximate the dependency relationship between a dependent variable \(Y\) and the independent variables \(X_i\).

Thus, our problem boils down to training our model to find the values of the intercept, \(\beta_0\), and the value of the parameter accompanying \(X_1\), \(\beta_1\), to then use these data as prediction in our test data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(heights\_df, }\AttributeTok{prop =} \FloatTok{0.5}\NormalTok{)}

\NormalTok{heights\_train }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(heights\_split)}
\NormalTok{heights\_test }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(heights\_split)}
\end{Highlighting}
\end{Shaded}

Now that we have our data we can train our model using tidymodels. We specify a linear regression model with \texttt{linear\_reg()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Model specification}
\NormalTok{lm\_spec }\OtherTok{\textless{}{-}} \FunctionTok{linear\_reg}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"lm"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"regression"}\NormalTok{)}

\CommentTok{\# Recipe}
\NormalTok{lm\_recipe }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(son }\SpecialCharTok{\textasciitilde{}}\NormalTok{ father, }\AttributeTok{data =}\NormalTok{ heights\_train)}

\CommentTok{\# Workflow}
\NormalTok{lm\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(lm\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(lm\_spec)}

\CommentTok{\# Cross{-}validation}
\NormalTok{heights\_folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(heights\_train, }\AttributeTok{v =} \DecValTok{10}\NormalTok{)}
\NormalTok{lm\_results }\OtherTok{\textless{}{-}} \FunctionTok{fit\_resamples}\NormalTok{(lm\_workflow, }\AttributeTok{resamples =}\NormalTok{ heights\_folds)}

\CommentTok{\# View results}
\FunctionTok{collect\_metrics}\NormalTok{(lm\_results)}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 6}
\CommentTok{\#\textgreater{}   .metric .estimator   mean     n std\_err .config        }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}   \textless{}chr\textgreater{}       \textless{}dbl\textgreater{} \textless{}int\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}          }
\CommentTok{\#\textgreater{} 1 rmse    standard   0.0584    10 0.00362 pre0\_mod0\_post0}
\CommentTok{\#\textgreater{} 2 rsq     standard   0.362     10 0.0821  pre0\_mod0\_post0}
\end{Highlighting}
\end{Shaded}

We see as main results the RMSE, which stands for root mean square error, and is the value that linear regression seeks to minimize. In addition, we have the R squared or \(R^2\), which is the coefficient of determination which determines the quality of the model to replicate the results. The higher and closer to 1, the better the quality of the model.

\begin{quote}
{[}!WARNING{]}
\textbf{Correlation implies association, not causation}: A high \(R^2\) or strong correlation means the variables move together, but it does \textbf{not} prove that one causes the other. There could be confounding variables at play.
\end{quote}

Now let's fit the final model and make predictions:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fit final model}
\NormalTok{heights\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(lm\_workflow, }\AttributeTok{data =}\NormalTok{ heights\_train)}

\CommentTok{\# Make predictions}
\NormalTok{heights\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(heights\_fit, }\AttributeTok{new\_data =}\NormalTok{ heights\_test)}

\CommentTok{\# Calculate RMSE}
\NormalTok{heights\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{rmse}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ son, }\AttributeTok{estimate =}\NormalTok{ .pred)}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 3}
\CommentTok{\#\textgreater{}   .metric .estimator .estimate}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}   \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 rmse    standard      0.0642}
\end{Highlighting}
\end{Shaded}

\begin{quote}
{[}!TIP{]}
\textbf{Model Diagnostics}: In a rigorous analysis, you should also inspect the \textbf{residuals} (the difference between predicted and actual values). The \texttt{augment()} function includes a \texttt{.resid} column for this purpose. Plotting residuals helps verify that your model isn't missing non-linear patterns.
\end{quote}

If we wish we can also report the coefficients of the equation and visualize them:

\(Y = \beta_0+\beta_1X\)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract model coefficients}
\NormalTok{heights\_fit }\SpecialCharTok{|\textgreater{}} \FunctionTok{extract\_fit\_parsnip}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{()}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 5}
\CommentTok{\#\textgreater{}   term        estimate std.error statistic      p.value}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}        \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 (Intercept)    0.644     0.183      3.51 0.000708    }
\CommentTok{\#\textgreater{} 2 father         0.631     0.104      6.05 0.0000000361}

\NormalTok{model\_coefs }\OtherTok{\textless{}{-}}\NormalTok{ heights\_fit }\SpecialCharTok{|\textgreater{}} \FunctionTok{extract\_fit\_parsnip}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{()}
\NormalTok{intercept\_val }\OtherTok{\textless{}{-}}\NormalTok{ model\_coefs}\SpecialCharTok{$}\NormalTok{estimate[}\DecValTok{1}\NormalTok{]}
\NormalTok{slope\_val }\OtherTok{\textless{}{-}}\NormalTok{ model\_coefs}\SpecialCharTok{$}\NormalTok{estimate[}\DecValTok{2}\NormalTok{]}

\CommentTok{\#Visualization}
\NormalTok{heights\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(father, son) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{intercept =}\NormalTok{ intercept\_val, }\AttributeTok{slope =}\NormalTok{ slope\_val, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-609-1} \end{center}

\section{Multiple Linear Regression}\label{multiple-linear-regression}

Now that we know linear regression we can execute a multiple linear regression model, which involves more than 1 variable as \emph{input}. To do this, we will use the \texttt{diamonds} dataset containing the prices and other attributes of almost 54,000 diamonds.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{data}\NormalTok{(}\StringTok{"diamonds"}\NormalTok{)}

\NormalTok{diamonds }\OtherTok{\textless{}{-}}\NormalTok{ diamonds }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{price =}\NormalTok{ price)}

\NormalTok{diamonds }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 10}
\CommentTok{\#\textgreater{}    carat cut       color clarity depth table price     x     y     z}
\CommentTok{\#\textgreater{}    \textless{}dbl\textgreater{} \textless{}ord\textgreater{}     \textless{}ord\textgreater{} \textless{}ord\textgreater{}   \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}int\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43}
\CommentTok{\#\textgreater{}  2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31}
\CommentTok{\#\textgreater{}  3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31}
\CommentTok{\#\textgreater{}  4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63}
\CommentTok{\#\textgreater{}  5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75}
\CommentTok{\#\textgreater{}  6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48}
\CommentTok{\#\textgreater{}  7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47}
\CommentTok{\#\textgreater{}  8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53}
\CommentTok{\#\textgreater{}  9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49}
\CommentTok{\#\textgreater{} 10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39}
\end{Highlighting}
\end{Shaded}

We split the data in two taking 70\% of data for training:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}
\NormalTok{diamonds\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(diamonds, }\AttributeTok{prop =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ price)}

\NormalTok{diamonds\_train }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(diamonds\_split)}
\NormalTok{diamonds\_test }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(diamonds\_split)}
\end{Highlighting}
\end{Shaded}

We now create our multiple linear regression model and report both the error results and the coefficients of the linear equation using a tidymodels workflow.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Model specification}
\NormalTok{diamonds\_spec }\OtherTok{\textless{}{-}} \FunctionTok{linear\_reg}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"lm"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"regression"}\NormalTok{)}

\CommentTok{\# Recipe}
\NormalTok{diamonds\_recipe }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(price }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ diamonds\_train)}

\CommentTok{\# Workflow}
\NormalTok{diamonds\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(diamonds\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(diamonds\_spec)}

\CommentTok{\# Cross{-}validation}
\NormalTok{diamonds\_folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(diamonds\_train, }\AttributeTok{v =} \DecValTok{10}\NormalTok{)}
\NormalTok{diamonds\_results }\OtherTok{\textless{}{-}} \FunctionTok{fit\_resamples}\NormalTok{(diamonds\_workflow, }\AttributeTok{resamples =}\NormalTok{ diamonds\_folds)}

\FunctionTok{collect\_metrics}\NormalTok{(diamonds\_results)}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 6}
\CommentTok{\#\textgreater{}   .metric .estimator     mean     n  std\_err .config        }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}   \textless{}chr\textgreater{}         \textless{}dbl\textgreater{} \textless{}int\textgreater{}    \textless{}dbl\textgreater{} \textless{}chr\textgreater{}          }
\CommentTok{\#\textgreater{} 1 rmse    standard   1136.       10 19.7     pre0\_mod0\_post0}
\CommentTok{\#\textgreater{} 2 rsq     standard      0.919    10  0.00256 pre0\_mod0\_post0}
\end{Highlighting}
\end{Shaded}

We see that it gives us the RMSE and an R squared quite closer to 1, which denotes a high quality of the model to replicate the results.

Let's use our model to predict the prices of the test data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fit final model}
\NormalTok{diamonds\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(diamonds\_workflow, }\AttributeTok{data =}\NormalTok{ diamonds\_train)}

\CommentTok{\# Extract coefficients}
\NormalTok{diamonds\_fit }\SpecialCharTok{|\textgreater{}} \FunctionTok{extract\_fit\_parsnip}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{()}
\CommentTok{\#\textgreater{} \# A tibble: 24 x 5}
\CommentTok{\#\textgreater{}    term        estimate std.error statistic   p.value}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 (Intercept)   6975.      473.      14.7  5.45e{-} 49}
\CommentTok{\#\textgreater{}  2 carat        11437.       60.7    188.   0        }
\CommentTok{\#\textgreater{}  3 cut.L          571.       27.1     21.1  7.51e{-} 98}
\CommentTok{\#\textgreater{}  4 cut.Q         {-}305.       21.7    {-}14.0  1.07e{-} 44}
\CommentTok{\#\textgreater{}  5 cut.C          139.       18.6      7.48 7.72e{-} 14}
\CommentTok{\#\textgreater{}  6 cut\^{}4          {-}23.2      14.8     {-}1.56 1.18e{-}  1}
\CommentTok{\#\textgreater{}  7 color.L      {-}1980.       20.8    {-}95.1  0        }
\CommentTok{\#\textgreater{}  8 color.Q       {-}685.       19.0    {-}36.1  6.69e{-}281}
\CommentTok{\#\textgreater{}  9 color.C       {-}186.       17.7    {-}10.5  6.23e{-} 26}
\CommentTok{\#\textgreater{} 10 color\^{}4         36.8      16.2      2.27 2.33e{-}  2}
\CommentTok{\#\textgreater{} \# i 14 more rows}

\CommentTok{\# Prediction and Error calculation}
\NormalTok{diamonds\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(diamonds\_fit, }\AttributeTok{new\_data =}\NormalTok{ diamonds\_test)}

\CommentTok{\# Mean Squared Error Calculation RMSE:}
\NormalTok{diamonds\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{rmse}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ price, }\AttributeTok{estimate =}\NormalTok{ .pred)}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 3}
\CommentTok{\#\textgreater{}   .metric .estimator .estimate}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}   \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 rmse    standard       1119.}
\end{Highlighting}
\end{Shaded}

Thus, we have learned to perform one more machine learning model: linear regression, both simple and multiple.

\section{Standard Method for Evaluating Accuracy}\label{standard-method-for-evaluating-accuracy}

Now that we know how to build models we will apply metrics that allow us better accuracy in classification models for \textbf{two classes}.

To do this let's recall the results of the model we created using the k-nearest neighbors algorithm to predict if the S\&P index goes up or down.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SP\_knn\_trained}
\CommentTok{\#\textgreater{} == Workflow [trained] ===============================}
\CommentTok{\#\textgreater{} Preprocessor: Recipe}
\CommentTok{\#\textgreater{} Model: nearest\_neighbor()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Preprocessor {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} 1 Recipe Step}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} * step\_normalize()}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-} Model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} kknn::train.kknn(formula = ..y \textasciitilde{} ., data = data, ks = min\_rows(44L,     data, 5))}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Type of response variable: nominal}
\CommentTok{\#\textgreater{} Minimal misclassification: 0.0864461}
\CommentTok{\#\textgreater{} Best kernel: optimal}
\CommentTok{\#\textgreater{} Best k: 44}
\end{Highlighting}
\end{Shaded}

In the penultimate line it can be read that \textbf{accuracy} (\texttt{accuracy}) was used to select the most optimal model using the largest value. However, this is not the only way to determine which is the most optimal model.

Let's remember how accuracy (\emph{accuracy}) is calculated by default, we have used the simple rule that if the probability of it being of a certain class is more than 50\% then that class is assigned and then we calculate the proportion of hits among the total cases.

However, it doesn't have to be 50\%, we could be more demanding and indicate that if the probability is greater than 60\% or 80\% then a certain class is assigned. We see that there are different probabilities and that would give us different \texttt{accuracy}.

This is how the area under the Receiver Operating Characteristic curve indicator arises, \emph{ROC} \citep{Fawcett2005}. This indicator measures how well a model can distinguish between two classes and is considered the standard method for evaluating the accuracy of predictive distribution models \citep{Lobo2007} and calculates accuracies not only for when we discriminate starting from 50\%, but for more probability values.

To use this metric we will modify our control parameters adding three attributes that will allow calculating the ROC.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SP2\_ctrl }\OtherTok{\textless{}{-}} \FunctionTok{metric\_set}\NormalTok{(roc\_auc, accuracy)}

\CommentTok{\# We define folds}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}
\NormalTok{SP2\_folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(SP\_train, }\AttributeTok{v =} \DecValTok{5}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ Direction)}
\end{Highlighting}
\end{Shaded}

With these modified parameters we will proceed to re-train our model selecting by ROC AUC.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}

\CommentTok{\# Tune grid specifying ROC as the metric to optimize}
\NormalTok{SP2\_knn\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  knn\_workflow,}
  \AttributeTok{resamples =}\NormalTok{ SP2\_folds,}
  \AttributeTok{grid =} \DecValTok{20}\NormalTok{,}
  \AttributeTok{metrics =}\NormalTok{ SP2\_ctrl}
\NormalTok{)}

\FunctionTok{show\_best}\NormalTok{(SP2\_knn\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 7}
\CommentTok{\#\textgreater{}   neighbors .metric .estimator  mean     n std\_err .config         }
\CommentTok{\#\textgreater{}       \textless{}int\textgreater{} \textless{}chr\textgreater{}   \textless{}chr\textgreater{}      \textless{}dbl\textgreater{} \textless{}int\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1        15 roc\_auc binary     0.965     5 0.00586 pre0\_mod13\_post0}
\CommentTok{\#\textgreater{} 2        13 roc\_auc binary     0.962     5 0.00632 pre0\_mod12\_post0}
\CommentTok{\#\textgreater{} 3        12 roc\_auc binary     0.960     5 0.00667 pre0\_mod11\_post0}
\CommentTok{\#\textgreater{} 4        11 roc\_auc binary     0.957     5 0.00717 pre0\_mod10\_post0}
\CommentTok{\#\textgreater{} 5        10 roc\_auc binary     0.955     5 0.00739 pre0\_mod09\_post0}
\end{Highlighting}
\end{Shaded}

We see that now ROC was used to select the most optimal model. The closer the ROC value is to 1 the better our model will be. With this model we can predict values from the test data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Select best k based on ROC}
\NormalTok{best\_k\_roc }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(SP2\_knn\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}

\CommentTok{\# Finalize workflow}
\NormalTok{final\_knn\_roc }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(knn\_workflow, best\_k\_roc)}

\CommentTok{\# Fit and predict}
\NormalTok{SP2\_knn\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(final\_knn\_roc, }\AttributeTok{data =}\NormalTok{ SP\_train)}
\NormalTok{SP2\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(SP2\_knn\_fit, }\AttributeTok{new\_data =}\NormalTok{ SP\_test)}

\CommentTok{\# Evaluate}
\NormalTok{SP2\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Direction, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\CommentTok{\#\textgreater{}           Truth}
\CommentTok{\#\textgreater{} Prediction Down  Up}
\CommentTok{\#\textgreater{}       Down  135  15}
\CommentTok{\#\textgreater{}       Up     16 147}

\NormalTok{SP2\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Direction, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 3}
\CommentTok{\#\textgreater{}   .metric  .estimator .estimate}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 accuracy binary         0.901}
\end{Highlighting}
\end{Shaded}

We see how our accuracy (\emph{accuracy}) has increased from 91.99\% to \textbf{93.27\%}. This metric is highly recommended to improve the accuracy of our model, in addition to allowing us to more easily use it as a comparator between different models we can create.

\section{Selection of the Most Optimal Model}\label{selection-of-the-most-optimal-model}

We have learned how to create some machine learning models. As we must have noticed, with \textbf{tidymodels} we follow the same pattern for partitioning, training, and prediction. The variation lies in how to pre-process the data and the parameter tuning. We could thus create multiple models, but finally we have to verify one which will serve us to make our predictions.

In this section, we are going to compare different predictive models accepting their default values and choose the best one using the tools presented in previous sections.

To do this, we are going to use a new case. This time we are evaluating the behavior of our 5,000 clients, some of whom have unsubscribed from our services. We have 19 predictors, most of them numeric, in the \texttt{mlc\_churn} dataset. To access the data we have to load the \texttt{modeldata} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"modeldata"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(modeldata)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(mlc\_churn)}

\FunctionTok{str}\NormalTok{(mlc\_churn)}
\CommentTok{\#\textgreater{} tibble [5,000 x 20] (S3: tbl\_df/tbl/data.frame)}
\CommentTok{\#\textgreater{}  $ state                        : Factor w/ 51 levels "AK","AL","AR",..: 17 36 32 36 37 2 20 25 19 50 ...}
\CommentTok{\#\textgreater{}  $ account\_length               : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ...}
\CommentTok{\#\textgreater{}  $ area\_code                    : Factor w/ 3 levels "area\_code\_408",..: 2 2 2 1 2 3 3 2 1 2 ...}
\CommentTok{\#\textgreater{}  $ international\_plan           : Factor w/ 2 levels "no","yes": 1 1 1 2 2 2 1 2 1 2 ...}
\CommentTok{\#\textgreater{}  $ voice\_mail\_plan              : Factor w/ 2 levels "no","yes": 2 2 1 1 1 1 2 1 1 2 ...}
\CommentTok{\#\textgreater{}  $ number\_vmail\_messages        : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ...}
\CommentTok{\#\textgreater{}  $ total\_day\_minutes            : num [1:5000] 265 162 243 299 167 ...}
\CommentTok{\#\textgreater{}  $ total\_day\_calls              : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ...}
\CommentTok{\#\textgreater{}  $ total\_day\_charge             : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ...}
\CommentTok{\#\textgreater{}  $ total\_eve\_minutes            : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ...}
\CommentTok{\#\textgreater{}  $ total\_eve\_calls              : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ...}
\CommentTok{\#\textgreater{}  $ total\_eve\_charge             : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ...}
\CommentTok{\#\textgreater{}  $ total\_night\_minutes          : num [1:5000] 245 254 163 197 187 ...}
\CommentTok{\#\textgreater{}  $ total\_night\_calls            : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ...}
\CommentTok{\#\textgreater{}  $ total\_night\_charge           : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ...}
\CommentTok{\#\textgreater{}  $ total\_intl\_minutes           : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ...}
\CommentTok{\#\textgreater{}  $ total\_intl\_calls             : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ...}
\CommentTok{\#\textgreater{}  $ total\_intl\_charge            : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ...}
\CommentTok{\#\textgreater{}  $ number\_customer\_service\_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ...}
\CommentTok{\#\textgreater{}  $ churn                        : Factor w/ 2 levels "yes","no": 2 2 2 2 2 2 2 2 2 2 ...}

\CommentTok{\# We translate outputs}
\NormalTok{mlc\_churn }\OtherTok{\textless{}{-}}\NormalTok{ mlc\_churn }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{churn\_status =}\NormalTok{ churn) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{churn\_status =} \FunctionTok{ifelse}\NormalTok{(churn\_status }\SpecialCharTok{==} \StringTok{"yes"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{, }\StringTok{"No"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{churn\_status =} \FunctionTok{as.factor}\NormalTok{(churn\_status))}
  
\CommentTok{\# Proportion of "Yes" and "No"s:}
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(mlc\_churn}\SpecialCharTok{$}\NormalTok{churn\_status))}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}     No    Yes }
\CommentTok{\#\textgreater{} 0.8586 0.1414}
\end{Highlighting}
\end{Shaded}

We create now sample of training and test, 70\% training.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}
\NormalTok{churn\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(mlc\_churn, }\AttributeTok{prop =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ churn\_status)}

\NormalTok{churn\_train }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(churn\_split)}
\NormalTok{churn\_test }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(churn\_split)}
\end{Highlighting}
\end{Shaded}

Up to here we have done exactly the same step as in previous models. However, previously we have specified the \emph{cross-validation} method within our control parameters. Now we will create a shared validation set to compare all models fairly.

We will create a list of 5 \emph{folds} using the function \texttt{vfold\_cv()} from \texttt{rsample}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}
\NormalTok{churn\_folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(churn\_train, }\AttributeTok{v =} \DecValTok{5}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ churn\_status)}
\NormalTok{churn\_folds}
\CommentTok{\#\textgreater{} \#  5{-}fold cross{-}validation using stratification }
\CommentTok{\#\textgreater{} \# A tibble: 5 x 2}
\CommentTok{\#\textgreater{}   splits             id   }
\CommentTok{\#\textgreater{}   \textless{}list\textgreater{}             \textless{}chr\textgreater{}}
\CommentTok{\#\textgreater{} 1 \textless{}split [2799/700]\textgreater{} Fold1}
\CommentTok{\#\textgreater{} 2 \textless{}split [2799/700]\textgreater{} Fold2}
\CommentTok{\#\textgreater{} 3 \textless{}split [2799/700]\textgreater{} Fold3}
\CommentTok{\#\textgreater{} 4 \textless{}split [2799/700]\textgreater{} Fold4}
\CommentTok{\#\textgreater{} 5 \textless{}split [2800/699]\textgreater{} Fold5}
\end{Highlighting}
\end{Shaded}

We will use the \textbf{ROC} metric for all models. In tidymodels, we define the metrics we want to calculate using a \texttt{metric\_set()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{churn\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{metric\_set}\NormalTok{(roc\_auc, accuracy, sensitivity, specificity)}
\end{Highlighting}
\end{Shaded}

The next step would be to choose the machine learning algorithms we want to use to create our models. \texttt{parsnip} provides a consistent interface for different models. We can check available engines for a model type, for example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{show\_engines}\NormalTok{(}\StringTok{"nearest\_neighbor"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 2}
\CommentTok{\#\textgreater{}   engine mode          }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}  \textless{}chr\textgreater{}         }
\CommentTok{\#\textgreater{} 1 kknn   classification}
\CommentTok{\#\textgreater{} 2 kknn   regression}
\end{Highlighting}
\end{Shaded}

We will create a series of models and compare them using ROC AUC. First, let's define a common recipe for preprocessing.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{churn\_recipe }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(churn\_status }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ churn\_train) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{step\_dummy}\NormalTok{(}\FunctionTok{all\_nominal\_predictors}\NormalTok{(), }\SpecialCharTok{{-}}\NormalTok{churn\_status) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{step\_normalize}\NormalTok{(}\FunctionTok{all\_numeric\_predictors}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\subsection{k-Nearest Neighbors Model}\label{k-nearest-neighbors-model}

Although it is a very simple model, it is also very useful. Let's start with this model that we already learned to create during this chapter.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Spec}
\NormalTok{knn\_spec }\OtherTok{\textless{}{-}} \FunctionTok{nearest\_neighbor}\NormalTok{(}\AttributeTok{neighbors =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"kknn"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Workflow}
\NormalTok{knn\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(churn\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(knn\_spec)}

\CommentTok{\# Tune}
\NormalTok{knn\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  knn\_workflow,}
  \AttributeTok{resamples =}\NormalTok{ churn\_folds,}
  \AttributeTok{grid =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{metrics =}\NormalTok{ churn\_metrics}
\NormalTok{)}

\FunctionTok{show\_best}\NormalTok{(knn\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 7}
\CommentTok{\#\textgreater{}   neighbors .metric .estimator  mean     n std\_err .config         }
\CommentTok{\#\textgreater{}       \textless{}int\textgreater{} \textless{}chr\textgreater{}   \textless{}chr\textgreater{}      \textless{}dbl\textgreater{} \textless{}int\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1        15 roc\_auc binary     0.684     5 0.0101  pre0\_mod10\_post0}
\CommentTok{\#\textgreater{} 2        13 roc\_auc binary     0.679     5 0.00972 pre0\_mod09\_post0}
\CommentTok{\#\textgreater{} 3        11 roc\_auc binary     0.676     5 0.0110  pre0\_mod08\_post0}
\CommentTok{\#\textgreater{} 4        10 roc\_auc binary     0.674     5 0.0119  pre0\_mod07\_post0}
\CommentTok{\#\textgreater{} 5         8 roc\_auc binary     0.665     5 0.0145  pre0\_mod06\_post0}
\end{Highlighting}
\end{Shaded}

\subsection{Generalized Linear Model - GLM}\label{generalized-linear-model---glm}

The \href{https://towardsdatascience.com/generalized-linear-models-9cbf848bb8ab}{generalized linear model} (GLM) is a flexible generalization of ordinary linear regression.

To do this we need to install the \texttt{glmnet} library before creating our model via tidymodels.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"glmnet"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Spec}
\NormalTok{glm\_spec }\OtherTok{\textless{}{-}} \FunctionTok{logistic\_reg}\NormalTok{(}\AttributeTok{penalty =} \FunctionTok{tune}\NormalTok{(), }\AttributeTok{mixture =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"glmnet"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Workflow}
\NormalTok{glm\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(churn\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(glm\_spec)}

\CommentTok{\# Tune}
\NormalTok{glm\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  glm\_workflow,}
  \AttributeTok{resamples =}\NormalTok{ churn\_folds,}
  \AttributeTok{grid =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{metrics =}\NormalTok{ churn\_metrics}
\NormalTok{)}

\FunctionTok{show\_best}\NormalTok{(glm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 8}
\CommentTok{\#\textgreater{}         penalty mixture .metric .estimator  mean     n std\_err .config         }
\CommentTok{\#\textgreater{}           \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}   \textless{}chr\textgreater{}      \textless{}dbl\textgreater{} \textless{}int\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1 0.00599         1     roc\_auc binary     0.819     5 0.00937 pre0\_mod08\_post0}
\CommentTok{\#\textgreater{} 2 0.0774          0.261 roc\_auc binary     0.813     5 0.00862 pre0\_mod09\_post0}
\CommentTok{\#\textgreater{} 3 0.000464        0.578 roc\_auc binary     0.808     5 0.0102  pre0\_mod07\_post0}
\CommentTok{\#\textgreater{} 4 0.00000278      0.894 roc\_auc binary     0.807     5 0.0104  pre0\_mod05\_post0}
\CommentTok{\#\textgreater{} 5 0.00000000129   0.789 roc\_auc binary     0.807     5 0.0104  pre0\_mod02\_post0}
\end{Highlighting}
\end{Shaded}

\subsection{Random Forest Model}\label{random-forest-model}

Random Forest is a supervised machine learning technique based on decision trees. We will use the \href{https://dialnet.unirioja.es/descarga/articulo/6230447.pdf}{random forest model} (RF).

To do this we will first install the \texttt{ranger} library and then create the model via tidymodels.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"ranger"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Spec}
\NormalTok{rf\_spec }\OtherTok{\textless{}{-}} \FunctionTok{rand\_forest}\NormalTok{(}\AttributeTok{mtry =} \FunctionTok{tune}\NormalTok{(), }\AttributeTok{trees =} \DecValTok{1000}\NormalTok{, }\AttributeTok{min\_n =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"ranger"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Workflow}
\NormalTok{rf\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(churn\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(rf\_spec)}

\CommentTok{\# Tune}
\NormalTok{rf\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  rf\_workflow,}
  \AttributeTok{resamples =}\NormalTok{ churn\_folds,}
  \AttributeTok{grid =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{metrics =}\NormalTok{ churn\_metrics}
\NormalTok{)}
\CommentTok{\#\textgreater{} i Creating pre{-}processing data to finalize 1 unknown parameter: "mtry"}

\FunctionTok{show\_best}\NormalTok{(rf\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 8}
\CommentTok{\#\textgreater{}    mtry min\_n .metric .estimator  mean     n std\_err .config         }
\CommentTok{\#\textgreater{}   \textless{}int\textgreater{} \textless{}int\textgreater{} \textless{}chr\textgreater{}   \textless{}chr\textgreater{}      \textless{}dbl\textgreater{} \textless{}int\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1     8    31 roc\_auc binary     0.914     5 0.00998 pre0\_mod02\_post0}
\CommentTok{\#\textgreater{} 2    16     2 roc\_auc binary     0.912     5 0.0104  pre0\_mod03\_post0}
\CommentTok{\#\textgreater{} 3    23    18 roc\_auc binary     0.911     5 0.00975 pre0\_mod04\_post0}
\CommentTok{\#\textgreater{} 4    31    35 roc\_auc binary     0.909     5 0.0101  pre0\_mod05\_post0}
\CommentTok{\#\textgreater{} 5    53    40 roc\_auc binary     0.906     5 0.00890 pre0\_mod08\_post0}
\end{Highlighting}
\end{Shaded}

\subsection{Support Vector Machine Model - SVM}\label{support-vector-machine-model---svm}

\href{http://numerentur.org/svm/}{Support vector machines} or support vector machines are a set of supervised learning algorithms.

To create this model we will use the \texttt{kernlab} engine.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"kernlab"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Spec}
\NormalTok{svm\_spec }\OtherTok{\textless{}{-}} \FunctionTok{svm\_rbf}\NormalTok{(}\AttributeTok{cost =} \FunctionTok{tune}\NormalTok{(), }\AttributeTok{rbf\_sigma =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"kernlab"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Workflow}
\NormalTok{svm\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(churn\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(svm\_spec)}

\CommentTok{\# Tune}
\NormalTok{svm\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  svm\_workflow,}
  \AttributeTok{resamples =}\NormalTok{ churn\_folds,}
  \AttributeTok{grid =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{metrics =}\NormalTok{ churn\_metrics}
\NormalTok{)}
\CommentTok{\#\textgreater{} maximum number of iterations reached 2.273272e{-}05 2.273273e{-}05maximum number of iterations reached 0.001260726 0.001226596maximum number of iterations reached 0.008990742 0.0089403maximum number of iterations reached 4.01911e{-}05 4.01911e{-}05maximum number of iterations reached 0.0004458751 0.0004390186maximum number of iterations reached 0.01426775 0.01386837maximum number of iterations reached 2.311619e{-}05 2.311619e{-}05maximum number of iterations reached 0.0004666225 0.0004600749maximum number of iterations reached 0.009561785 0.009488703maximum number of iterations reached 4.18965e{-}05 4.189651e{-}05maximum number of iterations reached 0.01467671 0.01418266maximum number of iterations reached 2.221129e{-}05 2.22113e{-}05maximum number of iterations reached 0.0009695224 0.0009465917maximum number of iterations reached 0.009269646 0.009208682maximum number of iterations reached 3.924845e{-}05 3.924845e{-}05maximum number of iterations reached 0.0002350936 0.0002328733maximum number of iterations reached 0.01304753 0.01272522maximum number of iterations reached 2.357812e{-}05 2.357812e{-}05maximum number of iterations reached 0.0003822001 0.000377737maximum number of iterations reached 0.009766638 0.009695014maximum number of iterations reached 4.284351e{-}05 4.284352e{-}05maximum number of iterations reached 0.01553881 0.01501075maximum number of iterations reached 2.310753e{-}05 2.310753e{-}05maximum number of iterations reached 0.0004798964 0.0004730654maximum number of iterations reached 0.009636723 0.009566509maximum number of iterations reached 4.147277e{-}05 4.147278e{-}05maximum number of iterations reached 0.0002249601 0.0002227933maximum number of iterations reached 0.01498293 0.01448009}

\FunctionTok{show\_best}\NormalTok{(svm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 8}
\CommentTok{\#\textgreater{}        cost   rbf\_sigma .metric .estimator  mean     n std\_err .config         }
\CommentTok{\#\textgreater{}       \textless{}dbl\textgreater{}       \textless{}dbl\textgreater{} \textless{}chr\textgreater{}   \textless{}chr\textgreater{}      \textless{}dbl\textgreater{} \textless{}int\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}           }
\CommentTok{\#\textgreater{} 1  0.00310  0.00599     roc\_auc binary     0.864     5 0.00811 pre0\_mod02\_post0}
\CommentTok{\#\textgreater{} 2 32        0.000464    roc\_auc binary     0.862     5 0.00900 pre0\_mod10\_post0}
\CommentTok{\#\textgreater{} 3  1        0.0000359   roc\_auc binary     0.794     5 0.0103  pre0\_mod07\_post0}
\CommentTok{\#\textgreater{} 4  0.0312   0.00000278  roc\_auc binary     0.793     5 0.0114  pre0\_mod04\_post0}
\CommentTok{\#\textgreater{} 5  0.000977 0.000000215 roc\_auc binary     0.793     5 0.0114  pre0\_mod01\_post0}
\end{Highlighting}
\end{Shaded}

\subsection{Naive Bayes Model}\label{naive-bayes-model}

Naïve Bayes (NB) is one of the simplest, yet powerful, algorithms for classification. It is based on \textbf{Bayes' Theorem}, which describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if cancer is related to age, then, using Bayes' theorem, a person's age can be used to more accurately assess the probability that they have cancer.

To use this model we will use the \texttt{naivebayes} library within tidymodels.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"naivebayes"}\NormalTok{, }\StringTok{"discrim"}\NormalTok{))}
\FunctionTok{library}\NormalTok{(naivebayes) }
\FunctionTok{library}\NormalTok{(discrim) }\CommentTok{\# Required for parsnip integration}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Spec}
\FunctionTok{library}\NormalTok{(discrim)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Attaching package: \textquotesingle{}discrim\textquotesingle{}}
\CommentTok{\#\textgreater{} The following object is masked from \textquotesingle{}package:dials\textquotesingle{}:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}     smoothness}
\NormalTok{nb\_spec }\OtherTok{\textless{}{-}} \FunctionTok{naive\_Bayes}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"naivebayes"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Workflow}
\NormalTok{nb\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(churn\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(nb\_spec)}

\CommentTok{\# Tune}
\NormalTok{nb\_res }\OtherTok{\textless{}{-}} \FunctionTok{fit\_resamples}\NormalTok{(}
\NormalTok{  nb\_workflow,}
  \AttributeTok{resamples =}\NormalTok{ churn\_folds,}
  \AttributeTok{metrics =}\NormalTok{ churn\_metrics}
\NormalTok{)}

\FunctionTok{collect\_metrics}\NormalTok{(nb\_res)}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 6}
\CommentTok{\#\textgreater{}   .metric     .estimator  mean     n  std\_err .config        }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}       \textless{}chr\textgreater{}      \textless{}dbl\textgreater{} \textless{}int\textgreater{}    \textless{}dbl\textgreater{} \textless{}chr\textgreater{}          }
\CommentTok{\#\textgreater{} 1 accuracy    binary     0.859     5 0.000246 pre0\_mod0\_post0}
\CommentTok{\#\textgreater{} 2 roc\_auc     binary     0.840     5 0.00983  pre0\_mod0\_post0}
\CommentTok{\#\textgreater{} 3 sensitivity binary     1         5 0        pre0\_mod0\_post0}
\CommentTok{\#\textgreater{} 4 specificity binary     0         5 0        pre0\_mod0\_post0}
\end{Highlighting}
\end{Shaded}

\subsection{Model Comparison}\label{model-comparison}

To compare the models, we can extract the metrics from each tuning result and visualize them.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Collect metrics}
\NormalTok{knn\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{collect\_metrics}\NormalTok{(knn\_res) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"kNN"}\NormalTok{)}
\NormalTok{glm\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{collect\_metrics}\NormalTok{(glm\_res) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"GLM"}\NormalTok{)}
\NormalTok{rf\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{collect\_metrics}\NormalTok{(rf\_res) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"RF"}\NormalTok{)}
\NormalTok{svm\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{collect\_metrics}\NormalTok{(svm\_res) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"SVM"}\NormalTok{)}
\NormalTok{nb\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{collect\_metrics}\NormalTok{(nb\_res) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Naive Bayes"}\NormalTok{)}

\CommentTok{\# Combine}
\NormalTok{all\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(knn\_metrics, glm\_metrics, rf\_metrics, svm\_metrics, nb\_metrics)}

\CommentTok{\# Visualize ROC AUC}
\NormalTok{all\_metrics }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(.metric }\SpecialCharTok{==} \StringTok{"roc\_auc"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ model, }\AttributeTok{y =}\NormalTok{ mean, }\AttributeTok{fill =}\NormalTok{ model)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"ROC AUC"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Model Comparison"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-634-1} \end{center}

For this case the random forest model (\emph{RF}) seems to be the best. This is not surprising given that this algorithm is related to its ability to cope with different input types and require little preprocessing. We can make our models better by pre-processing data and changing the ad-hoc parameters of each model.

\subsection{Predicting using the best model}\label{predicting-using-the-best-model}

Now that we have our best model (Random Forest), we proceed to perform the prediction on the test set. We need to finalize the workflow with the best hyperparameters from the tuning step first.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Select best parameters for RF}
\NormalTok{best\_rf }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(rf\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}

\CommentTok{\# Finalize workflow}
\NormalTok{final\_rf\_workflow }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(rf\_workflow, best\_rf)}

\CommentTok{\# Fit on training data}
\NormalTok{optimal\_model }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(final\_rf\_workflow, }\AttributeTok{data =}\NormalTok{ churn\_train)}

\CommentTok{\# Predict on test data}
\NormalTok{churn\_predictions }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(optimal\_model, }\AttributeTok{new\_data =}\NormalTok{ churn\_test)}

\CommentTok{\# Evaluate results}
\NormalTok{churn\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ churn\_status, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\CommentTok{\#\textgreater{}           Truth}
\CommentTok{\#\textgreater{} Prediction   No  Yes}
\CommentTok{\#\textgreater{}        No  1285   66}
\CommentTok{\#\textgreater{}        Yes    3  147}

\NormalTok{churn\_predictions }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ churn\_status, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 3}
\CommentTok{\#\textgreater{}   .metric  .estimator .estimate}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 accuracy binary         0.954}
\end{Highlighting}
\end{Shaded}

Thus, we have found how to create a customer churn prediction model given 19 prediction variables with an accuracy of 96\%.

\section{Exercises}\label{exercises-17}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{99}
\tightlist
\item
  The \texttt{attrition} data frame from the \texttt{modeldata} library shows data from a list of almost 1,500 employees of a company. Create a copy of this data frame and store it in the \texttt{workers} object. Then, build an RF model with this data to predict the \texttt{Attrition} field (job desertion). Where the class ``Yes'' means they resigned and ``No'' means they still work.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(attrition)}
\FunctionTok{str}\NormalTok{(attrition)}

\NormalTok{workers }\OtherTok{\textless{}{-}}\NormalTok{ attrition}

\NormalTok{workers }\OtherTok{\textless{}{-}}\NormalTok{ workers }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{attrition\_status =}\NormalTok{ Attrition)}

\CommentTok{\# 70\% for the training data}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{28}\NormalTok{)}
\NormalTok{workers\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(workers, }\AttributeTok{prop =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ attrition\_status)}

\NormalTok{workers\_train }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(workers\_split)}
\NormalTok{workers\_test }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(workers\_split)}

\CommentTok{\# Recipe}
\NormalTok{workers\_recipe }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(attrition\_status }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ workers\_train) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{step\_dummy}\NormalTok{(}\FunctionTok{all\_nominal\_predictors}\NormalTok{(), }\SpecialCharTok{{-}}\NormalTok{attrition\_status) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{step\_normalize}\NormalTok{(}\FunctionTok{all\_numeric\_predictors}\NormalTok{())}

\CommentTok{\# We create CV folds}
\NormalTok{workers\_folds }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(workers\_train, }\AttributeTok{v =} \DecValTok{5}\NormalTok{, }\AttributeTok{strata =}\NormalTok{ attrition\_status)}
\NormalTok{workers\_metrics }\OtherTok{\textless{}{-}} \FunctionTok{metric\_set}\NormalTok{(roc\_auc, accuracy)}

\CommentTok{\# We create the model}
\NormalTok{rf\_spec }\OtherTok{\textless{}{-}} \FunctionTok{rand\_forest}\NormalTok{(}\AttributeTok{trees =} \DecValTok{1000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"ranger"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\NormalTok{rf\_wf }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(workers\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(rf\_spec)}

\NormalTok{workers\_rf\_res }\OtherTok{\textless{}{-}} \FunctionTok{fit\_resamples}\NormalTok{(}
\NormalTok{  rf\_wf,}
  \AttributeTok{resamples =}\NormalTok{ workers\_folds,}
  \AttributeTok{metrics =}\NormalTok{ workers\_metrics}
\NormalTok{)}

\FunctionTok{collect\_metrics}\NormalTok{(workers\_rf\_res)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{100}
\tightlist
\item
  Using the training data from the previous exercise, build the GLM model using tidymodels.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Spec}
\NormalTok{glm\_spec }\OtherTok{\textless{}{-}} \FunctionTok{logistic\_reg}\NormalTok{(}\AttributeTok{penalty =} \FunctionTok{tune}\NormalTok{(), }\AttributeTok{mixture =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"glmnet"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Workflow}
\NormalTok{glm\_wf }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(workers\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(glm\_spec)}

\CommentTok{\# Tune}
\NormalTok{workers\_glm\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  glm\_wf,}
  \AttributeTok{resamples =}\NormalTok{ workers\_folds,}
  \AttributeTok{grid =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{metrics =}\NormalTok{ workers\_metrics}
\NormalTok{)}

\FunctionTok{show\_best}\NormalTok{(workers\_glm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{101}
\tightlist
\item
  Using the training data, build the SVM model.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Spec}
\NormalTok{svm\_spec }\OtherTok{\textless{}{-}} \FunctionTok{svm\_rbf}\NormalTok{(}\AttributeTok{cost =} \FunctionTok{tune}\NormalTok{(), }\AttributeTok{rbf\_sigma =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"kernlab"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\CommentTok{\# Workflow}
\NormalTok{svm\_wf }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_recipe}\NormalTok{(workers\_recipe) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{add\_model}\NormalTok{(svm\_spec)}

\CommentTok{\# Tune}
\NormalTok{workers\_svm\_res }\OtherTok{\textless{}{-}} \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{  svm\_wf,}
  \AttributeTok{resamples =}\NormalTok{ workers\_folds,}
  \AttributeTok{grid =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{metrics =}\NormalTok{ workers\_metrics}
\NormalTok{)}

\FunctionTok{show\_best}\NormalTok{(workers\_svm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{102}
\tightlist
\item
  From the created models, which is the most optimal?
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Collect best metrics from each model}
\NormalTok{rf\_best }\OtherTok{\textless{}{-}} \FunctionTok{show\_best}\NormalTok{(workers\_rf\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{, }\AttributeTok{n =} \DecValTok{1}\NormalTok{)}
\NormalTok{glm\_best }\OtherTok{\textless{}{-}} \FunctionTok{show\_best}\NormalTok{(workers\_glm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{, }\AttributeTok{n =} \DecValTok{1}\NormalTok{)}
\NormalTok{svm\_best }\OtherTok{\textless{}{-}} \FunctionTok{show\_best}\NormalTok{(workers\_svm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{, }\AttributeTok{n =} \DecValTok{1}\NormalTok{)}

\CommentTok{\# Create comparison tibble}
\NormalTok{model\_comparison }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(}
\NormalTok{  rf\_best }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Random Forest"}\NormalTok{),}
\NormalTok{  glm\_best }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"GLM"}\NormalTok{),}
\NormalTok{  svm\_best }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"SVM"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# Visualize}
\NormalTok{model\_comparison }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{reorder}\NormalTok{(model, mean), }\AttributeTok{y =}\NormalTok{ mean, }\AttributeTok{fill =}\NormalTok{ model)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean }\SpecialCharTok{{-}}\NormalTok{ std\_err, }\AttributeTok{ymax =}\NormalTok{ mean }\SpecialCharTok{+}\NormalTok{ std\_err), }\AttributeTok{width =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"ROC AUC"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Model"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Model Comparison by ROC AUC"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

We see how the results overlap, so we could opt for the two that have the highest mean ROC and among them choose the one that gives us a smaller range of values.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{103}
\tightlist
\item
  Create the confusion matrices for the three models created.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Finalize and fit each model}
\NormalTok{best\_rf }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(workers\_rf\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\NormalTok{final\_rf\_wf }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(rf\_wf, best\_rf)}
\NormalTok{rf\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(final\_rf\_wf, }\AttributeTok{data =}\NormalTok{ workers\_train)}

\NormalTok{best\_glm }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(workers\_glm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\NormalTok{final\_glm\_wf }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(glm\_wf, best\_glm)}
\NormalTok{glm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(final\_glm\_wf, }\AttributeTok{data =}\NormalTok{ workers\_train)}

\NormalTok{best\_svm }\OtherTok{\textless{}{-}} \FunctionTok{select\_best}\NormalTok{(workers\_svm\_res, }\AttributeTok{metric =} \StringTok{"roc\_auc"}\NormalTok{)}
\NormalTok{final\_svm\_wf }\OtherTok{\textless{}{-}} \FunctionTok{finalize\_workflow}\NormalTok{(svm\_wf, best\_svm)}
\NormalTok{svm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{fit}\NormalTok{(final\_svm\_wf, }\AttributeTok{data =}\NormalTok{ workers\_train)}

\CommentTok{\# Predictions and confusion matrices}
\NormalTok{rf\_preds }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(rf\_fit, }\AttributeTok{new\_data =}\NormalTok{ workers\_test)}
\NormalTok{rf\_preds }\SpecialCharTok{|\textgreater{}} \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ attrition\_status, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}

\NormalTok{glm\_preds }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(glm\_fit, }\AttributeTok{new\_data =}\NormalTok{ workers\_test)}
\NormalTok{glm\_preds }\SpecialCharTok{|\textgreater{}} \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ attrition\_status, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}

\NormalTok{svm\_preds }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(svm\_fit, }\AttributeTok{new\_data =}\NormalTok{ workers\_test)}
\NormalTok{svm\_preds }\SpecialCharTok{|\textgreater{}} \FunctionTok{conf\_mat}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ attrition\_status, }\AttributeTok{estimate =}\NormalTok{ .pred\_class)}
\end{Highlighting}
\end{Shaded}

Keep in mind that the model with the highest \texttt{ROC} value will not necessarily have the highest \texttt{accuracy}. Therefore the choice of the model was performed in a previous step. The ROC better balances sensitivity with the \href{https://en.wikipedia.org/wiki/False_positive_rate}{false positive rate}.

\section{Ethics: Bias in Algorithmic Decision Making}\label{ethics-bias-in-algorithmic-decision-making}

In the previous exercise, we built models to predict employee attrition using variables like \texttt{Gender}, \texttt{Age}, and \texttt{MaritalStatus}. While mathematically sound, obtaining a high accuracy score does not mean the model is ``good'' or ``fair'' to use in the real world.

\subsection{The Risk of Proxy Variables}\label{the-risk-of-proxy-variables}

Even if we remove explicit sensitive attributes (like Gender or Ethnicity), other variables can act as \textbf{proxies}.
* \textbf{Zip Code:} Often correlates with race or socioeconomic status.
* \textbf{Years of Experience:} Strongly correlated with Age.

\subsection{Feedback Loops}\label{feedback-loops}

If a company uses an algorithm to decide who to hire or fire based on historical data, they may perpetuate historical biases.
* \textbf{Scenario:} If a company historically didn't hire women for leadership roles, the training data will show that women are ``less likely to succeed'' in those roles.
* \textbf{Result:} The model creates a feedback loop, rejecting qualified female candidates because they don't match the historical pattern of ``success''.

\begin{quote}
{[}!IMPORTANT{]}
\textbf{What can we do?}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Audit your Data:} checking for representation balance (e.g., is one group significantly smaller?).
\item
  \textbf{Model Explainability:} Use tools like \texttt{DALEX} or \texttt{vip} (variable importance) to understand \emph{why} the model is making a decision. If \texttt{MaritalStatus} is the top predictor for firing someone, is that ethical?
\item
  \textbf{Human in the Loop:} These models should support human decision-making, not replace it entirely.
\end{enumerate}
\end{quote}

As Data Scientists, our responsibility extends beyond the AUC score. We must ensure our models do not harm individuals or groups.

\chapter{Unsupervised Learning}\label{unsupervised-learning}

Now that we know how to create supervised learning algorithms, understanding unsupervised learning becomes an intuitive exercise.

While in \textbf{supervised} learning we have a set of variables that we use to predict a certain output class (up/down, resign/not resign), in \textbf{unsupervised} learning we do not have expected output classes. In supervised learning we had training data and testing data that allowed us to validate the effectiveness of the model by its closeness to the known class. In unsupervised learning we do not have a default \emph{output}. This in turn generates a great challenge because it is very difficult to know if we have already finished the work or if we can still generate another model with which we feel more satisfied.

The simplest example to understand this type of learning is when we have our customer base and we want to segment them for the first time. In that case, we look for customers who behave in the same way, but being the first time, we don't know how many segments we can have. The challenge lies in determining the cut-off: how many segments do we seek to create?

\section{Learning Objectives}\label{learning-objectives-3}

By the end of this section, you will be able to:

By the end of this section, you will be able to clearly differentiate between supervised and unsupervised learning, understanding the distinct challenges of working with unlabeled data. We will apply the \textbf{k-means} clustering algorithm to segment data into optimal groups and use \textbf{hierarchical clustering} to visualize relationships through dendrograms. Furthermore, you will learn to evaluate the quality of these clusters using the \textbf{elbow} and \textbf{silhouette} methods, and perform basic \textbf{dimensionality reduction} to simplify complex datasets.

\section{Applications of Unsupervised Learning}\label{applications-of-unsupervised-learning}

The main applications of unsupervised learning are related to data \textbf{\emph{clustering}}. Here, the goal is to find homogeneous subgroups within the data. These algorithms are based on the distance between observations. The customer segmentation example would be an example of \emph{clustering}.

The most commonly used clustering algorithms are: k-means clustering and hierarchical clustering.

\section{K-Means Clustering}\label{k-means-clustering}

To understand this method we will use examples first with a minimal amount of variables and then little by little we will create a more generic model.

\subsection{Clustering with k = 2}\label{clustering-with-k-2}

Suppose we have a list of players on a soccer field and we take a photo from above to have their coordinates (variable 1 would be the x-axis and variable 2 would be the y-axis). We cannot see which team each player belongs to so we will paint everyone as black dots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{players }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{12}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{15}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{12}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{25}\NormalTok{, }\DecValTok{26}\NormalTok{),}
                    \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{0}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{15}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{                    )}

\NormalTok{players }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(x, y) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-647-1} \end{center}

This method allows us to group based on the definition of centroids. We will define as many centroids as groups we want to obtain. Since for this case we know that there must be two teams, we will use 2 centroids (k = 2).

The k-means algorithm then places these 2 points (centroids) randomly on the plane in a first iteration. Then, it calculates the distance between each center and the other data points. If it is closer to a centroid then it assigns it to centroid 1, otherwise to centroid 2.

\begin{center}\includegraphics[width=0.8\linewidth,alt={K-means iteration showing data points and distance calculations to two centroids}]{assets/images/06-machine-learning/kmeans-distance} \end{center}

A first grouping has already been performed. Now each centroid within each group is located at the mean of the other points in its group and another iteration occurs to reassign all points. This iteration is done over and over again until the centroids are fixed.

To create this model in R we will use the function \texttt{kmeans(data,\ centers\ =\ k)}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans\_model }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(players, }\AttributeTok{centers =} \DecValTok{2}\NormalTok{)}

\CommentTok{\# We print the coordinates of the centers}
\NormalTok{kmeans\_model}\SpecialCharTok{$}\NormalTok{centers}
\CommentTok{\#\textgreater{}           x          y}
\CommentTok{\#\textgreater{} 1 {-}11.33333 {-}0.5000000}
\CommentTok{\#\textgreater{} 2  14.83333  0.1666667}
\end{Highlighting}
\end{Shaded}

This means that for these two centers the average distance to the other points is the minimum, therefore the algorithm assigns them to one group or another. Let's see approximately where these centers are located if we marked them with an \textbf{x}.

\begin{center}\includegraphics[width=0.8\linewidth,alt={K-means result with two clusters and centroids marked with X}]{assets/images/06-machine-learning/kmeans-centers} \end{center}

Thus, once the model is created we can obtain the clustering results, team 1 or team 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{team }\OtherTok{\textless{}{-}}\NormalTok{ kmeans\_model}\SpecialCharTok{$}\NormalTok{cluster}
\end{Highlighting}
\end{Shaded}

We can add this team assignment as one more column of our \texttt{players} data set to be able to visualize them in R.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We add the cluster column}
\NormalTok{players\_grouped }\OtherTok{\textless{}{-}}\NormalTok{ players }\SpecialCharTok{|\textgreater{}} 
                         \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =}\NormalTok{ team)}

\CommentTok{\# We visualize the players according to the grouping}
\NormalTok{players\_grouped }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(x, y, }\AttributeTok{fill =} \FunctionTok{factor}\NormalTok{(cluster)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{5}\NormalTok{, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\StringTok{"\#EE220D"}\NormalTok{, }\StringTok{"\#01A2FF"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
  
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-652-1} \end{center}

We have found two centroids until minimizing the sum of the squared differences between each centroid and the other points in the cluster. We can access and see how much this value is, given that it is part of the model results.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sum of squares within each cluster}
\NormalTok{kmeans\_model}\SpecialCharTok{$}\NormalTok{withinss}
\CommentTok{\#\textgreater{} [1] 570.8333 863.6667}

\CommentTok{\# Total}
\NormalTok{kmeans\_model}\SpecialCharTok{$}\NormalTok{tot.withinss}
\CommentTok{\#\textgreater{} [1] 1434.5}
\end{Highlighting}
\end{Shaded}

\texttt{Tot.withinss} comes from \emph{Total within-cluster sum of squares}.

\subsection{Clustering with k \textgreater= 3}\label{clustering-with-k-3}

When we have 3 or more centers the idea is the same, we only change the \texttt{centers} parameter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans\_model }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(players, }\AttributeTok{centers =} \DecValTok{3}\NormalTok{)}

\NormalTok{team }\OtherTok{\textless{}{-}}\NormalTok{ kmeans\_model}\SpecialCharTok{$}\NormalTok{cluster}

\NormalTok{players\_grouped }\OtherTok{\textless{}{-}}\NormalTok{ players }\SpecialCharTok{|\textgreater{}} 
                         \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =}\NormalTok{ team)}

\NormalTok{players\_grouped }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(x, y, }\AttributeTok{color =} \FunctionTok{factor}\NormalTok{(cluster)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{kmeans\_model}\SpecialCharTok{$}\NormalTok{tot.withinss}
\CommentTok{\#\textgreater{} [1] 881.25}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-654-1} \end{center}

In this case we have found that the sum of squares within the clusters is smaller, so we could indicate that this grouping is more optimal than the grouping into two groups. However, the sum of squares is not necessarily the best indicator for choosing how many clusters to create.

\subsection{Determination of Optimal Clusters}\label{determination-of-optimal-clusters}

We can mainly use two methods to determine how many clusters we should build, \texttt{k}. The sum of squares method (\emph{wss}) and the average silhouette method (\emph{silhouette}).

To avoid having to calculate models for different values of \texttt{k} we will use the \texttt{factoextra} library, which was created especially to perform easy multivariate data analysis and elegant visualization, very useful for clustering.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"factoextra"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(factoextra)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Sum of Squares Method}\label{sum-of-squares-method}

To find the optimal ``k'' under this method, we will use the \textbf{elbow plot}, where we first calculate the total within-cluster sum of squares for different values of ``k''. Then, visually we will identify a point where there seems to be a very strong drop followed by a more gradual drop in the slope. To do this, we will use the function \texttt{fviz\_nbclust(data,\ type,\ method)} and enter our data, the type of algorithm that will be used to group and the measurement method.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fviz\_nbclust}\NormalTok{(players, }\AttributeTok{FUN =}\NormalTok{ kmeans, }\AttributeTok{method =} \StringTok{"wss"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-656-1} \end{center}

In this case the ``elbow'' is found at the value k = 2, from there the sum of squares reduces but at a slower rate.

\subsubsection{Average Silhouette Method}\label{average-silhouette-method}

The method described above is a visual aid that makes recognition difficult when the data points are closer. Therefore, it is much more frequent to perform a silhouette analysis \citep{Rousseeuw1987}. This approach measures the quality of a clustering. That is, it determines how well each object lies within its group. A high average silhouette width indicates a good clustering. The average silhouette method calculates the average silhouette of observations for different values of ``k''. The optimal number of groups ``k'' is the one that maximizes the average silhouette over a range of possible values for ``k''.

To do this, we change the \texttt{method} parameter in the function and obtain the silhouette analysis.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fviz\_nbclust}\NormalTok{(players, }\AttributeTok{FUN =}\NormalTok{ kmeans, }\AttributeTok{method =} \StringTok{"silhouette"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-657-1} \end{center}

Here it is clearly seen that for a value of \texttt{k=2} we have the best average, making this our optimal number of groups.

\begin{quote}
{[}!TIP{]}
\textbf{Interpreting Silhouette Scores}
Interpreting these scores is straightforward: a score close to \textbf{1} indicates that the data point is well-matched to its own cluster and distinct from neighbors, representing a strong grouping. A score near \textbf{0} suggests the point lies on the boundary between clusters, while a \textbf{negative} score implies the point may have been assigned to the wrong group. Generally, an average silhouette width above \textbf{0.5} signals a solid clustering structure.
\end{quote}

\subsection{k-means for more than 2 variables}\label{k-means-for-more-than-2-variables}

The method we have learned can be easily extended to more variables. Only in this case it would no longer be possible to visualize it like the soccer team and we would only visualize the results of the grouping and the learned metrics.

To do this, we will use the following customer dataset, where we will find a dataset of customers of a wholesale distributor. It includes the annual spending in monetary units on various product categories.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"http://archive.ics.uci.edu/ml/machine{-}learning{-}databases/00292/Wholesale\%20customers\%20data.csv"}
\NormalTok{customers }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url)}
\CommentTok{\#\textgreater{} Rows: 440 Columns: 8}
\CommentTok{\#\textgreater{} {-}{-} Column specification {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Delimiter: ","}
\CommentTok{\#\textgreater{} dbl (8): Channel, Region, Fresh, Milk, Grocery, Frozen, Detergents\_Paper, De...}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} i Use \textasciigrave{}spec()\textasciigrave{} to retrieve the full column specification for this data.}
\CommentTok{\#\textgreater{} i Specify the column types or set \textasciigrave{}show\_col\_types = FALSE\textasciigrave{} to quiet this message.}
\end{Highlighting}
\end{Shaded}

We are going to perform a grouping only considering the spending made on frozen foods, groceries and dairy products.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{customers\_filtered }\OtherTok{\textless{}{-}}\NormalTok{ customers }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(Milk, Grocery, Frozen)}

\CommentTok{\# We scale the data to ensure equal weight for all variables}
\NormalTok{customers\_scaled }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{scale}\NormalTok{(customers\_filtered))}
\end{Highlighting}
\end{Shaded}

Once we have our data we would create a silhouette analysis to determine the best value of ``k''.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fviz\_nbclust}\NormalTok{(customers\_scaled, }\AttributeTok{FUN =}\NormalTok{ kmeans, }\AttributeTok{method =} \StringTok{"silhouette"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-660-1} \end{center}

Again, we get that the recommended number of clusters is 2. Let's create the model for k = 2 and store the resulting cluster.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(customers\_scaled, }\AttributeTok{centers =} \DecValTok{2}\NormalTok{)}

\NormalTok{customers\_grouped }\OtherTok{\textless{}{-}}\NormalTok{ customers\_filtered }\SpecialCharTok{|\textgreater{}} 
                        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =}\NormalTok{ model}\SpecialCharTok{$}\NormalTok{cluster)}

\NormalTok{customers\_grouped}
\CommentTok{\#\textgreater{} \# A tibble: 440 x 4}
\CommentTok{\#\textgreater{}     Milk Grocery Frozen cluster}
\CommentTok{\#\textgreater{}    \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}   \textless{}int\textgreater{}}
\CommentTok{\#\textgreater{}  1  9656    7561    214       1}
\CommentTok{\#\textgreater{}  2  9810    9568   1762       1}
\CommentTok{\#\textgreater{}  3  8808    7684   2405       1}
\CommentTok{\#\textgreater{}  4  1196    4221   6404       1}
\CommentTok{\#\textgreater{}  5  5410    7198   3915       1}
\CommentTok{\#\textgreater{}  6  8259    5126    666       1}
\CommentTok{\#\textgreater{}  7  3199    6975    480       1}
\CommentTok{\#\textgreater{}  8  4956    9426   1669       1}
\CommentTok{\#\textgreater{}  9  3648    6192    425       1}
\CommentTok{\#\textgreater{} 10 11093   18881   1159       1}
\CommentTok{\#\textgreater{} \# i 430 more rows}
\end{Highlighting}
\end{Shaded}

Once we have grouped our data we can calculate the amount of data in each cluster and the mean of the values for each group and thus identify differences between these two potential customer segments.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{customers\_grouped }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(cluster) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{total =} \FunctionTok{n}\NormalTok{(), }
            \AttributeTok{mean\_Milk =} \FunctionTok{mean}\NormalTok{(Milk), }
            \AttributeTok{mean\_Grocery =} \FunctionTok{mean}\NormalTok{(Grocery),}
            \AttributeTok{mean\_Frozen =} \FunctionTok{mean}\NormalTok{(Frozen))}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 5}
\CommentTok{\#\textgreater{}   cluster total mean\_Milk mean\_Grocery mean\_Frozen}
\CommentTok{\#\textgreater{}     \textless{}int\textgreater{} \textless{}int\textgreater{}     \textless{}dbl\textgreater{}        \textless{}dbl\textgreater{}       \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1       1   395     4056.        5628.       2864.}
\CommentTok{\#\textgreater{} 2       2    45    21070.       28341.       4898.}
\end{Highlighting}
\end{Shaded}

Thus, we have learned to segment customers using machine learning.

\section{Hierarchical Clustering}\label{hierarchical-clustering}

Hierarchical clustering is another method for grouping data. The word hierarchical comes from the hierarchies that this algorithm creates to determine the clusters. Unlike k-means, we do not start by indicating how many clusters we want to create, but rather the algorithm shows us a list of possible combinations according to the hierarchy of distances between points. Let's see it with an example.

\subsection{Clustering with two variables}\label{clustering-with-two-variables}

To do this we will use the same soccer team example that we used previously. With the difference that this time we number each player to make visualization easier.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{12}

\NormalTok{players }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{12}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{15}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{12}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{25}\NormalTok{, }\DecValTok{26}\NormalTok{),}
                    \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{0}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{15}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}

\NormalTok{players }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(x, y, }\AttributeTok{label =}\NormalTok{ num) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{nudge\_x =} \FloatTok{1.3}\NormalTok{, }\AttributeTok{nudge\_y =} \FloatTok{1.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-663-1} \end{center}

This algorithm searches for the two points with the shortest distance, the closest ones, and groups them. Then it searches for another two points with the smallest distance and asks: is the distance between these two new points less than the distance of these points to the previously created group? If the answer is yes, it groups them, otherwise it groups the closest point to the first created group.

Let's understand the algorithm graphically. Points 1 and 2 have the lowest hierarchy since they have the shortest distance. Then the algorithm searches for the next two closest points (point 9 and 12) and when comparing with the midpoint of 1 and 2 it opts to create a new group with a slightly higher hierarchy and so on.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Initial hierarchical clustering step linking two closest points}]{assets/images/06-machine-learning/hclust-one} \end{center}

However, now that we have point 7 and 11 and we calculate the distance, it turns out that that distance is not the smallest compared to the distances with the other existing groups. For example, 7 is closer to the midpoint of 1 and 2, and 11 is closer to the midpoint of 5 and 6.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Hierarchical clustering merging additional nearby points into groups}]{assets/images/06-machine-learning/hclust-two} \end{center}

Thus, the algorithm creates a higher hierarchy for this grouping.

\begin{center}\includegraphics[width=0.8\linewidth,alt={Dendrogram showing hierarchical clustering tree structure with higher groupings}]{assets/images/06-machine-learning/hclust-three} \end{center}

The algorithm continues until it finally creates a group that includes everyone as the highest hierarchy. In the following graph we can not only appreciate this but also on the y-axis the distance between each point or group of points.

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-667-1} \end{center}

Up to here we haven't done more than generate hierarchies from the distances which will serve us later to determine how many clusters to generate. Let's create in R what has been advanced so far. The first thing we will do is calculate the distances between all points. To do this we will use the \texttt{dist()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{player\_distances }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(players)}
\end{Highlighting}
\end{Shaded}

With the calculated distances we can create the hierarchical model using the \texttt{hclust(distance\_matrix)} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hierarchical\_model }\OtherTok{\textless{}{-}} \FunctionTok{hclust}\NormalTok{(player\_distances)}
\end{Highlighting}
\end{Shaded}

Once our model is created we can visualize it using the \texttt{dendextend} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"dendextend"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(dendextend)}
\end{Highlighting}
\end{Shaded}

The visualization we saw is called a dendrogram. To do this we just have to convert our model to dendrogram format.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dend\_model }\OtherTok{\textless{}{-}} \FunctionTok{as.dendrogram}\NormalTok{(hierarchical\_model)}
\FunctionTok{plot}\NormalTok{(dend\_model)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-671-1} \end{center}

So far we have only seen the hierarchy, but what interests us is the grouping. The grouping is done by the calculated distance (\texttt{h} parameter). Let's try with a distance of 60. We will use the \texttt{color\_branches} and \texttt{color\_labels} functions to make the changes visible.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cut\_height }\OtherTok{\textless{}{-}} \DecValTok{60}

\NormalTok{dend\_model }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_branches}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_labels}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{plot}\NormalTok{()}
\CommentTok{\#\textgreater{} Warning in get\_col(col, k): Length of color vector was longer than the number}
\CommentTok{\#\textgreater{} of clusters {-} first k elements are used}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-672-1} \end{center}

Since the highest hierarchy distance is approximately 50, then in this case it groups everyone into one large cluster. Let's try with a lower number, for example 40.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cut\_height }\OtherTok{\textless{}{-}} \DecValTok{40}

\NormalTok{dend\_model }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_branches}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_labels}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{plot}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning in get\_col(col, k): Length of color vector was longer than the number}
\CommentTok{\#\textgreater{} of clusters {-} first k elements are used}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-673-1} \end{center}

By making a cut at 40 we now have two clusters, in this case the red color and the green color. Let's try with a lower number, 28.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cut\_height }\OtherTok{\textless{}{-}} \DecValTok{28}

\NormalTok{dend\_model }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_branches}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_labels}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{plot}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ cut\_height, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} Loading required namespace: colorspace}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-674-1} \end{center}

Now we have three clusters and so we could continue until obtaining the clusters we need.

We must have noticed how impractical it is to use the distances of the hierarchical model because they vary according to the data we have. This model allows us to make cuts not only by distances but also by indicating how many clusters we want, parameter \texttt{k}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{desired\_clusters }\OtherTok{\textless{}{-}} \DecValTok{3}

\NormalTok{dend\_model }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_branches}\NormalTok{(}\AttributeTok{k =}\NormalTok{ desired\_clusters) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{color\_labels}\NormalTok{(}\AttributeTok{k =}\NormalTok{ desired\_clusters) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{plot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-675-1} \end{center}

We see that it gives us the same grouping whether we use distances or number of desired clusters.

\subsection{Determination of Optimal Clusters}\label{determination-of-optimal-clusters-1}

To calculate how many clusters are optimal to create we will use the silhouette analysis again, but this time with the argument \texttt{FUN\ =\ hcut} to determine that it be evaluated based on a hierarchical model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fviz\_nbclust}\NormalTok{(players, }\AttributeTok{FUN =}\NormalTok{ hcut, }\AttributeTok{method =} \StringTok{"silhouette"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-676-1} \end{center}

It is not surprising that the value of \texttt{k} is also 2, which coincides with the number obtained in the k-means model.

\subsection{Obtain the grouping}\label{obtain-the-grouping}

Now that we have validated that the recommended number of clusters is 2, we calculate the grouping from the previously created model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{players\_grouped }\OtherTok{\textless{}{-}}\NormalTok{ players }\SpecialCharTok{|\textgreater{}} 
                        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =} \FunctionTok{cutree}\NormalTok{(hierarchical\_model, }\AttributeTok{k =} \DecValTok{2}\NormalTok{)}
\NormalTok{                               )}

\NormalTok{players\_grouped}
\CommentTok{\#\textgreater{} \# A tibble: 12 x 3}
\CommentTok{\#\textgreater{}        x     y cluster}
\CommentTok{\#\textgreater{}    \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}   \textless{}int\textgreater{}}
\CommentTok{\#\textgreater{}  1    {-}1     1       1}
\CommentTok{\#\textgreater{}  2    {-}2    {-}3       1}
\CommentTok{\#\textgreater{}  3     8     6       2}
\CommentTok{\#\textgreater{}  4     7    {-}8       2}
\CommentTok{\#\textgreater{}  5   {-}12     8       1}
\CommentTok{\#\textgreater{}  6   {-}15     0       1}
\CommentTok{\#\textgreater{}  7   {-}13   {-}10       1}
\CommentTok{\#\textgreater{}  8    15    16       2}
\CommentTok{\#\textgreater{}  9    21     2       2}
\CommentTok{\#\textgreater{} 10    12   {-}15       2}
\CommentTok{\#\textgreater{} 11   {-}25     1       1}
\CommentTok{\#\textgreater{} 12    26     0       2}
\end{Highlighting}
\end{Shaded}

Finally, let's visualize the grouping performed with this method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{players\_grouped }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(x, y, }\AttributeTok{color =} \FunctionTok{factor}\NormalTok{(cluster)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-678-1} \end{center}

We see that the grouping is the same as with the previous method, basically because we are talking about two variables and two clusters.

Both methods learned are very flexible, so the creation of models for more variables follows the same logic learned in these sections.

\section{Dimensionality Reduction}\label{dimensionality-reduction}

We have created clusters with a controlled number of variables. However, we are going to encounter in many cases many more variables that make interpretation difficult and it is important to identify if two variables have the same behavior to be able to take only one of them.

For this case we are going to take as an example a credit card customer dataset, adaptation of the \href{https://www.kaggle.com/arjunbhasin2013/ccdata}{public dataset in Kaggle}, from the following route.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/credit{-}cards.csv"}

\NormalTok{cards\_df }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url)}
\CommentTok{\#\textgreater{} Rows: 8636 Columns: 13}
\CommentTok{\#\textgreater{} {-}{-} Column specification {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Delimiter: ","}
\CommentTok{\#\textgreater{} dbl (13): balance, balance\_frequency, purchases, purchases\_first\_3\_months, f...}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} i Use \textasciigrave{}spec()\textasciigrave{} to retrieve the full column specification for this data.}
\CommentTok{\#\textgreater{} i Specify the column types or set \textasciigrave{}show\_col\_types = FALSE\textasciigrave{} to quiet this message.}
\end{Highlighting}
\end{Shaded}

We have more than 8 thousand customers with 13 attributes. We will analyze if there are strongly correlated variables. To do this we will use the \texttt{corrplot} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(corrplot)}
\end{Highlighting}
\end{Shaded}

Next, we will enter the dataset to visualize correlations between the variables,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{corrplot}\NormalTok{(}\FunctionTok{cor}\NormalTok{(cards\_df), }\AttributeTok{type=}\StringTok{"upper"}\NormalTok{, }\AttributeTok{method=}\StringTok{"ellipse"}\NormalTok{, }\AttributeTok{tl.cex=}\FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

There is a strong correlation between the total purchases variable and the purchases made in the first 3 months. We can visualize these two variables to validate.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cards\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{purchases, }\AttributeTok{y=}\NormalTok{purchases\_first\_3\_months) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title=}\StringTok{"Customer Attributes"}\NormalTok{,}
       \AttributeTok{subtitle=}\StringTok{"Relationship between total purchases and first 3 months"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Given this, we could include within our analysis only one of these two variables.

We could also validate the distribution of these variables.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We remove the purchases first 3 months variable}
\NormalTok{cards\_df }\OtherTok{\textless{}{-}}\NormalTok{ cards\_df[, }\SpecialCharTok{!}\FunctionTok{names}\NormalTok{(cards\_df) }\SpecialCharTok{==} \StringTok{"purchases\_first\_3\_months"}\NormalTok{]}

\NormalTok{cards\_df }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{everything}\NormalTok{(), }\AttributeTok{names\_to =} \StringTok{"attributes"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"values"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{values, }\AttributeTok{fill=}\NormalTok{attributes) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{colour=}\StringTok{"black"}\NormalTok{, }\AttributeTok{show.legend=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{attributes, }\AttributeTok{scales=}\StringTok{"free\_x"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{"Values"}\NormalTok{, }\AttributeTok{y=}\StringTok{"Frequency"}\NormalTok{,}
       \AttributeTok{title=}\StringTok{"Customer Attributes {-} Histogram"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We see data concentrations in some variables such as tenure (time our customer has been with us). We can validate it by zooming into that variable.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(cards\_df}\SpecialCharTok{$}\NormalTok{tenure)}

\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(cards\_df}\SpecialCharTok{$}\NormalTok{tenure))}
\end{Highlighting}
\end{Shaded}

85\% of our data are from customers who have been with us for 12 months. We could choose to filter the data to analyze customers who have 1 year and thus remove this variable from the grouping.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cards\_df }\OtherTok{\textless{}{-}}\NormalTok{ cards\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(tenure }\SpecialCharTok{==} \DecValTok{12}\NormalTok{)}

\NormalTok{cards\_df }\OtherTok{\textless{}{-}}\NormalTok{ cards\_df[, }\SpecialCharTok{!}\FunctionTok{names}\NormalTok{(cards\_df) }\SpecialCharTok{==} \StringTok{"tenure"}\NormalTok{]}

\CommentTok{\# We will do the same with the balance\_freq variable}
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(cards\_df}\SpecialCharTok{$}\NormalTok{balance\_freq))}

\NormalTok{cards\_df }\OtherTok{\textless{}{-}}\NormalTok{ cards\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(balance\_freq }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}

\NormalTok{cards\_df }\OtherTok{\textless{}{-}}\NormalTok{ cards\_df[, }\SpecialCharTok{!}\FunctionTok{names}\NormalTok{(cards\_df) }\SpecialCharTok{==} \StringTok{"balance\_freq"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

If we also analyze the distributions of each variable we find the following:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(cards\_df)}
\end{Highlighting}
\end{Shaded}

We see that there are variables that have maximums of 1, as there are others that have a maximum of 30 thousand or 50 thousand. We had already seen previously the importance of normalizing data. Here we will also do it with the \texttt{scale()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cards\_df\_norm }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{scale}\NormalTok{(cards\_df))}
\end{Highlighting}
\end{Shaded}

We can verify that the distribution does not change, only the scale.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cards\_df\_norm }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{everything}\NormalTok{(), }\AttributeTok{names\_to =} \StringTok{"attributes"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"values"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{values, }\AttributeTok{fill=}\NormalTok{attributes) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{colour=}\StringTok{"black"}\NormalTok{, }\AttributeTok{show.legend=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{attributes, }\AttributeTok{scales=}\StringTok{"free\_x"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{"Values"}\NormalTok{, }\AttributeTok{y=}\StringTok{"Frequency"}\NormalTok{,}
       \AttributeTok{title=}\StringTok{"Customer Attributes {-} Histogram"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Data preparation and variable reduction is a necessary step when we create machine learning models. However, we must do it carefully, given that in this exercise when preparing the data, although we have fewer variables (10), we also have fewer rows.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(cards\_df\_norm)}
\end{Highlighting}
\end{Shaded}

More advanced techniques such as \href{https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch18.pdf}{Principal Component Analysis} (PCA) and \href{https://math.mit.edu/classes/18.095/2016IAP/lec2/SVD_Notes.pdf}{Singular Value Decomposition} (SVD) are used to perform dimensionality reduction more rigorously so as not to lose so much data in our analysis. These techniques are widely used in practice and well-documented, though they require a solid understanding of linear algebra for proper interpretation.

\section{Exercises}\label{exercises-18}

In the following exercises we will work on post data from 10 fashion companies that have their pages on Facebook and the reactions of their followers. To do this, we will work with the data in the following repository:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"http://archive.ics.uci.edu/ml/machine{-}learning{-}databases/00488/Live.csv"}
\NormalTok{posts }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url)}

\CommentTok{\# We remove columns not relevant to the analysis}
\NormalTok{irrelevant\_columns }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"status\_type"}\NormalTok{,}\StringTok{"status\_id"}\NormalTok{, }\StringTok{"status\_published"}\NormalTok{, }\StringTok{"Column1"}\NormalTok{,}
                            \StringTok{"Column2"}\NormalTok{, }\StringTok{"Column3"}\NormalTok{, }\StringTok{"Column4"}\NormalTok{)}

\NormalTok{data\_posts }\OtherTok{\textless{}{-}}\NormalTok{ posts[, }\SpecialCharTok{!}\FunctionTok{names}\NormalTok{(posts) }\SpecialCharTok{\%in\%}\NormalTok{ irrelevant\_columns]}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{104}
\tightlist
\item
  With the \texttt{data\_posts} object normalized (use \texttt{scale()} function) and create the \texttt{data\_posts\_norm} object. Build a silhouette plot to determine how many cluster groups are recommended using the \textbf{k-means} algorithm.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_posts\_norm }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{scale}\NormalTok{(data\_posts))}

\FunctionTok{fviz\_nbclust}\NormalTok{(data\_posts\_norm, }\AttributeTok{FUN =}\NormalTok{ kmeans, }\AttributeTok{method =} \StringTok{"silhouette"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{105}
\tightlist
\item
  With the \texttt{data\_posts} object build a silhouette plot to determine how many cluster groups are recommended using the \textbf{hierarchical} algorithm.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fviz\_nbclust}\NormalTok{(data\_posts, }\AttributeTok{FUN =}\NormalTok{ hcut, }\AttributeTok{method =} \StringTok{"silhouette"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{106}
\tightlist
\item
  If you had to remove a variable from the analysis, which variable would it be?
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We perform a visualization of the correlation of variables}
\FunctionTok{corrplot}\NormalTok{(}\FunctionTok{cor}\NormalTok{(data\_posts), }\AttributeTok{type=}\StringTok{"upper"}\NormalTok{, }\AttributeTok{method=}\StringTok{"ellipse"}\NormalTok{, }\AttributeTok{tl.cex=}\FloatTok{0.9}\NormalTok{)}

\CommentTok{\# We can check it by plotting these two variables:}
\NormalTok{data\_posts }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{num\_reactions, }\AttributeTok{y=}\NormalTok{num\_likes) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{107}
\tightlist
\item
  Remove the \texttt{num\_reactions} variable from the \texttt{data\_posts\_norm} object and the \texttt{data\_posts} object and perform a silhouette analysis again using \texttt{data\_posts\_norm}. Does the number of clusters change?
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_posts }\OtherTok{\textless{}{-}}\NormalTok{ data\_posts[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]}
\NormalTok{data\_posts\_norm }\OtherTok{\textless{}{-}}\NormalTok{ data\_posts\_norm[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]}

\FunctionTok{fviz\_nbclust}\NormalTok{(data\_posts\_norm, }\AttributeTok{FUN =}\NormalTok{ kmeans, }\AttributeTok{method =} \StringTok{"silhouette"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The number of clusters does not change because there exists another variable with the same behavior as this one.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{108}
\tightlist
\item
  Create the k-means model to group using the recommended number of clusters found. Use the \texttt{data\_posts\_norm} object for the creation of the model. Create the \texttt{data\_posts\_grouped} object where the original data of \texttt{data\_posts} is with the additional column \texttt{cluster\_kmeans} indicating the cluster result of this model.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans\_model }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(data\_posts\_norm, }\AttributeTok{centers =} \DecValTok{2}\NormalTok{)}

\NormalTok{data\_posts\_grouped }\OtherTok{\textless{}{-}}\NormalTok{ data\_posts }\SpecialCharTok{|\textgreater{}} 
                        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster\_kmeans =}\NormalTok{ kmeans\_model}\SpecialCharTok{$}\NormalTok{cluster)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{109}
\tightlist
\item
  Create the hierarchical model to group using the recommended number of clusters found. Use the \texttt{data\_posts\_norm} object for the creation of the model. Add to the \texttt{data\_posts\_grouped} object the column \texttt{cluster\_hier} to store the result of the grouping.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distances }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(data\_posts\_norm)}
\NormalTok{hier\_model }\OtherTok{\textless{}{-}} \FunctionTok{hclust}\NormalTok{(distances)}

\NormalTok{data\_posts\_grouped }\OtherTok{\textless{}{-}}\NormalTok{ data\_posts\_grouped }\SpecialCharTok{|\textgreater{}} 
                        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster\_hier =} \FunctionTok{cutree}\NormalTok{(hier\_model, }\AttributeTok{k =} \DecValTok{2}\NormalTok{)}
\NormalTok{                               )}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{110}
\tightlist
\item
  Calculate the average of each value of the variables for each group of the k-means model.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_posts\_grouped }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cluster\_hier) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(cluster\_kmeans) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarise\_all}\NormalTok{(}\FunctionTok{list}\NormalTok{(mean))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{111}
\tightlist
\item
  Calculate the average of each value of the variables for each group of the hierarchical model.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_posts\_grouped }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cluster\_kmeans) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(cluster\_hier) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarise\_all}\NormalTok{(}\FunctionTok{list}\NormalTok{(mean))}
\end{Highlighting}
\end{Shaded}

\chapter{String processing and text mining}\label{string-processing-and-text-mining}

\section{Basic functions}\label{basic-functions}

We have already learned how to import data and consolidate it. However, we cannot yet work with this data. We have to validate through string processing and ensure a minimum quality to be able to perform our analyses.

For example, in the previous chapter we imported data from Wikipedia, however we did not focus on whether we could already perform operations or visualizations with our data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rvest)}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://es.wikipedia.org/wiki/Anexo:Pa\%C3\%ADses\_hispanos\_por\_poblaci\%C3\%B3n"}
\CommentTok{\#url \textless{}{-} "https://es.wikipedia.org/wiki/Distribuci\%C3\%B3n\_geogr\%C3\%A1fica\_del\_idioma\_espa\%C3\%B1ol" \#as a back up URL}
\NormalTok{html\_data }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(url)}

\NormalTok{web\_tables }\OtherTok{\textless{}{-}}\NormalTok{ html\_data }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{html\_nodes}\NormalTok{(}\StringTok{"body"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{html\_nodes}\NormalTok{(}\StringTok{"table"}\NormalTok{)}

\NormalTok{raw\_table }\OtherTok{\textless{}{-}}\NormalTok{ web\_tables[[}\DecValTok{2}\NormalTok{]] }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{html\_table}\NormalTok{()}

\NormalTok{raw\_table }\OtherTok{\textless{}{-}}\NormalTok{ raw\_table }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{setNames}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"N"}\NormalTok{, }\StringTok{"country"}\NormalTok{, }\StringTok{"population"}\NormalTok{, }\StringTok{"prop\_population"}\NormalTok{, }\StringTok{"avg\_change"}\NormalTok{, }\StringTok{"link"}\NormalTok{)) }

\NormalTok{raw\_table }\OtherTok{\textless{}{-}}\NormalTok{ raw\_table }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{as\_tibble}\NormalTok{()}

\NormalTok{raw\_table }\SpecialCharTok{|\textgreater{}} \FunctionTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We may not have noticed, but we can observe columns with spaces or commas where there should be numbers. We can validate this not only by analyzing the class of the column, but also if we try to calculate the average of that variable.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(raw\_table}\SpecialCharTok{$}\NormalTok{population)}

\FunctionTok{mean}\NormalTok{(raw\_table}\SpecialCharTok{$}\NormalTok{population)}
\end{Highlighting}
\end{Shaded}

We cannot do a direct conversion to number either because white spaces and commas are characters.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{as.numeric}\NormalTok{(raw\_table}\SpecialCharTok{$}\NormalTok{population)}
\end{Highlighting}
\end{Shaded}

There are so frequent and so many possible use cases that there are already multiple functions for processing strings included in the tidyverse library. Likewise, there is more than one way to process strings. It will always depend on how the raw data is found.

\subsection{Replacing characters}\label{replacing-characters}

One of the basic functions that we will use the most will be replacing characters. We apply this function when we are sure that this change will not compromise the rest of the data. We have spaces and we have commas. So we could start by replacing one of the two to normalize them using the \texttt{str\_replace\_all(string,\ pattern,\ replacement)} function. In the pattern attribute we will use \texttt{\textbackslash{}\textbackslash{}s}, which comes from \texttt{space}. We are going to learn first to modify the data stored in a vector and then we will replicate it to our entire table.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(stringr)}

\NormalTok{population\_vector }\OtherTok{\textless{}{-}}\NormalTok{ raw\_table}\SpecialCharTok{$}\NormalTok{population}

\NormalTok{population\_vector }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(population\_vector, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s"}\NormalTok{, }\StringTok{","}\NormalTok{)}

\NormalTok{population\_vector}
\end{Highlighting}
\end{Shaded}

We have purposely taken all the values to be separated by commas because now we can easily use the \texttt{parse\_number(vector)} function which not only replaces the commas with empty strings, but also removes any non-numeric value before the first number, which facilitates us if we had monetary values, and also converts the value from character type to numeric type.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{population\_vector }\OtherTok{\textless{}{-}} \FunctionTok{parse\_number}\NormalTok{(population\_vector)}

\CommentTok{\# Additional example in case we had a monetary value:}
\FunctionTok{parse\_number}\NormalTok{(}\StringTok{"$345,153"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This vector now allows us to perform mathematical operations or visualization of the distribution.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Convert to millions}
\NormalTok{population\_vector }\OtherTok{\textless{}{-}}\NormalTok{ population\_vector}\SpecialCharTok{/}\DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{6}

\CommentTok{\# We remove the last value which is the world population:}
\NormalTok{length\_val }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(population\_vector)}
\NormalTok{population\_vector }\OtherTok{\textless{}{-}}\NormalTok{ population\_vector[}\SpecialCharTok{{-}}\NormalTok{length\_val]}

\CommentTok{\# Visualization}
\FunctionTok{boxplot}\NormalTok{(population\_vector)}
\end{Highlighting}
\end{Shaded}

We already know which functions to use to transform the fields of our case. However, we have applied them to vectors. To mutate the columns of our table in raw form we will use the function \texttt{mutate(across(columns,\ function))} using the pipeline operator \texttt{\textbar{}\textgreater{}}. Let's apply the first change of spaces by commas and not only to column 3, population, but also to column 5, average change.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{raw\_table }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_replace\_all}\NormalTok{(., }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s"}\NormalTok{, }\StringTok{","}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

We have removed from the \texttt{str\_replace\_all} function the \texttt{string} attribute and replaced it with a dot \texttt{.}. And that dot \texttt{.} indicates that it will evaluate for each column \texttt{c(3,5)} of our table.

Now, let's apply the parse\_number function that we applied previously.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{raw\_table }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_replace\_all}\NormalTok{(., }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s"}\NormalTok{, }\StringTok{","}\NormalTok{))) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{parse\_number}\NormalTok{(.)))}
\end{Highlighting}
\end{Shaded}

\section{Regular expressions}\label{regular-expressions}

A \href{https://stringr.tidyverse.org/articles/regular-expressions.html}{regular expression}\footnote{\url{https://stringr.tidyverse.org/articles/regular-expressions.html}} (or regex as it is known in English) is a pattern that describes a set of strings. We have already used regex in the previous section using only the pattern \texttt{\textbackslash{}\textbackslash{}s}. However, usually we will have many more use cases that will require a pattern that can convert a wider range of cases.

Although we could analyze all possible use cases available in the documentation, we learn faster by use cases. Let's analyze a case that will allow us to learn some patterns little by little.

In the \texttt{dslabs} library we found and used previously the height data, \texttt{heights}, of students from a university expressed in inches.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dslabs)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{data}\NormalTok{(heights)}

\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}       sex height}
\CommentTok{\#\textgreater{} 1    Male     75}
\CommentTok{\#\textgreater{} 2    Male     70}
\CommentTok{\#\textgreater{} 3    Male     68}
\CommentTok{\#\textgreater{} 4    Male     74}
\CommentTok{\#\textgreater{} 5    Male     61}
\CommentTok{\#\textgreater{} 6  Female     65}
\CommentTok{\#\textgreater{} 7  Female     66}
\CommentTok{\#\textgreater{} 8  Female     62}
\CommentTok{\#\textgreater{} 9  Female     66}
\CommentTok{\#\textgreater{} 10   Male     67}
\end{Highlighting}
\end{Shaded}

These data were ready to be analyzed. However, that was not how it came from the source. The students had to fill out a survey and even when they were asked for their height in inches, they completed their height in inches, feet, centimeters, writing numbers, letters, etc. We can see the initial data from the form in the \texttt{reported\_heights} data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reported\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}             time\_stamp    sex height}
\CommentTok{\#\textgreater{} 1  2014{-}09{-}02 13:40:36   Male     75}
\CommentTok{\#\textgreater{} 2  2014{-}09{-}02 13:46:59   Male     70}
\CommentTok{\#\textgreater{} 3  2014{-}09{-}02 13:59:20   Male     68}
\CommentTok{\#\textgreater{} 4  2014{-}09{-}02 14:51:53   Male     74}
\CommentTok{\#\textgreater{} 5  2014{-}09{-}02 15:16:15   Male     61}
\CommentTok{\#\textgreater{} 6  2014{-}09{-}02 15:16:16 Female     65}
\CommentTok{\#\textgreater{} 7  2014{-}09{-}02 15:16:19 Female     66}
\CommentTok{\#\textgreater{} 8  2014{-}09{-}02 15:16:21 Female     62}
\CommentTok{\#\textgreater{} 9  2014{-}09{-}02 15:16:21 Female     66}
\CommentTok{\#\textgreater{} 10 2014{-}09{-}02 15:16:22   Male     67}
\end{Highlighting}
\end{Shaded}

Although we might think that they entered the data correctly, we do not have to trust and it is always better to validate the quality of our data. There are multiple ways to validate, as we can see below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\OtherTok{\textless{}{-}}\NormalTok{ reported\_heights}\SpecialCharTok{$}\NormalTok{height}

\CommentTok{\# Validation option 1: Random sample}
\FunctionTok{sample}\NormalTok{(heights, }\DecValTok{100}\NormalTok{)}
\CommentTok{\#\textgreater{}   [1] "71"       "67"       "66"       "64"       "70"       "70"      }
\CommentTok{\#\textgreater{}   [7] "76"       "1"        "59"       "67.2"     "69"       "67"      }
\CommentTok{\#\textgreater{}  [13] "67"       "6"        "62"       "69"       "74"       "69"      }
\CommentTok{\#\textgreater{}  [19] "178"      "69"       "74"       "169"      "67"       "68.5"    }
\CommentTok{\#\textgreater{}  [25] "68.5"     "71"       "68"       "158"      "6.1"      "708,661" }
\CommentTok{\#\textgreater{}  [31] "6.2"      "69"       "75"       "5\textquotesingle{}6"      "67"       "68.4"    }
\CommentTok{\#\textgreater{}  [37] "75"       "5.7"      "72"       "77"       "75"       "68"      }
\CommentTok{\#\textgreater{}  [43] "69"       "72"       "62"       "65"       "73"       "67"      }
\CommentTok{\#\textgreater{}  [49] "67"       "5.2"      "67.71"    "67"       "5\textquotesingle{}3"      "66"      }
\CommentTok{\#\textgreater{}  [55] "5\textquotesingle{}7.5\textquotesingle{}\textquotesingle{}"  "69"       "65"       "150"      "69"       "5\textquotesingle{}11\textquotesingle{}\textquotesingle{}"  }
\CommentTok{\#\textgreater{}  [61] "68.11024" "175"      "152"      "5\textquotesingle{} 10"    "65"       "74.5"    }
\CommentTok{\#\textgreater{}  [67] "70"       "72"       "73.22"    "63"       "5\textquotesingle{}9\textquotesingle{}\textquotesingle{}"    "68.5"    }
\CommentTok{\#\textgreater{}  [73] "74"       "74"       "5\textquotesingle{}7\textbackslash{}""    "6\textquotesingle{}3\textbackslash{}""    "67"       "73.22"   }
\CommentTok{\#\textgreater{}  [79] "74"       "72.8346"  "67.72"    "175"      "5.69"     "69.3"    }
\CommentTok{\#\textgreater{}  [85] "5\textquotesingle{}10\textquotesingle{}\textquotesingle{}"   "72"       "60"       "68"       "69"       "73"      }
\CommentTok{\#\textgreater{}  [91] "75"       "70"       "64"       "170"      "649,606"  "73"      }
\CommentTok{\#\textgreater{}  [97] "58"       "60"       "174"      "64.173"}

\CommentTok{\# Validation option 2: convert to numbers and count if there are NAs}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(heights)}
\CommentTok{\#\textgreater{} Warning: NAs introduced by coercion}
\FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(x))}
\CommentTok{\#\textgreater{} [1] 81}

\CommentTok{\# Validation option 3: add column of those that cannot be converted to number:}
\NormalTok{reported\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{numeric\_height =} \FunctionTok{as.numeric}\NormalTok{(height)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(numeric\_height)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning: There was 1 warning in \textasciigrave{}mutate()\textasciigrave{}.}
\CommentTok{\#\textgreater{} i In argument: \textasciigrave{}numeric\_height =}
\CommentTok{\#\textgreater{}   as.numeric(height)\textasciigrave{}.}
\CommentTok{\#\textgreater{} Caused by warning:}
\CommentTok{\#\textgreater{} ! NAs introduced by coercion}
\CommentTok{\#\textgreater{}             time\_stamp    sex                 height numeric\_height}
\CommentTok{\#\textgreater{} 1  2014{-}09{-}02 15:16:28   Male                  5\textquotesingle{} 4"             NA}
\CommentTok{\#\textgreater{} 2  2014{-}09{-}02 15:16:37 Female                  165cm             NA}
\CommentTok{\#\textgreater{} 3  2014{-}09{-}02 15:16:52   Male                    5\textquotesingle{}7             NA}
\CommentTok{\#\textgreater{} 4  2014{-}09{-}02 15:16:56   Male                  \textgreater{}9000             NA}
\CommentTok{\#\textgreater{} 5  2014{-}09{-}02 15:16:56   Male                   5\textquotesingle{}7"             NA}
\CommentTok{\#\textgreater{} 6  2014{-}09{-}02 15:17:09 Female                   5\textquotesingle{}3"             NA}
\CommentTok{\#\textgreater{} 7  2014{-}09{-}02 15:18:00   Male 5 feet and 8.11 inches             NA}
\CommentTok{\#\textgreater{} 8  2014{-}09{-}02 15:19:48   Male                   5\textquotesingle{}11             NA}
\CommentTok{\#\textgreater{} 9  2014{-}09{-}04 00:46:45   Male                  5\textquotesingle{}9\textquotesingle{}\textquotesingle{}             NA}
\CommentTok{\#\textgreater{} 10 2014{-}09{-}04 10:29:44   Male                 5\textquotesingle{}10\textquotesingle{}\textquotesingle{}             NA}
\end{Highlighting}
\end{Shaded}

We might want to choose to eliminate these NA data as they are not significant with respect to the total of 1,095 data points. However, there are several of these data points that follow a determined pattern and instead of being discarded could be converted to the scale we have in the rest of the data. For example, there are people who entered their height as 5'7'', which, for those who remember the conversion, can be converted because 1 foot is 12 inches. So \(5*12+7=67\). And so, like that case, we can detect patterns, but we have, again, to be careful in detecting the exact pattern and not a very generic one that can change other use cases. If everyone followed the same pattern \(x'y''\) or \(x'y\) it would be much easier to convert it to inches by calculating \(x*12+y\).

Let's start by extracting our column to a single character vector with all the values that do not convert automatically to number or were entered in inches. We detect this if they measure more than 5 and up to 7 feet (from 1.5m to 2.1 meters). After that we will create the transformations little by little.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}}\NormalTok{ reported\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(height)) }\SpecialCharTok{|} \CommentTok{\# Does not convert to number}
\NormalTok{         (}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(height)) }\SpecialCharTok{\&} \FunctionTok{as.numeric}\NormalTok{(height) }\SpecialCharTok{\textgreater{}=} \DecValTok{5} \SpecialCharTok{\&}
            \FunctionTok{as.numeric}\NormalTok{(height) }\SpecialCharTok{\textless{}=} \DecValTok{7}\NormalTok{ ) }\CommentTok{\# or entered in feet and not inches}
\NormalTok{        ) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(height)}

\FunctionTok{length}\NormalTok{(problematic\_heights)}
\CommentTok{\#\textgreater{} [1] 168}
\end{Highlighting}
\end{Shaded}

Adding the condition of having entered in feet we have 168 errors. We cannot ignore 15.3\% of errors.

We will use \texttt{str\_view()} to visualize matches. This function is extremely helpful when debugging regular expressions as it highlights exactly what is matching your pattern.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Let\textquotesingle{}s visualize entries containing "feet"}
\FunctionTok{str\_view}\NormalTok{(problematic\_heights, }\StringTok{"feet"}\NormalTok{, }\AttributeTok{match=}\ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{}  [10] | 5 \textless{}feet\textgreater{} and 8.11 inches}
\CommentTok{\#\textgreater{}  [82] | 5 \textless{}feet\textgreater{} 7inches}
\CommentTok{\#\textgreater{} [140] | 5 \textless{}feet\textgreater{} 6 inches}
\end{Highlighting}
\end{Shaded}

We can also use \texttt{str\_detect(string,\ pattern)} to get a logical value (\texttt{TRUE}/\texttt{FALSE}) to filter our vector.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(problematic\_heights, }\StringTok{"feet"}\NormalTok{)}

\NormalTok{problematic\_heights[index] }\CommentTok{\# Match the pattern}
\CommentTok{\#\textgreater{} [1] "5 feet and 8.11 inches" "5 feet 7inches"         "5 feet 6 inches"}
\NormalTok{problematic\_heights[}\SpecialCharTok{!}\NormalTok{index] }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Do not match the pattern}
  \FunctionTok{head}\NormalTok{(}\DecValTok{40}\NormalTok{) }
\CommentTok{\#\textgreater{}  [1] "6"                      "5\textquotesingle{} 4\textbackslash{}""                 "5.3"                   }
\CommentTok{\#\textgreater{}  [4] "165cm"                  "6"                      "5\textquotesingle{}7"                   }
\CommentTok{\#\textgreater{}  [7] "\textgreater{}9000"                  "5\textquotesingle{}7\textbackslash{}""                  "5\textquotesingle{}3\textbackslash{}""                 }
\CommentTok{\#\textgreater{} [10] "5.25"                   "5\textquotesingle{}11"                   "5.5"                   }
\CommentTok{\#\textgreater{} [13] "5\textquotesingle{}9\textquotesingle{}\textquotesingle{}"                  "6"                      "6.5"                   }
\CommentTok{\#\textgreater{} [16] "5\textquotesingle{}10\textquotesingle{}\textquotesingle{}"                 "5.8"                    "5"                     }
\CommentTok{\#\textgreater{} [19] "5.6"                    "5,3"                    "6\textquotesingle{}"                    }
\CommentTok{\#\textgreater{} [22] "6"                      "5.9"                    "6,8"                   }
\CommentTok{\#\textgreater{} [25] "5\textquotesingle{} 10"                  "5.5"                    "6.2"                   }
\CommentTok{\#\textgreater{} [28] "Five foot eight inches" "6.2"                    "5.8"                   }
\CommentTok{\#\textgreater{} [31] "5.1"                    "5.11"                   "5\textquotesingle{}5\textbackslash{}""                 }
\CommentTok{\#\textgreater{} [34] "5\textquotesingle{}2\textbackslash{}""                  "5.75"                   "5,4"                   }
\CommentTok{\#\textgreater{} [37] "7"                      "5.4"                    "6.1"                   }
\CommentTok{\#\textgreater{} [40] "5\textquotesingle{}3"}
\end{Highlighting}
\end{Shaded}

\subsection{Alternation}\label{alternation}

\texttt{\textbar{}} is the alternation operator that will choose between one or more possible values. In our case, we have indicated to detect if there is the word ``feet'', but we also have ``ft'' and ``foot'' to refer to the same thing in our data. Thus, we can create the pattern ``feet'' or ``ft'' or ``foot''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Visualize the matches}
\FunctionTok{str\_view}\NormalTok{(problematic\_heights, }\StringTok{"feet|ft|foot"}\NormalTok{, }\AttributeTok{match=}\ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{}  [10] | 5 \textless{}feet\textgreater{} and 8.11 inches}
\CommentTok{\#\textgreater{}  [29] | Five \textless{}foot\textgreater{} eight inches}
\CommentTok{\#\textgreater{}  [82] | 5 \textless{}feet\textgreater{} 7inches}
\CommentTok{\#\textgreater{} [124] | 5\textless{}ft\textgreater{} 9 inches}
\CommentTok{\#\textgreater{} [125] | 5 \textless{}ft\textgreater{} 9 inches}
\CommentTok{\#\textgreater{} [140] | 5 \textless{}feet\textgreater{} 6 inches}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(problematic\_heights, }\StringTok{"feet|ft|foot"}\NormalTok{)}
\NormalTok{problematic\_heights[index] }\CommentTok{\# Match}
\CommentTok{\#\textgreater{} [1] "5 feet and 8.11 inches" "Five foot eight inches" "5 feet 7inches"        }
\CommentTok{\#\textgreater{} [4] "5ft 9 inches"           "5 ft 9 inches"          "5 feet 6 inches"}
\end{Highlighting}
\end{Shaded}

In the same way we can find the variations for inches and other symbols that we can remove:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(problematic\_heights, }\StringTok{"inches|in|\textquotesingle{}\textquotesingle{}|}\SpecialCharTok{\textbackslash{}"}\StringTok{|cm|and"}\NormalTok{)}
\NormalTok{problematic\_heights[index] }\CommentTok{\# Match}
\CommentTok{\#\textgreater{}  [1] "5\textquotesingle{} 4\textbackslash{}""                 "165cm"                  "5\textquotesingle{}7\textbackslash{}""                 }
\CommentTok{\#\textgreater{}  [4] "5\textquotesingle{}3\textbackslash{}""                  "5 feet and 8.11 inches" "5\textquotesingle{}9\textquotesingle{}\textquotesingle{}"                 }
\CommentTok{\#\textgreater{}  [7] "5\textquotesingle{}10\textquotesingle{}\textquotesingle{}"                 "Five foot eight inches" "5\textquotesingle{}5\textbackslash{}""                 }
\CommentTok{\#\textgreater{} [10] "5\textquotesingle{}2\textbackslash{}""                  "5\textquotesingle{}10\textquotesingle{}\textquotesingle{}"                 "5\textquotesingle{}3\textquotesingle{}\textquotesingle{}"                 }
\CommentTok{\#\textgreater{} [13] "5\textquotesingle{}7\textquotesingle{}\textquotesingle{}"                  "5\textquotesingle{}3\textbackslash{}""                  "5\textquotesingle{}6\textquotesingle{}\textquotesingle{}"                 }
\CommentTok{\#\textgreater{} [16] "5\textquotesingle{}7.5\textquotesingle{}\textquotesingle{}"                "5\textquotesingle{}7.5\textquotesingle{}\textquotesingle{}"                "5\textquotesingle{}2\textbackslash{}""                 }
\CommentTok{\#\textgreater{} [19] "5\textquotesingle{} 7.78\textbackslash{}""              "5 feet 7inches"         "5\textquotesingle{}8\textbackslash{}""                 }
\CommentTok{\#\textgreater{} [22] "5\textquotesingle{}11\textbackslash{}""                 "5\textquotesingle{}7\textbackslash{}""                  "5\textquotesingle{} 11\textbackslash{}""               }
\CommentTok{\#\textgreater{} [25] "6\textquotesingle{}1\textbackslash{}""                  "69\textbackslash{}""                   "5\textquotesingle{} 7\textbackslash{}""                }
\CommentTok{\#\textgreater{} [28] "5\textquotesingle{}10\textquotesingle{}\textquotesingle{}"                 "5ft 9 inches"           "5 ft 9 inches"         }
\CommentTok{\#\textgreater{} [31] "5\textquotesingle{}11\textquotesingle{}\textquotesingle{}"                 "5\textquotesingle{}8\textbackslash{}""                  "5 feet 6 inches"       }
\CommentTok{\#\textgreater{} [34] "5\textquotesingle{}10\textquotesingle{}\textquotesingle{}"                 "6\textquotesingle{}3\textbackslash{}""                  "5\textquotesingle{}5\textquotesingle{}\textquotesingle{}"                 }
\CommentTok{\#\textgreater{} [37] "5\textquotesingle{}7\textbackslash{}""                  "6\textquotesingle{}4\textbackslash{}""                  "170 cm"}
\end{Highlighting}
\end{Shaded}

In this case we have entered \texttt{\textquotesingle{}\textquotesingle{}} to detect those who entered that symbol to denote inches and \texttt{\textbackslash{}"} in case they used double quotes. In this latter case we have used \texttt{\textbackslash{}} so that it does not generate an error when interpreting as closing the string.

We could already start replacing based on the detected patterns:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(problematic\_heights, }\StringTok{"feet|ft|foot"}\NormalTok{, }\StringTok{"\textquotesingle{}"}\NormalTok{)}
\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(problematic\_heights, }\StringTok{"inches|in|\textquotesingle{}\textquotesingle{}|}\SpecialCharTok{\textbackslash{}"}\StringTok{|cm|and"}\NormalTok{, }\StringTok{""}\NormalTok{)}

\NormalTok{problematic\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "6"             "5\textquotesingle{} 4"          "5.3"           "165"          }
\CommentTok{\#\textgreater{}  [5] "6"             "5\textquotesingle{}7"           "\textgreater{}9000"         "5\textquotesingle{}7"          }
\CommentTok{\#\textgreater{}  [9] "5\textquotesingle{}3"           "5 \textquotesingle{}  8.11 "    "5.25"          "5\textquotesingle{}11"         }
\CommentTok{\#\textgreater{} [13] "5.5"           "5\textquotesingle{}9"           "6"             "6.5"          }
\CommentTok{\#\textgreater{} [17] "5\textquotesingle{}10"          "5.8"           "5"             "5.6"          }
\CommentTok{\#\textgreater{} [21] "5,3"           "6\textquotesingle{}"            "6"             "5.9"          }
\CommentTok{\#\textgreater{} [25] "6,8"           "5\textquotesingle{} 10"         "5.5"           "6.2"          }
\CommentTok{\#\textgreater{} [29] "Five \textquotesingle{} eight " "6.2"}
\end{Highlighting}
\end{Shaded}

As an additional effort, we could also look to solve that some people have written words instead of numbers. For this we create a function that replaces each word with a number and apply it to the vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{words\_to\_number }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(s)\{}
  \FunctionTok{str\_to\_lower}\NormalTok{(s) }\SpecialCharTok{|\textgreater{}}  
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"zero"}\NormalTok{, }\StringTok{"0"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"one"}\NormalTok{, }\StringTok{"1"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"two"}\NormalTok{, }\StringTok{"2"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"three"}\NormalTok{, }\StringTok{"3"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"four"}\NormalTok{, }\StringTok{"4"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"five"}\NormalTok{, }\StringTok{"5"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"six"}\NormalTok{, }\StringTok{"6"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"seven"}\NormalTok{, }\StringTok{"7"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"eight"}\NormalTok{, }\StringTok{"8"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"nine"}\NormalTok{, }\StringTok{"9"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"ten"}\NormalTok{, }\StringTok{"10"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"eleven"}\NormalTok{, }\StringTok{"11"}\NormalTok{)}
\NormalTok{\}}

\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{words\_to\_number}\NormalTok{(problematic\_heights)}
\NormalTok{problematic\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "6"          "5\textquotesingle{} 4"       "5.3"        "165"        "6"         }
\CommentTok{\#\textgreater{}  [6] "5\textquotesingle{}7"        "\textgreater{}9000"      "5\textquotesingle{}7"        "5\textquotesingle{}3"        "5 \textquotesingle{}  8.11 "}
\CommentTok{\#\textgreater{} [11] "5.25"       "5\textquotesingle{}11"       "5.5"        "5\textquotesingle{}9"        "6"         }
\CommentTok{\#\textgreater{} [16] "6.5"        "5\textquotesingle{}10"       "5.8"        "5"          "5.6"       }
\CommentTok{\#\textgreater{} [21] "5,3"        "6\textquotesingle{}"         "6"          "5.9"        "6,8"       }
\CommentTok{\#\textgreater{} [26] "5\textquotesingle{} 10"      "5.5"        "6.2"        "5 \textquotesingle{} 8 "     "6.2"}
\end{Highlighting}
\end{Shaded}

\subsection{Anchoring}\label{anchoring}

Now that it is more standardized we can start with regex with more generic characteristics. For example, there is a person who has entered \texttt{6\textquotesingle{}}. It would be convenient to have everything in the form feet plus inches. With which we should have \texttt{6\textquotesingle{}0}. To achieve this we have to create a regex according to this generic situation. We will use the symbol \texttt{\^{}} to anchor our validation to ``start with'' and the symbol \texttt{\$} to match with the end of the string. Before replacing, let's first see who matches.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str\_view}\NormalTok{(problematic\_heights, }\StringTok{"\^{}6\textquotesingle{}$"}\NormalTok{, }\AttributeTok{match=}\ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} [22] | \textless{}6\textquotesingle{}\textgreater{}}
\end{Highlighting}
\end{Shaded}

This regex indicates that it starts with \texttt{6\textquotesingle{}} and that the expression ends there. We could still make it more generic to address those who, in the future, write 5 inches (1.52m) or 6 inches (1.82m). For this we will use brackets and inside them we will put all the values that we will accept.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(problematic\_heights, }\StringTok{"\^{}[56]\textquotesingle{}$"}\NormalTok{)}
\NormalTok{problematic\_heights[index] }\CommentTok{\# Match}
\CommentTok{\#\textgreater{} [1] "6\textquotesingle{}"}
\end{Highlighting}
\end{Shaded}

There is still only one result, but our regex is more generic now and we can already use it to replace. Before replacing in our vector we are going to do a test to learn how to create what we need from a pattern.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_vec }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"5\textquotesingle{}"}\NormalTok{, }\StringTok{"6\textquotesingle{}"}\NormalTok{)}

\FunctionTok{str\_replace\_all}\NormalTok{(test\_vec, }\StringTok{"\^{}([56])\textquotesingle{}$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}0"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] "5\textquotesingle{}0" "6\textquotesingle{}0"}
\end{Highlighting}
\end{Shaded}

We have placed between parentheses to indicate that what is inside is our first value and we use \texttt{\textbackslash{}\textbackslash{}1} to refer to that first value. So we are indicating to write the first value, then a quote \texttt{\textquotesingle{}}, and then a zero \texttt{0}.

Now we are ready to apply to our entire vector. We are going to make the change to consider not only 5 and 6, but up to the value of 7 inches (2.1m). Likewise, we are going to take the cases in which there is only a number without the foot symbol \texttt{\textquotesingle{}}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(problematic\_heights, }\StringTok{"\^{}([5{-}7])\textquotesingle{}$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}0"}\NormalTok{)}
\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(problematic\_heights, }\StringTok{"\^{}([5{-}7])$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}0"}\NormalTok{)}

\NormalTok{problematic\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "6\textquotesingle{}0"        "5\textquotesingle{} 4"       "5.3"        "165"        "6\textquotesingle{}0"       }
\CommentTok{\#\textgreater{}  [6] "5\textquotesingle{}7"        "\textgreater{}9000"      "5\textquotesingle{}7"        "5\textquotesingle{}3"        "5 \textquotesingle{}  8.11 "}
\CommentTok{\#\textgreater{} [11] "5.25"       "5\textquotesingle{}11"       "5.5"        "5\textquotesingle{}9"        "6\textquotesingle{}0"       }
\CommentTok{\#\textgreater{} [16] "6.5"        "5\textquotesingle{}10"       "5.8"        "5\textquotesingle{}0"        "5.6"       }
\CommentTok{\#\textgreater{} [21] "5,3"        "6\textquotesingle{}0"        "6\textquotesingle{}0"        "5.9"        "6,8"       }
\CommentTok{\#\textgreater{} [26] "5\textquotesingle{} 10"      "5.5"        "6.2"        "5 \textquotesingle{} 8 "     "6.2"}
\end{Highlighting}
\end{Shaded}

\subsection{Repetitions}\label{repetitions}

We can control how many times a pattern matches using repetition operators:

We can control how many times a pattern matches using repetition operators. The question mark \textbf{\texttt{?}} indicates that the preceding element matches \textbf{0 or 1} time (making it optional). The plus sign \textbf{\texttt{+}} requires \textbf{1 or more} matches, ensuring the element is present at least once. The asterisk \textbf{\texttt{*}} allows for \textbf{0 or more} matches, meaning the element can be absent or repeated indefinitely.

For example, to find all cases where instead of using the foot symbol \texttt{\textquotesingle{}} they entered a comma, a period, or a space we will use the following pattern:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pattern }\OtherTok{\textless{}{-}} \StringTok{"\^{}([4{-}7])}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*[,}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)$"}
\end{Highlighting}
\end{Shaded}

Let's read the pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The string starts with a digit ranging from 4 to 7.
\item
  \texttt{\textbackslash{}\textbackslash{}s} means that it is followed by a white space, but we use \texttt{*} to indicate that this character appears 0 or more times.
\item
  After that space we will look for any of the following characters: \texttt{,}, a period \texttt{\textbackslash{}\textbackslash{}.} (to which we put double backslash because the period alone in a pattern means ``any value'').
\item
  We use \texttt{\textbackslash{}\textbackslash{}s*} again to look for zero or more white spaces.
\item
  Finally we indicate that the string ends there with a digit, to denote that look for any digit we use \texttt{\textbackslash{}\textbackslash{}d}, d for digit. And we add asterisk so that it keeps one or more digits that it finds.
\end{enumerate}

In summary: it starts with a number, then symbols and then a digit. Between the symbols there could be white spaces. That is our pattern.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str\_view}\NormalTok{(problematic\_heights, pattern, }\AttributeTok{match=}\ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{}  [3] | \textless{}5.3\textgreater{}}
\CommentTok{\#\textgreater{} [11] | \textless{}5.25\textgreater{}}
\CommentTok{\#\textgreater{} [13] | \textless{}5.5\textgreater{}}
\CommentTok{\#\textgreater{} [16] | \textless{}6.5\textgreater{}}
\CommentTok{\#\textgreater{} [18] | \textless{}5.8\textgreater{}}
\CommentTok{\#\textgreater{} [20] | \textless{}5.6\textgreater{}}
\CommentTok{\#\textgreater{} [21] | \textless{}5,3\textgreater{}}
\CommentTok{\#\textgreater{} [24] | \textless{}5.9\textgreater{}}
\CommentTok{\#\textgreater{} [25] | \textless{}6,8\textgreater{}}
\CommentTok{\#\textgreater{} [27] | \textless{}5.5\textgreater{}}
\CommentTok{\#\textgreater{} [28] | \textless{}6.2\textgreater{}}
\CommentTok{\#\textgreater{} [30] | \textless{}6.2\textgreater{}}
\CommentTok{\#\textgreater{} [31] | \textless{}5.8\textgreater{}}
\CommentTok{\#\textgreater{} [32] | \textless{}5.1\textgreater{}}
\CommentTok{\#\textgreater{} [33] | \textless{}5.11\textgreater{}}
\CommentTok{\#\textgreater{} [36] | \textless{}5.75\textgreater{}}
\CommentTok{\#\textgreater{} [37] | \textless{}5,4\textgreater{}}
\CommentTok{\#\textgreater{} [39] | \textless{}5.4\textgreater{}}
\CommentTok{\#\textgreater{} [40] | \textless{}6.1\textgreater{}}
\CommentTok{\#\textgreater{} [42] | \textless{}5.6\textgreater{}}
\CommentTok{\#\textgreater{} ... and 48 more}
\end{Highlighting}
\end{Shaded}

We already found the values that match the pattern, so we are ready to replace.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(}
\NormalTok{                        problematic\_heights, }
                        \StringTok{"\^{}([4{-}7])}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*[,}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1.}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2\textquotesingle{}0"}
\NormalTok{                   )}

\NormalTok{problematic\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "6\textquotesingle{}0"        "5\textquotesingle{} 4"       "5.3\textquotesingle{}0"      "165"        "6\textquotesingle{}0"       }
\CommentTok{\#\textgreater{}  [6] "5\textquotesingle{}7"        "\textgreater{}9000"      "5\textquotesingle{}7"        "5\textquotesingle{}3"        "5 \textquotesingle{}  8.11 "}
\CommentTok{\#\textgreater{} [11] "5.25\textquotesingle{}0"     "5\textquotesingle{}11"       "5.5\textquotesingle{}0"      "5\textquotesingle{}9"        "6\textquotesingle{}0"       }
\CommentTok{\#\textgreater{} [16] "6.5\textquotesingle{}0"      "5\textquotesingle{}10"       "5.8\textquotesingle{}0"      "5\textquotesingle{}0"        "5.6\textquotesingle{}0"     }
\CommentTok{\#\textgreater{} [21] "5.3\textquotesingle{}0"      "6\textquotesingle{}0"        "6\textquotesingle{}0"        "5.9\textquotesingle{}0"      "6.8\textquotesingle{}0"     }
\CommentTok{\#\textgreater{} [26] "5\textquotesingle{} 10"      "5.5\textquotesingle{}0"      "6.2\textquotesingle{}0"      "5 \textquotesingle{} 8 "     "6.2\textquotesingle{}0"}
\end{Highlighting}
\end{Shaded}

Another pattern we see now is when before or after the foot symbol \texttt{\textquotesingle{}} there is a white space. Let's make the change with what we learned and include cases where there are decimals:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(problematic\_heights, }
                     \StringTok{"\^{}([4{-}7]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}\NormalTok{)}

\NormalTok{problematic\_heights[index] }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Match}
  \FunctionTok{head}\NormalTok{(}\DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "6\textquotesingle{}0"        "5\textquotesingle{} 4"       "5.3\textquotesingle{}0"      "6\textquotesingle{}0"        "5\textquotesingle{}7"       }
\CommentTok{\#\textgreater{}  [6] "5\textquotesingle{}7"        "5\textquotesingle{}3"        "5 \textquotesingle{}  8.11 " "5.25\textquotesingle{}0"     "5\textquotesingle{}11"      }
\CommentTok{\#\textgreater{} [11] "5.5\textquotesingle{}0"      "5\textquotesingle{}9"        "6\textquotesingle{}0"        "6.5\textquotesingle{}0"      "5\textquotesingle{}10"      }
\CommentTok{\#\textgreater{} [16] "5.8\textquotesingle{}0"      "5\textquotesingle{}0"        "5.6\textquotesingle{}0"      "5.3\textquotesingle{}0"      "6\textquotesingle{}0"       }
\CommentTok{\#\textgreater{} [21] "6\textquotesingle{}0"        "5.9\textquotesingle{}0"      "6.8\textquotesingle{}0"      "5\textquotesingle{} 10"      "5.5\textquotesingle{}0"     }
\CommentTok{\#\textgreater{} [26] "6.2\textquotesingle{}0"      "5 \textquotesingle{} 8 "     "6.2\textquotesingle{}0"      "5.8\textquotesingle{}0"      "5.1\textquotesingle{}0"}

\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(}
\NormalTok{                      problematic\_heights, }
                      \StringTok{"\^{}([4{-}7]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}\NormalTok{,}
                      \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2"}
\NormalTok{                   )}

\NormalTok{problematic\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "6\textquotesingle{}0"    "5\textquotesingle{}4"    "5.3\textquotesingle{}0"  "165"    "6\textquotesingle{}0"    "5\textquotesingle{}7"    "\textgreater{}9000"  "5\textquotesingle{}7"   }
\CommentTok{\#\textgreater{}  [9] "5\textquotesingle{}3"    "5\textquotesingle{}8.11" "5.25\textquotesingle{}0" "5\textquotesingle{}11"   "5.5\textquotesingle{}0"  "5\textquotesingle{}9"    "6\textquotesingle{}0"    "6.5\textquotesingle{}0" }
\CommentTok{\#\textgreater{} [17] "5\textquotesingle{}10"   "5.8\textquotesingle{}0"  "5\textquotesingle{}0"    "5.6\textquotesingle{}0"  "5.3\textquotesingle{}0"  "6\textquotesingle{}0"    "6\textquotesingle{}0"    "5.9\textquotesingle{}0" }
\CommentTok{\#\textgreater{} [25] "6.8\textquotesingle{}0"  "5\textquotesingle{}10"   "5.5\textquotesingle{}0"  "6.2\textquotesingle{}0"  "5\textquotesingle{}8"    "6.2\textquotesingle{}0"}
\end{Highlighting}
\end{Shaded}

Likewise, we have the pattern in which they entered: feet + space + inches without any symbol. Let's make the change with what we learned.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(problematic\_heights, }\StringTok{"\^{}([4{-}7])}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s+(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}\NormalTok{)}

\NormalTok{problematic\_heights[index] }\CommentTok{\# Match}
\CommentTok{\#\textgreater{} [1] "5 11" "6 04"}

\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace\_all}\NormalTok{(}
\NormalTok{                      problematic\_heights, }
                      \StringTok{"\^{}([4{-}7])}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s+(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2"}
\NormalTok{                   )}

\NormalTok{problematic\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "6\textquotesingle{}0"    "5\textquotesingle{}4"    "5.3\textquotesingle{}0"  "165"    "6\textquotesingle{}0"    "5\textquotesingle{}7"    "\textgreater{}9000"  "5\textquotesingle{}7"   }
\CommentTok{\#\textgreater{}  [9] "5\textquotesingle{}3"    "5\textquotesingle{}8.11" "5.25\textquotesingle{}0" "5\textquotesingle{}11"   "5.5\textquotesingle{}0"  "5\textquotesingle{}9"    "6\textquotesingle{}0"    "6.5\textquotesingle{}0" }
\CommentTok{\#\textgreater{} [17] "5\textquotesingle{}10"   "5.8\textquotesingle{}0"  "5\textquotesingle{}0"    "5.6\textquotesingle{}0"  "5.3\textquotesingle{}0"  "6\textquotesingle{}0"    "6\textquotesingle{}0"    "5.9\textquotesingle{}0" }
\CommentTok{\#\textgreater{} [25] "6.8\textquotesingle{}0"  "5\textquotesingle{}10"   "5.5\textquotesingle{}0"  "6.2\textquotesingle{}0"  "5\textquotesingle{}8"    "6.2\textquotesingle{}0"}
\end{Highlighting}
\end{Shaded}

We are ready to put all the patterns together and the power of patterns is that they can serve us for future exercises. Thus, we will create a function where we will place each change that we can verify to a string.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{format\_errors }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(string)\{}
\NormalTok{  string }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"feet|ft|foot"}\NormalTok{, }\StringTok{"\textquotesingle{}"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Change feet for \textquotesingle{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"inches|in|\textquotesingle{}\textquotesingle{}|}\SpecialCharTok{\textbackslash{}"}\StringTok{|cm|and"}\NormalTok{, }\StringTok{""}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Remove symbols}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"\^{}([5{-}7])\textquotesingle{}$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}0"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Adds 0 to 5\textquotesingle{}, 6\textquotesingle{} or 7\textquotesingle{}}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"\^{}([5{-}7])$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}0"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Adds 0 to 5, 6 or 7}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"\^{}([4{-}7])}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*[,}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1.}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2\textquotesingle{}0"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Change 5.3\textquotesingle{} to 5.3\textquotesingle{}0}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"\^{}([4{-}7]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\#Removes spaces in middle}
    \FunctionTok{str\_replace\_all}\NormalTok{(}\StringTok{"\^{}([4{-}7])}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s+(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Adds \textquotesingle{}}
    \FunctionTok{str\_replace}\NormalTok{(}\StringTok{"\^{}([12])}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*,}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)$"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1.}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Changes decimals from commas to dots}
    \FunctionTok{str\_trim}\NormalTok{() }\CommentTok{\#Removes spaces at start and end}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Thus, we have created two functions that could be useful to us if we were to work with surveys of the same type again.

Before applying it to our entire table let's extract the values to a vector again to apply the created functions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{problematic\_heights }\OtherTok{\textless{}{-}}\NormalTok{ reported\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(height)) }\SpecialCharTok{|} \CommentTok{\# Does not convert to number}
\NormalTok{         (}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(height)) }\SpecialCharTok{\&} \FunctionTok{as.numeric}\NormalTok{(height) }\SpecialCharTok{\textgreater{}=} \DecValTok{5} \SpecialCharTok{\&}
            \FunctionTok{as.numeric}\NormalTok{(height) }\SpecialCharTok{\textless{}=} \DecValTok{7}\NormalTok{ ) }\CommentTok{\# or entered in feet and not inches}
\NormalTok{        ) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(height)}
\end{Highlighting}
\end{Shaded}

Now let's apply the created functions:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formatted\_heights }\OtherTok{\textless{}{-}}\NormalTok{ problematic\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{words\_to\_number}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{format\_errors}\NormalTok{()}

\NormalTok{pattern }\OtherTok{\textless{}{-}} \StringTok{"\^{}([4{-}7]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(formatted\_heights, pattern)}
\NormalTok{formatted\_heights[}\SpecialCharTok{!}\NormalTok{index] }\CommentTok{\# Do not match the pattern}
\CommentTok{\#\textgreater{}  [1] "165"       "\textgreater{}9000"     "2\textquotesingle{}33"      "1.70"      "yyy"       "6*12"     }
\CommentTok{\#\textgreater{}  [7] "69"        "708,661"   "649,606"   "728,346"   "170"       "7,283,465"}
\end{Highlighting}
\end{Shaded}

We have managed to reduce from 168 errors of 1095 records, 15.3\% of errors, to 12 errors of 1095, 1\% of errors. We can now apply to our initial table.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Apply created formulas}
\NormalTok{heights }\OtherTok{\textless{}{-}}\NormalTok{ reported\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(height) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{height =} \FunctionTok{words\_to\_number}\NormalTok{(height) }\SpecialCharTok{|\textgreater{}} \FunctionTok{format\_errors}\NormalTok{())}

\CommentTok{\# Get random samples to validate quality}
\NormalTok{random\_indices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(heights)) }
\NormalTok{heights[random\_indices, ] }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{}               time\_stamp    sex height}
\CommentTok{\#\textgreater{} 155  2014{-}09{-}02 15:17:12 Female     63}
\CommentTok{\#\textgreater{} 426  2015{-}01{-}06 22:58:54   Male   5\textquotesingle{}12}
\CommentTok{\#\textgreater{} 1029 2016{-}07{-}26 13:02:34   Male     67}
\CommentTok{\#\textgreater{} 326  2014{-}10{-}14 05:18:11   Male     71}
\CommentTok{\#\textgreater{} 789  2016{-}01{-}25 08:15:45 Female    5\textquotesingle{}5}
\CommentTok{\#\textgreater{} 985  2016{-}04{-}23 17:15:26   Male   67.5}
\CommentTok{\#\textgreater{} 39   2014{-}09{-}02 15:16:31   Male     72}
\CommentTok{\#\textgreater{} 822  2016{-}01{-}25 21:18:33   Male     68}
\CommentTok{\#\textgreater{} 986  2016{-}04{-}25 06:11:45   Male    180}
\CommentTok{\#\textgreater{} 137  2014{-}09{-}02 15:17:02   Male     68}
\CommentTok{\#\textgreater{} 455  2015{-}01{-}28 03:59:44   Male  5.5\textquotesingle{}0}
\CommentTok{\#\textgreater{} 589  2015{-}05{-}25 16:19:20   Male     69}
\CommentTok{\#\textgreater{} 1089 2017{-}09{-}04 07:28:40   Male     69}
\CommentTok{\#\textgreater{} 196  2014{-}09{-}02 15:18:30 Female  64.57}
\CommentTok{\#\textgreater{} 680  2015{-}09{-}01 22:45:11   Male     68}
\end{Highlighting}
\end{Shaded}

We still have to do some conversions. However, since they follow a determined pattern we can use the \texttt{extract(source\_column,\ new\_columns,\ pattern,\ remove\_source)} function to confirm creating new columns for each value of our pattern.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pattern }\OtherTok{\textless{}{-}} \StringTok{"\^{}([4{-}7]}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d*)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s*$"}

\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{extract}\NormalTok{(height, }\FunctionTok{c}\NormalTok{(}\StringTok{"feet"}\NormalTok{, }\StringTok{"inches"}\NormalTok{), }\AttributeTok{regex =}\NormalTok{ pattern, }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{}             time\_stamp    sex height feet inches}
\CommentTok{\#\textgreater{} 1  2014{-}09{-}02 13:40:36   Male     75 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 2  2014{-}09{-}02 13:46:59   Male     70 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 3  2014{-}09{-}02 13:59:20   Male     68 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 4  2014{-}09{-}02 14:51:53   Male     74 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 5  2014{-}09{-}02 15:16:15   Male     61 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 6  2014{-}09{-}02 15:16:16 Female     65 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 7  2014{-}09{-}02 15:16:19 Female     66 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 8  2014{-}09{-}02 15:16:21 Female     62 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 9  2014{-}09{-}02 15:16:21 Female     66 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 10 2014{-}09{-}02 15:16:22   Male     67 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 11 2014{-}09{-}02 15:16:22   Male     72 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 12 2014{-}09{-}02 15:16:23   Male    6\textquotesingle{}0    6      0}
\CommentTok{\#\textgreater{} 13 2014{-}09{-}02 15:16:23   Male     69 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 14 2014{-}09{-}02 15:16:26   Male     68 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\CommentTok{\#\textgreater{} 15 2014{-}09{-}02 15:16:26   Male     69 \textless{}NA\textgreater{}   \textless{}NA\textgreater{}}
\end{Highlighting}
\end{Shaded}

Now that we have the data that matches the pattern in two other columns, and we know they are numbers, we can convert everything to number.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{extract}\NormalTok{(height, }\FunctionTok{c}\NormalTok{(}\StringTok{"feet"}\NormalTok{, }\StringTok{"inches"}\NormalTok{), }\AttributeTok{regex =}\NormalTok{ pattern, }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"height"}\NormalTok{, }\StringTok{"feet"}\NormalTok{, }\StringTok{"inches"}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{as.numeric}\NormalTok{(.))) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning: There was 1 warning in \textasciigrave{}mutate()\textasciigrave{}.}
\CommentTok{\#\textgreater{} i In argument: \textasciigrave{}across(c("height", "feet",}
\CommentTok{\#\textgreater{}   "inches"), \textasciitilde{}as.numeric(.))\textasciigrave{}.}
\CommentTok{\#\textgreater{} Caused by warning:}
\CommentTok{\#\textgreater{} ! NAs introduced by coercion}
\CommentTok{\#\textgreater{}             time\_stamp    sex height feet inches}
\CommentTok{\#\textgreater{} 1  2014{-}09{-}02 13:40:36   Male     75   NA     NA}
\CommentTok{\#\textgreater{} 2  2014{-}09{-}02 13:46:59   Male     70   NA     NA}
\CommentTok{\#\textgreater{} 3  2014{-}09{-}02 13:59:20   Male     68   NA     NA}
\CommentTok{\#\textgreater{} 4  2014{-}09{-}02 14:51:53   Male     74   NA     NA}
\CommentTok{\#\textgreater{} 5  2014{-}09{-}02 15:16:15   Male     61   NA     NA}
\CommentTok{\#\textgreater{} 6  2014{-}09{-}02 15:16:16 Female     65   NA     NA}
\CommentTok{\#\textgreater{} 7  2014{-}09{-}02 15:16:19 Female     66   NA     NA}
\CommentTok{\#\textgreater{} 8  2014{-}09{-}02 15:16:21 Female     62   NA     NA}
\CommentTok{\#\textgreater{} 9  2014{-}09{-}02 15:16:21 Female     66   NA     NA}
\CommentTok{\#\textgreater{} 10 2014{-}09{-}02 15:16:22   Male     67   NA     NA}
\CommentTok{\#\textgreater{} 11 2014{-}09{-}02 15:16:22   Male     72   NA     NA}
\CommentTok{\#\textgreater{} 12 2014{-}09{-}02 15:16:23   Male     NA    6      0}
\CommentTok{\#\textgreater{} 13 2014{-}09{-}02 15:16:23   Male     69   NA     NA}
\CommentTok{\#\textgreater{} 14 2014{-}09{-}02 15:16:26   Male     68   NA     NA}
\CommentTok{\#\textgreater{} 15 2014{-}09{-}02 15:16:26   Male     69   NA     NA}
\end{Highlighting}
\end{Shaded}

Now that our columns are numeric we can perform operations to calculate height.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{extract}\NormalTok{(height, }\FunctionTok{c}\NormalTok{(}\StringTok{"feet"}\NormalTok{, }\StringTok{"inches"}\NormalTok{), }\AttributeTok{regex =}\NormalTok{ pattern, }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"height"}\NormalTok{, }\StringTok{"feet"}\NormalTok{, }\StringTok{"inches"}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{as.numeric}\NormalTok{(.))) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{fixed\_heights =}\NormalTok{ feet}\SpecialCharTok{*}\DecValTok{12} \SpecialCharTok{+}\NormalTok{ inches) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning: There was 1 warning in \textasciigrave{}mutate()\textasciigrave{}.}
\CommentTok{\#\textgreater{} i In argument: \textasciigrave{}across(c("height", "feet",}
\CommentTok{\#\textgreater{}   "inches"), \textasciitilde{}as.numeric(.))\textasciigrave{}.}
\CommentTok{\#\textgreater{} Caused by warning:}
\CommentTok{\#\textgreater{} ! NAs introduced by coercion}
\CommentTok{\#\textgreater{}             time\_stamp    sex height feet inches fixed\_heights}
\CommentTok{\#\textgreater{} 1  2014{-}09{-}02 13:40:36   Male     75   NA     NA            NA}
\CommentTok{\#\textgreater{} 2  2014{-}09{-}02 13:46:59   Male     70   NA     NA            NA}
\CommentTok{\#\textgreater{} 3  2014{-}09{-}02 13:59:20   Male     68   NA     NA            NA}
\CommentTok{\#\textgreater{} 4  2014{-}09{-}02 14:51:53   Male     74   NA     NA            NA}
\CommentTok{\#\textgreater{} 5  2014{-}09{-}02 15:16:15   Male     61   NA     NA            NA}
\CommentTok{\#\textgreater{} 6  2014{-}09{-}02 15:16:16 Female     65   NA     NA            NA}
\CommentTok{\#\textgreater{} 7  2014{-}09{-}02 15:16:19 Female     66   NA     NA            NA}
\CommentTok{\#\textgreater{} 8  2014{-}09{-}02 15:16:21 Female     62   NA     NA            NA}
\CommentTok{\#\textgreater{} 9  2014{-}09{-}02 15:16:21 Female     66   NA     NA            NA}
\CommentTok{\#\textgreater{} 10 2014{-}09{-}02 15:16:22   Male     67   NA     NA            NA}
\CommentTok{\#\textgreater{} 11 2014{-}09{-}02 15:16:22   Male     72   NA     NA            NA}
\CommentTok{\#\textgreater{} 12 2014{-}09{-}02 15:16:23   Male     NA    6      0            72}
\CommentTok{\#\textgreater{} 13 2014{-}09{-}02 15:16:23   Male     69   NA     NA            NA}
\CommentTok{\#\textgreater{} 14 2014{-}09{-}02 15:16:26   Male     68   NA     NA            NA}
\CommentTok{\#\textgreater{} 15 2014{-}09{-}02 15:16:26   Male     69   NA     NA            NA}
\end{Highlighting}
\end{Shaded}

Finally, we will do a validation of whether the height is in an interval and/or if it was expressed in centimeters or meters.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We assume for a person a minimum 50" (1.2m) and max 84" (2.1m)}
\NormalTok{min }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{max }\OtherTok{\textless{}{-}} \DecValTok{84}

\NormalTok{heights }\OtherTok{\textless{}{-}}\NormalTok{ heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{extract}\NormalTok{(height, }\FunctionTok{c}\NormalTok{(}\StringTok{"feet"}\NormalTok{, }\StringTok{"inches"}\NormalTok{), }\AttributeTok{regex =}\NormalTok{ pattern, }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"height"}\NormalTok{, }\StringTok{"feet"}\NormalTok{, }\StringTok{"inches"}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{as.numeric}\NormalTok{(.))) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{fixed\_heights =}\NormalTok{ feet}\SpecialCharTok{*}\DecValTok{12} \SpecialCharTok{+}\NormalTok{ inches) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{final\_height =} \FunctionTok{case\_when}\NormalTok{(}
    \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(height) }\SpecialCharTok{\&} \FunctionTok{between}\NormalTok{(height, min, max) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ height, }\CommentTok{\#inches }
    \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(height) }\SpecialCharTok{\&} \FunctionTok{between}\NormalTok{(height}\SpecialCharTok{/}\FloatTok{2.54}\NormalTok{, min, max) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ height}\SpecialCharTok{/}\FloatTok{2.54}\NormalTok{, }\CommentTok{\#cm}
    \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(height) }\SpecialCharTok{\&} \FunctionTok{between}\NormalTok{(height}\SpecialCharTok{*}\DecValTok{100}\SpecialCharTok{/}\FloatTok{2.54}\NormalTok{, min, max) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ height}\SpecialCharTok{*}\DecValTok{100}\SpecialCharTok{/}\FloatTok{2.54}\NormalTok{, }\CommentTok{\#meters}
    \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(fixed\_heights) }\SpecialCharTok{\&}\NormalTok{ inches }\SpecialCharTok{\textless{}} \DecValTok{12} \SpecialCharTok{\&} 
      \FunctionTok{between}\NormalTok{(fixed\_heights, min, max) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ fixed\_heights, }\CommentTok{\#feet\textquotesingle{}inches}
    \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \FunctionTok{as.numeric}\NormalTok{(}\ConstantTok{NA}\NormalTok{)))}
\CommentTok{\#\textgreater{} Warning: There was 1 warning in \textasciigrave{}mutate()\textasciigrave{}.}
\CommentTok{\#\textgreater{} i In argument: \textasciigrave{}across(c("height", "feet",}
\CommentTok{\#\textgreater{}   "inches"), \textasciitilde{}as.numeric(.))\textasciigrave{}.}
\CommentTok{\#\textgreater{} Caused by warning:}
\CommentTok{\#\textgreater{} ! NAs introduced by coercion}

\CommentTok{\# Random Sample:}
\NormalTok{random\_indices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(heights)) }
\NormalTok{heights[random\_indices, ] }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{time\_stamp) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Shows all columns except time\_stamp}
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}         sex   height feet inches fixed\_heights final\_height}
\CommentTok{\#\textgreater{} 201  Female 67.00000   NA     NA            NA     67.00000}
\CommentTok{\#\textgreater{} 1006   Male 68.11024   NA     NA            NA     68.11024}
\CommentTok{\#\textgreater{} 651    Male 70.00000   NA     NA            NA     70.00000}
\CommentTok{\#\textgreater{} 545    Male 68.00000   NA     NA            NA     68.00000}
\CommentTok{\#\textgreater{} 617    Male 69.00000   NA     NA            NA     69.00000}
\CommentTok{\#\textgreater{} 17     Male 75.00000   NA     NA            NA     75.00000}
\CommentTok{\#\textgreater{} 102  Female 71.00000   NA     NA            NA     71.00000}
\CommentTok{\#\textgreater{} 71     Male 73.00000   NA     NA            NA     73.00000}
\CommentTok{\#\textgreater{} 80   Female 72.00000   NA     NA            NA     72.00000}
\CommentTok{\#\textgreater{} 643    Male 72.00000   NA     NA            NA     72.00000}
\end{Highlighting}
\end{Shaded}

We already have our sample validated, we would only have to take the columns we need and start using the object for the analyses we need.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final\_heights }\OtherTok{\textless{}{-}}\NormalTok{ heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(}\AttributeTok{gender =}\NormalTok{ sex, }\AttributeTok{heights =}\NormalTok{ final\_height)}

\NormalTok{final\_heights }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}    gender heights}
\CommentTok{\#\textgreater{} 1    Male      75}
\CommentTok{\#\textgreater{} 2    Male      70}
\CommentTok{\#\textgreater{} 3    Male      68}
\CommentTok{\#\textgreater{} 4    Male      74}
\CommentTok{\#\textgreater{} 5    Male      61}
\CommentTok{\#\textgreater{} 6  Female      65}
\CommentTok{\#\textgreater{} 7  Female      66}
\CommentTok{\#\textgreater{} 8  Female      62}
\CommentTok{\#\textgreater{} 9  Female      66}
\CommentTok{\#\textgreater{} 10   Male      67}
\end{Highlighting}
\end{Shaded}

\section{From strings to dates}\label{from-strings-to-dates}

Regularly when we import data, we are not only going to want to transform numeric data. We will also have multiple cases where we need to transform our string to a date in some particular format. For this, we will use the \texttt{lubridate} library, included in \texttt{tidyverse}, which provides us with diverse functions to make date treatment more accessible.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lubridate)}
\end{Highlighting}
\end{Shaded}

When the text string is in the ISO 8601 date format (YYYY-MM-DD), we can directly use the \texttt{month()}, \texttt{day()}, \texttt{year()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dates\_char }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"2010{-}05{-}19"}\NormalTok{, }\StringTok{"2020{-}05{-}06"}\NormalTok{, }\StringTok{"2010{-}02{-}03"}\NormalTok{)}

\FunctionTok{str}\NormalTok{(dates\_char)}
\CommentTok{\#\textgreater{}  chr [1:3] "2010{-}05{-}19" "2020{-}05{-}06" "2010{-}02{-}03"}

\FunctionTok{month}\NormalTok{(dates\_char)}
\CommentTok{\#\textgreater{} [1] 5 5 2}
\end{Highlighting}
\end{Shaded}

However, we do not always have the date in that format and \texttt{lubridate()} gives other functions that are more flexible when coercing data. Look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dates }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{20090101}\NormalTok{, }\StringTok{"2009{-}01{-}02"}\NormalTok{, }\StringTok{"2009 01 03"}\NormalTok{, }\StringTok{"2009{-}1{-}4"}\NormalTok{,}
       \StringTok{"2009{-}1, 5"}\NormalTok{, }\StringTok{"Created on 2009 1 6"}\NormalTok{, }\StringTok{"200901 !!! 07"}\NormalTok{)}

\FunctionTok{str}\NormalTok{(dates)}
\CommentTok{\#\textgreater{}  chr [1:7] "20090101" "2009{-}01{-}02" "2009 01 03" "2009{-}1{-}4" "2009{-}1, 5" ...}

\FunctionTok{ymd}\NormalTok{(dates)}
\CommentTok{\#\textgreater{} [1] "2009{-}01{-}01" "2009{-}01{-}02" "2009{-}01{-}03" "2009{-}01{-}04" "2009{-}01{-}05"}
\CommentTok{\#\textgreater{} [6] "2009{-}01{-}06" "2009{-}01{-}07"}
\end{Highlighting}
\end{Shaded}

The first data entered was a number, but we already know that it coerces it to text. Then, we have different values entered, but all follow the same pattern. First is the year, then the month and then the day. When we know that first is the year, then month and then day we will use the \texttt{ymd()} function to convert all dates to ISO 8601 format.

In the same way, we will have the following functions that we can use depending on the form in which we have the date from our source. In all cases it will be convenient for us to convert to ISO 8601 format. For example here we can see when it correctly recognizes the format and when the formatting fails.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \StringTok{"28/03/89"}
\FunctionTok{ymd}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] NA}
\FunctionTok{mdy}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] NA}
\FunctionTok{ydm}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] NA}
\FunctionTok{myd}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] NA}
\FunctionTok{dmy}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] "1989{-}03{-}28"}
\FunctionTok{dym}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] NA}
\end{Highlighting}
\end{Shaded}

Finally, in the same way that we can use these functions of days, months and years, we can also use to refer to hours, minutes and seconds.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Format with hours, minutes and seconds}
\NormalTok{date\_val }\OtherTok{\textless{}{-}} \StringTok{"Feb/2/2012 12:34:56"}
\FunctionTok{mdy\_hms}\NormalTok{(date\_val)}
\CommentTok{\#\textgreater{} [1] "2012{-}02{-}02 12:34:56 UTC"}

\CommentTok{\# Additional data: Showing system date:}
\FunctionTok{now}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] "2025{-}12{-}25 16:14:44 GMT"}
\end{Highlighting}
\end{Shaded}

\section{Exercises}\label{exercises-19}

Before solving the following exercise run this Script:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sales }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{month =} \FunctionTok{c}\NormalTok{(}\StringTok{"April"}\NormalTok{, }\StringTok{"May"}\NormalTok{, }\StringTok{"June"}\NormalTok{),}
  \AttributeTok{revenue =} \FunctionTok{c}\NormalTok{(}\StringTok{"s/32,124"}\NormalTok{, }\StringTok{"s/35,465"}\NormalTok{, }\StringTok{"S/38,332"}\NormalTok{),}
  \AttributeTok{profit =} \FunctionTok{c}\NormalTok{(}\StringTok{"s/8,120"}\NormalTok{, }\StringTok{"s/9,432"}\NormalTok{, }\StringTok{"s/10,543"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{112}
\tightlist
\item
  Convert the \texttt{revenue} and \texttt{profit} columns in the \texttt{sales} object to numeric values, removing any currency symbols or formatting characters.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Solution 1}
\NormalTok{sales }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{parse\_number}\NormalTok{(.)))}

\CommentTok{\# Alternative solution, longer}
\NormalTok{sales }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_replace\_all}\NormalTok{(., }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{S/|,"}\NormalTok{, }\StringTok{""}\NormalTok{))) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{as.numeric}\NormalTok{(.)))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{113}
\tightlist
\item
  Clean the \texttt{universities} vector so that all university names are standardized. Specifically, replace abbreviations like ``Univ.'' or ``U.'' at the beginning of the string with the full word ``University''.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{universities }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{str\_replace}\NormalTok{(}\StringTok{"\^{}Univ}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s|\^{}U}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.?}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s"}\NormalTok{, }\StringTok{"University "}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

For the following exercises, we are going to work on the survey data conducted prior to Brexit in the UK. Run the Script first:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rvest)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://en.wikipedia.org/w/index.php?title=Opinion\_polling\_for\_the\_United\_Kingdom\_European\_Union\_membership\_referendum\&oldid=896735054"}
\NormalTok{table\_html }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(url) }\SpecialCharTok{|\textgreater{}} \FunctionTok{html\_nodes}\NormalTok{(}\StringTok{"table"}\NormalTok{)}
\NormalTok{polls }\OtherTok{\textless{}{-}}\NormalTok{ table\_html[[}\DecValTok{5}\NormalTok{]] }\SpecialCharTok{|\textgreater{}} \FunctionTok{html\_table}\NormalTok{(}\AttributeTok{fill =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{114}
\tightlist
\item
  Update the \texttt{polls} object by renaming columns to \texttt{c("date",\ "remain",\ "leave",\ "undecided",\ "spread",\ "sample",\ "pollster",\ "type",\ "notes")}. Then, filter the dataset to retain only rows where the \texttt{remain} column contains a percentage symbol (``\%'').
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(polls) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"date"}\NormalTok{, }\StringTok{"remain"}\NormalTok{, }\StringTok{"leave"}\NormalTok{, }\StringTok{"undecided"}\NormalTok{, }\StringTok{"spread"}\NormalTok{,}
                  \StringTok{"sample"}\NormalTok{, }\StringTok{"pollster"}\NormalTok{, }\StringTok{"type"}\NormalTok{, }\StringTok{"notes"}\NormalTok{)}
\NormalTok{polls }\OtherTok{\textless{}{-}}\NormalTok{ polls[}\FunctionTok{str\_detect}\NormalTok{(polls}\SpecialCharTok{$}\NormalTok{remain, }\StringTok{"\%"}\NormalTok{), ]}
\NormalTok{polls }

\CommentTok{\# If we want to validate the number of polls:}
\FunctionTok{nrow}\NormalTok{(polls)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{115}
\tightlist
\item
  Extract the \texttt{remain} column into a vector and convert the text percentages into proper numeric probabilities (e.g., convert ``50\%'' to 0.5).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{remain }\OtherTok{\textless{}{-}}\NormalTok{ polls}\SpecialCharTok{$}\NormalTok{remain}

\CommentTok{\# Solution 1:}
\NormalTok{percentages }\OtherTok{\textless{}{-}} \FunctionTok{parse\_number}\NormalTok{(remain)}\SpecialCharTok{/}\DecValTok{100}

\CommentTok{\# Solution 1:}
\NormalTok{temp }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace}\NormalTok{(remain, }\StringTok{"\%"}\NormalTok{, }\StringTok{""}\NormalTok{)}
\NormalTok{percentages }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(temp)}\SpecialCharTok{/}\DecValTok{100}

\CommentTok{\# Solution 2:}
\NormalTok{temp }\OtherTok{\textless{}{-}} \FunctionTok{str\_remove}\NormalTok{(remain, }\StringTok{"\%"}\NormalTok{)}
\NormalTok{percentages }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(temp)}\SpecialCharTok{/}\DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{116}
\tightlist
\item
  In the \texttt{undecided} column, the value ``N/A'' appears when the sum of \texttt{remain} and \texttt{leave} equals 100\%. Create a vector for \texttt{undecided} where these ``N/A'' values are replaced with ``0\%''.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{undecided }\OtherTok{\textless{}{-}}\NormalTok{ polls}\SpecialCharTok{$}\NormalTok{undecided}

\FunctionTok{str\_replace}\NormalTok{(undecided, }\StringTok{"N/A"}\NormalTok{, }\StringTok{"0\%"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{117}
\tightlist
\item
  encapsulate your cleaning logic into a single function named \texttt{format\_percentage(string)}. Test this function with the vector \texttt{c("13.5\%",\ "N/A",\ "10\%")} to verify it handles both percentages and ``N/A'' values correctly.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{format\_percentage }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(string)\{}
\NormalTok{  string }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{str\_replace}\NormalTok{(}\StringTok{"N/A"}\NormalTok{, }\StringTok{"0\%"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{parse\_number}\NormalTok{()}\SpecialCharTok{/}\DecValTok{100}
\NormalTok{\}}

\CommentTok{\# Function test:}
\NormalTok{test\_vec }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"13.5\%"}\NormalTok{, }\StringTok{"N/A"}\NormalTok{, }\StringTok{"10\%"}\NormalTok{)}

\FunctionTok{format\_percentage}\NormalTok{(test\_vec)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{118}
\tightlist
\item
  Apply \texttt{format\_percentage} to the \texttt{remain}, \texttt{leave}, \texttt{undecided}, and \texttt{spread} columns in the \texttt{polls} dataset. Also, ensure the \texttt{sample} column is converted to a numeric type.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{polls }\OtherTok{\textless{}{-}}\NormalTok{ polls }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"remain"}\NormalTok{, }\StringTok{"leave"}\NormalTok{, }\StringTok{"undecided"}\NormalTok{, }\StringTok{"spread"}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{format\_percentage}\NormalTok{(.))) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"sample"}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{parse\_number}\NormalTok{(.)))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{119}
\tightlist
\item
  Import the Peruvian COVID-19 dataset from \href{https://www.datosabiertos.gob.pe/sites/default/files/DATOSABIERTOS_SISCOVID.csv}{this URL} into an object named \texttt{covid\_peru}. Convert the birth date column (\texttt{FECHA\_NACIMIENTO}) to a proper Date format and calculate the age distribution of the infected individuals using a histogram.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://www.datosabiertos.gob.pe/sites/default/files/DATOSABIERTOS\_SISCOVID.csv"}
\NormalTok{covid\_peru }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(url)}

\CommentTok{\# We look for those that do not follow the ISO 8601 standard:}
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(covid\_peru}\SpecialCharTok{$}\NormalTok{FECHA\_NACIMIENTO, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{4\}{-}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{2\}{-}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{2\}"}\NormalTok{)}
\NormalTok{covid\_peru}\SpecialCharTok{$}\NormalTok{FECHA\_NACIMIENTO[}\SpecialCharTok{!}\NormalTok{index]}

\CommentTok{\# We see dates in DD/MM/YYYY format}
\CommentTok{\# We replace to ISO 8601 format:}
\NormalTok{covid\_peru }\OtherTok{\textless{}{-}}\NormalTok{ covid\_peru }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\StringTok{"FECHA\_NACIMIENTO"}\NormalTok{, }
            \SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_replace}\NormalTok{(., }\StringTok{"(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{2\})/(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{2\})/(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{4\})"}\NormalTok{, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{3{-}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{2{-}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{1"}\NormalTok{)}
\NormalTok{            ))}

\CommentTok{\# We search again for those that do not follow ISO 8601 standard:}
\NormalTok{index }\OtherTok{\textless{}{-}} \FunctionTok{str\_detect}\NormalTok{(covid\_peru}\SpecialCharTok{$}\NormalTok{FECHA\_NACIMIENTO, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{4\}{-}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{2\}{-}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{2\}"}\NormalTok{)}
\NormalTok{covid\_peru}\SpecialCharTok{$}\NormalTok{FECHA\_NACIMIENTO[}\SpecialCharTok{!}\NormalTok{index]}

\CommentTok{\# Convert column to date:}
\NormalTok{covid\_peru }\OtherTok{\textless{}{-}}\NormalTok{ covid\_peru }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\StringTok{"FECHA\_NACIMIENTO"}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{ymd}\NormalTok{(.)))}

\CommentTok{\# Now that it is date format we create histogram:}
\NormalTok{covid\_peru }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{age =} \FunctionTok{year}\NormalTok{(}\FunctionTok{now}\NormalTok{()) }\SpecialCharTok{{-}} \FunctionTok{year}\NormalTok{(FECHA\_NACIMIENTO)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(age) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{hist}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\section{Text Mining using Tidy Data}\label{text-mining-using-tidy-data}

Text mining is the discovery by computer of new information, previously unknown, by automatically extracting information from different written resources. Written resources can be websites, books, chats, comments, emails, reviews, articles, etc.

To perform text mining efficiently in R, we will use the \texttt{tidytext} package. The ``tidy'' text format is defined as a table with one token per row. A token can be a word, a sentence, or a paragraph, but usually, it is single words. This structure allows us to use all the standard tools we've learned (\texttt{dplyr}, \texttt{ggplot2}) to analyze text.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Install packages if you haven\textquotesingle{}t yet}
\CommentTok{\# install.packages("tidytext")}

\FunctionTok{library}\NormalTok{(tidytext)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(syuzhet) }\CommentTok{\# For sentiment analysis}
\FunctionTok{library}\NormalTok{(wordcloud) }
\end{Highlighting}
\end{Shaded}

\subsection{Importing data and Tokenization}\label{importing-data-and-tokenization}

Word maps or word clouds allow us to quickly identify which are the words that are repeated most in a text.

We are going to analyze the work ``Pride and Prejudice'' written by the author Jane Austen. We will obtain the text from the \href{www.gutenberg.org}{Project Gutenberg}\footnote{www.gutenberg.org} website. We will use the \texttt{get\_text\_as\_string()} function from \texttt{syuzhet} to import properly.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://www.gutenberg.org/cache/epub/1342/pg1342.txt"}

\CommentTok{\# Import text as a single string}
\NormalTok{pride\_book }\OtherTok{\textless{}{-}} \FunctionTok{get\_text\_as\_string}\NormalTok{(url)}

\CommentTok{\# Convert to a data frame with sentences or just lines}
\CommentTok{\# Here we will split by newline to create a rudimentary structure}
\NormalTok{text\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{text =} \FunctionTok{str\_split}\NormalTok{(pride\_book, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)[[}\DecValTok{1}\NormalTok{]]}
\NormalTok{)}

\CommentTok{\# Remove empty lines}
\NormalTok{text\_df }\OtherTok{\textless{}{-}}\NormalTok{ text\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(text }\SpecialCharTok{!=} \StringTok{""}\NormalTok{)}

\FunctionTok{head}\NormalTok{(text\_df)}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 1}
\CommentTok{\#\textgreater{}   text                                                                          }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}                                                                         }
\CommentTok{\#\textgreater{} 1 "The Project Gutenberg eBook of Pride and Prejudice      This ebook is for th\textasciitilde{}}
\end{Highlighting}
\end{Shaded}

\subsection{Text cleaning and Tokenization}\label{text-cleaning-and-tokenization}

Now we will clean the text and convert it to specific tokens (words). The \texttt{unnest\_tokens()} function automatically:
1. Splits text into tokens (words by default).
2. Removes punctuation.
3. Converts to lowercase.

\begin{quote}
\textbf{Note on AI:} This process of breaking text into ``tokens'' is exactly how Large Language Models like GPT-4 work. In \textbf{Chapter 14 (Data Science in the Age of AI)}, we will see that LLMs are essentially probabilistic engines that predict the next token in a sequence. Understanding how to handle tokens here is the foundation for understanding Generative AI.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We eliminate first rows of notes/prologue if needed, though unnest\_tokens handles a lot.}
\CommentTok{\# Let\textquotesingle{}s clean some metadata lines roughly}
\NormalTok{start\_line }\OtherTok{\textless{}{-}} \DecValTok{115}
\NormalTok{text\_df }\OtherTok{\textless{}{-}}\NormalTok{ text\_df[start\_line}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(text\_df), ]}

\CommentTok{\# Tokenize}
\NormalTok{tidy\_pride }\OtherTok{\textless{}{-}}\NormalTok{ text\_df }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{unnest\_tokens}\NormalTok{(word, text)}

\CommentTok{\# See the result}
\FunctionTok{head}\NormalTok{(tidy\_pride)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 1}
\CommentTok{\#\textgreater{}   word }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}}
\CommentTok{\#\textgreater{} 1 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 2 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 3 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 4 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 5 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 6 \textless{}NA\textgreater{}}
\end{Highlighting}
\end{Shaded}

Now we have a table where each row is a word. This is the ``tidy'' format.

However, we clearly have words that do not add meaning (stop words), such as ``the'', ``and'', ``of''. We can remove them using a list of stop words. The \texttt{tm} package provides a good list for English.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tm)}
\NormalTok{english\_stop\_words }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{word =} \FunctionTok{stopwords}\NormalTok{(}\StringTok{"english"}\NormalTok{))}

\CommentTok{\# Remove stop words using anti\_join}
\NormalTok{tidy\_pride\_clean }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_pride }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{anti\_join}\NormalTok{(english\_stop\_words, }\AttributeTok{by =} \StringTok{"word"}\NormalTok{)}

\FunctionTok{head}\NormalTok{(tidy\_pride\_clean)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 1}
\CommentTok{\#\textgreater{}   word }
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}}
\CommentTok{\#\textgreater{} 1 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 2 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 3 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 4 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 5 \textless{}NA\textgreater{} }
\CommentTok{\#\textgreater{} 6 \textless{}NA\textgreater{}}
\end{Highlighting}
\end{Shaded}

We might also want to remove custom words or numbers that appeared in the extraction.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{custom\_stop\_words }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{word =} \FunctionTok{c}\NormalTok{(}\StringTok{"mr"}\NormalTok{, }\StringTok{"mrs"}\NormalTok{, }\StringTok{"miss"}\NormalTok{, }\StringTok{"said"}\NormalTok{, }\StringTok{"will"}\NormalTok{, }
                                     \StringTok{"one"}\NormalTok{, }\StringTok{"much"}\NormalTok{, }\StringTok{"may"}\NormalTok{, }\StringTok{"can"}\NormalTok{, }\StringTok{"now"}\NormalTok{, }\StringTok{"sir"}\NormalTok{, }\StringTok{"lady"}\NormalTok{))}

\NormalTok{tidy\_pride\_clean }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_pride\_clean }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{anti\_join}\NormalTok{(custom\_stop\_words, }\AttributeTok{by =} \StringTok{"word"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{str\_detect}\NormalTok{(word, }\StringTok{"\^{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+$"}\NormalTok{)) }\CommentTok{\# Remove pure numbers}
\end{Highlighting}
\end{Shaded}

\subsection{Word Cloud}\label{word-cloud}

Now that we have our clean data, calculating word frequency is as simple as using \texttt{count()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{word\_counts }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_pride\_clean }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{count}\NormalTok{(word, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{head}\NormalTok{(word\_counts)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 2}
\CommentTok{\#\textgreater{}   word          n}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}int\textgreater{}}
\CommentTok{\#\textgreater{} 1 elizabeth   605}
\CommentTok{\#\textgreater{} 2 darcy       383}
\CommentTok{\#\textgreater{} 3 must        322}
\CommentTok{\#\textgreater{} 4 bennet      309}
\CommentTok{\#\textgreater{} 5 jane        274}
\CommentTok{\#\textgreater{} 6 bingley     262}
\end{Highlighting}
\end{Shaded}

We can create the word cloud directly from this data frame.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wordcloud}\NormalTok{(}\AttributeTok{words =}\NormalTok{ word\_counts}\SpecialCharTok{$}\NormalTok{word, }
          \AttributeTok{freq =}\NormalTok{ word\_counts}\SpecialCharTok{$}\NormalTok{n,}
          \AttributeTok{min.freq =} \DecValTok{5}\NormalTok{,}
          \AttributeTok{max.words =} \DecValTok{80}\NormalTok{, }
          \AttributeTok{random.order =} \ConstantTok{FALSE}\NormalTok{, }
          \AttributeTok{colors =} \FunctionTok{brewer.pal}\NormalTok{(}\AttributeTok{name =} \StringTok{"Dark2"}\NormalTok{, }\AttributeTok{n =} \DecValTok{8}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-774-1} \end{center}

\subsection{Word Frequency Plot}\label{word-frequency-plot}

Since we have the data in a tidy format, plotting a bar chart of the most frequent words is straightforward with \texttt{ggplot2}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{word\_counts }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{head}\NormalTok{(}\DecValTok{20}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(n, }\FunctionTok{reorder}\NormalTok{(word, n))) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{x =} \StringTok{"Frequency"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Most common words in Pride and Prejudice"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-775-1} \end{center}

\section{Sentiment Analysis}\label{sentiment-analysis}

Sentiment analysis allows us to know the tone of the messages. We will use the \texttt{syuzhet} package combined with our tidy data skills.

Let's use the same example of tweets.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readxl)}

\CommentTok{\# Download tweets}
\NormalTok{url }\OtherTok{\textless{}{-}} \StringTok{"https://dparedesi.github.io/Data{-}Science{-}with{-}R{-}book/data/rmapalacios{-}tweets.xlsx"}
\NormalTok{temp\_file }\OtherTok{\textless{}{-}} \FunctionTok{tempfile}\NormalTok{()}
\FunctionTok{download.file}\NormalTok{(url, temp\_file)}
\NormalTok{posts }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(temp\_file)}
\FunctionTok{file.remove}\NormalTok{(temp\_file)}
\CommentTok{\#\textgreater{} [1] TRUE}

\CommentTok{\# Filter for tweets only and create a tidy dataframe}
\NormalTok{tweets\_df }\OtherTok{\textless{}{-}}\NormalTok{ posts }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Tweet Type}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \StringTok{"Tweet"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(}\AttributeTok{text =}\NormalTok{ Text) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{tweet\_id =} \FunctionTok{row\_number}\NormalTok{()) }

\FunctionTok{head}\NormalTok{(tweets\_df)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 2}
\CommentTok{\#\textgreater{}   text                                                                  tweet\_id}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}                                                                    \textless{}int\textgreater{}}
\CommentTok{\#\textgreater{} 1 "Le agradezco mucho regidor.\textbackslash{}nUna visita al niño y a su madre pueden\textasciitilde{}        1}
\CommentTok{\#\textgreater{} 2 "Esto esta prohibido en tantas normas que no se por donde empezar.\textbackslash{}n\textasciitilde{}        2}
\CommentTok{\#\textgreater{} 3 "Nadie lo sabe y a los ministros sectoriales parece importarles poco\textasciitilde{}        3}
\CommentTok{\#\textgreater{} 4 "Ahora se llama \textbackslash{}"trabajo remoto\textbackslash{}" con el auspicio del Estado peruan\textasciitilde{}        4}
\CommentTok{\#\textgreater{} 5 "¿Y usted esta muy seguro que va a salir a trabajar el lunes 25? Vay\textasciitilde{}        5}
\CommentTok{\#\textgreater{} 6 "No saben como abundan. https://t.co/r1qMGOhGcR"                             6}
\end{Highlighting}
\end{Shaded}

Now we clean the tweets. \texttt{unnest\_tokens} handles most of it, but for tweets, we might want to remove URL links first.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Custom cleaning function for tweets before tokenization}
\NormalTok{clean\_tweets }\OtherTok{\textless{}{-}}\NormalTok{ tweets\_df }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{text =} \FunctionTok{str\_replace\_all}\NormalTok{(text, }\StringTok{"http}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{S+"}\NormalTok{, }\StringTok{""}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# remove URLs}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{text =} \FunctionTok{str\_replace\_all}\NormalTok{(text, }\StringTok{"@}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{S+"}\NormalTok{, }\StringTok{""}\NormalTok{)) }\CommentTok{\# remove mentions}

\CommentTok{\# Get Sentiment scores for each tweet}
\CommentTok{\# syuzhet works well with the full text vector for scoring}
\NormalTok{tweet\_sentiments }\OtherTok{\textless{}{-}} \FunctionTok{get\_nrc\_sentiment}\NormalTok{(clean\_tweets}\SpecialCharTok{$}\NormalTok{text, }\AttributeTok{language =} \StringTok{"spanish"}\NormalTok{)}

\CommentTok{\# Combine with original data}
\NormalTok{tweets\_with\_sentiment }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(clean\_tweets, tweet\_sentiments)}

\FunctionTok{head}\NormalTok{(tweets\_with\_sentiment)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 12}
\CommentTok{\#\textgreater{}   text    tweet\_id anger anticipation disgust  fear   joy sadness surprise trust}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}      \textless{}int\textgreater{} \textless{}dbl\textgreater{}        \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}    \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 "Le ag\textasciitilde{}        1     0            1       0     2     1       3        0     3}
\CommentTok{\#\textgreater{} 2 "Esto \textasciitilde{}        2     4            0       3     5     0       3        0     0}
\CommentTok{\#\textgreater{} 3 "Nadie\textasciitilde{}        3     0            0       0     0     0       0        0     0}
\CommentTok{\#\textgreater{} 4 "Ahora\textasciitilde{}        4     0            1       0     0     1       0        1     1}
\CommentTok{\#\textgreater{} 5 "¿Y us\textasciitilde{}        5     0            2       0     1     3       2        0     4}
\CommentTok{\#\textgreater{} 6 "No sa\textasciitilde{}        6     0            0       0     0     0       0        0     0}
\CommentTok{\#\textgreater{} \# i 2 more variables: negative \textless{}dbl\textgreater{}, positive \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

We can now reshape this data to visualize emotions using \texttt{pivot\_longer}, just like we do with any tidy dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{translate\_emotions }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(string)\{}
  \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"anger"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Anger"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"anticipation"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Anticipation"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"disgust"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Disgust"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"fear"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Fear"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"joy"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Joy"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"sadness"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Sadness"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"surprise"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Surprise"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"trust"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Trust"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"negative"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Negative"}\NormalTok{,}
\NormalTok{    string }\SpecialCharTok{==} \StringTok{"positive"} \SpecialCharTok{\textasciitilde{}} \StringTok{"Positive"}\NormalTok{,}
    \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}}\NormalTok{ string}
\NormalTok{  )}
\NormalTok{\}}

\CommentTok{\# Summarize totals}
\NormalTok{sentiment\_totals }\OtherTok{\textless{}{-}}\NormalTok{ tweets\_with\_sentiment }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarise}\NormalTok{(}\FunctionTok{across}\NormalTok{(anger}\SpecialCharTok{:}\NormalTok{positive, sum)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{everything}\NormalTok{(), }\AttributeTok{names\_to =} \StringTok{"sentiment"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"total"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sentiment =} \FunctionTok{translate\_emotions}\NormalTok{(sentiment))}

\NormalTok{sentiment\_totals}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 2}
\CommentTok{\#\textgreater{}    sentiment    total}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}        \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 Anger          805}
\CommentTok{\#\textgreater{}  2 Anticipation   905}
\CommentTok{\#\textgreater{}  3 Disgust        807}
\CommentTok{\#\textgreater{}  4 Fear          1344}
\CommentTok{\#\textgreater{}  5 Joy            549}
\CommentTok{\#\textgreater{}  6 Sadness       1378}
\CommentTok{\#\textgreater{}  7 Surprise       421}
\CommentTok{\#\textgreater{}  8 Trust         1373}
\CommentTok{\#\textgreater{}  9 Negative      2535}
\CommentTok{\#\textgreater{} 10 Positive      2314}
\end{Highlighting}
\end{Shaded}

Visualizing:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Separate positive/negative from specific emotions}
\NormalTok{general\_sentiments }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Positive"}\NormalTok{, }\StringTok{"Negative"}\NormalTok{)}

\NormalTok{sentiment\_totals }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\NormalTok{sentiment }\SpecialCharTok{\%in\%}\NormalTok{ general\_sentiments) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder}\NormalTok{(sentiment, total), total, }\AttributeTok{fill =}\NormalTok{ sentiment)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{y =} \StringTok{"Total Score"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Emotions in Tweets"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{sentiment\_totals }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(sentiment }\SpecialCharTok{\%in\%}\NormalTok{ general\_sentiments) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(sentiment, total, }\AttributeTok{fill =}\NormalTok{ sentiment)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{y =} \StringTok{"Total Score"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Positive vs Negative Sentiment"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-779-1} \includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-779-2} \end{center}

This tidy approach makes it much easier to inspect the data at every step and integrate valid data science workflows (filtering, joining, plotting) without learning a separate system just for text.

\section{Exercises}\label{exercises-20}

For these exercises we will use more books from Project Gutenberg using the \texttt{gutenbergr} library.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("gutenbergr")}
\FunctionTok{library}\NormalTok{(gutenbergr)}

\CommentTok{\# Tibble: list of books in Gutenberg.org}
\NormalTok{gutenberg\_metadata}

\CommentTok{\# List of books in Spanish}
\FunctionTok{gutenberg\_works}\NormalTok{(}\AttributeTok{languages =} \StringTok{"es"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{120}
\tightlist
\item
  Use \texttt{gutenberg\_download(2000)} to download the text of ``El ingenioso hidalgo don Quijote de la Mancha'' and store the result in an object named \texttt{download}.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{download }\OtherTok{\textless{}{-}} \FunctionTok{gutenberg\_download}\NormalTok{(}\DecValTok{2000}\NormalTok{)}
\NormalTok{quijote\_text }\OtherTok{\textless{}{-}}\NormalTok{ download}\SpecialCharTok{$}\NormalTok{text}
\FunctionTok{head}\NormalTok{(quijote\_text)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{121}
\tightlist
\item
  Extract a random sample of 1,000 lines from the text. Clean this sample by tokenizing into words and removing standard Spanish stop words.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{sample\_lines }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{text =} \FunctionTok{sample}\NormalTok{(quijote\_text, }\DecValTok{1000}\NormalTok{))}

\NormalTok{tidy\_quijote }\OtherTok{\textless{}{-}}\NormalTok{ sample\_lines }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{unnest\_tokens}\NormalTok{(word, text) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{anti\_join}\NormalTok{(spanish\_stop\_words, }\AttributeTok{by =} \StringTok{"word"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \CommentTok{\# Remove extra stop words if needed}
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\NormalTok{word }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"don"}\NormalTok{, }\StringTok{"quijote"}\NormalTok{, }\StringTok{"sancho"}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{122}
\tightlist
\item
  Visualize the most frequent words in your cleaned Quijote sample using a word cloud.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{quijote\_counts }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_quijote }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{count}\NormalTok{(word, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{wordcloud}\NormalTok{(}\AttributeTok{words =}\NormalTok{ quijote\_counts}\SpecialCharTok{$}\NormalTok{word, }
          \AttributeTok{freq =}\NormalTok{ quijote\_counts}\SpecialCharTok{$}\NormalTok{n,}
          \AttributeTok{min.freq =} \DecValTok{2}\NormalTok{,}
          \AttributeTok{max.words =} \DecValTok{80}\NormalTok{, }
          \AttributeTok{colors =} \FunctionTok{brewer.pal}\NormalTok{(}\DecValTok{8}\NormalTok{, }\StringTok{"Dark2"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{123}
\tightlist
\item
  Analyze the sentiments present in your text sample to determine the overall emotional tone.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reconstruct text for syuzhet or do word{-}by{-}word sentiment if using tidytext lexicon}
\CommentTok{\# Using syuzhet on the original sample lines is often better for context, }
\CommentTok{\# but let\textquotesingle{}s try token{-}based simply for the exercise or just use the lines:}

\CommentTok{\# Extract sentiments from the lines}
\NormalTok{quijote\_sentiments }\OtherTok{\textless{}{-}} \FunctionTok{get\_nrc\_sentiment}\NormalTok{(sample\_lines}\SpecialCharTok{$}\NormalTok{text, }\AttributeTok{language =} \StringTok{"spanish"}\NormalTok{)}

\CommentTok{\# Summarize/Plot}
\NormalTok{quijote\_sentiments }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{everything}\NormalTok{(), sum)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{(}\FunctionTok{everything}\NormalTok{(), }\AttributeTok{names\_to =} \StringTok{"sentiment"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"count"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder}\NormalTok{(sentiment, count), count)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Sentiments in Don Quijote Sample"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\part{Generative AI}\label{part-generative-ai}

\chapter{Data Science in the Age of AI}\label{genai-intro}

The field of Data Science is in a state of constant evolution. We started by learning how to handle vectors and lists in Base R, we moved to the elegance of the \textbf{tidyverse} for data manipulation, and we explored the robustness of \textbf{tidymodels} for machine learning. Now, we are facing a new paradigm shift: \textbf{Generative AI}.

Just as the calculator did not replace the mathematician, Large Language Models (LLMs) will not replace the Data Scientist. However, a Data Scientist using AI will likely replace one who does not.

In this part of the book, we will demystify these ``magic black boxes''. We will learn what they are, how to control them programmatically from R, and how to use them to unlock unstructured data that was previously inaccessible.

\section{What is a Large Language Model?}\label{what-is-a-large-language-model}

To work effectively with LLMs, we must stop treating them as ``people'' and start treating them as \textbf{probabilistic engines}.

\subsection{It's all about Probability}\label{its-all-about-probability}

At its most fundamental level, an LLM like GPT-4, Claude, or Llama is a ``next token prediction machine''. It has been trained on a massive corpus of text (books, websites, code repositories) to answer a simple statistical question:

\begin{quote}
\emph{Given the sequence of text ``The capital of France is\ldots{}'', what is the most likely next piece of text?}
\end{quote}

The model does not ``know'' geography. It knows that, statistically, the token ``Paris'' appears more frequently after that sequence than ``London'' or ``Potato''.

\subsection{Tokens vs.~Words}\label{tokens-vs.-words}

We often think models read words, but they actually process \textbf{tokens}, which can be whole words, fragments, or even spaces. For instance, ``apple'' might be a single token, while a complex word like ``antidisestablishmentarianism'' could be split into four or five. A useful rule of thumb is that \textbf{1,000 tokens are roughly equivalent to 750 words}. This distinction is critical for two reasons: \textbf{Cost}, as you are billed by the token for both input and output; and \textbf{Context Window}, which serves as the model's short-term memory. A model with a 128k context window can effectively ``remember'' about 96,000 words of conversation before it begins to lose track of the beginning.

\subsection{Temperature: Controlling Creativity}\label{temperature-controlling-creativity}

One of the most important parameters you can control is \textbf{Temperature}, which dictates the randomness of the output. A temperature of \textbf{0} makes the model deterministic, always selecting the most probable next token---ideal for tasks requiring precision like data extraction, coding, or math. Conversely, raising the temperature to \textbf{1} or higher encourages the model to take risks and choose less likely tokens, making it suitable for creative writing, brainstorming, and poetry.

\begin{quote}
{[}!TIP{]}
\textbf{For Data Science, start at 0.} When writing code or extracting data, we want reliability, not creativity.
\end{quote}

\section{Setting Up Your AI Environment}\label{setting-up-your-ai-environment}

Before we write code, we must secure our environment. Accessing high-quality models usually requires an API Key (from OpenAI, Anthropic, Google, etc.).

\begin{quote}
{[}!DANGER{]}
\textbf{NEVER} paste your API key directly into your R script. If you push that script to GitHub, bots will steal your key in seconds and drain your bank account.
* \textbf{Anonymize:} If you must use a public tool, rename columns (\texttt{Client\_A}, \texttt{Revenue\_X}) and inject fake values before prompting.
\end{quote}

\subsection{The Solution: Local LLMs}\label{the-solution-local-llms}

For sensitive data, the best solution is running a \textbf{Local LLM} on your own machine using tools like \textbf{Ollama} or \textbf{LM Studio}. This approach ensures 100\% privacy and offline access, though it does come with trade-offs: it requires a capable computer (such as a Mac M-series or NVIDIA GPU), and local models are typically smaller and less capable than massive cloud models like GPT-4.

\subsection{\texorpdfstring{The \texttt{.Renviron} File}{The .Renviron File}}\label{the-.renviron-file}

The standard way to handle secrets in R is the \texttt{.Renviron} file. This file lives in your project's root or your home directory and is not tracked by Git (ensure it is in your \texttt{.gitignore}).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open or create the file using R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usethis}\SpecialCharTok{::}\FunctionTok{edit\_r\_environ}\NormalTok{()}
\end{Highlighting}
\end{Shaded}
\item
  Add your keys in the following format:

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{OPENAI\_API\_KEY}\OperatorTok{=}\StringTok{"sk{-}proj{-}12345..."}
\VariableTok{ANTHROPIC\_API\_KEY}\OperatorTok{=}\StringTok{"sk{-}ant{-}12345..."}
\VariableTok{GITHUB\_PAT}\OperatorTok{=}\StringTok{"ghp\_12345..."}
\end{Highlighting}
\end{Shaded}
\item
  Restart your R session.
\item
  Access them in R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Sys.getenv}\NormalTok{(}\StringTok{"OPENAI\_API\_KEY"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\section{AI as the ``Pair Programmer''}\label{ai-as-the-pair-programmer}

The most immediate value of AI is not replacing your analysis, but accelerating the code you write to perform it.

\subsection{The Great Refactorer}\label{the-great-refactorer}

We all have old code: nested \texttt{for} loops, variable names like \texttt{x1}, \texttt{x2}, and manual indexing. AI excels at modernizing legacy code.

\textbf{Scenario:} You have this Base R code to filter and clean data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Old Code}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"sales.csv"}\NormalTok{)}
\NormalTok{clean\_data }\OtherTok{\textless{}{-}}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{amount }\SpecialCharTok{\textgreater{}} \DecValTok{100}\NormalTok{, ]}
\NormalTok{clean\_data}\SpecialCharTok{$}\NormalTok{date }\OtherTok{\textless{}{-}} \FunctionTok{as.Date}\NormalTok{(clean\_data}\SpecialCharTok{$}\NormalTok{date)}
\NormalTok{final }\OtherTok{\textless{}{-}}\NormalTok{ clean\_data[}\FunctionTok{order}\NormalTok{(clean\_data}\SpecialCharTok{$}\NormalTok{date), ]}
\end{Highlighting}
\end{Shaded}

\textbf{Prompt to AI:}
\textgreater{} ``Refactor this R code to use the \texttt{tidyverse} and the pipe (\texttt{\textbar{}\textgreater{}}) operator. Ensure variable names are snake\_case.''

\textbf{AI Output:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}

\NormalTok{sales\_data }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"sales.csv"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(amount }\SpecialCharTok{\textgreater{}} \DecValTok{100}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{date =} \FunctionTok{as.Date}\NormalTok{(date)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{arrange}\NormalTok{(date)}
\end{Highlighting}
\end{Shaded}

\subsection{The Translator}\label{the-translator}

One of the hardest parts of learning R is knowing \emph{which} package does what you want. You can describe your intent in plain English (or Spanish!) and get the function.

\textbf{Example Prompt:}
\textgreater{} ``I have this R code using \texttt{purrr::map}. Can you explain what it does in simple terms and suggest if there is a more modern way to write it?''

\subsection{Pro Tip: Prompt Engineering 101}\label{pro-tip-prompt-engineering-101}

Getting good code from an LLM isn't magic; it's engineering. A high-quality prompt typically combines four key components. First, establish a \textbf{Role} (``You are an expert R programmer\ldots{}'') to frame the model's perspective. Second, clearly define the \textbf{Task} (``Write a function to\ldots{}''). Third, set explicit \textbf{Constraints} (``Use \texttt{dplyr}, not base R; do not assume clean data''). Finally, specify the desired \textbf{Format} (``Return the code in a single block with comments'') to ensure the output matches your needs.

\begin{quote}
{[}!TIP{]}
\textbf{Iterate.} Your first prompt uses vague terms. Your second prompt clarifies them. Your third prompt gets the perfect answer.
``I have a date column `2023-12-25'. I want to extract the week number of the year. Which \texttt{lubridate} function should I use?''
\end{quote}

\textbf{AI Output:}
\textgreater{} ``You should use \texttt{lubridate::isoweek()} or \texttt{lubridate::week()}.''

\subsection{The Regex Master}\label{the-regex-master}

Regular Expressions (Regex) are powerful but notoriously difficult to write. This is arguably the \emph{best} use case for LLMs.

\textbf{Scenario:} You have a column with messy Peru phone numbers: \texttt{(51)\ 999-999-999}, \texttt{+51\ 999\ 999\ 999}.

\textbf{Prompt:}
\textgreater{} ``I have inconsistent phone numbers. Write a regex compatible with \texttt{stringr} to extract only the 9 digits of the mobile number, ignoring country code.''

\textbf{AI Output:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(stringr)}
\NormalTok{phones }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"(51) 987{-}654{-}321"}\NormalTok{, }\StringTok{"+51 987654321"}\NormalTok{, }\StringTok{"987 654 321"}\NormalTok{)}
\CommentTok{\# The Pattern: Simple extraction of 9 consecutive digits}
\NormalTok{clean\_phones }\OtherTok{\textless{}{-}} \FunctionTok{str\_extract}\NormalTok{(phones, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d\{9\}"}\NormalTok{) }
\FunctionTok{print}\NormalTok{(clean\_phones)}
\CommentTok{\#\textgreater{} [1] NA          "987654321" NA}
\end{Highlighting}
\end{Shaded}

\subsection{The Error Decoder}\label{the-error-decoder}

R error messages can be cryptic.
* \emph{``Error in result{[}{[}1{]}{]} : subscript out of bounds''}
* \emph{``Error: aesthetics must be either length 1 or the same as the data''}

Instead of staring at the screen, paste the error \textbf{and} the code chunk into the AI. It will usually pinpoint the exact mismatch in list lengths or ggplot layers.

\section{The Risks: Hallucinations}\label{the-risks-hallucinations}

We cannot finish this introduction without a warning. LLMs are \textbf{people pleasers}. They want to give you an answer, even if they have to invent it.

\subsection{The ``Package'' Hallucination}\label{the-package-hallucination}

It is common for an LLM to invent an R function that \emph{should} exist but doesn't.

\begin{quote}
\textbf{User:} ``How do I calculate the Gini coefficient in \texttt{dplyr}?''
\textbf{AI:} ``Just use \texttt{summarize(gini\ =\ gini\_coeff(income))}!''
\end{quote}

There is no \texttt{gini\_coeff} function in \texttt{dplyr} default exports. It sounded plausible, but running it will crash your script. \textbf{Always verify functions in the Help tab (\texttt{?function\_name}).}

In the next chapter, we will stop chatting and start coding. We will build an engine to send data to the AI and get structured insights back.

\begin{verbatim}
# LLMs as an Analysis Engine {#genai-api}

In the previous chapter, we treated AI as a chatbot that helps us write code. Now, we are going to flip the script. We will treat the Large Language Model as a **function** within our R code—a function that accepts unstructured text as input and returns structured data as output. This approach turns unstructured text into structured data with minimal code.

This is the transition from "Chatting with AI" to "Building with AI".

## The API Economy

To interact with models programmatically, we use **APIs** (Application Programming Interfaces). Instead of a web interface, we send HTTP requests.

While there are R packages like `openai`, `ellmer` or `chattr` that wrap these APIs, as a Data Scientist it is critical to understand how to build the connection yourself using `httr2`. This gives you full control over error handling, retries, and costs.

### Prerequisite: The Setup

Ensure you have your API key stored in the `.Renviron` file as discussed in the previous chapter.


``` r
library(tidyverse)
library(httr2)
library(jsonlite)

# Reload environment if needed
readRenviron(".Renviron")
\end{verbatim}

\section{Building a Robust Request}\label{building-a-robust-request}

A production-quality API request needs more than just a URL. It needs \textbf{Authentication}, \textbf{Retry Logic}, and \textbf{Error Handling}.

Let's build a wrapper function to query OpenAI's GPT-4o-mini (a cost-effective model).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{query\_openai }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(prompt, }\AttributeTok{system\_prompt =} \StringTok{"You are a helpful assistant."}\NormalTok{) \{}
  
\NormalTok{  api\_key }\OtherTok{\textless{}{-}} \FunctionTok{Sys.getenv}\NormalTok{(}\StringTok{"OPENAI\_API\_KEY"}\NormalTok{)}
  
  \ControlFlowTok{if}\NormalTok{ (api\_key }\SpecialCharTok{==} \StringTok{""}\NormalTok{) }\FunctionTok{stop}\NormalTok{(}\StringTok{"Error: OPENAI\_API\_KEY not found in environment."}\NormalTok{)}
  
  \CommentTok{\# 1. Construct the Request}
\NormalTok{  req }\OtherTok{\textless{}{-}} \FunctionTok{request}\NormalTok{(}\StringTok{"https://api.openai.com/v1/chat/completions"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{req\_headers}\NormalTok{(}\AttributeTok{Authorization =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Bearer"}\NormalTok{, api\_key)) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{req\_body\_json}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
      \AttributeTok{model =} \StringTok{"gpt{-}4o{-}mini"}\NormalTok{,}
      \AttributeTok{messages =} \FunctionTok{list}\NormalTok{(}
        \FunctionTok{list}\NormalTok{(}\AttributeTok{role =} \StringTok{"system"}\NormalTok{, }\AttributeTok{content =}\NormalTok{ system\_prompt),}
        \FunctionTok{list}\NormalTok{(}\AttributeTok{role =} \StringTok{"user"}\NormalTok{, }\AttributeTok{content =}\NormalTok{ prompt)}
\NormalTok{      ),}
      \AttributeTok{temperature =} \DecValTok{0} \CommentTok{\# Deterministic for data tasks}
\NormalTok{    )) }\SpecialCharTok{|\textgreater{}} 
    \CommentTok{\# 2. Add Robustness: Retry 3 times if server fails (500) or rate limited (429)}
    \FunctionTok{req\_retry}\NormalTok{(}\AttributeTok{max\_tries =} \DecValTok{3}\NormalTok{, }\AttributeTok{backoff =} \SpecialCharTok{\textasciitilde{}} \DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \CommentTok{\# Exponential backoff}
    \FunctionTok{req\_throttle}\NormalTok{(}\AttributeTok{rate =} \DecValTok{100}\SpecialCharTok{/}\DecValTok{60}\NormalTok{) }\CommentTok{\# 100 requests per minute}
  
  \CommentTok{\# 3. Perform Request \& Handle Errors}
\NormalTok{  response }\OtherTok{\textless{}{-}} \FunctionTok{req\_perform}\NormalTok{(req)}
  
  \CommentTok{\# 4. Parse the content}
\NormalTok{  result }\OtherTok{\textless{}{-}}\NormalTok{ response }\SpecialCharTok{|\textgreater{}} \FunctionTok{resp\_body\_json}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(result}\SpecialCharTok{$}\NormalTok{choices[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{message}\SpecialCharTok{$}\NormalTok{content)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Now we have a function \texttt{query\_openai()} that we can use like any other R function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{query\_openai}\NormalTok{(}\StringTok{"What is the capital of Peru?"}\NormalTok{)}
\CommentTok{\# [1] "The capital of Peru is Lima."}
\end{Highlighting}
\end{Shaded}

\section{The Holy Grail: Structured Data extraction}\label{the-holy-grail-structured-data-extraction}

The biggest problem with LLMs is that they love to talk. If you ask for a sentiment score, they might say: \emph{``Here is the sentiment score you requested based on my analysis: Positive.''}

We don't want that. We want \texttt{"Positive"}. Or even better, we want a JSON object.

\subsection{Forcing JSON Output}\label{forcing-json-output}

Most modern models support ``JSON Mode''. This guarantees the output is machine-readable valid JSON.

Let's say we have a dataset of raw customer reviews and want to extract specific insights. We need to capture the \textbf{Sentiment} (Positive or Negative), a list of mentioned \textbf{Topics}, and the \textbf{Urgency} level---flagging it as `High' if the user is angry or at risk of churning, and `Low' otherwise.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{extract\_review\_data }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(review\_text) \{}
  
\NormalTok{  system\_instructions }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  You are a data extraction engine. }
\StringTok{  Extract the following fields from the user review and return ONLY a JSON object:}
\StringTok{  {-} sentiment: \textquotesingle{}Positive\textquotesingle{}, \textquotesingle{}Neutral\textquotesingle{}, or \textquotesingle{}Negative\textquotesingle{}}
\StringTok{  {-} topics: a list of strings (e.g., [\textquotesingle{}Price\textquotesingle{}, \textquotesingle{}UX\textquotesingle{}])}
\StringTok{  {-} urgency: \textquotesingle{}High\textquotesingle{} if the user is angry/churning, else \textquotesingle{}Low\textquotesingle{}}
\StringTok{  "}
  
  \CommentTok{\# Note: To enforce strict JSON, we often need to tell the model in the prompt}
  \CommentTok{\# AND set response\_format = \{ type: \textquotesingle{}json\_object\textquotesingle{} \} if supported.}
  
\NormalTok{  response\_json }\OtherTok{\textless{}{-}} \FunctionTok{query\_openai}\NormalTok{(review\_text, }\AttributeTok{system\_label =}\NormalTok{ system\_instructions)}
  
  \CommentTok{\# Parse JSON string to R list}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{fromJSON}\NormalTok{(response\_json))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{\texorpdfstring{Batch Processing: The \texttt{purrr} Workflow}{Batch Processing: The purrr Workflow}}\label{batch-processing-the-purrr-workflow}

Now, let's apply this to a Data Frame. When processing hundreds of rows, we \textbf{must} be careful.

Now, let's apply this to a Data Frame. When processing hundreds of rows, we must be careful. First, we need to respect \textbf{Rate Limits}, as APIs will block you if you send too many requests too quickly (e.g., 1000 in a second). Second, consider \textbf{Cost} by always testing on a small sample like \texttt{head(df,\ 5)} before running the full job. Finally, ensure \textbf{Error Safety}: if row 99 fails, we want to capture that error gracefully so the entire loop doesn't crash.

We use \texttt{purrr::map} with \texttt{possibly()} (or \texttt{safely()}) generally, but for API calls, adding a small \texttt{Sys.sleep()} is wise.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sample Data}
\NormalTok{reviews\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{,}
  \AttributeTok{text =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"I love this product! Best purchase ever."}\NormalTok{,}
    \StringTok{"The delivery was late and the item is broken. I want a refund."}\NormalTok{,}
    \StringTok{"It\textquotesingle{}s okay, but a bit expensive for what it is."}
\NormalTok{  )}
\NormalTok{)}

\CommentTok{\# 1. Create a Safe Function (returns NULL instead of crashing)}
\NormalTok{safe\_extract }\OtherTok{\textless{}{-}} \FunctionTok{possibly}\NormalTok{(extract\_review\_data, }\AttributeTok{otherwise =} \ConstantTok{NULL}\NormalTok{)}

\CommentTok{\# 2. Iterate}
\NormalTok{results\_df }\OtherTok{\textless{}{-}}\NormalTok{ reviews\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ai\_data =} \FunctionTok{map}\NormalTok{(text, }\ControlFlowTok{function}\NormalTok{(t) \{}
    \FunctionTok{Sys.sleep}\NormalTok{(}\FloatTok{0.5}\NormalTok{) }\CommentTok{\# Be polite to the API}
    \FunctionTok{safe\_extract}\NormalTok{(t)}
\NormalTok{  \})) }\SpecialCharTok{|\textgreater{}} 
  \CommentTok{\# 3. Unnest the JSON structure}
  \FunctionTok{unnest\_wider}\NormalTok{(ai\_data)}

\FunctionTok{print}\NormalTok{(results\_df)}
\end{Highlighting}
\end{Shaded}

\textbf{Resulting Data Frame:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
id & text & sentiment & topics & urgency \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & I love\ldots{} & Positive & {[}``Product''{]} & Low \\
2 & The delivery\ldots{} & Negative & {[}``Shipping'', ``Product''{]} & High \\
3 & It's okay\ldots{} & Neutral & {[}``Price''{]} & Low \\
\end{longtable}
}

\section{Summary}\label{summary}

We have turned an unstructured text column into usable columns for filtering and plotting. This is the true power of ``LLMs as Data Engines''.

\begin{itemize}
\tightlist
\item
  We use \texttt{httr2} for robust connections.
\item
  We use System Prompts to force JSON structure.
\item
  We use \texttt{purrr} and \texttt{unnest\_wider} to flatten that AI insight back into our Tidyverse workflow.
\end{itemize}

In the next chapter, we will discuss Ethics. But before that, there is one more superpower we need to unlock: \textbf{Embeddings}.

\section{Beyond Generation: Embeddings}\label{beyond-generation-embeddings}

So far, we have used LLMs to \emph{generate} text. But they can also \emph{understand} text by converting it into numbers. This is called an \textbf{Embedding}.

An embedding is a list of numbers (a vector, e.g., 1536 numbers long) that represents the semantic meaning of a text.

Consider the difference between a ``Dog'' and a ``Puppy''; their corresponding vectors will be mathematically very close because they share similar semantic meanings. In contrast, ``Dog'' and ``Sandwich'' will be far apart. This capability powers \textbf{Semantic Search}. Unlike a standard keyword search that looks for exact matches like ``Climate'' or ``Change''---and potentially misses relevant documents---a semantic search converts your query into a vector. It then finds documents with the closest vectors, allowing you to retrieve a report on ``Global warming effect on maize'' even if it doesn't contain the exact words from your query ``Climate change impact on corn.''

\subsection{R Implementation}\label{r-implementation}

Getting an embedding is just another API call:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get\_embedding }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(text) \{}
\NormalTok{  req }\OtherTok{\textless{}{-}} \FunctionTok{request}\NormalTok{(}\StringTok{"https://api.openai.com/v1/embeddings"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{req\_headers}\NormalTok{(}\AttributeTok{Authorization =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Bearer"}\NormalTok{, }\FunctionTok{Sys.getenv}\NormalTok{(}\StringTok{"OPENAI\_API\_KEY"}\NormalTok{))) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{req\_body\_json}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
      \AttributeTok{model =} \StringTok{"text{-}embedding{-}3{-}small"}\NormalTok{,}
      \AttributeTok{input =}\NormalTok{ text}
\NormalTok{    ))}
  
\NormalTok{  resp }\OtherTok{\textless{}{-}} \FunctionTok{req\_perform}\NormalTok{(req)}
  \CommentTok{\# Extract the vector}
\NormalTok{  resp }\SpecialCharTok{|\textgreater{}} \FunctionTok{resp\_body\_json}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{pluck}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"embedding"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \FunctionTok{unlist}\NormalTok{()}
\NormalTok{\}}

\NormalTok{v1 }\OtherTok{\textless{}{-}} \FunctionTok{get\_embedding}\NormalTok{(}\StringTok{"The dog barked"}\NormalTok{)}
\NormalTok{v2 }\OtherTok{\textless{}{-}} \FunctionTok{get\_embedding}\NormalTok{(}\StringTok{"The canine made noise"}\NormalTok{)}
\CommentTok{\# cosine\_sim \textless{}{-} sum(v1 * v2) / (sqrt(sum(v1\^{}2)) * sqrt(sum(v2\^{}2)))}
\CommentTok{\# The result will be very high (close to 1).}
\end{Highlighting}
\end{Shaded}

This vectorization is the foundation of \textbf{RAG (Retrieval Augmented Generation)}, which allows you to chat with your own PDFs.

\chapter{Text Analysis with Embeddings}\label{genai-embeddings}

In the previous chapters, we learned how to generate text and how to extract data from it. But what if we want to \emph{understand} the relationship between thousands of documents without reading them?

This is where \textbf{Embeddings} come in. They are arguably the most powerful yet underutilized tool in the AI toolkit for Data Scientists.

\section{Beyond Bag-of-Words}\label{beyond-bag-of-words}

Traditional text mining techniques, such as word clouds or TF-IDF, treat text as a simple ``bag of words,'' ignoring context. For example, the sentence ``I sat on the \textbf{bank} of the river'' and ``I went to the \textbf{bank} to deposit money'' are treated as identical because they both contain the word ``bank,'' even though the meaning offers a completely different context. To a human---and to an Embedding model---these distinctions are clear.

\section{What is an Embedding?}\label{what-is-an-embedding}

An embedding is a translation of text into a \textbf{vector of numbers}.

Imagine plotting words on a hypothetical 2D graph based on their meaning. In this space, \textbf{King} might sit at coordinates \texttt{(5,\ 5)}, with \textbf{Queen} located nearby at \texttt{(5,\ 7)} due to their semantic similarity. \textbf{Apple}, unrelated to royalty, would be positioned far away at \texttt{(10,\ 2)}. Modern embedding models like OpenAI's \texttt{text-embedding-3-small} scale this concept up massively, placing words not in two dimensions, but in \textbf{1,536 dimensions}. This high-dimensional space allows them to capture subtle nuances of meaning, tone, and context that simple coordinates cannot.

\section{Getting Embeddings in R}\label{getting-embeddings-in-r}

We can request embeddings using the same \texttt{httr2} workflow we built in the previous chapter, but hitting the \texttt{/embeddings} endpoint.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get\_embedding }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(text\_input) \{}
  
\NormalTok{  api\_key }\OtherTok{\textless{}{-}} \FunctionTok{Sys.getenv}\NormalTok{(}\StringTok{"OPENAI\_API\_KEY"}\NormalTok{)}
  
\NormalTok{  req }\OtherTok{\textless{}{-}} \FunctionTok{request}\NormalTok{(}\StringTok{"https://api.openai.com/v1/embeddings"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{req\_headers}\NormalTok{(}\AttributeTok{Authorization =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Bearer"}\NormalTok{, api\_key)) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{req\_body\_json}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
      \AttributeTok{model =} \StringTok{"text{-}embedding{-}3{-}small"}\NormalTok{,}
      \AttributeTok{input =}\NormalTok{ text\_input}
\NormalTok{    ))}
  
\NormalTok{  resp }\OtherTok{\textless{}{-}} \FunctionTok{req\_perform}\NormalTok{(req)}
\NormalTok{  result }\OtherTok{\textless{}{-}}\NormalTok{ resp }\SpecialCharTok{|\textgreater{}} \FunctionTok{resp\_body\_json}\NormalTok{()}
  
  \CommentTok{\# The embedding is a list of numbers}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(result}\SpecialCharTok{$}\NormalTok{data[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{embedding))}
\NormalTok{\}}

\CommentTok{\# Example}
\NormalTok{vector\_dog }\OtherTok{\textless{}{-}} \FunctionTok{get\_embedding}\NormalTok{(}\StringTok{"The dog barked"}\NormalTok{)}
\FunctionTok{length}\NormalTok{(vector\_dog) }
\CommentTok{\# [1] 1536}
\end{Highlighting}
\end{Shaded}

\section{Visualizing Meaning (Dimensionality Reduction)}\label{visualizing-meaning-dimensionality-reduction}

We cannot visualize 1,536 dimensions. But we can use mathematical techniques like \textbf{PCA} (Principal Component Analysis) or \textbf{UMAP} to squash those dimensions down to 2, preserving relative distances.

Let's assume we have a dataframe \texttt{news\_df} with headlines and their calculated embeddings.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidymodels)}

\CommentTok{\# Assume \textquotesingle{}embeddings\_mat\textquotesingle{} is a matrix where each row is an embedding vector}
\NormalTok{pca\_rec }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{., }\AttributeTok{data =} \FunctionTok{as.data.frame}\NormalTok{(embeddings\_mat)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{step\_pca}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{(), }\AttributeTok{num\_comp =} \DecValTok{2}\NormalTok{)}

\NormalTok{pca\_prep }\OtherTok{\textless{}{-}} \FunctionTok{prep}\NormalTok{(pca\_rec)}
\NormalTok{pca\_data }\OtherTok{\textless{}{-}} \FunctionTok{bake}\NormalTok{(pca\_prep, }\AttributeTok{new\_data =} \ConstantTok{NULL}\NormalTok{)}

\CommentTok{\# Add back the text labels}
\NormalTok{plot\_data }\OtherTok{\textless{}{-}}\NormalTok{ pca\_data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{bind\_cols}\NormalTok{(news\_df }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(headline, category))}

\CommentTok{\# Plot}
\NormalTok{plot\_data }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ PC1, }\AttributeTok{y =}\NormalTok{ PC2, }\AttributeTok{color =}\NormalTok{ category)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.8}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Map of News Headlines"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If we did this correctly, we would see distinct ``clusters''. Sports news would cluster in one corner, politics in another, and technology in a third---even if they never share the exact same keywords!

\section{Building a Semantic Search Engine}\label{building-a-semantic-search-engine}

The ``Hello World'' of Embeddings is \textbf{Semantic Search}, which fundamentally differs from traditional approaches. While a \textbf{Keyword Search} for ``cheap phone'' rigidly looks for the exact words ``cheap'' AND ``phone,'' a \textbf{Semantic Search} for ``budget friendly mobile'' understands the underlying intent---that ``budget'' relates to ``cheap'' and ``mobile'' to ``phone.''

Mathematically, this is calculated using \textbf{Cosine Similarity}. The closer the angle between two vectors, the more similar their meaning.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Function to calculate Cosine Similarity}
\NormalTok{cosine\_sim }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(a, b) \{}
  \FunctionTok{sum}\NormalTok{(a }\SpecialCharTok{*}\NormalTok{ b) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(a}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(b}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)))}
\NormalTok{\}}

\NormalTok{search\_news }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(query, data\_vectors, data\_text) \{}
  
  \CommentTok{\# 1. Embed the query}
\NormalTok{  query\_vec }\OtherTok{\textless{}{-}} \FunctionTok{get\_embedding}\NormalTok{(query)}
  
  \CommentTok{\# 2. Compare against all document vectors}
\NormalTok{  similarities }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(data\_vectors, }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(doc\_vec) \{}
    \FunctionTok{cosine\_sim}\NormalTok{(query\_vec, doc\_vec)}
\NormalTok{  \})}
  
  \CommentTok{\# 3. Return top 3 matches}
\NormalTok{  results }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{text =}\NormalTok{ data\_text,}
    \AttributeTok{score =}\NormalTok{ similarities}
\NormalTok{  ) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(score)) }\SpecialCharTok{|\textgreater{}} 
    \FunctionTok{head}\NormalTok{(}\DecValTok{3}\NormalTok{)}
  
  \FunctionTok{return}\NormalTok{(results)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Now you can search for concepts, not just keywords!

\section{Summary: The AI Workflow}\label{summary-the-ai-workflow}

We have completed our journey through Generative AI in R.

We have completed our journey through Generative AI in R, covering three foundational pillars. We started by understanding that \textbf{Foundations} of models are probabilistic engines predicting tokens, not reasoning beings. Then, we moved to \textbf{APIs}, building robust pipelines to extract structured JSON data from unstructured text. Finally, we explored \textbf{Embeddings}, learning to represent text as numerical vectors to enable powerful search and clustering by meaning.

The future of Data Science is hybrid. It combines the statistical rigor of tools like \texttt{tidymodels} with the semantic understanding of Large Language Models. You are now equipped to build that future.

\part{Real Cases}\label{part-real-cases}

\chapter*{Introduction}\label{introduction-3}


Having mastered the fundamentals of R programming, data transformation, and visualization, it's time to put these skills into practice with real-world scenarios. The following case studies demonstrate end-to-end data science workflows that you might encounter in professional settings.

\textbf{In this chapter, you will:}

\begin{itemize}
\tightlist
\item
  Connect R to external APIs (Google Analytics) for automated data retrieval.
\item
  Apply cleaning, transformation, and visualization to real estate market data.
\item
  Practice the full workflow: problem definition → data access → analysis → insights.
\end{itemize}

Each case introduces complementary libraries such as \texttt{googleAnalyticsR} for API access and \texttt{lubridate} for date manipulation, reinforcing patterns from earlier chapters while adding new practical tools.

\chapter{Case Study: Real Estate Market Analysis}\label{case-study-real-estate-market-analysis}

In this case study, we will apply our data transformation and visualization skills to analyzing the real estate market. We will use the \texttt{txhousing} dataset provided by the \texttt{ggplot2} package, which contains information about housing sales in Texas.

This dataset allows us to explore concepts like tracking value over time, comparing categories, and analyzing transaction volume---skills that transfer directly to financial analysis, sales reporting, and business intelligence.

\section{Objectives}\label{objectives}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Data Cleaning}: Handle missing values and format dates.
\item
  \textbf{Transformation}: Aggregate data by city and year to find trends.
\item
  \textbf{Visualization}: Create time-series plots to analyze market health.
\item
  \textbf{Analysis}: Identify cities with the highest growth and stability.
\end{enumerate}

\section{Loading Libraries}\label{loading-libraries}

We will use the core \texttt{tidyverse} libraries.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(scales)}
\FunctionTok{library}\NormalTok{(ggthemes)}
\end{Highlighting}
\end{Shaded}

\section{Exploring the Data}\label{exploring-the-data}

First, let's load and inspect the data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(}\StringTok{"txhousing"}\NormalTok{)}
\FunctionTok{glimpse}\NormalTok{(txhousing)}
\CommentTok{\#\textgreater{} Rows: 8,602}
\CommentTok{\#\textgreater{} Columns: 9}
\CommentTok{\#\textgreater{} $ city      \textless{}chr\textgreater{} "Abilene", "Abilene", "Abilene", "Abilene", "Abilene", "Abil\textasciitilde{}}
\CommentTok{\#\textgreater{} $ year      \textless{}int\textgreater{} 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, \textasciitilde{}}
\CommentTok{\#\textgreater{} $ month     \textless{}int\textgreater{} 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7, \textasciitilde{}}
\CommentTok{\#\textgreater{} $ sales     \textless{}dbl\textgreater{} 72, 98, 130, 98, 141, 156, 152, 131, 104, 101, 100, 92, 75, \textasciitilde{}}
\CommentTok{\#\textgreater{} $ volume    \textless{}dbl\textgreater{} 5380000, 6505000, 9285000, 9730000, 10590000, 13910000, 1263\textasciitilde{}}
\CommentTok{\#\textgreater{} $ median    \textless{}dbl\textgreater{} 71400, 58700, 58100, 68600, 67300, 66900, 73500, 75000, 6450\textasciitilde{}}
\CommentTok{\#\textgreater{} $ listings  \textless{}dbl\textgreater{} 701, 746, 784, 785, 794, 780, 742, 765, 771, 764, 721, 658, \textasciitilde{}}
\CommentTok{\#\textgreater{} $ inventory \textless{}dbl\textgreater{} 6.3, 6.6, 6.8, 6.9, 6.8, 6.6, 6.2, 6.4, 6.5, 6.6, 6.2, 5.7, \textasciitilde{}}
\CommentTok{\#\textgreater{} $ date      \textless{}dbl\textgreater{} 2000.000, 2000.083, 2000.167, 2000.250, 2000.333, 2000.417, \textasciitilde{}}
\end{Highlighting}
\end{Shaded}

The dataset contains:
- \texttt{city}: Name of the city.
- \texttt{year}, \texttt{month}: Date components.
- \texttt{sales}: Number of sales.
- \texttt{volume}: Total value of sales.
- \texttt{median}: Median sale price.
- \texttt{listings}: Total active listings.
- \texttt{inventory}: ``Months inventory'': amount of time it would take to sell all current listings at current sales pace.
- \texttt{date}: Date in decimal format (e.g., 2000.08).

\section{Data Cleaning}\label{data-cleaning}

Real-world data often has missing values (\texttt{NA}). Let's check how many missing values we have in the \texttt{sales} column.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(txhousing}\SpecialCharTok{$}\NormalTok{sales))}
\CommentTok{\#\textgreater{} [1] 568}
\end{Highlighting}
\end{Shaded}

We see there are records with no sales data. For our analysis of market volume, we should remove these incomplete records. We will creating a clean dataset \texttt{housing\_clean}.

We will also create a proper \texttt{date} column using \texttt{lubridate::make\_date()}, which is easier to work with than the decimal date.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{housing\_clean }\OtherTok{\textless{}{-}}\NormalTok{ txhousing }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(sales)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{date\_proper =} \FunctionTok{make\_date}\NormalTok{(year, month, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{date) }\CommentTok{\# Remove the decimal date}
\end{Highlighting}
\end{Shaded}

\section{Exploratory Analysis}\label{exploratory-analysis}

\subsection{Market Volume Over Time}\label{market-volume-over-time}

Let's look at the total sales volume across all of Texas over time. This gives us a ``macro'' view of the market, similar to how we might look at total portfolio value in a financial context.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Aggregate by date}
\NormalTok{total\_market }\OtherTok{\textless{}{-}}\NormalTok{ housing\_clean }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(date\_proper) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{total\_sales =} \FunctionTok{sum}\NormalTok{(sales),}
    \AttributeTok{total\_volume =} \FunctionTok{sum}\NormalTok{(volume, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\CommentTok{\# Plot Volume}
\NormalTok{total\_market }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date\_proper, }\AttributeTok{y =}\NormalTok{ total\_volume)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{labels =} \FunctionTok{label\_dollar}\NormalTok{(}\AttributeTok{scale =} \FloatTok{1e{-}9}\NormalTok{, }\AttributeTok{suffix =} \StringTok{"B"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Total Texas Housing Market Volume"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Monthly Total Sales Volume (Billions)"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"Year"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Volume ($)"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-806-1} \end{center}

We can clearly see the seasonality (peaks in summer) and the impact of the 2008 financial crisis (dip around 2008-2010), followed by a strong recovery.

\subsection{Comparing Cities}\label{comparing-cities}

Just as we might compare different companies or portfolios, let's compare the median housing prices in the major cities. We'll focus on the ``Big 4'' Texas cities: Austin, Dallas, Houston, and San Antonio.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{major\_cities }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Austin"}\NormalTok{, }\StringTok{"Dallas"}\NormalTok{, }\StringTok{"Houston"}\NormalTok{, }\StringTok{"San Antonio"}\NormalTok{)}

\NormalTok{city\_trends }\OtherTok{\textless{}{-}}\NormalTok{ housing\_clean }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(city }\SpecialCharTok{\%in\%}\NormalTok{ major\_cities)}

\NormalTok{city\_trends }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date\_proper, }\AttributeTok{y =}\NormalTok{ median, }\AttributeTok{color =}\NormalTok{ city)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{labels =} \FunctionTok{label\_dollar}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Median Housing Prices in Major Cities"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"Year"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Median Price"}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"City"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-807-1} \end{center}

Austin (green) clearly shows the steepest growth curve, especially post-2012.

\section{Creating Indicators}\label{creating-indicators}

In financial analysis, we often create ratios. Here, let's look at \textbf{Inventory}, which is a measure of supply vs.~demand.
- \textbf{High Inventory}: Buyer's market (prices might drop).
- \textbf{Low Inventory}: Seller's market (prices might rise).

Let's look at the average inventory per year for these cities.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{city\_inventory }\OtherTok{\textless{}{-}}\NormalTok{ city\_trends }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{group\_by}\NormalTok{(city, year) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{avg\_inventory =} \FunctionTok{mean}\NormalTok{(inventory, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{), }\AttributeTok{.groups =} \StringTok{"drop"}\NormalTok{)}

\NormalTok{city\_inventory }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ year, }\AttributeTok{y =}\NormalTok{ avg\_inventory, }\AttributeTok{color =}\NormalTok{ city)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{linewidth =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_fivethirtyeight}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Market Health: Months of Inventory"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Lower means easier to sell (Seller\textquotesingle{}s Market)"}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"City"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{Data-Science-with-R_files/figure-latex/unnamed-chunk-808-1} \end{center}

We see a convergence around 2014-2015 where inventory became very tight across all major cities.

\section{Try It Yourself}\label{try-it-yourself}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Expand the Analysis}: Add ``Fort Worth'' to \texttt{major\_cities} and re-run the median price comparison. How does it compare to the Big 4?
\item
  \textbf{Calculate Growth}: Compute the year-over-year percentage change in median price for Austin. Which year had the highest growth?
\item
  \textbf{Seasonality Deep Dive}: Which month typically has the highest sales volume? Create a boxplot of sales by month to visualize seasonal patterns.
\end{enumerate}

\section{Conclusions}\label{conclusions}

Through this case study, we performed essential Data Science tasks on a real dataset:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Cleaning}: Handling \texttt{NA} values and formatting dates with \texttt{lubridate}.
\item
  \textbf{Aggregation}: Summarizing billions of dollars of volume into clear trend lines.
\item
  \textbf{Comparison}: Benchmarking cities against each other to identify leaders.
\item
  \textbf{Indicators}: Creating business-relevant metrics like months of inventory.
\end{enumerate}

\begin{quote}
{[}!TIP{]}
This exact workflow applies to countless domains: stock prices, customer churn, inventory management, or any time-series business data. Master the pattern here, and you can adapt it anywhere.
\end{quote}

\chapter{Google Analytics from R}\label{google-analytics-from-r}

Understanding the audience that enters our website helps us make better decisions, whether these are commercial or content release decisions. We can, thus, insert a visit counter or use Google Analytics to start collecting much more than the total visits.

\section{Problem}\label{problem}

We have a website to which we already placed the Google Analytics code to understand visit statistics to my website, but I want reports that today the web does not provide us. We need to access the raw data to represent our own reports and access them even without having to enter the Google Analytics website.

\begin{quote}
{[}!IMPORTANT{]}
Google sunsetted Universal Analytics in July 2023. The \texttt{googleAnalyticsR} package now supports GA4. The concepts here remain valid, but the specific function parameters may differ. See the \href{https://code.markedmondson.me/googleAnalyticsR/}{package documentation} for GA4-specific usage.
\end{quote}

\section{Access to data}\label{access-to-data}

We are going to assume for this case that we already have a google analytics account and we are already tracking data from our website through some view. For this case I am going to use the statistics to the website that you are currently reading.

To access the Google Analytics data we will use the \href{http://code.markedmondson.me/googleAnalyticsR/articles/v4.html}{\texttt{googleAnalyticsR}} library. In addition, to quickly manipulate dates from or to we will use the \texttt{lubridate} library.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"googleAnalyticsR"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(googleAnalyticsR)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Then, we have to authenticate. To do this we will use the \texttt{ga\_auth()} function, which will open a web page to log in with the account in which we have access to Google Analytics.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ga\_auth}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Now that we are authenticated we can bring all our accounts using the \texttt{ga\_account\_list()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{account\_list }\OtherTok{\textless{}{-}} \FunctionTok{ga\_account\_list}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

From here we will search for the row of the website that interests us and from there we will obtain the \texttt{propertyId} column. The Property ID in Google Analytics 4 for this website is the following:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{property\_id }\OtherTok{\textless{}{-}} \DecValTok{123456789} \CommentTok{\# Replace with your GA4 Property ID}
\end{Highlighting}
\end{Shaded}

Finally, we need two variables of the date from when to when we want the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{from\_date }\OtherTok{\textless{}{-}} \StringTok{"2024{-}01{-}01"}
\NormalTok{to\_date }\OtherTok{\textless{}{-}} \StringTok{"2024{-}03{-}31"}
\end{Highlighting}
\end{Shaded}

Or if we wish we can only calculate the information of the last two months, or two days, etc.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Two months ago until now}
\CommentTok{\# Two months ago until now}
\NormalTok{from\_date }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{today}\NormalTok{() }\SpecialCharTok{{-}} \FunctionTok{months}\NormalTok{(}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} \FunctionTok{as.character}\NormalTok{()}
\NormalTok{to\_date }\OtherTok{\textless{}{-}} \FunctionTok{today}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{as.character}\NormalTok{()}

\NormalTok{from\_date}
\NormalTok{to\_date}
\end{Highlighting}
\end{Shaded}

Thus, we can already make a call to obtain the data we need using the \texttt{ga\_data()} function (the standard for GA4).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{history }\OtherTok{\textless{}{-}} \FunctionTok{ga\_data}\NormalTok{(property\_id,}
                 \AttributeTok{date\_range =} \FunctionTok{c}\NormalTok{(from\_date, to\_date),}
                 \AttributeTok{metrics =} \StringTok{"activeUsers"}\NormalTok{,}
                 \AttributeTok{dimensions =} \StringTok{"date"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

With this data frame we could filter it or visualize it, depending on what we need.

\section{Visualization}\label{visualization}

Now with access to the data we can use the multiple \href{https://ga-dev-tools.appspot.com/dimensions-metrics-explorer/}{metrics and dimensions available}. For this case we are going to exemplify visualizing the city from where they visit this website in the last 90 days, which is related to the information in the paragraph of the main page, the preface, of this website (however, for that other calculation it is performed for another period of time).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Last 90 days to date}
\NormalTok{from\_date }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\FunctionTok{now}\NormalTok{(), }\AttributeTok{length =} \DecValTok{2}\NormalTok{, }\AttributeTok{by =} \StringTok{"{-}90 days"}\NormalTok{)[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_date}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{as.character}\NormalTok{()}
\NormalTok{to\_date }\OtherTok{\textless{}{-}} \FunctionTok{now}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_date}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{as.character}\NormalTok{()}

\CommentTok{\# We add the city as a dimension}
\NormalTok{history }\OtherTok{\textless{}{-}} \FunctionTok{ga\_data}\NormalTok{(property\_id,}
                 \AttributeTok{date\_range =} \FunctionTok{c}\NormalTok{(from\_date, to\_date),}
                 \AttributeTok{metrics =} \StringTok{"activeUsers"}\NormalTok{,}
                 \AttributeTok{dimensions =} \StringTok{"city"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

As we see, the dimension also allows a vector as input. We will create a \textbf{bar chart} with the top 5 cities that visited this website in the last 90 days.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{history }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(city }\SpecialCharTok{!=} \StringTok{"(not set)"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(city) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{total =} \FunctionTok{sum}\NormalTok{(activeUsers)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{proportion =}\NormalTok{ total }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(total)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{5}\NormalTok{, }\AttributeTok{wt =}\NormalTok{ proportion) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{city =} \FunctionTok{reorder}\NormalTok{(city, proportion, sum)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{aes}\NormalTok{(proportion, city) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Proportion of visits"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Proportion of visits by city"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{""}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Keep in mind that in this case there is an issue of recognition of IPs coming from Lima, Peru, and that is why they do not appear as the first visitor. At the time of performing this analysis they all appeared as ``(not set)''. However, if the same analysis is done by country and not by city, Peru is recognized and appears as one of the top visiting the web.

\section{Conclusion}\label{conclusion}

Accessing Google Analytics data programmatically opens powerful possibilities:

\begin{itemize}
\tightlist
\item
  \textbf{Automated Reporting}: Schedule R scripts to generate weekly/monthly reports.
\item
  \textbf{Custom Metrics}: Combine GA data with internal business data for richer analysis.
\item
  \textbf{Interactive Dashboards}: Use Shiny to create real-time analytics dashboards.
\end{itemize}

With the \texttt{googleAnalyticsR} package, you can query any metric or dimension available in your GA account, transforming raw clickstream data into actionable business insights---all without leaving your R environment.

\chapter{Appendix A: Responsible AI Checklist}\label{ethics-checklist}

As we conclude this book, it is crucial to remember that technical skills are only half of the equation. Data science has real-world consequences. Before deploying any model, analysis, or reliable pipeline to production, use this checklist to ensure your work is robust, fair, and transparent.

This checklist is designed to be actionable for R users, pointing to specific packages and practices where applicable.

\section{Data Quality \& Lineage}\label{data-quality-lineage}

\begin{itemize}
\item
  ``Garbage in, garbage out'' applies to ethics as well as accuracy.*
\item[$\square$]
  \textbf{Provenance:} Do I know exactly where this data came from? Is the source trustworthy?
\item[$\square$]
  \textbf{Consent \& Privacy:} Was the data collected with consent? Does it contain Personally Identifiable Information (PII)?

  \begin{itemize}
  \tightlist
  \item
    \emph{Tip:} Use packages like \texttt{introdat} or custom scripts to scan for patterns resembling PII (emails, SSNs) before data leaves your secure environment.
  \end{itemize}
\item[$\square$]
  \textbf{Representation:} Does the training data match the real-world population it will be applied to?

  \begin{itemize}
  \tightlist
  \item
    \emph{Action:} Check distribution of key demographics in your train vs.~production sets.
  \end{itemize}
\item[$\square$]
  \textbf{Validation:} Have I validated the data schema and constraints?

  \begin{itemize}
  \tightlist
  \item
    \emph{Tool:} Use the \textbf{\texttt{pointblank}} or \textbf{\texttt{validator}} packages to define and enforce data quality rules (e.g., \texttt{col\_vals\_between(age,\ 0,\ 120)}).
  \end{itemize}
\end{itemize}

\section{Fairness \& Bias}\label{fairness-bias}

\emph{Algorithms can reinforce existing inequalities.}

\begin{itemize}
\tightlist
\item[$\square$]
  \textbf{Protected Classes:} Have I checked performance across different groups (Gender, Age, Ethnicity)?
\item[$\square$]
  \textbf{Bias Detection:} Have I quantified the bias in my model?

  \begin{itemize}
  \tightlist
  \item
    \emph{Tool:} Use \textbf{\texttt{fairness}}, \textbf{\texttt{fairmodels}}, or \textbf{\texttt{dalex}} to calculate metrics like Disparate Impact or Equal Opportunity difference.
  \item
    \emph{Example Code:} \texttt{fairness\_check(explainer,\ protected\ =\ data\$gender,\ privileged\ =\ "Male")}
  \end{itemize}
\item[$\square$]
  \textbf{Proxy Variables:} Are there variables (like Zip Code) acting as proxies for protected classes?
\item[$\square$]
  \textbf{Impact:} Who could be harmed if this model makes a mistake? (e.g., Denying a loan vs.~Recommending a bad movie).
\end{itemize}

\section{Transparency \& Explainability}\label{transparency-explainability}

\emph{Black boxes should not make high-stakes decisions.}

\begin{itemize}
\tightlist
\item[$\square$]
  \textbf{Documentation:} Is the model card created? (Inputs, Outputs, Limitations, Intended Use).
\item[$\square$]
  \textbf{Explainability:} Can I explain to a non-technical stakeholder \emph{why} the model made a specific prediction?

  \begin{itemize}
  \tightlist
  \item
    \emph{Tool:} Use \textbf{\texttt{dalex}}, \textbf{\texttt{lime}}, or \textbf{\texttt{iml}} to create feature contribution plots or breakdown plots.
  \end{itemize}
\item[$\square$]
  \textbf{Feedback Loop:} Is there a mechanism for users to report errors or contest decisions?
\end{itemize}

\section{Reproducibility \& Integrity}\label{reproducibility-integrity}

\emph{Science must be reproducible.}

\begin{itemize}
\tightlist
\item[$\square$]
  \textbf{Environment Sealing:} Is the R environment reproducible?

  \begin{itemize}
  \tightlist
  \item
    \emph{Tool:} Use \textbf{\texttt{renv}} to capture package versions in a \texttt{renv.lock} file.
  \end{itemize}
\item[$\square$]
  \textbf{Randomness Control:} Are random seeds set (\texttt{set.seed()}) for key steps like splitting data or initializing weights?
\item[$\square$]
  \textbf{Code Versioning:} Is the code committed to version control (Git) with clear messages?
\end{itemize}

\section{GenAI Specifics}\label{genai-specifics}

\emph{If using Large Language Models (LLMs).}

\begin{itemize}
\tightlist
\item[$\square$]
  \textbf{Fact-Checking:} Have I verified AI-generated code/facts against reliable sources? Hallucinations are common.
\item[$\square$]
  \textbf{Security:} Have I ensured no sensitive data is being sent to public APIs?
\item[$\square$]
  \textbf{Attribution:} Am I transparent about which parts of the work were AI-generated?
\end{itemize}

\begin{quote}
``With great power comes great responsibility.'' --- \emph{Stan Lee (and every Data Scientist)}
\end{quote}

\chapter{Appendix B: Object Oriented Programming with R6}\label{r6-intro}

In R, Object-Oriented Programming (OOP) can be implemented in several ways. Traditionally, R has used systems called S3 and S4 for OOP.

\textbf{S3} is an informal and flexible system. It is based on the idea of generic functions, which can have different methods depending on the class of the object they apply to. For example, the \texttt{print()} function is a generic function having different methods for printing different types of objects, such as vectors, lists, or data frames.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example of generic function in S3}
\FunctionTok{print}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))  }\CommentTok{\# Prints a numeric vector}
\CommentTok{\#\textgreater{} [1] 1 2 3}
\FunctionTok{print}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{a =} \DecValTok{1}\NormalTok{, }\AttributeTok{b =} \DecValTok{2}\NormalTok{))  }\CommentTok{\# Prints a list}
\CommentTok{\#\textgreater{} $a}
\CommentTok{\#\textgreater{} [1] 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $b}
\CommentTok{\#\textgreater{} [1] 2}
\end{Highlighting}
\end{Shaded}

\textbf{S4} is a more formal and structured system than S3. It defines classes and methods more explicitly, using special syntax. S4 is often used in packages requiring a more rigorous object structure, like Bioconductor.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example of class definition in S4}
\FunctionTok{setClass}\NormalTok{(}\StringTok{"Person"}\NormalTok{, }\AttributeTok{slots =} \FunctionTok{c}\NormalTok{(}\AttributeTok{name =} \StringTok{"character"}\NormalTok{, }\AttributeTok{age =} \StringTok{"numeric"}\NormalTok{))}

\CommentTok{\# Example of object creation in S4}
\NormalTok{my\_person }\OtherTok{\textless{}{-}} \FunctionTok{new}\NormalTok{(}\StringTok{"Person"}\NormalTok{, }\AttributeTok{name =} \StringTok{"John"}\NormalTok{, }\AttributeTok{age =} \DecValTok{30}\NormalTok{)}

\NormalTok{my\_person}
\CommentTok{\#\textgreater{} An object of class "Person"}
\CommentTok{\#\textgreater{} Slot "name":}
\CommentTok{\#\textgreater{} [1] "John"}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Slot "age":}
\CommentTok{\#\textgreater{} [1] 30}
\end{Highlighting}
\end{Shaded}

However, both S3 and S4 can be somewhat confusing and limited, especially for more complex projects. Luckily, there is a more modern and robust alternative: the R6 package. This package offers a more intuitive and efficient way to implement OOP in R, with features facilitating code organization, reuse, and maintenance. If you are new to OOP, don't worry about S3 and S4 details for now. With R6, you can learn basic OOP concepts more easily and apply them to your data analysis projects.

\section{The R6 package: Classes, methods, encapsulation, and inheritance}\label{the-r6-package-classes-methods-encapsulation-and-inheritance}

The R6 package implements a class and object system similar to other object-oriented programming languages like Python or Java. It provides a robust and efficient way to create objects with attributes and methods, allowing encapsulation and inheritance.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"R6"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(R6)}
\end{Highlighting}
\end{Shaded}

\textbf{Classes:}

A class is like a blueprint or template for creating objects. It defines the attributes (data) and methods (functions) that objects of that class will have. In R6, classes are created with the \texttt{R6Class()} function.

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# Define a "Person" class}
\NormalTok{Person }\OtherTok{\textless{}{-}} \FunctionTok{R6Class}\NormalTok{(}\StringTok{"Person"}\NormalTok{,}
  \AttributeTok{public =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{name =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{age =} \ConstantTok{NULL}\NormalTok{,}
    
    \CommentTok{\# Constructor}
    \AttributeTok{initialize =} \ControlFlowTok{function}\NormalTok{(name, age) \{}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{name }\OtherTok{\textless{}{-}}\NormalTok{ name}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{age }\OtherTok{\textless{}{-}}\NormalTok{ age}
\NormalTok{    \},}
    
    \CommentTok{\# Method to greet}
    \AttributeTok{greet =} \ControlFlowTok{function}\NormalTok{() \{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"Hello, my name is"}\NormalTok{, self}\SpecialCharTok{$}\NormalTok{name, }\StringTok{"and I am"}\NormalTok{, self}\SpecialCharTok{$}\NormalTok{age, }\StringTok{"years old.}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In this example, a \texttt{Person} class is defined with \texttt{name} and \texttt{age} attributes, and \texttt{greet()} method. The \texttt{public} list defines public members of the class, i.e., attributes and methods accessible from outside the object.

\textbf{Objects:}

An object is an instance of a class. It is a concrete entity having attributes and methods defined by the class. In R6, objects are created with the \texttt{\$new()} method.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create an object of class "Person"}
\NormalTok{juan }\OtherTok{\textless{}{-}}\NormalTok{ Person}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(}\AttributeTok{name =} \StringTok{"Juan"}\NormalTok{, }\AttributeTok{age =} \DecValTok{30}\NormalTok{)}

\NormalTok{juan}
\CommentTok{\#\textgreater{} \textless{}Person\textgreater{}}
\CommentTok{\#\textgreater{}   Public:}
\CommentTok{\#\textgreater{}     age: 30}
\CommentTok{\#\textgreater{}     clone: function (deep = FALSE) }
\CommentTok{\#\textgreater{}     greet: function () }
\CommentTok{\#\textgreater{}     initialize: function (name, age) }
\CommentTok{\#\textgreater{}     name: Juan}
\end{Highlighting}
\end{Shaded}

\textbf{Methods:}

Methods are functions operating on an object's attributes. They allow accessing and modifying object data, as well as performing other actions. In R6, methods are defined within the \texttt{public} list of the class.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Call greet() method of object "juan"}
\NormalTok{juan}\SpecialCharTok{$}\FunctionTok{greet}\NormalTok{()}
\CommentTok{\#\textgreater{} Hello, my name is Juan and I am 30 years old.}
\end{Highlighting}
\end{Shaded}

\textbf{Encapsulation:}

Encapsulation is a mechanism allowing hiding internal details of an object and controlling access to its attributes. This protects object data and facilitates usage. In R6, encapsulation is achieved by distinguishing between public and private members.

Public members are defined in \texttt{public} list and can be accessed from outside the object. Private members are defined in \texttt{private} list and can only be accessed from within the object, through methods.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define a "BankAccount" class with encapsulation}
\NormalTok{BankAccount }\OtherTok{\textless{}{-}} \FunctionTok{R6Class}\NormalTok{(}\StringTok{"BankAccount"}\NormalTok{,}
  \AttributeTok{public =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{holder =} \ConstantTok{NULL}\NormalTok{,}
    
    \CommentTok{\# Constructor}
    \AttributeTok{initialize =} \ControlFlowTok{function}\NormalTok{(holder) \{}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{holder }\OtherTok{\textless{}{-}}\NormalTok{ holder}
\NormalTok{      private}\SpecialCharTok{$}\NormalTok{balance }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{    \},}
    
    \CommentTok{\# Method to deposit money}
    \AttributeTok{deposit =} \ControlFlowTok{function}\NormalTok{(amount) \{}
\NormalTok{      private}\SpecialCharTok{$}\NormalTok{balance }\OtherTok{\textless{}{-}}\NormalTok{ private}\SpecialCharTok{$}\NormalTok{balance }\SpecialCharTok{+}\NormalTok{ amount}
\NormalTok{    \},}
    
    \CommentTok{\# Method to withdraw money}
    \AttributeTok{withdraw =} \ControlFlowTok{function}\NormalTok{(amount) \{}
      \ControlFlowTok{if}\NormalTok{ (amount }\SpecialCharTok{\textless{}=}\NormalTok{ private}\SpecialCharTok{$}\NormalTok{balance) \{}
\NormalTok{        private}\SpecialCharTok{$}\NormalTok{balance }\OtherTok{\textless{}{-}}\NormalTok{ private}\SpecialCharTok{$}\NormalTok{balance }\SpecialCharTok{{-}}\NormalTok{ amount}
\NormalTok{      \} }\ControlFlowTok{else}\NormalTok{ \{}
        \FunctionTok{stop}\NormalTok{(}\StringTok{"Insufficient funds."}\NormalTok{)}
\NormalTok{      \}}
\NormalTok{    \},}
    
    \CommentTok{\# Method to check balance}
    \AttributeTok{check\_balance =} \ControlFlowTok{function}\NormalTok{() \{}
      \FunctionTok{return}\NormalTok{(private}\SpecialCharTok{$}\NormalTok{balance)}
\NormalTok{    \}}
\NormalTok{  ),}
  \AttributeTok{private =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{balance =} \ConstantTok{NULL}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Inheritance:}

Inheritance is a mechanism allowing creating new classes from existing classes, inheriting their attributes and methods. This facilitates code reuse and creation of class hierarchies. In R6, inheritance is specified with \texttt{inherit} argument of \texttt{R6Class()} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define a "Student" class inheriting from "Person"}
\NormalTok{Student }\OtherTok{\textless{}{-}} \FunctionTok{R6Class}\NormalTok{(}\StringTok{"Student"}\NormalTok{,}
  \AttributeTok{inherit =}\NormalTok{ Person,}
  \AttributeTok{public =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{major =} \ConstantTok{NULL}\NormalTok{,}
    
    \CommentTok{\# Constructor}
    \AttributeTok{initialize =} \ControlFlowTok{function}\NormalTok{(name, age, major) \{}
\NormalTok{      super}\SpecialCharTok{$}\FunctionTok{initialize}\NormalTok{(name, age)}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{major }\OtherTok{\textless{}{-}}\NormalTok{ major}
\NormalTok{    \},}
    
    \CommentTok{\# Method to show student info}
    \AttributeTok{show\_info =} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{      super}\SpecialCharTok{$}\FunctionTok{greet}\NormalTok{()}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"Major:"}\NormalTok{, self}\SpecialCharTok{$}\NormalTok{major, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  )}
\NormalTok{)}

\CommentTok{\# Create an object of class "Student"}
\NormalTok{maria }\OtherTok{\textless{}{-}}\NormalTok{ Student}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(}\AttributeTok{name =} \StringTok{"Maria"}\NormalTok{, }\AttributeTok{age =} \DecValTok{20}\NormalTok{, }\AttributeTok{major =} \StringTok{"Engineering"}\NormalTok{)}

\CommentTok{\# Call method show\_info()}
\NormalTok{maria}\SpecialCharTok{$}\FunctionTok{show\_info}\NormalTok{()}
\CommentTok{\#\textgreater{} Hello, my name is Maria and I am 20 years old.}
\CommentTok{\#\textgreater{} Major: Engineering}
\end{Highlighting}
\end{Shaded}

In this example, \texttt{Student} class inherits from \texttt{Person} class. \texttt{Student} constructor calls parent class constructor (\texttt{super\$initialize()}) to initialize inherited attributes. \texttt{show\_info()} method calls parent class \texttt{greet()} method (\texttt{super\$greet()}) and then shows student-specific information.

With R6, you can create classes and objects with a high degree of flexibility and control, allowing you to apply OOP effectively in your data analysis projects.

\section{Exercises}\label{exercises-21}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{124}
\tightlist
\item
  Create a class called \texttt{Pet} with attributes \texttt{name}, \texttt{species} and \texttt{age}, and methods \texttt{introduce()} (showing name, species and age of pet) and \texttt{have\_birthday()} (incrementing pet age by 1).
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(R6)}

\NormalTok{Pet }\OtherTok{\textless{}{-}} \FunctionTok{R6Class}\NormalTok{(}\StringTok{"Pet"}\NormalTok{,}
  \AttributeTok{public =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{name =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{species =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{age =} \ConstantTok{NULL}\NormalTok{,}
    
    \AttributeTok{initialize =} \ControlFlowTok{function}\NormalTok{(name, species, age) \{}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{name }\OtherTok{\textless{}{-}}\NormalTok{ name}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{species }\OtherTok{\textless{}{-}}\NormalTok{ species}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{age }\OtherTok{\textless{}{-}}\NormalTok{ age}
\NormalTok{    \},}
    
    \AttributeTok{introduce =} \ControlFlowTok{function}\NormalTok{() \{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"Hello, I am"}\NormalTok{, self}\SpecialCharTok{$}\NormalTok{name, }\StringTok{", a"}\NormalTok{, self}\SpecialCharTok{$}\NormalTok{species, }\StringTok{"of"}\NormalTok{, self}\SpecialCharTok{$}\NormalTok{age, }\StringTok{"years old.}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \},}
    
    \AttributeTok{have\_birthday =} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{age }\OtherTok{\textless{}{-}}\NormalTok{ self}\SpecialCharTok{$}\NormalTok{age }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{    \}}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{125}
\tightlist
\item
  Create a class called \texttt{Dog} inheriting from \texttt{Pet} class (from previous exercises). \texttt{Dog} class should have an additional attribute called \texttt{breed} and a method called \texttt{bark()}.
\end{enumerate}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Dog }\OtherTok{\textless{}{-}} \FunctionTok{R6Class}\NormalTok{(}\StringTok{"Dog"}\NormalTok{,}
  \AttributeTok{inherit =}\NormalTok{ Pet,}
  \AttributeTok{public =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{breed =} \ConstantTok{NULL}\NormalTok{,}
    
    \AttributeTok{initialize =} \ControlFlowTok{function}\NormalTok{(name, age, breed) \{}
\NormalTok{      super}\SpecialCharTok{$}\FunctionTok{initialize}\NormalTok{(name, }\StringTok{"dog"}\NormalTok{, age)}
\NormalTok{      self}\SpecialCharTok{$}\NormalTok{breed }\OtherTok{\textless{}{-}}\NormalTok{ breed}
\NormalTok{    \},}
    
    \AttributeTok{bark =} \ControlFlowTok{function}\NormalTok{() \{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"Woof! Woof!}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\chapter*{References}\label{references}


\bibliography{book.bib,packages.bib}

\end{document}
