<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Supervised Learning | Data Science with R</title>
  <meta name="description" content="Theory and practice to enter the world of data analysis and predictions with R, by Daniel Paredes" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Supervised Learning | Data Science with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Theory and practice to enter the world of data analysis and predictions with R, by Daniel Paredes" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Supervised Learning | Data Science with R" />
  
  <meta name="twitter:description" content="Theory and practice to enter the world of data analysis and predictions with R, by Daniel Paredes" />
  

<meta name="author" content="Author: Mg. Daniel Paredes Inilupu" />


<meta name="date" content="2025-12-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-2.html"/>
<link rel="next" href="unsupervised-learning.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics: Sin Vista -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VJJ963010J"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VJJ963010J');
</script>

<!-- Global site tag (gtag.js) - Google Analytics: Vista -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-165839710-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-165839710-1');
</script>

<!-- Global site tag (gtag.js) - Google Analytics: Agentedec4mbio -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-17876479-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-17876479-1');
</script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#why-r"><i class="fa fa-check"></i>Why R?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#installing-r"><i class="fa fa-check"></i>Installing R</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#installing-rstudio"><i class="fa fa-check"></i>Installing RStudio</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#rstudio-sections"><i class="fa fa-check"></i>RStudio Sections</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#testing-rstudio"><i class="fa fa-check"></i>Testing RStudio</a></li>
</ul></li>
<li class="part"><span><b>I Fundamentals and Key Tools</b></span></li>
<li class="chapter" data-level="1" data-path="objects.html"><a href="objects.html"><i class="fa fa-check"></i><b>1</b> Objects</a>
<ul>
<li class="chapter" data-level="1.1" data-path="objects.html"><a href="objects.html#what-are-objects-in-r"><i class="fa fa-check"></i><b>1.1</b> What are objects in R?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="objects.html"><a href="objects.html#r-as-an-object-oriented-language"><i class="fa fa-check"></i><b>1.1.1</b> R as an object-oriented language</a></li>
<li class="chapter" data-level="1.1.2" data-path="objects.html"><a href="objects.html#the-power-of-abstraction"><i class="fa fa-check"></i><b>1.1.2</b> The power of abstraction</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="objects.html"><a href="objects.html#variables-the-first-objects-on-your-journey"><i class="fa fa-check"></i><b>1.2</b> Variables: The first objects on your journey</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="objects.html"><a href="objects.html#creating-variables-in-r"><i class="fa fa-check"></i><b>1.2.1</b> Creating variables in R</a></li>
<li class="chapter" data-level="1.2.2" data-path="objects.html"><a href="objects.html#operations-with-variables"><i class="fa fa-check"></i><b>1.2.2</b> Operations with variables</a></li>
<li class="chapter" data-level="1.2.3" data-path="objects.html"><a href="objects.html#best-practices-for-naming-variables"><i class="fa fa-check"></i><b>1.2.3</b> Best practices for naming variables</a></li>
<li class="chapter" data-level="1.2.4" data-path="objects.html"><a href="objects.html#data-types"><i class="fa fa-check"></i><b>1.2.4</b> Data types</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="objects.html"><a href="objects.html#object-types-for-complex-data"><i class="fa fa-check"></i><b>1.3</b> Object types for complex data</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="objects.html"><a href="objects.html#vectors-organizing-information-of-the-same-type"><i class="fa fa-check"></i><b>1.3.1</b> Vectors: organizing information of the same type</a></li>
<li class="chapter" data-level="1.3.2" data-path="objects.html"><a href="objects.html#lists-grouping-objects-of-different-types"><i class="fa fa-check"></i><b>1.3.2</b> Lists: grouping objects of different types</a></li>
<li class="chapter" data-level="1.3.3" data-path="objects.html"><a href="objects.html#matrices-organizing-data-in-rows-and-columns"><i class="fa fa-check"></i><b>1.3.3</b> Matrices: organizing data in rows and columns</a></li>
<li class="chapter" data-level="1.3.4" data-path="objects.html"><a href="objects.html#arrays-multidimensional-matrices"><i class="fa fa-check"></i><b>1.3.4</b> Arrays: multidimensional matrices</a></li>
<li class="chapter" data-level="1.3.5" data-path="objects.html"><a href="objects.html#factors-representing-categorical-data"><i class="fa fa-check"></i><b>1.3.5</b> Factors: representing categorical data</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="objects.html"><a href="objects.html#the-universe-of-objects-in-r"><i class="fa fa-check"></i><b>1.4</b> The Universe of Objects in R</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="objects.html"><a href="objects.html#philosophy-of-objects-in-r"><i class="fa fa-check"></i><b>1.4.1</b> Philosophy of objects in R</a></li>
<li class="chapter" data-level="1.4.2" data-path="objects.html"><a href="objects.html#comparison-with-other-languages"><i class="fa fa-check"></i><b>1.4.2</b> Comparison with other languages</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="objects.html"><a href="objects.html#exercises"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>2</b> Functions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="functions.html"><a href="functions.html#introduction-to-the-world-of-functions"><i class="fa fa-check"></i><b>2.1</b> Introduction to the world of functions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="functions.html"><a href="functions.html#what-are-functions"><i class="fa fa-check"></i><b>2.1.1</b> What are functions?</a></li>
<li class="chapter" data-level="2.1.2" data-path="functions.html"><a href="functions.html#why-use-functions"><i class="fa fa-check"></i><b>2.1.2</b> Why use functions?</a></li>
<li class="chapter" data-level="2.1.3" data-path="functions.html"><a href="functions.html#first-functions-exploring-basic-r-functions"><i class="fa fa-check"></i><b>2.1.3</b> First functions: exploring basic R functions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="functions.html"><a href="functions.html#anatomy-of-a-function"><i class="fa fa-check"></i><b>2.2</b> Anatomy of a function</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="functions.html"><a href="functions.html#arguments-the-ingredients-of-the-function"><i class="fa fa-check"></i><b>2.2.1</b> Arguments: the ingredients of the function</a></li>
<li class="chapter" data-level="2.2.2" data-path="functions.html"><a href="functions.html#body-the-instructions-of-the-function"><i class="fa fa-check"></i><b>2.2.2</b> Body: the instructions of the function</a></li>
<li class="chapter" data-level="2.2.3" data-path="functions.html"><a href="functions.html#return-value-the-result-of-the-function"><i class="fa fa-check"></i><b>2.2.3</b> Return value: the result of the function</a></li>
<li class="chapter" data-level="2.2.4" data-path="functions.html"><a href="functions.html#examples-creating-simple-functions-step-by-step"><i class="fa fa-check"></i><b>2.2.4</b> Examples: creating simple functions step by step</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="functions.html"><a href="functions.html#mastering-the-use-of-functions"><i class="fa fa-check"></i><b>2.3</b> Mastering the use of functions</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="functions.html"><a href="functions.html#functions-with-a-variable-number-of-arguments-...-adapting-to-different-situations"><i class="fa fa-check"></i><b>2.3.1</b> Functions with a variable number of arguments (<code>...</code>): Adapting to different situations</a></li>
<li class="chapter" data-level="2.3.2" data-path="functions.html"><a href="functions.html#variable-scope-local-and-global-variables"><i class="fa fa-check"></i><b>2.3.2</b> Variable scope: local and global variables</a></li>
<li class="chapter" data-level="2.3.3" data-path="functions.html"><a href="functions.html#examples-functions-to-calculate-taxes-discounts-etc."><i class="fa fa-check"></i><b>2.3.3</b> Examples: functions to calculate taxes, discounts, etc.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="functions.html"><a href="functions.html#higher-order-functions"><i class="fa fa-check"></i><b>2.4</b> Higher-order functions</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="functions.html"><a href="functions.html#lapply-and-sapply-applying-a-function-to-each-element"><i class="fa fa-check"></i><b>2.4.1</b> <code>lapply()</code> and <code>sapply()</code>: applying a function to each element</a></li>
<li class="chapter" data-level="2.4.2" data-path="functions.html"><a href="functions.html#apply-applying-a-function-to-rows-or-columns"><i class="fa fa-check"></i><b>2.4.2</b> <code>apply()</code>: applying a function to rows or columns</a></li>
<li class="chapter" data-level="2.4.3" data-path="functions.html"><a href="functions.html#mapply-applying-a-function-to-multiple-arguments"><i class="fa fa-check"></i><b>2.4.3</b> <code>mapply()</code>: applying a function to multiple arguments</a></li>
<li class="chapter" data-level="2.4.4" data-path="functions.html"><a href="functions.html#examples-data-analysis-with-higher-order-functions"><i class="fa fa-check"></i><b>2.4.4</b> Examples: data analysis with higher-order functions</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="functions.html"><a href="functions.html#closures-functions-with-memory"><i class="fa fa-check"></i><b>2.5</b> Closures: functions with memory</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="functions.html"><a href="functions.html#concept-functions-that-remember"><i class="fa fa-check"></i><b>2.5.1</b> Concept: functions that “remember”</a></li>
<li class="chapter" data-level="2.5.2" data-path="functions.html"><a href="functions.html#applications-creating-counters-functions-with-internal-state"><i class="fa fa-check"></i><b>2.5.2</b> Applications: creating counters, functions with internal state</a></li>
<li class="chapter" data-level="2.5.3" data-path="functions.html"><a href="functions.html#examples-simulating-a-game-creating-an-operation-history"><i class="fa fa-check"></i><b>2.5.3</b> Examples: simulating a game, creating an operation history</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="functions.html"><a href="functions.html#debugging-and-error-handling-solving-the-mysteries-of-your-code"><i class="fa fa-check"></i><b>2.6</b> Debugging and error handling: solving the mysteries of your code</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="functions.html"><a href="functions.html#identifying-errors-common-error-messages-in-r"><i class="fa fa-check"></i><b>2.6.1</b> Identifying errors: common error messages in R</a></li>
<li class="chapter" data-level="2.6.2" data-path="functions.html"><a href="functions.html#debugging-tools-debug-traceback"><i class="fa fa-check"></i><b>2.6.2</b> Debugging tools: <code>debug()</code>, <code>traceback()</code></a></li>
<li class="chapter" data-level="2.6.3" data-path="functions.html"><a href="functions.html#error-handling-trycatch"><i class="fa fa-check"></i><b>2.6.3</b> Error handling: <code>tryCatch()</code></a></li>
<li class="chapter" data-level="2.6.4" data-path="functions.html"><a href="functions.html#examples-debugging-functions-with-errors-handling-exceptions"><i class="fa fa-check"></i><b>2.6.4</b> Examples: debugging functions with errors, handling exceptions</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="functions.html"><a href="functions.html#exercises-1"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-frames.html"><a href="data-frames.html"><i class="fa fa-check"></i><b>3</b> Data Frames</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-frames.html"><a href="data-frames.html#introduction-to-data-frames"><i class="fa fa-check"></i><b>3.1</b> Introduction to Data Frames</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="data-frames.html"><a href="data-frames.html#what-are-data-frames"><i class="fa fa-check"></i><b>3.1.1</b> What are data frames?</a></li>
<li class="chapter" data-level="3.1.2" data-path="data-frames.html"><a href="data-frames.html#why-data-frames"><i class="fa fa-check"></i><b>3.1.2</b> Why data frames?</a></li>
<li class="chapter" data-level="3.1.3" data-path="data-frames.html"><a href="data-frames.html#data-frames-in-action-exploring-information-about-the-united-states"><i class="fa fa-check"></i><b>3.1.3</b> Data Frames in action: exploring information about the United States</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-frames.html"><a href="data-frames.html#creating-data-frames-building-your-database-for-the-move"><i class="fa fa-check"></i><b>3.2</b> Creating Data Frames: Building your database for the move</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="data-frames.html"><a href="data-frames.html#importing-data-from-files-csv-excel"><i class="fa fa-check"></i><b>3.2.1</b> Importing data from files: CSV, Excel</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-frames.html"><a href="data-frames.html#creating-data-frames-manually"><i class="fa fa-check"></i><b>3.2.2</b> Creating data frames manually</a></li>
<li class="chapter" data-level="3.2.3" data-path="data-frames.html"><a href="data-frames.html#examples"><i class="fa fa-check"></i><b>3.2.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-frames.html"><a href="data-frames.html#exploring-data-frames-discovering-the-secrets-of-your-data"><i class="fa fa-check"></i><b>3.3</b> Exploring Data Frames: Discovering the secrets of your data</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="data-frames.html"><a href="data-frames.html#accessing-rows-columns-and-cells"><i class="fa fa-check"></i><b>3.3.1</b> Accessing rows, columns, and cells</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-frames.html"><a href="data-frames.html#functions-for-exploring-data-frames"><i class="fa fa-check"></i><b>3.3.2</b> Functions for exploring data frames</a></li>
<li class="chapter" data-level="3.3.3" data-path="data-frames.html"><a href="data-frames.html#examples-exploring-data-frames-with-move-information"><i class="fa fa-check"></i><b>3.3.3</b> Examples: exploring data frames with move information</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-frames.html"><a href="data-frames.html#manipulating-data-frames-transforming-your-data"><i class="fa fa-check"></i><b>3.4</b> Manipulating Data Frames: Transforming your data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="data-frames.html"><a href="data-frames.html#introduction-to-the-pipeline-operator"><i class="fa fa-check"></i><b>3.4.1</b> Introduction to the pipeline operator (<code>|&gt;</code>)</a></li>
<li class="chapter" data-level="3.4.2" data-path="data-frames.html"><a href="data-frames.html#transforming-a-table-with-mutate"><i class="fa fa-check"></i><b>3.4.2</b> Transforming a table with <code>mutate()</code></a></li>
<li class="chapter" data-level="3.4.3" data-path="data-frames.html"><a href="data-frames.html#filtering-data-selecting-cities-that-interest-you"><i class="fa fa-check"></i><b>3.4.3</b> Filtering data: selecting cities that interest you</a></li>
<li class="chapter" data-level="3.4.4" data-path="data-frames.html"><a href="data-frames.html#sorting-data-finding-the-safest-cities"><i class="fa fa-check"></i><b>3.4.4</b> Sorting data: finding the safest cities</a></li>
<li class="chapter" data-level="3.4.5" data-path="data-frames.html"><a href="data-frames.html#aggregating-and-summarizing-data-obtaining-general-overview"><i class="fa fa-check"></i><b>3.4.5</b> Aggregating and summarizing data: obtaining general overview</a></li>
<li class="chapter" data-level="3.4.6" data-path="data-frames.html"><a href="data-frames.html#joining-data-frames-combining-information"><i class="fa fa-check"></i><b>3.4.6</b> Joining data frames: combining information</a></li>
<li class="chapter" data-level="3.4.7" data-path="data-frames.html"><a href="data-frames.html#examples-1"><i class="fa fa-check"></i><b>3.4.7</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="data-frames.html"><a href="data-frames.html#exercises-2"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
<li class="chapter" data-level="3.6" data-path="data-frames.html"><a href="data-frames.html#data-frames-in-plots"><i class="fa fa-check"></i><b>3.6</b> Data frames in plots</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="data-frames.html"><a href="data-frames.html#scatter-plots"><i class="fa fa-check"></i><b>3.6.1</b> Scatter plots</a></li>
<li class="chapter" data-level="3.6.2" data-path="data-frames.html"><a href="data-frames.html#histograms"><i class="fa fa-check"></i><b>3.6.2</b> Histograms</a></li>
<li class="chapter" data-level="3.6.3" data-path="data-frames.html"><a href="data-frames.html#box-plot"><i class="fa fa-check"></i><b>3.6.3</b> Box plot</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="data-frames.html"><a href="data-frames.html#data-interpretation"><i class="fa fa-check"></i><b>3.7</b> Data interpretation</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="data-frames.html"><a href="data-frames.html#quartiles"><i class="fa fa-check"></i><b>3.7.1</b> Quartiles</a></li>
<li class="chapter" data-level="3.7.2" data-path="data-frames.html"><a href="data-frames.html#interpretation-of-box-plot"><i class="fa fa-check"></i><b>3.7.2</b> Interpretation of box plot</a></li>
<li class="chapter" data-level="3.7.3" data-path="data-frames.html"><a href="data-frames.html#examples-2"><i class="fa fa-check"></i><b>3.7.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="data-frames.html"><a href="data-frames.html#exercises-3"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="advanced-techniques.html"><a href="advanced-techniques.html"><i class="fa fa-check"></i><b>4</b> Advanced Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="advanced-techniques.html"><a href="advanced-techniques.html#metaprogramming-writing-code-that-writes-code"><i class="fa fa-check"></i><b>4.1</b> Metaprogramming: writing code that writes code</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="advanced-techniques.html"><a href="advanced-techniques.html#manipulating-expressions-the-art-of-sculpting-code"><i class="fa fa-check"></i><b>4.1.1</b> Manipulating expressions: The art of sculpting code</a></li>
<li class="chapter" data-level="4.1.2" data-path="advanced-techniques.html"><a href="advanced-techniques.html#examples-3"><i class="fa fa-check"></i><b>4.1.2</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="advanced-techniques.html"><a href="advanced-techniques.html#functional-programming-a-new-paradigm"><i class="fa fa-check"></i><b>4.2</b> Functional programming: a new paradigm</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="advanced-techniques.html"><a href="advanced-techniques.html#basic-principles-of-functional-programming"><i class="fa fa-check"></i><b>4.2.1</b> Basic principles of functional programming</a></li>
<li class="chapter" data-level="4.2.2" data-path="advanced-techniques.html"><a href="advanced-techniques.html#higher-order-functions-in-r"><i class="fa fa-check"></i><b>4.2.2</b> Higher-order functions in R</a></li>
<li class="chapter" data-level="4.2.3" data-path="advanced-techniques.html"><a href="advanced-techniques.html#examples-4"><i class="fa fa-check"></i><b>4.2.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="advanced-techniques.html"><a href="advanced-techniques.html#r6-the-future-of-oop-in-r"><i class="fa fa-check"></i><b>4.3</b> R6: The future of OOP in R</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="advanced-techniques.html"><a href="advanced-techniques.html#the-r6-package-classes-methods-encapsulation-and-inheritance"><i class="fa fa-check"></i><b>4.3.1</b> The R6 package: Classes, methods, encapsulation, and inheritance</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="advanced-techniques.html"><a href="advanced-techniques.html#exercises-4"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Data Visualization and Summarization</b></span></li>
<li class="chapter" data-level="5" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html"><i class="fa fa-check"></i><b>5</b> Ggplot and dplyr</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#creating-the-ggplot-object"><i class="fa fa-check"></i><b>5.1</b> Creating the ggplot object</a></li>
<li class="chapter" data-level="5.2" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#aesthetic-mapping-layer"><i class="fa fa-check"></i><b>5.2</b> Aesthetic mapping layer</a></li>
<li class="chapter" data-level="5.3" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#geoms-layer"><i class="fa fa-check"></i><b>5.3</b> Geoms layer</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#tweaking-aes-and-geoms"><i class="fa fa-check"></i><b>5.3.1</b> Tweaking aes and geoms</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#scale-layer"><i class="fa fa-check"></i><b>5.4</b> Scale layer</a></li>
<li class="chapter" data-level="5.5" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#label-title-and-legend-layer"><i class="fa fa-check"></i><b>5.5</b> Label, title and legend layer</a></li>
<li class="chapter" data-level="5.6" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#reference-lines"><i class="fa fa-check"></i><b>5.6</b> Reference lines</a></li>
<li class="chapter" data-level="5.7" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#changing-the-plot-style"><i class="fa fa-check"></i><b>5.7</b> Changing the plot style</a></li>
<li class="chapter" data-level="5.8" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#summarizing-data-with-dplyr"><i class="fa fa-check"></i><b>5.8</b> Summarizing data with dplyr</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#summarize-function"><i class="fa fa-check"></i><b>5.8.1</b> Summarize function</a></li>
<li class="chapter" data-level="5.8.2" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#group-by-function"><i class="fa fa-check"></i><b>5.8.2</b> Group By Function</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#exercises-5"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gapminder.html"><a href="gapminder.html"><i class="fa fa-check"></i><b>6</b> Gapminder</a>
<ul>
<li class="chapter" data-level="6.1" data-path="gapminder.html"><a href="gapminder.html#initial-gapminder-plots"><i class="fa fa-check"></i><b>6.1</b> Initial gapminder plots</a></li>
<li class="chapter" data-level="6.2" data-path="gapminder.html"><a href="gapminder.html#facets"><i class="fa fa-check"></i><b>6.2</b> Facets</a></li>
<li class="chapter" data-level="6.3" data-path="gapminder.html"><a href="gapminder.html#time-series"><i class="fa fa-check"></i><b>6.3</b> Time series</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="gapminder.html"><a href="gapminder.html#individual-time-series"><i class="fa fa-check"></i><b>6.3.1</b> Individual time series</a></li>
<li class="chapter" data-level="6.3.2" data-path="gapminder.html"><a href="gapminder.html#multiple-time-series"><i class="fa fa-check"></i><b>6.3.2</b> Multiple time series</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="gapminder.html"><a href="gapminder.html#exercises-6"><i class="fa fa-check"></i><b>6.4</b> Exercises</a></li>
<li class="chapter" data-level="6.5" data-path="gapminder.html"><a href="gapminder.html#histograms-with-ggplot"><i class="fa fa-check"></i><b>6.5</b> Histograms with ggplot</a></li>
<li class="chapter" data-level="6.6" data-path="gapminder.html"><a href="gapminder.html#box-plots-with-ggplot"><i class="fa fa-check"></i><b>6.6</b> Box plots with ggplot</a></li>
<li class="chapter" data-level="6.7" data-path="gapminder.html"><a href="gapminder.html#comparison-of-distributions"><i class="fa fa-check"></i><b>6.7</b> Comparison of distributions</a></li>
<li class="chapter" data-level="6.8" data-path="gapminder.html"><a href="gapminder.html#exercises-7"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Statistics</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-probabilities.html"><a href="introduction-to-probabilities.html"><i class="fa fa-check"></i>Introduction to Probabilities</a></li>
<li class="chapter" data-level="7" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html"><i class="fa fa-check"></i><b>7</b> Discrete Probabilities</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#calculation-using-the-mathematical-definition"><i class="fa fa-check"></i><b>7.1</b> Calculation using the mathematical definition</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#monte-carlo-simulation-for-discrete-variables"><i class="fa fa-check"></i><b>7.2</b> Monte Carlo Simulation for Discrete Variables</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#other-functions-to-create-vectors"><i class="fa fa-check"></i><b>7.2.1</b> Other functions to create vectors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#exercises-8"><i class="fa fa-check"></i><b>7.3</b> Exercises</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#combinations-and-permutations"><i class="fa fa-check"></i><b>7.4</b> Combinations and Permutations</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#permutations"><i class="fa fa-check"></i><b>7.4.1</b> Permutations</a></li>
<li class="chapter" data-level="7.4.2" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#combinations"><i class="fa fa-check"></i><b>7.4.2</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#sufficient-experiments-with-monte-carlo-simulation"><i class="fa fa-check"></i><b>7.5</b> Sufficient Experiments with Monte Carlo Simulation</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#case-birthdays-in-classrooms"><i class="fa fa-check"></i><b>7.6</b> Case: Birthdays in Classrooms</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#exercises-9"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#integrative-exercise"><i class="fa fa-check"></i><b>7.8</b> Integrative Exercise</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#monty-hall-problem"><i class="fa fa-check"></i><b>7.8.1</b> Monty Hall Problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html"><i class="fa fa-check"></i><b>8</b> Continuous Probabilities</a>
<ul>
<li class="chapter" data-level="8.1" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#empirical-distribution"><i class="fa fa-check"></i><b>8.1</b> Empirical Distribution</a></li>
<li class="chapter" data-level="8.2" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#theoretical-distribution"><i class="fa fa-check"></i><b>8.2</b> Theoretical Distribution</a></li>
<li class="chapter" data-level="8.3" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#exercises-10"><i class="fa fa-check"></i><b>8.3</b> Exercises</a></li>
<li class="chapter" data-level="8.4" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#monte-carlo-simulation-for-continuous-variables"><i class="fa fa-check"></i><b>8.4</b> Monte Carlo Simulation for Continuous Variables</a></li>
<li class="chapter" data-level="8.5" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#exercises-11"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>9</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="9.1" data-path="statistical-inference.html"><a href="statistical-inference.html#expected-value"><i class="fa fa-check"></i><b>9.1</b> Expected Value</a></li>
<li class="chapter" data-level="9.2" data-path="statistical-inference.html"><a href="statistical-inference.html#central-limit-theorem"><i class="fa fa-check"></i><b>9.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="9.3" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-12"><i class="fa fa-check"></i><b>9.3</b> Exercises</a></li>
<li class="chapter" data-level="9.4" data-path="statistical-inference.html"><a href="statistical-inference.html#parameter-estimation-method"><i class="fa fa-check"></i><b>9.4</b> Parameter Estimation Method</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="statistical-inference.html"><a href="statistical-inference.html#margin-of-error"><i class="fa fa-check"></i><b>9.4.1</b> Margin of Error</a></li>
<li class="chapter" data-level="9.4.2" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>9.4.2</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="statistical-inference.html"><a href="statistical-inference.html#spread-estimation"><i class="fa fa-check"></i><b>9.5</b> Spread Estimation</a></li>
<li class="chapter" data-level="9.6" data-path="statistical-inference.html"><a href="statistical-inference.html#estimates-outside-election-polls"><i class="fa fa-check"></i><b>9.6</b> Estimates Outside Election Polls</a></li>
<li class="chapter" data-level="9.7" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-13"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Data Wrangling</b></span></li>
<li class="chapter" data-level="" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="10" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html"><i class="fa fa-check"></i><b>10</b> Data import and consolidation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#importing-from-files"><i class="fa fa-check"></i><b>10.1</b> Importing from files</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#working-directory"><i class="fa fa-check"></i><b>10.1.1</b> Working Directory</a></li>
<li class="chapter" data-level="10.1.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#readr-and-readxl-packages"><i class="fa fa-check"></i><b>10.1.2</b> readr and readxl packages</a></li>
<li class="chapter" data-level="10.1.3" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#importing-files-from-the-internet"><i class="fa fa-check"></i><b>10.1.3</b> Importing files from the internet</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#tidy-data"><i class="fa fa-check"></i><b>10.2</b> Tidy data</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#transforming-to-tidy-data"><i class="fa fa-check"></i><b>10.2.1</b> Transforming to tidy data</a></li>
<li class="chapter" data-level="10.2.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#separate-function"><i class="fa fa-check"></i><b>10.2.2</b> separate function</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#exercises-14"><i class="fa fa-check"></i><b>10.3</b> Exercises</a></li>
<li class="chapter" data-level="10.4" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#joining-tables"><i class="fa fa-check"></i><b>10.4</b> Joining tables</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#join-functions"><i class="fa fa-check"></i><b>10.4.1</b> Join functions</a></li>
<li class="chapter" data-level="10.4.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#joining-without-a-common-identifier"><i class="fa fa-check"></i><b>10.4.2</b> Joining without a common identifier</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#web-scraping"><i class="fa fa-check"></i><b>10.5</b> Web Scraping</a></li>
<li class="chapter" data-level="10.6" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#exercises-15"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html"><i class="fa fa-check"></i><b>11</b> String processing and text mining</a>
<ul>
<li class="chapter" data-level="11.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#basic-functions"><i class="fa fa-check"></i><b>11.1</b> Basic functions</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#replacing-characters"><i class="fa fa-check"></i><b>11.1.1</b> Replacing characters</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#regular-expressions"><i class="fa fa-check"></i><b>11.2</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#alternation"><i class="fa fa-check"></i><b>11.2.1</b> Alternation</a></li>
<li class="chapter" data-level="11.2.2" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#anchoring"><i class="fa fa-check"></i><b>11.2.2</b> Anchoring</a></li>
<li class="chapter" data-level="11.2.3" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#repetitions"><i class="fa fa-check"></i><b>11.2.3</b> Repetitions</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#from-strings-to-dates"><i class="fa fa-check"></i><b>11.3</b> From strings to dates</a></li>
<li class="chapter" data-level="11.4" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#exercises-16"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
<li class="chapter" data-level="11.5" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#text-mining-word-cloud"><i class="fa fa-check"></i><b>11.5</b> Text Mining: Word Cloud</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#importing-data"><i class="fa fa-check"></i><b>11.5.1</b> Importing data</a></li>
<li class="chapter" data-level="11.5.2" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#text-cleaning"><i class="fa fa-check"></i><b>11.5.2</b> Text cleaning</a></li>
<li class="chapter" data-level="11.5.3" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#creating-the-corpus"><i class="fa fa-check"></i><b>11.5.3</b> Creating the Corpus</a></li>
<li class="chapter" data-level="11.5.4" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#nd-data-cleaning"><i class="fa fa-check"></i><b>11.5.4</b> 2nd Data Cleaning</a></li>
<li class="chapter" data-level="11.5.5" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#word-frequency"><i class="fa fa-check"></i><b>11.5.5</b> Word frequency</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#text-mining-sentiment-analysis"><i class="fa fa-check"></i><b>11.6</b> Text Mining: Sentiment Analysis</a></li>
<li class="chapter" data-level="11.7" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#exercises-17"><i class="fa fa-check"></i><b>11.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Machine learning</b></span></li>
<li class="chapter" data-level="" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="12" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>12</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="supervised-learning.html"><a href="supervised-learning.html#classification-and-regression"><i class="fa fa-check"></i><b>12.1</b> Classification and Regression</a></li>
<li class="chapter" data-level="12.2" data-path="supervised-learning.html"><a href="supervised-learning.html#knn-k-nearest-neighbors"><i class="fa fa-check"></i><b>12.2</b> kNN: k-Nearest Neighbors</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="supervised-learning.html"><a href="supervised-learning.html#two-variables-as-input"><i class="fa fa-check"></i><b>12.2.1</b> Two variables as input</a></li>
<li class="chapter" data-level="12.2.2" data-path="supervised-learning.html"><a href="supervised-learning.html#multiple-variables-as-input"><i class="fa fa-check"></i><b>12.2.2</b> Multiple variables as input</a></li>
<li class="chapter" data-level="12.2.3" data-path="supervised-learning.html"><a href="supervised-learning.html#diverse-values-of-k"><i class="fa fa-check"></i><b>12.2.3</b> Diverse values of k</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="supervised-learning.html"><a href="supervised-learning.html#tidymodels-framework"><i class="fa fa-check"></i><b>12.3</b> tidymodels Framework</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="supervised-learning.html"><a href="supervised-learning.html#creation-of-training-and-test-data"><i class="fa fa-check"></i><b>12.3.1</b> Creation of training and test data</a></li>
<li class="chapter" data-level="12.3.2" data-path="supervised-learning.html"><a href="supervised-learning.html#training-our-prediction-algorithm"><i class="fa fa-check"></i><b>12.3.2</b> Training our prediction algorithm</a></li>
<li class="chapter" data-level="12.3.3" data-path="supervised-learning.html"><a href="supervised-learning.html#data-pre-processing-with-recipes"><i class="fa fa-check"></i><b>12.3.3</b> Data Pre-processing with Recipes</a></li>
<li class="chapter" data-level="12.3.4" data-path="supervised-learning.html"><a href="supervised-learning.html#creating-a-workflow"><i class="fa fa-check"></i><b>12.3.4</b> Creating a Workflow</a></li>
<li class="chapter" data-level="12.3.5" data-path="supervised-learning.html"><a href="supervised-learning.html#parameter-tuning-with-cross-validation"><i class="fa fa-check"></i><b>12.3.5</b> Parameter Tuning with Cross-Validation</a></li>
<li class="chapter" data-level="12.3.6" data-path="supervised-learning.html"><a href="supervised-learning.html#finalizing-the-model"><i class="fa fa-check"></i><b>12.3.6</b> Finalizing the Model</a></li>
<li class="chapter" data-level="12.3.7" data-path="supervised-learning.html"><a href="supervised-learning.html#testing-the-prediction-model"><i class="fa fa-check"></i><b>12.3.7</b> Testing the prediction model</a></li>
<li class="chapter" data-level="12.3.8" data-path="supervised-learning.html"><a href="supervised-learning.html#model-evaluation-with-yardstick"><i class="fa fa-check"></i><b>12.3.8</b> Model Evaluation with yardstick</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="supervised-learning.html"><a href="supervised-learning.html#confusion-matrix"><i class="fa fa-check"></i><b>12.4</b> Confusion Matrix</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="supervised-learning.html"><a href="supervised-learning.html#accuracy"><i class="fa fa-check"></i><b>12.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="12.4.2" data-path="supervised-learning.html"><a href="supervised-learning.html#sensitivity"><i class="fa fa-check"></i><b>12.4.2</b> Sensitivity</a></li>
<li class="chapter" data-level="12.4.3" data-path="supervised-learning.html"><a href="supervised-learning.html#specificity"><i class="fa fa-check"></i><b>12.4.3</b> Specificity</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="supervised-learning.html"><a href="supervised-learning.html#exercises-18"><i class="fa fa-check"></i><b>12.5</b> Exercises</a></li>
<li class="chapter" data-level="12.6" data-path="supervised-learning.html"><a href="supervised-learning.html#simple-linear-regression"><i class="fa fa-check"></i><b>12.6</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="12.7" data-path="supervised-learning.html"><a href="supervised-learning.html#multiple-linear-regression"><i class="fa fa-check"></i><b>12.7</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="12.8" data-path="supervised-learning.html"><a href="supervised-learning.html#standard-method-for-evaluating-accuracy"><i class="fa fa-check"></i><b>12.8</b> Standard Method for Evaluating Accuracy</a></li>
<li class="chapter" data-level="12.9" data-path="supervised-learning.html"><a href="supervised-learning.html#selection-of-the-most-optimal-model"><i class="fa fa-check"></i><b>12.9</b> Selection of the Most Optimal Model</a>
<ul>
<li class="chapter" data-level="12.9.1" data-path="supervised-learning.html"><a href="supervised-learning.html#k-nearest-neighbors-model"><i class="fa fa-check"></i><b>12.9.1</b> k-Nearest Neighbors Model</a></li>
<li class="chapter" data-level="12.9.2" data-path="supervised-learning.html"><a href="supervised-learning.html#generalized-linear-model---glm"><i class="fa fa-check"></i><b>12.9.2</b> Generalized Linear Model - GLM</a></li>
<li class="chapter" data-level="12.9.3" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forest-model"><i class="fa fa-check"></i><b>12.9.3</b> Random Forest Model</a></li>
<li class="chapter" data-level="12.9.4" data-path="supervised-learning.html"><a href="supervised-learning.html#support-vector-machine-model---svm"><i class="fa fa-check"></i><b>12.9.4</b> Support Vector Machine Model - SVM</a></li>
<li class="chapter" data-level="12.9.5" data-path="supervised-learning.html"><a href="supervised-learning.html#naive-bayes-model"><i class="fa fa-check"></i><b>12.9.5</b> Naive Bayes Model</a></li>
<li class="chapter" data-level="12.9.6" data-path="supervised-learning.html"><a href="supervised-learning.html#model-comparison"><i class="fa fa-check"></i><b>12.9.6</b> Model Comparison</a></li>
<li class="chapter" data-level="12.9.7" data-path="supervised-learning.html"><a href="supervised-learning.html#predicting-using-the-best-model"><i class="fa fa-check"></i><b>12.9.7</b> Predicting using the best model</a></li>
</ul></li>
<li class="chapter" data-level="12.10" data-path="supervised-learning.html"><a href="supervised-learning.html#exercises-19"><i class="fa fa-check"></i><b>12.10</b> Exercises</a></li>
<li class="chapter" data-level="12.11" data-path="supervised-learning.html"><a href="supervised-learning.html#ethics-bias-in-algorithmic-decision-making"><i class="fa fa-check"></i><b>12.11</b> Ethics: Bias in Algorithmic Decision Making</a>
<ul>
<li class="chapter" data-level="12.11.1" data-path="supervised-learning.html"><a href="supervised-learning.html#the-risk-of-proxy-variables"><i class="fa fa-check"></i><b>12.11.1</b> The Risk of Proxy Variables</a></li>
<li class="chapter" data-level="12.11.2" data-path="supervised-learning.html"><a href="supervised-learning.html#feedback-loops"><i class="fa fa-check"></i><b>12.11.2</b> Feedback Loops</a></li>
<li class="chapter" data-level="12.11.3" data-path="supervised-learning.html"><a href="supervised-learning.html#what-can-we-do"><i class="fa fa-check"></i><b>12.11.3</b> What can we do?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>13</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="13.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-clustering"><i class="fa fa-check"></i><b>13.1</b> K-Means Clustering</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-with-k-2"><i class="fa fa-check"></i><b>13.1.1</b> Clustering with k = 2</a></li>
<li class="chapter" data-level="13.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-with-k-3"><i class="fa fa-check"></i><b>13.1.2</b> Clustering with k &gt;= 3</a></li>
<li class="chapter" data-level="13.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#determination-of-optimal-clusters"><i class="fa fa-check"></i><b>13.1.3</b> Determination of Optimal Clusters</a></li>
<li class="chapter" data-level="13.1.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-for-more-than-2-variables"><i class="fa fa-check"></i><b>13.1.4</b> k-means for more than 2 variables</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#hierarchical-clustering"><i class="fa fa-check"></i><b>13.2</b> Hierarchical Clustering</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-with-two-variables"><i class="fa fa-check"></i><b>13.2.1</b> Clustering with two variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#determination-of-optimal-clusters-1"><i class="fa fa-check"></i><b>13.2.2</b> Determination of Optimal Clusters</a></li>
<li class="chapter" data-level="13.2.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#obtain-the-grouping"><i class="fa fa-check"></i><b>13.2.3</b> Obtain the grouping</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#dimensionality-reduction"><i class="fa fa-check"></i><b>13.3</b> Dimensionality Reduction</a></li>
<li class="chapter" data-level="13.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#exercises-20"><i class="fa fa-check"></i><b>13.4</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Real Cases</b></span></li>
<li class="chapter" data-level="" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="14" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html"><i class="fa fa-check"></i><b>14</b> Case Study: Real Estate Market Analysis</a>
<ul>
<li class="chapter" data-level="14.1" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#objectives"><i class="fa fa-check"></i><b>14.1</b> Objectives</a></li>
<li class="chapter" data-level="14.2" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#loading-libraries"><i class="fa fa-check"></i><b>14.2</b> Loading Libraries</a></li>
<li class="chapter" data-level="14.3" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#exploring-the-data"><i class="fa fa-check"></i><b>14.3</b> Exploring the Data</a></li>
<li class="chapter" data-level="14.4" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#data-cleaning"><i class="fa fa-check"></i><b>14.4</b> Data Cleaning</a></li>
<li class="chapter" data-level="14.5" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#exploratory-analysis"><i class="fa fa-check"></i><b>14.5</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#market-volume-over-time"><i class="fa fa-check"></i><b>14.5.1</b> Market Volume Over Time</a></li>
<li class="chapter" data-level="14.5.2" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#comparing-cities"><i class="fa fa-check"></i><b>14.5.2</b> Comparing Cities</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#creating-indicators"><i class="fa fa-check"></i><b>14.6</b> Creating Indicators</a></li>
<li class="chapter" data-level="14.7" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#conclusions"><i class="fa fa-check"></i><b>14.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html"><i class="fa fa-check"></i><b>15</b> Google Analytics from R</a>
<ul>
<li class="chapter" data-level="15.1" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#problem"><i class="fa fa-check"></i><b>15.1</b> Problem</a></li>
<li class="chapter" data-level="15.2" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#access-to-data"><i class="fa fa-check"></i><b>15.2</b> Access to data</a></li>
<li class="chapter" data-level="15.3" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#visualization"><i class="fa fa-check"></i><b>15.3</b> Visualization</a></li>
<li class="chapter" data-level="15.4" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#conclusion"><i class="fa fa-check"></i><b>15.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="genai-intro.html"><a href="genai-intro.html"><i class="fa fa-check"></i><b>16</b> Data Science in the Age of AI</a>
<ul>
<li class="chapter" data-level="16.1" data-path="genai-intro.html"><a href="genai-intro.html#what-is-a-large-language-model"><i class="fa fa-check"></i><b>16.1</b> What is a Large Language Model?</a></li>
<li class="chapter" data-level="16.2" data-path="genai-intro.html"><a href="genai-intro.html#coding-with-ai-the-pair-programmer"><i class="fa fa-check"></i><b>16.2</b> Coding with AI: The “Pair Programmer”</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="genai-intro.html"><a href="genai-intro.html#explaining-complex-code"><i class="fa fa-check"></i><b>16.2.1</b> 1. Explaining Complex Code</a></li>
<li class="chapter" data-level="16.2.2" data-path="genai-intro.html"><a href="genai-intro.html#generating-boilerplate"><i class="fa fa-check"></i><b>16.2.2</b> 2. Generating Boilerplate</a></li>
<li class="chapter" data-level="16.2.3" data-path="genai-intro.html"><a href="genai-intro.html#regex-the-ultimate-use-case"><i class="fa fa-check"></i><b>16.2.3</b> 3. Regex: The Ultimate Use Case</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="genai-intro.html"><a href="genai-intro.html#ethics-risks-in-the-ai-era"><i class="fa fa-check"></i><b>16.3</b> Ethics &amp; Risks in the AI Era</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="genai-intro.html"><a href="genai-intro.html#hallucinations-fabrication"><i class="fa fa-check"></i><b>16.3.1</b> 1. Hallucinations &amp; Fabrication</a></li>
<li class="chapter" data-level="16.3.2" data-path="genai-intro.html"><a href="genai-intro.html#the-reproducibility-crisis"><i class="fa fa-check"></i><b>16.3.2</b> 2. The Reproducibility Crisis</a></li>
<li class="chapter" data-level="16.3.3" data-path="genai-intro.html"><a href="genai-intro.html#data-privacy-ip"><i class="fa fa-check"></i><b>16.3.3</b> 3. Data Privacy &amp; IP</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="genai-api.html"><a href="genai-api.html"><i class="fa fa-check"></i><b>17</b> LLMs as an Analysis Engine</a>
<ul>
<li class="chapter" data-level="17.1" data-path="genai-api.html"><a href="genai-api.html#the-evolution-of-nlp"><i class="fa fa-check"></i><b>17.1</b> The Evolution of NLP</a></li>
<li class="chapter" data-level="17.2" data-path="genai-api.html"><a href="genai-api.html#interacting-with-apis-from-r"><i class="fa fa-check"></i><b>17.2</b> Interacting with APIs from R</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="genai-api.html"><a href="genai-api.html#prerequisite-api-keys"><i class="fa fa-check"></i><b>17.2.1</b> Prerequisite: API Keys</a></li>
<li class="chapter" data-level="17.2.2" data-path="genai-api.html"><a href="genai-api.html#making-a-request"><i class="fa fa-check"></i><b>17.2.2</b> Making a Request</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="genai-api.html"><a href="genai-api.html#zero-shot-classification"><i class="fa fa-check"></i><b>17.3</b> Zero-Shot Classification</a></li>
<li class="chapter" data-level="17.4" data-path="genai-api.html"><a href="genai-api.html#text-cleaning-with-llms"><i class="fa fa-check"></i><b>17.4</b> Text Cleaning with LLMs</a></li>
<li class="chapter" data-level="17.5" data-path="genai-api.html"><a href="genai-api.html#summary"><i class="fa fa-check"></i><b>17.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ethics-checklist.html"><a href="ethics-checklist.html"><i class="fa fa-check"></i><b>18</b> Appendix A: Responsible AI Checklist</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ethics-checklist.html"><a href="ethics-checklist.html#data-quality-lineage"><i class="fa fa-check"></i><b>18.1</b> 1. Data Quality &amp; lineage</a></li>
<li class="chapter" data-level="18.2" data-path="ethics-checklist.html"><a href="ethics-checklist.html#fairness-bias"><i class="fa fa-check"></i><b>18.2</b> 2. Fairness &amp; Bias</a></li>
<li class="chapter" data-level="18.3" data-path="ethics-checklist.html"><a href="ethics-checklist.html#transparency-explainability"><i class="fa fa-check"></i><b>18.3</b> 3. Transparency &amp; Explainability</a></li>
<li class="chapter" data-level="18.4" data-path="ethics-checklist.html"><a href="ethics-checklist.html#genai-specifics"><i class="fa fa-check"></i><b>18.4</b> 4. GenAI Specifics</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-learning" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Supervised Learning<a href="supervised-learning.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>To understand supervised learning intuitively, we will use a daily example. We have all been to the doctor and at some point told them that we have a sore throat, headache, and fever. They will ask us a few more questions and then tell us what illness we might have and what treatment to follow.</p>
<p>Intuitively, we know that the doctor had to <strong>train</strong> initially from classes and books showing past cases, and study which symptoms are signs of each disease. Then, they started to <strong>test</strong> what they learned on a group of patients during their internship. Finally, when they were already trained, they had the license to be able to <strong>apply</strong> this learning to patients in their office or hospital.</p>
<p>This is an example of <strong>supervised learning</strong> because the <strong>training</strong> was performed from known data or <em>inputs</em> which are labeled (sore throat, headache, fever) with the purpose of obtaining a result or <em>output</em> that was also known and labeled (do they have the flu or not?). When a doctor <strong>tests</strong> what they learned, the patient inputs are known and also the output given by a more experienced doctor who can say how effective their training is. When the doctor goes out to see patients, they will only have <em>labeled inputs</em> with the purpose of <strong>predicting</strong> a <em>labeled output</em>.</p>
<p>This is the logic that has been taken to computational algorithms. We can see it on Facebook, which collects a series of inputs, such as our likes, shares, etc., to predict what we might want to consume and shows it to us as a recommendation. And we will also see it in our work environment when we have inputs from our clients, such as consumption, purchasing power, place where they live, etc., to predict which of our products we predict they are more prone to buy and thus call them to offer that product.</p>
<div id="classification-and-regression" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Classification and Regression<a href="supervised-learning.html#classification-and-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are multiple supervised learning algorithms, but we will differentiate them into two according to the type of variable we handle.</p>
<p>When the variable is discrete, we will call them <strong>classification</strong>. The examples above are proof of this. We have classified into two classes (flu or not) or several classes (product “x” to recommend).</p>
<p>When the variable is continuous, we will call them <strong>regression</strong>. Predicting house prices given the characteristics of the house such as size, price, etc. is one of the common examples of regression.</p>
<p>In the following sections, we will learn some algorithms indicating whether they are classification or regression.</p>
</div>
<div id="knn-k-nearest-neighbors" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> kNN: k-Nearest Neighbors<a href="supervised-learning.html#knn-k-nearest-neighbors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s start with a simple but very useful <strong>classification</strong> algorithm, the k-Nearest Neighbors algorithm (<em>kNN</em>).</p>
<div id="two-variables-as-input" class="section level3 hasAnchor" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> Two variables as input<a href="supervised-learning.html#two-variables-as-input" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s start by understanding it visually. Imagine that we have two variables as <em>input</em> and as <em>output</em> it gives us whether it is Red Class or Blue Class. This data is our training data.</p>
<p><img src="img/kNN-train.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>Now that we have our training data, we will start using the test data. As we want to predict the class, the <em>output</em>, we will see how one of these data points would look visually and paint it yellow. Next, we calculate the distance between this point and the other data points.</p>
<p><img src="img/kNN-test.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>We have traced only some distances, but we could do it with all of them. For this example, we will take the k = 3 nearest neighbors.</p>
<p><img src="img/kNN-classify.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>We notice that if we focus only on the 3 nearest neighbors, there are more reds than blues, so our prediction will be that this point must be Class R (red).</p>
<p>Calculating the distance on a Cartesian plane is relatively simple, we only have variables as input: on the x-axis and y-axis. However, the same logic can be taken to more variables.</p>
</div>
<div id="multiple-variables-as-input" class="section level3 hasAnchor" number="12.2.2">
<h3><span class="header-section-number">12.2.2</span> Multiple variables as input<a href="supervised-learning.html#multiple-variables-as-input" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s see how it would be with 4 variables as input. We are going to work again with the <code>iris</code> data frame, which, as we will recall, has 4 attributes of a plant and the last column is the species to which it belongs.</p>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb536-1"><a href="supervised-learning.html#cb536-1" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb536-2"><a href="supervised-learning.html#cb536-2" tabindex="-1"></a></span>
<span id="cb536-3"><a href="supervised-learning.html#cb536-3" tabindex="-1"></a>iris <span class="sc">|&gt;</span> </span>
<span id="cb536-4"><a href="supervised-learning.html#cb536-4" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb536-5"><a href="supervised-learning.html#cb536-5" tabindex="-1"></a><span class="co">#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width Species</span></span>
<span id="cb536-6"><a href="supervised-learning.html#cb536-6" tabindex="-1"></a><span class="co">#&gt; 1           5.1         3.5          1.4         0.2  setosa</span></span>
<span id="cb536-7"><a href="supervised-learning.html#cb536-7" tabindex="-1"></a><span class="co">#&gt; 2           4.9         3.0          1.4         0.2  setosa</span></span>
<span id="cb536-8"><a href="supervised-learning.html#cb536-8" tabindex="-1"></a><span class="co">#&gt; 3           4.7         3.2          1.3         0.2  setosa</span></span>
<span id="cb536-9"><a href="supervised-learning.html#cb536-9" tabindex="-1"></a><span class="co">#&gt; 4           4.6         3.1          1.5         0.2  setosa</span></span>
<span id="cb536-10"><a href="supervised-learning.html#cb536-10" tabindex="-1"></a><span class="co">#&gt; 5           5.0         3.6          1.4         0.2  setosa</span></span>
<span id="cb536-11"><a href="supervised-learning.html#cb536-11" tabindex="-1"></a><span class="co">#&gt; 6           5.4         3.9          1.7         0.4  setosa</span></span>
<span id="cb536-12"><a href="supervised-learning.html#cb536-12" tabindex="-1"></a><span class="co">#&gt; 7           4.6         3.4          1.4         0.3  setosa</span></span>
<span id="cb536-13"><a href="supervised-learning.html#cb536-13" tabindex="-1"></a><span class="co">#&gt; 8           5.0         3.4          1.5         0.2  setosa</span></span>
<span id="cb536-14"><a href="supervised-learning.html#cb536-14" tabindex="-1"></a><span class="co">#&gt; 9           4.4         2.9          1.4         0.2  setosa</span></span>
<span id="cb536-15"><a href="supervised-learning.html#cb536-15" tabindex="-1"></a><span class="co">#&gt; 10          4.9         3.1          1.5         0.1  setosa</span></span></code></pre></div>
<p>The idea is as follows, we will take training data, 50 data points. From this data, we have the 4 input attributes and the last column is the output, the species. We will use the kNN algorithm taking this training data as input to create our model. Then, with testing data, another 50 data points, we will test our model.</p>
<p>Let’s start by taking a random sample of 100 records and separate half for training and half for testing. Since we have 150 data points in our data frame, let’s take a sample of the indices. In this case, we are going to use the <code>set.seed(n)</code> function to force the random sample values to be the same always. Thus, we can all obtain the same results and the explanation in the book in these chapters is consistent with the results that each reader obtains. For a real exercise, we should not include that line. It is recommended to read the documentation <code>?set.seed()</code>.</p>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="supervised-learning.html#cb537-1" tabindex="-1"></a><span class="co"># 28 is the author&#39;s birthday</span></span>
<span id="cb537-2"><a href="supervised-learning.html#cb537-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb537-3"><a href="supervised-learning.html#cb537-3" tabindex="-1"></a></span>
<span id="cb537-4"><a href="supervised-learning.html#cb537-4" tabindex="-1"></a>sample_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">150</span>, <span class="dv">100</span>)</span>
<span id="cb537-5"><a href="supervised-learning.html#cb537-5" tabindex="-1"></a></span>
<span id="cb537-6"><a href="supervised-learning.html#cb537-6" tabindex="-1"></a>train_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(sample_idx, <span class="dv">50</span>)</span>
<span id="cb537-7"><a href="supervised-learning.html#cb537-7" tabindex="-1"></a></span>
<span id="cb537-8"><a href="supervised-learning.html#cb537-8" tabindex="-1"></a>test_idx <span class="ot">&lt;-</span> sample_idx[<span class="sc">!</span>sample_idx <span class="sc">%in%</span> train_idx]</span></code></pre></div>
<p>Now that we have the indices we can build our training data and our test.</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="supervised-learning.html#cb538-1" tabindex="-1"></a>iris_train <span class="ot">&lt;-</span> iris[train_idx, ]</span>
<span id="cb538-2"><a href="supervised-learning.html#cb538-2" tabindex="-1"></a>iris_test <span class="ot">&lt;-</span> iris[test_idx, ]</span>
<span id="cb538-3"><a href="supervised-learning.html#cb538-3" tabindex="-1"></a></span>
<span id="cb538-4"><a href="supervised-learning.html#cb538-4" tabindex="-1"></a>iris_train_input <span class="ot">&lt;-</span> iris_train[, <span class="sc">-</span><span class="dv">5</span>]</span>
<span id="cb538-5"><a href="supervised-learning.html#cb538-5" tabindex="-1"></a>iris_train_output <span class="ot">&lt;-</span> iris_train[, <span class="dv">5</span>]</span>
<span id="cb538-6"><a href="supervised-learning.html#cb538-6" tabindex="-1"></a></span>
<span id="cb538-7"><a href="supervised-learning.html#cb538-7" tabindex="-1"></a>iris_test_input <span class="ot">&lt;-</span> iris_test[, <span class="sc">-</span><span class="dv">5</span>]</span>
<span id="cb538-8"><a href="supervised-learning.html#cb538-8" tabindex="-1"></a>iris_test_output <span class="ot">&lt;-</span> iris_test[, <span class="dv">5</span>]</span></code></pre></div>
<p>Although we could build the algorithms to calculate the minimum distances for each point, R provides us with libraries that facilitate the creation of these models. To do this, we will load the <code>class</code> library, which will allow us to execute kNN quickly.</p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="supervised-learning.html#cb539-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;class&quot;</span>)</span>
<span id="cb539-2"><a href="supervised-learning.html#cb539-2" tabindex="-1"></a></span>
<span id="cb539-3"><a href="supervised-learning.html#cb539-3" tabindex="-1"></a><span class="fu">library</span>(class)</span></code></pre></div>
<p>This library provides us with the <code>knn()</code> function, which will take the training data to create the model and once the model is created it will take the test data to predict the <em>output</em> for our test data.</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="supervised-learning.html#cb540-1" tabindex="-1"></a>iris_test_output_kNN <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> iris_train_input, </span>
<span id="cb540-2"><a href="supervised-learning.html#cb540-2" tabindex="-1"></a>                       <span class="at">cl =</span> iris_train_output, </span>
<span id="cb540-3"><a href="supervised-learning.html#cb540-3" tabindex="-1"></a>                       <span class="at">test =</span> iris_test_input, </span>
<span id="cb540-4"><a href="supervised-learning.html#cb540-4" tabindex="-1"></a>                       <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb540-5"><a href="supervised-learning.html#cb540-5" tabindex="-1"></a></span>
<span id="cb540-6"><a href="supervised-learning.html#cb540-6" tabindex="-1"></a>iris_test_output_kNN</span>
<span id="cb540-7"><a href="supervised-learning.html#cb540-7" tabindex="-1"></a><span class="co">#&gt;  [1] versicolor versicolor versicolor versicolor setosa     versicolor</span></span>
<span id="cb540-8"><a href="supervised-learning.html#cb540-8" tabindex="-1"></a><span class="co">#&gt;  [7] virginica  virginica  virginica  virginica  versicolor versicolor</span></span>
<span id="cb540-9"><a href="supervised-learning.html#cb540-9" tabindex="-1"></a><span class="co">#&gt; [13] virginica  versicolor versicolor versicolor setosa     versicolor</span></span>
<span id="cb540-10"><a href="supervised-learning.html#cb540-10" tabindex="-1"></a><span class="co">#&gt; [19] versicolor virginica  virginica  setosa     versicolor versicolor</span></span>
<span id="cb540-11"><a href="supervised-learning.html#cb540-11" tabindex="-1"></a><span class="co">#&gt; [25] versicolor virginica  setosa     setosa     versicolor versicolor</span></span>
<span id="cb540-12"><a href="supervised-learning.html#cb540-12" tabindex="-1"></a><span class="co">#&gt; [31] virginica  setosa     setosa     virginica  virginica  setosa    </span></span>
<span id="cb540-13"><a href="supervised-learning.html#cb540-13" tabindex="-1"></a><span class="co">#&gt; [37] setosa     virginica  setosa     versicolor setosa     virginica </span></span>
<span id="cb540-14"><a href="supervised-learning.html#cb540-14" tabindex="-1"></a><span class="co">#&gt; [43] setosa     setosa     setosa     virginica  virginica  versicolor</span></span>
<span id="cb540-15"><a href="supervised-learning.html#cb540-15" tabindex="-1"></a><span class="co">#&gt; [49] virginica  versicolor</span></span>
<span id="cb540-16"><a href="supervised-learning.html#cb540-16" tabindex="-1"></a><span class="co">#&gt; Levels: setosa versicolor virginica</span></span></code></pre></div>
<p>Thus, the knn function throws us the prediction just by entering the training data as attributes, the test inputs, and how many nearest neighbors it will look for (k). And not only that, we can compare our prediction with the test <em>output</em> to see how <strong>accurate</strong> (<em>accuracy</em>) our model is. To do this, we calculate the percentage of correct predictions regarding the test <em>output</em>.</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="supervised-learning.html#cb541-1" tabindex="-1"></a><span class="fu">mean</span>(iris_test_output_kNN <span class="sc">==</span> iris_test_output)</span>
<span id="cb541-2"><a href="supervised-learning.html#cb541-2" tabindex="-1"></a><span class="co">#&gt; [1] 0.94</span></span></code></pre></div>
<p>In addition, we can place a summary in a table, also known as a <strong>confusion matrix</strong>, to see how many predicted values were equal to the real ones using the <code>table()</code> function.</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="supervised-learning.html#cb542-1" tabindex="-1"></a><span class="fu">table</span>(iris_test_output_kNN, iris_test_output)</span>
<span id="cb542-2"><a href="supervised-learning.html#cb542-2" tabindex="-1"></a><span class="co">#&gt;                     iris_test_output</span></span>
<span id="cb542-3"><a href="supervised-learning.html#cb542-3" tabindex="-1"></a><span class="co">#&gt; iris_test_output_kNN setosa versicolor virginica</span></span>
<span id="cb542-4"><a href="supervised-learning.html#cb542-4" tabindex="-1"></a><span class="co">#&gt;           setosa         14          0         0</span></span>
<span id="cb542-5"><a href="supervised-learning.html#cb542-5" tabindex="-1"></a><span class="co">#&gt;           versicolor      0         18         2</span></span>
<span id="cb542-6"><a href="supervised-learning.html#cb542-6" tabindex="-1"></a><span class="co">#&gt;           virginica       0          1        15</span></span></code></pre></div>
<p>Let’s interpret this result cell by cell:</p>
<ol style="list-style-type: decimal">
<li>Our kNN model predicted 14 values as species “setosa” and it turns out that in our test the real value, <em>output</em>, was also setosa.</li>
<li>Our model predicted 20 as species versicolor. However, in the real-test data, of those 20, only 18 are versicolor and 2 are virginica.</li>
<li>Our model predicted 16 as species virginica. However, in the real-test data, of those 16, only 15 are virginica.</li>
</ol>
</div>
<div id="diverse-values-of-k" class="section level3 hasAnchor" number="12.2.3">
<h3><span class="header-section-number">12.2.3</span> Diverse values of k<a href="supervised-learning.html#diverse-values-of-k" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So far we have only used a single value for k, 3 nearest neighbors. However, we could see the accuracy for different values of k. Since we have 50 values in our training data, we will see the hits taking a maximum of 50 nearest neighbors.</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="supervised-learning.html#cb543-1" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">50</span></span>
<span id="cb543-2"><a href="supervised-learning.html#cb543-2" tabindex="-1"></a>result_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(k, <span class="at">precision =</span> <span class="dv">0</span>)</span>
<span id="cb543-3"><a href="supervised-learning.html#cb543-3" tabindex="-1"></a></span>
<span id="cb543-4"><a href="supervised-learning.html#cb543-4" tabindex="-1"></a><span class="cf">for</span>(n <span class="cf">in</span> k){</span>
<span id="cb543-5"><a href="supervised-learning.html#cb543-5" tabindex="-1"></a>  iris_test_output_kNN <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> iris_train_input, </span>
<span id="cb543-6"><a href="supervised-learning.html#cb543-6" tabindex="-1"></a>                              <span class="at">cl =</span> iris_train_output, </span>
<span id="cb543-7"><a href="supervised-learning.html#cb543-7" tabindex="-1"></a>                              <span class="at">test =</span> iris_test_input, </span>
<span id="cb543-8"><a href="supervised-learning.html#cb543-8" tabindex="-1"></a>                              <span class="at">k =</span> n)</span>
<span id="cb543-9"><a href="supervised-learning.html#cb543-9" tabindex="-1"></a>  </span>
<span id="cb543-10"><a href="supervised-learning.html#cb543-10" tabindex="-1"></a>  result_df<span class="sc">$</span>precision[n] <span class="ot">&lt;-</span> <span class="fu">mean</span>(iris_test_output_kNN <span class="sc">==</span> iris_test_output)</span>
<span id="cb543-11"><a href="supervised-learning.html#cb543-11" tabindex="-1"></a>}</span>
<span id="cb543-12"><a href="supervised-learning.html#cb543-12" tabindex="-1"></a></span>
<span id="cb543-13"><a href="supervised-learning.html#cb543-13" tabindex="-1"></a>result_df <span class="sc">|&gt;</span> </span>
<span id="cb543-14"><a href="supervised-learning.html#cb543-14" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb543-15"><a href="supervised-learning.html#cb543-15" tabindex="-1"></a>  <span class="fu">aes</span>(k, precision) <span class="sc">+</span></span>
<span id="cb543-16"><a href="supervised-learning.html#cb543-16" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="Data-Science-con-R_files/figure-html/unnamed-chunk-702-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>As we can see, for this case, starting from a certain number of nearest neighbors, the success rate of our algorithm begins to reduce. It will depend on each case to choose the best “k” for our model.</p>
<p>We have thus built our first machine learning model.</p>
</div>
</div>
<div id="tidymodels-framework" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> tidymodels Framework<a href="supervised-learning.html#tidymodels-framework" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we have created our first machine learning model, we have seen ourselves with many lines of code. For example, to split the sample into training and test, to calculate the optimal “k”, etc. To make the work easier, we will use the <code>tidymodels</code> framework. <a href="https://www.tidymodels.org/">tidymodels</a><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> is a collection of packages for modeling and machine learning using tidyverse principles. It provides a unified, modern interface for:</p>
<ul>
<li><strong>rsample</strong>: Data splitting and resampling</li>
<li><strong>recipes</strong>: Feature engineering and preprocessing<br />
</li>
<li><strong>parsnip</strong>: Unified model specification</li>
<li><strong>tune</strong>: Hyperparameter tuning</li>
<li><strong>yardstick</strong>: Model evaluation metrics</li>
<li><strong>workflows</strong>: Bundling recipes and models together</li>
</ul>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="supervised-learning.html#cb544-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;tidymodels&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="supervised-learning.html#cb545-1" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb545-2"><a href="supervised-learning.html#cb545-2" tabindex="-1"></a><span class="co">#&gt; ── Attaching packages ─────────── tidymodels 1.4.1 ──</span></span>
<span id="cb545-3"><a href="supervised-learning.html#cb545-3" tabindex="-1"></a><span class="co">#&gt; ✔ broom        1.0.11     ✔ tailor       0.1.0 </span></span>
<span id="cb545-4"><a href="supervised-learning.html#cb545-4" tabindex="-1"></a><span class="co">#&gt; ✔ dials        1.4.2      ✔ tune         2.0.1 </span></span>
<span id="cb545-5"><a href="supervised-learning.html#cb545-5" tabindex="-1"></a><span class="co">#&gt; ✔ infer        1.1.0      ✔ workflows    1.3.0 </span></span>
<span id="cb545-6"><a href="supervised-learning.html#cb545-6" tabindex="-1"></a><span class="co">#&gt; ✔ parsnip      1.4.0      ✔ workflowsets 1.1.1 </span></span>
<span id="cb545-7"><a href="supervised-learning.html#cb545-7" tabindex="-1"></a><span class="co">#&gt; ✔ recipes      1.3.1      ✔ yardstick    1.3.2 </span></span>
<span id="cb545-8"><a href="supervised-learning.html#cb545-8" tabindex="-1"></a><span class="co">#&gt; ✔ rsample      1.3.1</span></span>
<span id="cb545-9"><a href="supervised-learning.html#cb545-9" tabindex="-1"></a><span class="co">#&gt; ── Conflicts ────────────── tidymodels_conflicts() ──</span></span>
<span id="cb545-10"><a href="supervised-learning.html#cb545-10" tabindex="-1"></a><span class="co">#&gt; ✖ NLP::annotate()          masks ggplot2::annotate()</span></span>
<span id="cb545-11"><a href="supervised-learning.html#cb545-11" tabindex="-1"></a><span class="co">#&gt; ✖ rsample::calibration()   masks caret::calibration()</span></span>
<span id="cb545-12"><a href="supervised-learning.html#cb545-12" tabindex="-1"></a><span class="co">#&gt; ✖ scales::discard()        masks purrr::discard()</span></span>
<span id="cb545-13"><a href="supervised-learning.html#cb545-13" tabindex="-1"></a><span class="co">#&gt; ✖ Matrix::expand()         masks tidyr::expand()</span></span>
<span id="cb545-14"><a href="supervised-learning.html#cb545-14" tabindex="-1"></a><span class="co">#&gt; ✖ dplyr::filter()          masks stats::filter()</span></span>
<span id="cb545-15"><a href="supervised-learning.html#cb545-15" tabindex="-1"></a><span class="co">#&gt; ✖ recipes::fixed()         masks stringr::fixed()</span></span>
<span id="cb545-16"><a href="supervised-learning.html#cb545-16" tabindex="-1"></a><span class="co">#&gt; ✖ dplyr::lag()             masks stats::lag()</span></span>
<span id="cb545-17"><a href="supervised-learning.html#cb545-17" tabindex="-1"></a><span class="co">#&gt; ✖ caret::lift()            masks purrr::lift()</span></span>
<span id="cb545-18"><a href="supervised-learning.html#cb545-18" tabindex="-1"></a><span class="co">#&gt; ✖ Matrix::pack()           masks tidyr::pack()</span></span>
<span id="cb545-19"><a href="supervised-learning.html#cb545-19" tabindex="-1"></a><span class="co">#&gt; ✖ rsample::permutations()  masks gtools::permutations()</span></span>
<span id="cb545-20"><a href="supervised-learning.html#cb545-20" tabindex="-1"></a><span class="co">#&gt; ✖ yardstick::precision()   masks caret::precision()</span></span>
<span id="cb545-21"><a href="supervised-learning.html#cb545-21" tabindex="-1"></a><span class="co">#&gt; ✖ dials::prune()           masks dendextend::prune()</span></span>
<span id="cb545-22"><a href="supervised-learning.html#cb545-22" tabindex="-1"></a><span class="co">#&gt; ✖ yardstick::recall()      masks caret::recall()</span></span>
<span id="cb545-23"><a href="supervised-learning.html#cb545-23" tabindex="-1"></a><span class="co">#&gt; ✖ yardstick::sensitivity() masks caret::sensitivity()</span></span>
<span id="cb545-24"><a href="supervised-learning.html#cb545-24" tabindex="-1"></a><span class="co">#&gt; ✖ yardstick::spec()        masks readr::spec()</span></span>
<span id="cb545-25"><a href="supervised-learning.html#cb545-25" tabindex="-1"></a><span class="co">#&gt; ✖ yardstick::specificity() masks caret::specificity()</span></span>
<span id="cb545-26"><a href="supervised-learning.html#cb545-26" tabindex="-1"></a><span class="co">#&gt; ✖ recipes::step()          masks stats::step()</span></span>
<span id="cb545-27"><a href="supervised-learning.html#cb545-27" tabindex="-1"></a><span class="co">#&gt; ✖ Matrix::unpack()         masks tidyr::unpack()</span></span>
<span id="cb545-28"><a href="supervised-learning.html#cb545-28" tabindex="-1"></a><span class="co">#&gt; ✖ recipes::update()        masks Matrix::update(), stats::update()</span></span></code></pre></div>
<p>We are going to do another example with k-nearest neighbors, but this time using the functions of the Caret library. The data for this example will be obtained from the <code>ISLR</code> library, which contains the daily percentage returns for the S&amp;P 500 stock index between 2001 and 2005. This data frame has 8 columns that we will use as <em>input</em> and the last column that has two classes (whether the index goes up or down) that we will use as <em>output</em> (See <code>?Smarket</code>).</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="supervised-learning.html#cb546-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;ISLR&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="supervised-learning.html#cb547-1" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb547-2"><a href="supervised-learning.html#cb547-2" tabindex="-1"></a><span class="fu">data</span>(Smarket)</span>
<span id="cb547-3"><a href="supervised-learning.html#cb547-3" tabindex="-1"></a><span class="co"># Data frame that we will use</span></span>
<span id="cb547-4"><a href="supervised-learning.html#cb547-4" tabindex="-1"></a>Smarket <span class="sc">|&gt;</span> </span>
<span id="cb547-5"><a href="supervised-learning.html#cb547-5" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb547-6"><a href="supervised-learning.html#cb547-6" tabindex="-1"></a><span class="co">#&gt;    Year   Lag1   Lag2   Lag3   Lag4   Lag5 Volume  Today Direction</span></span>
<span id="cb547-7"><a href="supervised-learning.html#cb547-7" tabindex="-1"></a><span class="co">#&gt; 1  2001  0.381 -0.192 -2.624 -1.055  5.010 1.1913  0.959        Up</span></span>
<span id="cb547-8"><a href="supervised-learning.html#cb547-8" tabindex="-1"></a><span class="co">#&gt; 2  2001  0.959  0.381 -0.192 -2.624 -1.055 1.2965  1.032        Up</span></span>
<span id="cb547-9"><a href="supervised-learning.html#cb547-9" tabindex="-1"></a><span class="co">#&gt; 3  2001  1.032  0.959  0.381 -0.192 -2.624 1.4112 -0.623      Down</span></span>
<span id="cb547-10"><a href="supervised-learning.html#cb547-10" tabindex="-1"></a><span class="co">#&gt; 4  2001 -0.623  1.032  0.959  0.381 -0.192 1.2760  0.614        Up</span></span>
<span id="cb547-11"><a href="supervised-learning.html#cb547-11" tabindex="-1"></a><span class="co">#&gt; 5  2001  0.614 -0.623  1.032  0.959  0.381 1.2057  0.213        Up</span></span>
<span id="cb547-12"><a href="supervised-learning.html#cb547-12" tabindex="-1"></a><span class="co">#&gt; 6  2001  0.213  0.614 -0.623  1.032  0.959 1.3491  1.392        Up</span></span>
<span id="cb547-13"><a href="supervised-learning.html#cb547-13" tabindex="-1"></a><span class="co">#&gt; 7  2001  1.392  0.213  0.614 -0.623  1.032 1.4450 -0.403      Down</span></span>
<span id="cb547-14"><a href="supervised-learning.html#cb547-14" tabindex="-1"></a><span class="co">#&gt; 8  2001 -0.403  1.392  0.213  0.614 -0.623 1.4078  0.027        Up</span></span>
<span id="cb547-15"><a href="supervised-learning.html#cb547-15" tabindex="-1"></a><span class="co">#&gt; 9  2001  0.027 -0.403  1.392  0.213  0.614 1.1640  1.303        Up</span></span>
<span id="cb547-16"><a href="supervised-learning.html#cb547-16" tabindex="-1"></a><span class="co">#&gt; 10 2001  1.303  0.027 -0.403  1.392  0.213 1.2326  0.287        Up</span></span>
<span id="cb547-17"><a href="supervised-learning.html#cb547-17" tabindex="-1"></a></span>
<span id="cb547-18"><a href="supervised-learning.html#cb547-18" tabindex="-1"></a><span class="co"># We make some translations for ease of analysis</span></span>
<span id="cb547-19"><a href="supervised-learning.html#cb547-19" tabindex="-1"></a>Smarket <span class="ot">&lt;-</span> Smarket <span class="sc">|&gt;</span> </span>
<span id="cb547-20"><a href="supervised-learning.html#cb547-20" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">Direction =</span> Direction) <span class="sc">|&gt;</span> </span>
<span id="cb547-21"><a href="supervised-learning.html#cb547-21" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Direction =</span> <span class="fu">ifelse</span>(Direction <span class="sc">==</span> <span class="st">&quot;Up&quot;</span>, <span class="st">&quot;Sube&quot;</span>, <span class="st">&quot;Baja&quot;</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb547-22"><a href="supervised-learning.html#cb547-22" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(<span class="st">&quot;Direction&quot;</span>), <span class="sc">~</span><span class="fu">as.factor</span>(.)))</span></code></pre></div>
<div id="creation-of-training-and-test-data" class="section level3 hasAnchor" number="12.3.1">
<h3><span class="header-section-number">12.3.1</span> Creation of training and test data<a href="supervised-learning.html#creation-of-training-and-test-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From the total of our data frame, we will split a part of the data for training and the other to do the tests. tidymodels provides the <code>initial_split()</code> function from the <code>rsample</code> package which creates a clean split object. We allocate 75% of the data for training using the <code>prop</code> argument, and we can use <code>strata</code> to ensure balanced class distribution.</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="supervised-learning.html#cb548-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb548-2"><a href="supervised-learning.html#cb548-2" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(Smarket, <span class="at">prop =</span> <span class="fl">0.75</span>, <span class="at">strata =</span> Direction)</span>
<span id="cb548-3"><a href="supervised-learning.html#cb548-3" tabindex="-1"></a></span>
<span id="cb548-4"><a href="supervised-learning.html#cb548-4" tabindex="-1"></a>SP_train <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb548-5"><a href="supervised-learning.html#cb548-5" tabindex="-1"></a>SP_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span>
<span id="cb548-6"><a href="supervised-learning.html#cb548-6" tabindex="-1"></a></span>
<span id="cb548-7"><a href="supervised-learning.html#cb548-7" tabindex="-1"></a><span class="co"># Check the split</span></span>
<span id="cb548-8"><a href="supervised-learning.html#cb548-8" tabindex="-1"></a><span class="fu">nrow</span>(SP_train)</span>
<span id="cb548-9"><a href="supervised-learning.html#cb548-9" tabindex="-1"></a><span class="co">#&gt; [1] 937</span></span>
<span id="cb548-10"><a href="supervised-learning.html#cb548-10" tabindex="-1"></a><span class="fu">nrow</span>(SP_test)</span>
<span id="cb548-11"><a href="supervised-learning.html#cb548-11" tabindex="-1"></a><span class="co">#&gt; [1] 313</span></span></code></pre></div>
<p>This function makes sampling data much simpler and returns a split object that we can use with <code>training()</code> and <code>testing()</code> accessor functions.</p>
</div>
<div id="training-our-prediction-algorithm" class="section level3 hasAnchor" number="12.3.2">
<h3><span class="header-section-number">12.3.2</span> Training our prediction algorithm<a href="supervised-learning.html#training-our-prediction-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In tidymodels, we build models in a structured way using three key components:
1. <strong>Model specification</strong> (<code>parsnip</code>): Define the type of model and its engine
2. <strong>Recipe</strong> (<code>recipes</code>): Define preprocessing steps
3. <strong>Workflow</strong> (<code>workflows</code>): Bundle recipe and model together</p>
<p>Let’s start by specifying our k-nearest neighbors model. We use <code>tune()</code> as a placeholder for the <code>neighbors</code> parameter to indicate we want to find the optimal value.</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="supervised-learning.html#cb549-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb549-2"><a href="supervised-learning.html#cb549-2" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb549-3"><a href="supervised-learning.html#cb549-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb549-4"><a href="supervised-learning.html#cb549-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb549-5"><a href="supervised-learning.html#cb549-5" tabindex="-1"></a></span>
<span id="cb549-6"><a href="supervised-learning.html#cb549-6" tabindex="-1"></a>knn_spec</span>
<span id="cb549-7"><a href="supervised-learning.html#cb549-7" tabindex="-1"></a><span class="co">#&gt; K-Nearest Neighbor Model Specification (classification)</span></span>
<span id="cb549-8"><a href="supervised-learning.html#cb549-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb549-9"><a href="supervised-learning.html#cb549-9" tabindex="-1"></a><span class="co">#&gt; Main Arguments:</span></span>
<span id="cb549-10"><a href="supervised-learning.html#cb549-10" tabindex="-1"></a><span class="co">#&gt;   neighbors = tune()</span></span>
<span id="cb549-11"><a href="supervised-learning.html#cb549-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb549-12"><a href="supervised-learning.html#cb549-12" tabindex="-1"></a><span class="co">#&gt; Computational engine: kknn</span></span></code></pre></div>
</div>
<div id="data-pre-processing-with-recipes" class="section level3 hasAnchor" number="12.3.3">
<h3><span class="header-section-number">12.3.3</span> Data Pre-processing with Recipes<a href="supervised-learning.html#data-pre-processing-with-recipes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>tidymodels uses <code>recipes</code> for preprocessing. The <code>scale</code> method (division by standard deviation) and <code>centering</code> (subtraction of the mean) are implemented with <code>step_normalize()</code>.</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="supervised-learning.html#cb550-1" tabindex="-1"></a><span class="co"># Define preprocessing recipe</span></span>
<span id="cb550-2"><a href="supervised-learning.html#cb550-2" tabindex="-1"></a>knn_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Direction <span class="sc">~</span> ., <span class="at">data =</span> SP_train) <span class="sc">|&gt;</span></span>
<span id="cb550-3"><a href="supervised-learning.html#cb550-3" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span>
<span id="cb550-4"><a href="supervised-learning.html#cb550-4" tabindex="-1"></a></span>
<span id="cb550-5"><a href="supervised-learning.html#cb550-5" tabindex="-1"></a>knn_recipe</span>
<span id="cb550-6"><a href="supervised-learning.html#cb550-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb550-7"><a href="supervised-learning.html#cb550-7" tabindex="-1"></a><span class="co">#&gt; ── Recipe ───────────────────────────────────────────</span></span>
<span id="cb550-8"><a href="supervised-learning.html#cb550-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb550-9"><a href="supervised-learning.html#cb550-9" tabindex="-1"></a><span class="co">#&gt; ── Inputs</span></span>
<span id="cb550-10"><a href="supervised-learning.html#cb550-10" tabindex="-1"></a><span class="co">#&gt; Number of variables by role</span></span>
<span id="cb550-11"><a href="supervised-learning.html#cb550-11" tabindex="-1"></a><span class="co">#&gt; outcome:   1</span></span>
<span id="cb550-12"><a href="supervised-learning.html#cb550-12" tabindex="-1"></a><span class="co">#&gt; predictor: 8</span></span>
<span id="cb550-13"><a href="supervised-learning.html#cb550-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb550-14"><a href="supervised-learning.html#cb550-14" tabindex="-1"></a><span class="co">#&gt; ── Operations</span></span>
<span id="cb550-15"><a href="supervised-learning.html#cb550-15" tabindex="-1"></a><span class="co">#&gt; • Centering and scaling for:</span></span>
<span id="cb550-16"><a href="supervised-learning.html#cb550-16" tabindex="-1"></a><span class="co">#&gt;   all_numeric_predictors()</span></span></code></pre></div>
</div>
<div id="creating-a-workflow" class="section level3 hasAnchor" number="12.3.4">
<h3><span class="header-section-number">12.3.4</span> Creating a Workflow<a href="supervised-learning.html#creating-a-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A workflow bundles the recipe and model specification together for easy training and prediction.</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="supervised-learning.html#cb551-1" tabindex="-1"></a><span class="co"># Bundle into workflow</span></span>
<span id="cb551-2"><a href="supervised-learning.html#cb551-2" tabindex="-1"></a>knn_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb551-3"><a href="supervised-learning.html#cb551-3" tabindex="-1"></a>  <span class="fu">add_recipe</span>(knn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb551-4"><a href="supervised-learning.html#cb551-4" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec)</span>
<span id="cb551-5"><a href="supervised-learning.html#cb551-5" tabindex="-1"></a></span>
<span id="cb551-6"><a href="supervised-learning.html#cb551-6" tabindex="-1"></a>knn_workflow</span>
<span id="cb551-7"><a href="supervised-learning.html#cb551-7" tabindex="-1"></a><span class="co">#&gt; ══ Workflow ═════════════════════════════════════════</span></span>
<span id="cb551-8"><a href="supervised-learning.html#cb551-8" tabindex="-1"></a><span class="co">#&gt; Preprocessor: Recipe</span></span>
<span id="cb551-9"><a href="supervised-learning.html#cb551-9" tabindex="-1"></a><span class="co">#&gt; Model: nearest_neighbor()</span></span>
<span id="cb551-10"><a href="supervised-learning.html#cb551-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb551-11"><a href="supervised-learning.html#cb551-11" tabindex="-1"></a><span class="co">#&gt; ── Preprocessor ─────────────────────────────────────</span></span>
<span id="cb551-12"><a href="supervised-learning.html#cb551-12" tabindex="-1"></a><span class="co">#&gt; 1 Recipe Step</span></span>
<span id="cb551-13"><a href="supervised-learning.html#cb551-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb551-14"><a href="supervised-learning.html#cb551-14" tabindex="-1"></a><span class="co">#&gt; • step_normalize()</span></span>
<span id="cb551-15"><a href="supervised-learning.html#cb551-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb551-16"><a href="supervised-learning.html#cb551-16" tabindex="-1"></a><span class="co">#&gt; ── Model ────────────────────────────────────────────</span></span>
<span id="cb551-17"><a href="supervised-learning.html#cb551-17" tabindex="-1"></a><span class="co">#&gt; K-Nearest Neighbor Model Specification (classification)</span></span>
<span id="cb551-18"><a href="supervised-learning.html#cb551-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb551-19"><a href="supervised-learning.html#cb551-19" tabindex="-1"></a><span class="co">#&gt; Main Arguments:</span></span>
<span id="cb551-20"><a href="supervised-learning.html#cb551-20" tabindex="-1"></a><span class="co">#&gt;   neighbors = tune()</span></span>
<span id="cb551-21"><a href="supervised-learning.html#cb551-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb551-22"><a href="supervised-learning.html#cb551-22" tabindex="-1"></a><span class="co">#&gt; Computational engine: kknn</span></span></code></pre></div>
</div>
<div id="parameter-tuning-with-cross-validation" class="section level3 hasAnchor" number="12.3.5">
<h3><span class="header-section-number">12.3.5</span> Parameter Tuning with Cross-Validation<a href="supervised-learning.html#parameter-tuning-with-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the most important parts of training machine learning models is tuning the parameters. We use <code>vfold_cv()</code> to create cross-validation folds and <code>tune_grid()</code> to search for the best hyperparameters.</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="supervised-learning.html#cb552-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb552-2"><a href="supervised-learning.html#cb552-2" tabindex="-1"></a></span>
<span id="cb552-3"><a href="supervised-learning.html#cb552-3" tabindex="-1"></a><span class="co"># Create 5-fold cross-validation</span></span>
<span id="cb552-4"><a href="supervised-learning.html#cb552-4" tabindex="-1"></a>folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(SP_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> Direction)</span>
<span id="cb552-5"><a href="supervised-learning.html#cb552-5" tabindex="-1"></a></span>
<span id="cb552-6"><a href="supervised-learning.html#cb552-6" tabindex="-1"></a><span class="co"># Create a grid of k values to try</span></span>
<span id="cb552-7"><a href="supervised-learning.html#cb552-7" tabindex="-1"></a>k_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(<span class="fu">neighbors</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">50</span>)), <span class="at">levels =</span> <span class="dv">20</span>)</span>
<span id="cb552-8"><a href="supervised-learning.html#cb552-8" tabindex="-1"></a></span>
<span id="cb552-9"><a href="supervised-learning.html#cb552-9" tabindex="-1"></a><span class="co"># Tune the model</span></span>
<span id="cb552-10"><a href="supervised-learning.html#cb552-10" tabindex="-1"></a>knn_tune_results <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb552-11"><a href="supervised-learning.html#cb552-11" tabindex="-1"></a>  knn_workflow,</span>
<span id="cb552-12"><a href="supervised-learning.html#cb552-12" tabindex="-1"></a>  <span class="at">resamples =</span> folds,</span>
<span id="cb552-13"><a href="supervised-learning.html#cb552-13" tabindex="-1"></a>  <span class="at">grid =</span> k_grid</span>
<span id="cb552-14"><a href="supervised-learning.html#cb552-14" tabindex="-1"></a>)</span>
<span id="cb552-15"><a href="supervised-learning.html#cb552-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb552-16"><a href="supervised-learning.html#cb552-16" tabindex="-1"></a><span class="co">#&gt; Attaching package: &#39;kknn&#39;</span></span>
<span id="cb552-17"><a href="supervised-learning.html#cb552-17" tabindex="-1"></a><span class="co">#&gt; The following object is masked from &#39;package:caret&#39;:</span></span>
<span id="cb552-18"><a href="supervised-learning.html#cb552-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb552-19"><a href="supervised-learning.html#cb552-19" tabindex="-1"></a><span class="co">#&gt;     contr.dummy</span></span>
<span id="cb552-20"><a href="supervised-learning.html#cb552-20" tabindex="-1"></a></span>
<span id="cb552-21"><a href="supervised-learning.html#cb552-21" tabindex="-1"></a>knn_tune_results</span>
<span id="cb552-22"><a href="supervised-learning.html#cb552-22" tabindex="-1"></a><span class="co">#&gt; # Tuning results</span></span>
<span id="cb552-23"><a href="supervised-learning.html#cb552-23" tabindex="-1"></a><span class="co">#&gt; # 5-fold cross-validation using stratification </span></span>
<span id="cb552-24"><a href="supervised-learning.html#cb552-24" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 4</span></span>
<span id="cb552-25"><a href="supervised-learning.html#cb552-25" tabindex="-1"></a><span class="co">#&gt;   splits            id    .metrics          .notes          </span></span>
<span id="cb552-26"><a href="supervised-learning.html#cb552-26" tabindex="-1"></a><span class="co">#&gt;   &lt;list&gt;            &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          </span></span>
<span id="cb552-27"><a href="supervised-learning.html#cb552-27" tabindex="-1"></a><span class="co">#&gt; 1 &lt;split [748/189]&gt; Fold1 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb552-28"><a href="supervised-learning.html#cb552-28" tabindex="-1"></a><span class="co">#&gt; 2 &lt;split [750/187]&gt; Fold2 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb552-29"><a href="supervised-learning.html#cb552-29" tabindex="-1"></a><span class="co">#&gt; 3 &lt;split [750/187]&gt; Fold3 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb552-30"><a href="supervised-learning.html#cb552-30" tabindex="-1"></a><span class="co">#&gt; 4 &lt;split [750/187]&gt; Fold4 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb552-31"><a href="supervised-learning.html#cb552-31" tabindex="-1"></a><span class="co">#&gt; 5 &lt;split [750/187]&gt; Fold5 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span></code></pre></div>
<p>We can visualize the tuning results using <code>autoplot()</code>:</p>
<div class="sourceCode" id="cb553"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb553-1"><a href="supervised-learning.html#cb553-1" tabindex="-1"></a><span class="fu">autoplot</span>(knn_tune_results)</span></code></pre></div>
<p><img src="Data-Science-con-R_files/figure-html/unnamed-chunk-712-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>We can see the accuracy for each value of “k”. The <code>show_best()</code> function shows us the top performing values:</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="supervised-learning.html#cb554-1" tabindex="-1"></a><span class="fu">show_best</span>(knn_tune_results, <span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb554-2"><a href="supervised-learning.html#cb554-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 7</span></span>
<span id="cb554-3"><a href="supervised-learning.html#cb554-3" tabindex="-1"></a><span class="co">#&gt;   neighbors .metric  .estimator  mean     n std_err .config         </span></span>
<span id="cb554-4"><a href="supervised-learning.html#cb554-4" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb554-5"><a href="supervised-learning.html#cb554-5" tabindex="-1"></a><span class="co">#&gt; 1        44 accuracy binary     0.905     5  0.0114 pre0_mod18_post0</span></span>
<span id="cb554-6"><a href="supervised-learning.html#cb554-6" tabindex="-1"></a><span class="co">#&gt; 2        42 accuracy binary     0.904     5  0.0116 pre0_mod17_post0</span></span>
<span id="cb554-7"><a href="supervised-learning.html#cb554-7" tabindex="-1"></a><span class="co">#&gt; 3        37 accuracy binary     0.902     5  0.0115 pre0_mod15_post0</span></span>
<span id="cb554-8"><a href="supervised-learning.html#cb554-8" tabindex="-1"></a><span class="co">#&gt; 4        31 accuracy binary     0.902     5  0.0112 pre0_mod13_post0</span></span>
<span id="cb554-9"><a href="supervised-learning.html#cb554-9" tabindex="-1"></a><span class="co">#&gt; 5        47 accuracy binary     0.901     5  0.0119 pre0_mod19_post0</span></span></code></pre></div>
</div>
<div id="finalizing-the-model" class="section level3 hasAnchor" number="12.3.6">
<h3><span class="header-section-number">12.3.6</span> Finalizing the Model<a href="supervised-learning.html#finalizing-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once we’ve found the best hyperparameters, we finalize our workflow with those values:</p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="supervised-learning.html#cb555-1" tabindex="-1"></a><span class="co"># Select the best k value</span></span>
<span id="cb555-2"><a href="supervised-learning.html#cb555-2" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> <span class="fu">select_best</span>(knn_tune_results, <span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb555-3"><a href="supervised-learning.html#cb555-3" tabindex="-1"></a>best_k</span>
<span id="cb555-4"><a href="supervised-learning.html#cb555-4" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 2</span></span>
<span id="cb555-5"><a href="supervised-learning.html#cb555-5" tabindex="-1"></a><span class="co">#&gt;   neighbors .config         </span></span>
<span id="cb555-6"><a href="supervised-learning.html#cb555-6" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;           </span></span>
<span id="cb555-7"><a href="supervised-learning.html#cb555-7" tabindex="-1"></a><span class="co">#&gt; 1        44 pre0_mod18_post0</span></span>
<span id="cb555-8"><a href="supervised-learning.html#cb555-8" tabindex="-1"></a></span>
<span id="cb555-9"><a href="supervised-learning.html#cb555-9" tabindex="-1"></a><span class="co"># Finalize the workflow with the best parameters</span></span>
<span id="cb555-10"><a href="supervised-learning.html#cb555-10" tabindex="-1"></a>final_knn_workflow <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(knn_workflow, best_k)</span>
<span id="cb555-11"><a href="supervised-learning.html#cb555-11" tabindex="-1"></a></span>
<span id="cb555-12"><a href="supervised-learning.html#cb555-12" tabindex="-1"></a><span class="co"># Fit the final model on the entire training set</span></span>
<span id="cb555-13"><a href="supervised-learning.html#cb555-13" tabindex="-1"></a>SP_knn_trained <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_knn_workflow, <span class="at">data =</span> SP_train)</span>
<span id="cb555-14"><a href="supervised-learning.html#cb555-14" tabindex="-1"></a></span>
<span id="cb555-15"><a href="supervised-learning.html#cb555-15" tabindex="-1"></a>SP_knn_trained</span>
<span id="cb555-16"><a href="supervised-learning.html#cb555-16" tabindex="-1"></a><span class="co">#&gt; ══ Workflow [trained] ═══════════════════════════════</span></span>
<span id="cb555-17"><a href="supervised-learning.html#cb555-17" tabindex="-1"></a><span class="co">#&gt; Preprocessor: Recipe</span></span>
<span id="cb555-18"><a href="supervised-learning.html#cb555-18" tabindex="-1"></a><span class="co">#&gt; Model: nearest_neighbor()</span></span>
<span id="cb555-19"><a href="supervised-learning.html#cb555-19" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb555-20"><a href="supervised-learning.html#cb555-20" tabindex="-1"></a><span class="co">#&gt; ── Preprocessor ─────────────────────────────────────</span></span>
<span id="cb555-21"><a href="supervised-learning.html#cb555-21" tabindex="-1"></a><span class="co">#&gt; 1 Recipe Step</span></span>
<span id="cb555-22"><a href="supervised-learning.html#cb555-22" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb555-23"><a href="supervised-learning.html#cb555-23" tabindex="-1"></a><span class="co">#&gt; • step_normalize()</span></span>
<span id="cb555-24"><a href="supervised-learning.html#cb555-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb555-25"><a href="supervised-learning.html#cb555-25" tabindex="-1"></a><span class="co">#&gt; ── Model ────────────────────────────────────────────</span></span>
<span id="cb555-26"><a href="supervised-learning.html#cb555-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb555-27"><a href="supervised-learning.html#cb555-27" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb555-28"><a href="supervised-learning.html#cb555-28" tabindex="-1"></a><span class="co">#&gt; kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(44L,     data, 5))</span></span>
<span id="cb555-29"><a href="supervised-learning.html#cb555-29" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb555-30"><a href="supervised-learning.html#cb555-30" tabindex="-1"></a><span class="co">#&gt; Type of response variable: nominal</span></span>
<span id="cb555-31"><a href="supervised-learning.html#cb555-31" tabindex="-1"></a><span class="co">#&gt; Minimal misclassification: 0.0864461</span></span>
<span id="cb555-32"><a href="supervised-learning.html#cb555-32" tabindex="-1"></a><span class="co">#&gt; Best kernel: optimal</span></span>
<span id="cb555-33"><a href="supervised-learning.html#cb555-33" tabindex="-1"></a><span class="co">#&gt; Best k: 44</span></span></code></pre></div>
<p>We see the substantial improvement now that we have adjusted some parameters and made it reprocess first. Note that each time we adjust parameters, the value of “k” can change until the most optimal one is found. In this case, it changed to k = 29. This does not mean that the lower the “k”, the better the algorithm, only that it is the most optimal for this particular case with these adjustments made.</p>
</div>
<div id="testing-the-prediction-model" class="section level3 hasAnchor" number="12.3.7">
<h3><span class="header-section-number">12.3.7</span> Testing the prediction model<a href="supervised-learning.html#testing-the-prediction-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We already have our model trained and ready to test it. tidymodels makes it easy to make predictions using the <code>augment()</code> function which adds predictions directly to our test data.</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="supervised-learning.html#cb556-1" tabindex="-1"></a><span class="co"># Make predictions on test data</span></span>
<span id="cb556-2"><a href="supervised-learning.html#cb556-2" tabindex="-1"></a>SP_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(SP_knn_trained, <span class="at">new_data =</span> SP_test)</span>
<span id="cb556-3"><a href="supervised-learning.html#cb556-3" tabindex="-1"></a></span>
<span id="cb556-4"><a href="supervised-learning.html#cb556-4" tabindex="-1"></a><span class="co"># View predictions</span></span>
<span id="cb556-5"><a href="supervised-learning.html#cb556-5" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span> </span>
<span id="cb556-6"><a href="supervised-learning.html#cb556-6" tabindex="-1"></a>  <span class="fu">select</span>(Direction, .pred_class, .pred_Baja, .pred_Sube) <span class="sc">|&gt;</span></span>
<span id="cb556-7"><a href="supervised-learning.html#cb556-7" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb556-8"><a href="supervised-learning.html#cb556-8" tabindex="-1"></a><span class="co">#&gt; # A tibble: 10 × 4</span></span>
<span id="cb556-9"><a href="supervised-learning.html#cb556-9" tabindex="-1"></a><span class="co">#&gt;    Direction .pred_class .pred_Baja .pred_Sube</span></span>
<span id="cb556-10"><a href="supervised-learning.html#cb556-10" tabindex="-1"></a><span class="co">#&gt;    &lt;fct&gt;     &lt;fct&gt;            &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span id="cb556-11"><a href="supervised-learning.html#cb556-11" tabindex="-1"></a><span class="co">#&gt;  1 Sube      Sube            0.243      0.757 </span></span>
<span id="cb556-12"><a href="supervised-learning.html#cb556-12" tabindex="-1"></a><span class="co">#&gt;  2 Sube      Sube            0.404      0.596 </span></span>
<span id="cb556-13"><a href="supervised-learning.html#cb556-13" tabindex="-1"></a><span class="co">#&gt;  3 Baja      Baja            0.611      0.389 </span></span>
<span id="cb556-14"><a href="supervised-learning.html#cb556-14" tabindex="-1"></a><span class="co">#&gt;  4 Baja      Baja            0.977      0.0231</span></span>
<span id="cb556-15"><a href="supervised-learning.html#cb556-15" tabindex="-1"></a><span class="co">#&gt;  5 Sube      Sube            0.230      0.770 </span></span>
<span id="cb556-16"><a href="supervised-learning.html#cb556-16" tabindex="-1"></a><span class="co">#&gt;  6 Baja      Sube            0.472      0.528 </span></span>
<span id="cb556-17"><a href="supervised-learning.html#cb556-17" tabindex="-1"></a><span class="co">#&gt;  7 Baja      Baja            0.955      0.0447</span></span>
<span id="cb556-18"><a href="supervised-learning.html#cb556-18" tabindex="-1"></a><span class="co">#&gt;  8 Sube      Sube            0.0361     0.964 </span></span>
<span id="cb556-19"><a href="supervised-learning.html#cb556-19" tabindex="-1"></a><span class="co">#&gt;  9 Baja      Baja            0.522      0.478 </span></span>
<span id="cb556-20"><a href="supervised-learning.html#cb556-20" tabindex="-1"></a><span class="co">#&gt; 10 Baja      Baja            1          0</span></span></code></pre></div>
<p>The <code>augment()</code> function adds three columns: <code>.pred_class</code> (the predicted class), and probability columns for each class (<code>.pred_Baja</code> and <code>.pred_Sube</code>). This makes it very easy to compare predictions with actual values.</p>
<p>As we can see, for each test value the model calculates the estimated probability for each class. The algorithm assigns the class with the highest probability.</p>
</div>
<div id="model-evaluation-with-yardstick" class="section level3 hasAnchor" number="12.3.8">
<h3><span class="header-section-number">12.3.8</span> Model Evaluation with yardstick<a href="supervised-learning.html#model-evaluation-with-yardstick" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To evaluate our model, we use the <code>yardstick</code> package. The <code>conf_mat()</code> function creates a confusion matrix, and we can calculate various metrics like accuracy, sensitivity, and specificity.</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="supervised-learning.html#cb557-1" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb557-2"><a href="supervised-learning.html#cb557-2" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span></span>
<span id="cb557-3"><a href="supervised-learning.html#cb557-3" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb557-4"><a href="supervised-learning.html#cb557-4" tabindex="-1"></a><span class="co">#&gt;           Truth</span></span>
<span id="cb557-5"><a href="supervised-learning.html#cb557-5" tabindex="-1"></a><span class="co">#&gt; Prediction Baja Sube</span></span>
<span id="cb557-6"><a href="supervised-learning.html#cb557-6" tabindex="-1"></a><span class="co">#&gt;       Baja  132    4</span></span>
<span id="cb557-7"><a href="supervised-learning.html#cb557-7" tabindex="-1"></a><span class="co">#&gt;       Sube   19  158</span></span>
<span id="cb557-8"><a href="supervised-learning.html#cb557-8" tabindex="-1"></a></span>
<span id="cb557-9"><a href="supervised-learning.html#cb557-9" tabindex="-1"></a><span class="co"># Calculate accuracy</span></span>
<span id="cb557-10"><a href="supervised-learning.html#cb557-10" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span></span>
<span id="cb557-11"><a href="supervised-learning.html#cb557-11" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb557-12"><a href="supervised-learning.html#cb557-12" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb557-13"><a href="supervised-learning.html#cb557-13" tabindex="-1"></a><span class="co">#&gt;   .metric  .estimator .estimate</span></span>
<span id="cb557-14"><a href="supervised-learning.html#cb557-14" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb557-15"><a href="supervised-learning.html#cb557-15" tabindex="-1"></a><span class="co">#&gt; 1 accuracy binary         0.927</span></span>
<span id="cb557-16"><a href="supervised-learning.html#cb557-16" tabindex="-1"></a></span>
<span id="cb557-17"><a href="supervised-learning.html#cb557-17" tabindex="-1"></a><span class="co"># Calculate multiple metrics at once</span></span>
<span id="cb557-18"><a href="supervised-learning.html#cb557-18" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span></span>
<span id="cb557-19"><a href="supervised-learning.html#cb557-19" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb557-20"><a href="supervised-learning.html#cb557-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 3</span></span>
<span id="cb557-21"><a href="supervised-learning.html#cb557-21" tabindex="-1"></a><span class="co">#&gt;   .metric  .estimator .estimate</span></span>
<span id="cb557-22"><a href="supervised-learning.html#cb557-22" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb557-23"><a href="supervised-learning.html#cb557-23" tabindex="-1"></a><span class="co">#&gt; 1 accuracy binary         0.927</span></span>
<span id="cb557-24"><a href="supervised-learning.html#cb557-24" tabindex="-1"></a><span class="co">#&gt; 2 kap      binary         0.852</span></span></code></pre></div>
<p>We obtain the accuracy as well as other metrics. The yardstick package provides many evaluation functions including <code>sens()</code> (sensitivity), <code>spec()</code> (specificity), <code>precision()</code>, <code>recall()</code>, and more.</p>
</div>
</div>
<div id="confusion-matrix" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> Confusion Matrix<a href="supervised-learning.html#confusion-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have already used confusion matrices in our two previous examples. Now it is our turn to properly understand its definition as well as some of the evaluation metrics of this matrix.</p>
<p>A confusion matrix, also known as an error matrix, allows us to visualize the performance of an algorithm, generally a supervised learning one (in unsupervised learning it is generally called a matching matrix). Each row of the matrix represents the instances in a predicted class, while each column represents the instances in a real class (or vice versa). The name derives from the fact that it makes it easy to see if the system confuses two classes (i.e., commonly mislabeling one as another).</p>
<p>Binary classifications, when the <em>outcome</em> can take only two classes, yield this following confusion matrix.</p>
<p><img src="img/confusion-matrix.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<div id="accuracy" class="section level3 hasAnchor" number="12.4.1">
<h3><span class="header-section-number">12.4.1</span> Accuracy<a href="supervised-learning.html#accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have already been using this term in our examples. The accuracy of the model can be calculated from the confusion matrix:</p>
<p><span class="math inline">\(Accuracy=\frac{VP+VN}{VP+VN+FP+FN}\)</span></p>
<p>The <em>accuracy</em> of the model is the proportion of times the algorithm predicted correctly, regarding the total data evaluated.</p>
</div>
<div id="sensitivity" class="section level3 hasAnchor" number="12.4.2">
<h3><span class="header-section-number">12.4.2</span> Sensitivity<a href="supervised-learning.html#sensitivity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sensitivity (also called true positive rate, recall, or probability of detection in some fields) measures the proportion of real positives that are correctly identified as such (for example, the percentage of sick people who are correctly identified as having the condition).</p>
<p><span class="math inline">\(Sensitivity=\frac{VP}{VP+FN}\)</span></p>
</div>
<div id="specificity" class="section level3 hasAnchor" number="12.4.3">
<h3><span class="header-section-number">12.4.3</span> Specificity<a href="supervised-learning.html#specificity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Specificity (also called true negative rate) measures the proportion of real negatives that are correctly identified as such (for example, the percentage of healthy people who are correctly identified as not having the condition).</p>
<p><span class="math inline">\(Specificity=\frac{VN}{VN+FP}\)</span></p>
</div>
</div>
<div id="exercises-18" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> Exercises<a href="supervised-learning.html#exercises-18" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol start="111" style="list-style-type: decimal">
<li>Using the tidymodels library, partition the <code>iris</code> data frame in such a way as to have 70% training data and 30% test data.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="supervised-learning.html#cb558-1" tabindex="-1"></a>iris_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(iris, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> Species)</span>
<span id="cb558-2"><a href="supervised-learning.html#cb558-2" tabindex="-1"></a></span>
<span id="cb558-3"><a href="supervised-learning.html#cb558-3" tabindex="-1"></a>iris_train <span class="ot">&lt;-</span> <span class="fu">training</span>(iris_split)</span>
<span id="cb558-4"><a href="supervised-learning.html#cb558-4" tabindex="-1"></a>iris_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(iris_split)</span></code></pre></div>
</details>
<ol start="112" style="list-style-type: decimal">
<li>Using tidymodels and the training data obtained in the previous exercise, create a k-nearest neighbor model with tuning. Plot the result.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="supervised-learning.html#cb559-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb559-2"><a href="supervised-learning.html#cb559-2" tabindex="-1"></a>iris_knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb559-3"><a href="supervised-learning.html#cb559-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb559-4"><a href="supervised-learning.html#cb559-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb559-5"><a href="supervised-learning.html#cb559-5" tabindex="-1"></a></span>
<span id="cb559-6"><a href="supervised-learning.html#cb559-6" tabindex="-1"></a><span class="co"># Recipe with preprocessing</span></span>
<span id="cb559-7"><a href="supervised-learning.html#cb559-7" tabindex="-1"></a>iris_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> iris_train) <span class="sc">|&gt;</span></span>
<span id="cb559-8"><a href="supervised-learning.html#cb559-8" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span>
<span id="cb559-9"><a href="supervised-learning.html#cb559-9" tabindex="-1"></a></span>
<span id="cb559-10"><a href="supervised-learning.html#cb559-10" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb559-11"><a href="supervised-learning.html#cb559-11" tabindex="-1"></a>iris_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb559-12"><a href="supervised-learning.html#cb559-12" tabindex="-1"></a>  <span class="fu">add_recipe</span>(iris_recipe) <span class="sc">|&gt;</span></span>
<span id="cb559-13"><a href="supervised-learning.html#cb559-13" tabindex="-1"></a>  <span class="fu">add_model</span>(iris_knn_spec)</span>
<span id="cb559-14"><a href="supervised-learning.html#cb559-14" tabindex="-1"></a></span>
<span id="cb559-15"><a href="supervised-learning.html#cb559-15" tabindex="-1"></a><span class="co"># Cross-validation and tuning</span></span>
<span id="cb559-16"><a href="supervised-learning.html#cb559-16" tabindex="-1"></a>iris_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(iris_train, <span class="at">v =</span> <span class="dv">5</span>)</span>
<span id="cb559-17"><a href="supervised-learning.html#cb559-17" tabindex="-1"></a>iris_tune <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(iris_workflow, <span class="at">resamples =</span> iris_folds, <span class="at">grid =</span> <span class="dv">20</span>)</span>
<span id="cb559-18"><a href="supervised-learning.html#cb559-18" tabindex="-1"></a></span>
<span id="cb559-19"><a href="supervised-learning.html#cb559-19" tabindex="-1"></a><span class="fu">autoplot</span>(iris_tune)</span></code></pre></div>
</details>
<ol start="113" style="list-style-type: decimal">
<li>Use the model created in the previous exercise to predict the <em>outputs</em> of the <code>test</code> object. Report the confusion matrix.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb560-1"><a href="supervised-learning.html#cb560-1" tabindex="-1"></a><span class="co"># Finalize model with best k</span></span>
<span id="cb560-2"><a href="supervised-learning.html#cb560-2" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> <span class="fu">select_best</span>(iris_tune, <span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb560-3"><a href="supervised-learning.html#cb560-3" tabindex="-1"></a>final_iris_wf <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(iris_workflow, best_k)</span>
<span id="cb560-4"><a href="supervised-learning.html#cb560-4" tabindex="-1"></a>iris_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_iris_wf, <span class="at">data =</span> iris_train)</span>
<span id="cb560-5"><a href="supervised-learning.html#cb560-5" tabindex="-1"></a></span>
<span id="cb560-6"><a href="supervised-learning.html#cb560-6" tabindex="-1"></a><span class="co"># Predict and evaluate</span></span>
<span id="cb560-7"><a href="supervised-learning.html#cb560-7" tabindex="-1"></a>iris_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(iris_fit, <span class="at">new_data =</span> iris_test)</span>
<span id="cb560-8"><a href="supervised-learning.html#cb560-8" tabindex="-1"></a>iris_predictions <span class="sc">|&gt;</span> <span class="fu">conf_mat</span>(<span class="at">truth =</span> Species, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
</details>
</div>
<div id="simple-linear-regression" class="section level2 hasAnchor" number="12.6">
<h2><span class="header-section-number">12.6</span> Simple Linear Regression<a href="supervised-learning.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now we have to predict on continuous variables, the supervision algorithms for these cases are called <strong>regression</strong>.</p>
<p>To understand linear regression we are going to start with an example with a single variable as <em>input</em>, this is known as Simple Linear Regression. To do this we are going to use data from the <code>HistData</code> library where we will find a dataset that enumerates the individual observations of 934 children in 205 families stored in the object <code>GaltonFamilies</code>.</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="supervised-learning.html#cb561-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;HistData&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="supervised-learning.html#cb562-1" tabindex="-1"></a><span class="fu">library</span>(HistData)</span>
<span id="cb562-2"><a href="supervised-learning.html#cb562-2" tabindex="-1"></a><span class="fu">data</span>(GaltonFamilies)</span>
<span id="cb562-3"><a href="supervised-learning.html#cb562-3" tabindex="-1"></a></span>
<span id="cb562-4"><a href="supervised-learning.html#cb562-4" tabindex="-1"></a><span class="co"># We make some filters to have one dad and one son per family</span></span>
<span id="cb562-5"><a href="supervised-learning.html#cb562-5" tabindex="-1"></a>heights_df <span class="ot">&lt;-</span> GaltonFamilies <span class="sc">|&gt;</span></span>
<span id="cb562-6"><a href="supervised-learning.html#cb562-6" tabindex="-1"></a>  <span class="fu">filter</span>(gender <span class="sc">==</span> <span class="st">&quot;male&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb562-7"><a href="supervised-learning.html#cb562-7" tabindex="-1"></a>  <span class="fu">group_by</span>(family) <span class="sc">|&gt;</span></span>
<span id="cb562-8"><a href="supervised-learning.html#cb562-8" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">n =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> <span class="co"># random sample of 1 son per family</span></span>
<span id="cb562-9"><a href="supervised-learning.html#cb562-9" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">|&gt;</span></span>
<span id="cb562-10"><a href="supervised-learning.html#cb562-10" tabindex="-1"></a>  <span class="fu">select</span>(father, childHeight) <span class="sc">|&gt;</span></span>
<span id="cb562-11"><a href="supervised-learning.html#cb562-11" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">son =</span> childHeight, <span class="at">father =</span> father) <span class="sc">|&gt;</span> </span>
<span id="cb562-12"><a href="supervised-learning.html#cb562-12" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">father =</span> father<span class="sc">/</span><span class="fl">39.37</span>) <span class="sc">|&gt;</span> <span class="co"># From inches to meters</span></span>
<span id="cb562-13"><a href="supervised-learning.html#cb562-13" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">son =</span> son<span class="sc">/</span><span class="fl">39.37</span>) <span class="co"># From inches to meters</span></span></code></pre></div>
<p>Visually we could see if there is a relationship between the heights of dad and son:</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="supervised-learning.html#cb563-1" tabindex="-1"></a>heights_df <span class="sc">|&gt;</span> </span>
<span id="cb563-2"><a href="supervised-learning.html#cb563-2" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb563-3"><a href="supervised-learning.html#cb563-3" tabindex="-1"></a>  <span class="fu">aes</span>(father, son) <span class="sc">+</span></span>
<span id="cb563-4"><a href="supervised-learning.html#cb563-4" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb563-5"><a href="supervised-learning.html#cb563-5" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Data-Science-con-R_files/figure-html/unnamed-chunk-726-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>As we can see, there is a positive correlation, such that the taller the father, the son grows to be taller as an adult. This line, however, is nothing more than a default line. The challenge lies in finding which line minimizes the distance of the points to this line, known as error minimization.</p>
<p>We could try to predict the height the son will have from the father’s height using the equation of this line:</p>
<p><span class="math inline">\(Y = \beta_0+\beta_1X\)</span></p>
<p>Where <span class="math inline">\(X\)</span> is an independent, explanatory variable, in this case the dad’s height. <span class="math inline">\(\beta_1\)</span> is a parameter that measures the influence that the explanatory variable has on the dependent variable <span class="math inline">\(Y\)</span> and <span class="math inline">\(\beta_0\)</span> is the intercept or constant term. In our case, the son’s height.</p>
<p>In statistics, <strong>linear regression</strong> or linear adjustment is a mathematical model used to approximate the dependency relationship between a dependent variable <span class="math inline">\(Y\)</span> and the independent variables <span class="math inline">\(X_i\)</span>.</p>
<p>Thus, our problem boils down to training our model to find the values of the intercept, <span class="math inline">\(\beta_0\)</span>, and the value of the parameter accompanying <span class="math inline">\(X_1\)</span>, <span class="math inline">\(\beta_1\)</span>, to then use these data as prediction in our test data.</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="supervised-learning.html#cb564-1" tabindex="-1"></a>heights_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(heights_df, <span class="at">prop =</span> <span class="fl">0.5</span>)</span>
<span id="cb564-2"><a href="supervised-learning.html#cb564-2" tabindex="-1"></a></span>
<span id="cb564-3"><a href="supervised-learning.html#cb564-3" tabindex="-1"></a>heights_train <span class="ot">&lt;-</span> <span class="fu">training</span>(heights_split)</span>
<span id="cb564-4"><a href="supervised-learning.html#cb564-4" tabindex="-1"></a>heights_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(heights_split)</span></code></pre></div>
<p>Now that we have our data we can train our model using tidymodels. We specify a linear regression model with <code>linear_reg()</code>.</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="supervised-learning.html#cb565-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb565-2"><a href="supervised-learning.html#cb565-2" tabindex="-1"></a>lm_spec <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">|&gt;</span></span>
<span id="cb565-3"><a href="supervised-learning.html#cb565-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb565-4"><a href="supervised-learning.html#cb565-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb565-5"><a href="supervised-learning.html#cb565-5" tabindex="-1"></a></span>
<span id="cb565-6"><a href="supervised-learning.html#cb565-6" tabindex="-1"></a><span class="co"># Recipe</span></span>
<span id="cb565-7"><a href="supervised-learning.html#cb565-7" tabindex="-1"></a>lm_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(son <span class="sc">~</span> father, <span class="at">data =</span> heights_train)</span>
<span id="cb565-8"><a href="supervised-learning.html#cb565-8" tabindex="-1"></a></span>
<span id="cb565-9"><a href="supervised-learning.html#cb565-9" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb565-10"><a href="supervised-learning.html#cb565-10" tabindex="-1"></a>lm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb565-11"><a href="supervised-learning.html#cb565-11" tabindex="-1"></a>  <span class="fu">add_recipe</span>(lm_recipe) <span class="sc">|&gt;</span></span>
<span id="cb565-12"><a href="supervised-learning.html#cb565-12" tabindex="-1"></a>  <span class="fu">add_model</span>(lm_spec)</span>
<span id="cb565-13"><a href="supervised-learning.html#cb565-13" tabindex="-1"></a></span>
<span id="cb565-14"><a href="supervised-learning.html#cb565-14" tabindex="-1"></a><span class="co"># Cross-validation</span></span>
<span id="cb565-15"><a href="supervised-learning.html#cb565-15" tabindex="-1"></a>heights_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(heights_train, <span class="at">v =</span> <span class="dv">10</span>)</span>
<span id="cb565-16"><a href="supervised-learning.html#cb565-16" tabindex="-1"></a>lm_results <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(lm_workflow, <span class="at">resamples =</span> heights_folds)</span>
<span id="cb565-17"><a href="supervised-learning.html#cb565-17" tabindex="-1"></a></span>
<span id="cb565-18"><a href="supervised-learning.html#cb565-18" tabindex="-1"></a><span class="co"># View results</span></span>
<span id="cb565-19"><a href="supervised-learning.html#cb565-19" tabindex="-1"></a><span class="fu">collect_metrics</span>(lm_results)</span>
<span id="cb565-20"><a href="supervised-learning.html#cb565-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb565-21"><a href="supervised-learning.html#cb565-21" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator   mean     n std_err .config        </span></span>
<span id="cb565-22"><a href="supervised-learning.html#cb565-22" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          </span></span>
<span id="cb565-23"><a href="supervised-learning.html#cb565-23" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard   0.0584    10 0.00362 pre0_mod0_post0</span></span>
<span id="cb565-24"><a href="supervised-learning.html#cb565-24" tabindex="-1"></a><span class="co">#&gt; 2 rsq     standard   0.362     10 0.0821  pre0_mod0_post0</span></span></code></pre></div>
<p>We see as main results the RMSE, which stands for root mean square error, and is the value that linear regression seeks to minimize. In addition, we have the R squared or <span class="math inline">\(R^2\)</span>, which is the coefficient of determination which determines the quality of the model to replicate the results. The higher and closer to 1, the better the quality of the model.</p>
<p>Now let’s fit the final model and make predictions:</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="supervised-learning.html#cb566-1" tabindex="-1"></a><span class="co"># Fit final model</span></span>
<span id="cb566-2"><a href="supervised-learning.html#cb566-2" tabindex="-1"></a>heights_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(lm_workflow, <span class="at">data =</span> heights_train)</span>
<span id="cb566-3"><a href="supervised-learning.html#cb566-3" tabindex="-1"></a></span>
<span id="cb566-4"><a href="supervised-learning.html#cb566-4" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb566-5"><a href="supervised-learning.html#cb566-5" tabindex="-1"></a>heights_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(heights_fit, <span class="at">new_data =</span> heights_test)</span>
<span id="cb566-6"><a href="supervised-learning.html#cb566-6" tabindex="-1"></a></span>
<span id="cb566-7"><a href="supervised-learning.html#cb566-7" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb566-8"><a href="supervised-learning.html#cb566-8" tabindex="-1"></a>heights_predictions <span class="sc">|&gt;</span></span>
<span id="cb566-9"><a href="supervised-learning.html#cb566-9" tabindex="-1"></a>  <span class="fu">rmse</span>(<span class="at">truth =</span> son, <span class="at">estimate =</span> .pred)</span>
<span id="cb566-10"><a href="supervised-learning.html#cb566-10" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb566-11"><a href="supervised-learning.html#cb566-11" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator .estimate</span></span>
<span id="cb566-12"><a href="supervised-learning.html#cb566-12" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb566-13"><a href="supervised-learning.html#cb566-13" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard      0.0642</span></span></code></pre></div>
<p>If we wish we can also report the coefficients of the equation and visualize them:</p>
<p><span class="math inline">\(Y = \beta_0+\beta_1X\)</span></p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="supervised-learning.html#cb567-1" tabindex="-1"></a><span class="co"># Extract model coefficients</span></span>
<span id="cb567-2"><a href="supervised-learning.html#cb567-2" tabindex="-1"></a>heights_fit <span class="sc">|&gt;</span> <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb567-3"><a href="supervised-learning.html#cb567-3" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 5</span></span>
<span id="cb567-4"><a href="supervised-learning.html#cb567-4" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic      p.value</span></span>
<span id="cb567-5"><a href="supervised-learning.html#cb567-5" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;</span></span>
<span id="cb567-6"><a href="supervised-learning.html#cb567-6" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)    0.644     0.183      3.51 0.000708    </span></span>
<span id="cb567-7"><a href="supervised-learning.html#cb567-7" tabindex="-1"></a><span class="co">#&gt; 2 father         0.631     0.104      6.05 0.0000000361</span></span>
<span id="cb567-8"><a href="supervised-learning.html#cb567-8" tabindex="-1"></a></span>
<span id="cb567-9"><a href="supervised-learning.html#cb567-9" tabindex="-1"></a>model_coefs <span class="ot">&lt;-</span> heights_fit <span class="sc">|&gt;</span> <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb567-10"><a href="supervised-learning.html#cb567-10" tabindex="-1"></a>intercept_val <span class="ot">&lt;-</span> model_coefs<span class="sc">$</span>estimate[<span class="dv">1</span>]</span>
<span id="cb567-11"><a href="supervised-learning.html#cb567-11" tabindex="-1"></a>slope_val <span class="ot">&lt;-</span> model_coefs<span class="sc">$</span>estimate[<span class="dv">2</span>]</span>
<span id="cb567-12"><a href="supervised-learning.html#cb567-12" tabindex="-1"></a></span>
<span id="cb567-13"><a href="supervised-learning.html#cb567-13" tabindex="-1"></a><span class="co">#Visualization</span></span>
<span id="cb567-14"><a href="supervised-learning.html#cb567-14" tabindex="-1"></a>heights_df <span class="sc">|&gt;</span> </span>
<span id="cb567-15"><a href="supervised-learning.html#cb567-15" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb567-16"><a href="supervised-learning.html#cb567-16" tabindex="-1"></a>  <span class="fu">aes</span>(father, son) <span class="sc">+</span></span>
<span id="cb567-17"><a href="supervised-learning.html#cb567-17" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb567-18"><a href="supervised-learning.html#cb567-18" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">lty =</span> <span class="dv">2</span>, <span class="at">intercept =</span> intercept_val, <span class="at">slope =</span> slope_val, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Data-Science-con-R_files/figure-html/unnamed-chunk-730-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="multiple-linear-regression" class="section level2 hasAnchor" number="12.7">
<h2><span class="header-section-number">12.7</span> Multiple Linear Regression<a href="supervised-learning.html#multiple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we know linear regression we can execute a multiple linear regression model, which involves more than 1 variable as <em>input</em>. To do this, we will use the <code>diamonds</code> dataset containing the prices and other attributes of almost 54,000 diamonds.</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="supervised-learning.html#cb568-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb568-2"><a href="supervised-learning.html#cb568-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;diamonds&quot;</span>)</span>
<span id="cb568-3"><a href="supervised-learning.html#cb568-3" tabindex="-1"></a></span>
<span id="cb568-4"><a href="supervised-learning.html#cb568-4" tabindex="-1"></a>diamonds <span class="ot">&lt;-</span> diamonds <span class="sc">|&gt;</span> </span>
<span id="cb568-5"><a href="supervised-learning.html#cb568-5" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">price =</span> price)</span>
<span id="cb568-6"><a href="supervised-learning.html#cb568-6" tabindex="-1"></a></span>
<span id="cb568-7"><a href="supervised-learning.html#cb568-7" tabindex="-1"></a>diamonds <span class="sc">|&gt;</span> </span>
<span id="cb568-8"><a href="supervised-learning.html#cb568-8" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb568-9"><a href="supervised-learning.html#cb568-9" tabindex="-1"></a><span class="co">#&gt; # A tibble: 10 × 10</span></span>
<span id="cb568-10"><a href="supervised-learning.html#cb568-10" tabindex="-1"></a><span class="co">#&gt;    carat cut       color clarity depth table price     x     y     z</span></span>
<span id="cb568-11"><a href="supervised-learning.html#cb568-11" tabindex="-1"></a><span class="co">#&gt;    &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb568-12"><a href="supervised-learning.html#cb568-12" tabindex="-1"></a><span class="co">#&gt;  1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43</span></span>
<span id="cb568-13"><a href="supervised-learning.html#cb568-13" tabindex="-1"></a><span class="co">#&gt;  2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31</span></span>
<span id="cb568-14"><a href="supervised-learning.html#cb568-14" tabindex="-1"></a><span class="co">#&gt;  3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31</span></span>
<span id="cb568-15"><a href="supervised-learning.html#cb568-15" tabindex="-1"></a><span class="co">#&gt;  4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63</span></span>
<span id="cb568-16"><a href="supervised-learning.html#cb568-16" tabindex="-1"></a><span class="co">#&gt;  5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75</span></span>
<span id="cb568-17"><a href="supervised-learning.html#cb568-17" tabindex="-1"></a><span class="co">#&gt;  6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48</span></span>
<span id="cb568-18"><a href="supervised-learning.html#cb568-18" tabindex="-1"></a><span class="co">#&gt;  7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47</span></span>
<span id="cb568-19"><a href="supervised-learning.html#cb568-19" tabindex="-1"></a><span class="co">#&gt;  8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53</span></span>
<span id="cb568-20"><a href="supervised-learning.html#cb568-20" tabindex="-1"></a><span class="co">#&gt;  9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49</span></span>
<span id="cb568-21"><a href="supervised-learning.html#cb568-21" tabindex="-1"></a><span class="co">#&gt; 10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39</span></span></code></pre></div>
<p>We split the data in two taking 70% of data for training:</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="supervised-learning.html#cb569-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb569-2"><a href="supervised-learning.html#cb569-2" tabindex="-1"></a>diamonds_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(diamonds, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> price)</span>
<span id="cb569-3"><a href="supervised-learning.html#cb569-3" tabindex="-1"></a></span>
<span id="cb569-4"><a href="supervised-learning.html#cb569-4" tabindex="-1"></a>diamonds_train <span class="ot">&lt;-</span> <span class="fu">training</span>(diamonds_split)</span>
<span id="cb569-5"><a href="supervised-learning.html#cb569-5" tabindex="-1"></a>diamonds_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(diamonds_split)</span></code></pre></div>
<p>We now create our multiple linear regression model and report both the error results and the coefficients of the linear equation using a tidymodels workflow.</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="supervised-learning.html#cb570-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb570-2"><a href="supervised-learning.html#cb570-2" tabindex="-1"></a>diamonds_spec <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">|&gt;</span></span>
<span id="cb570-3"><a href="supervised-learning.html#cb570-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb570-4"><a href="supervised-learning.html#cb570-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb570-5"><a href="supervised-learning.html#cb570-5" tabindex="-1"></a></span>
<span id="cb570-6"><a href="supervised-learning.html#cb570-6" tabindex="-1"></a><span class="co"># Recipe</span></span>
<span id="cb570-7"><a href="supervised-learning.html#cb570-7" tabindex="-1"></a>diamonds_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(price <span class="sc">~</span> ., <span class="at">data =</span> diamonds_train)</span>
<span id="cb570-8"><a href="supervised-learning.html#cb570-8" tabindex="-1"></a></span>
<span id="cb570-9"><a href="supervised-learning.html#cb570-9" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb570-10"><a href="supervised-learning.html#cb570-10" tabindex="-1"></a>diamonds_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb570-11"><a href="supervised-learning.html#cb570-11" tabindex="-1"></a>  <span class="fu">add_recipe</span>(diamonds_recipe) <span class="sc">|&gt;</span></span>
<span id="cb570-12"><a href="supervised-learning.html#cb570-12" tabindex="-1"></a>  <span class="fu">add_model</span>(diamonds_spec)</span>
<span id="cb570-13"><a href="supervised-learning.html#cb570-13" tabindex="-1"></a></span>
<span id="cb570-14"><a href="supervised-learning.html#cb570-14" tabindex="-1"></a><span class="co"># Cross-validation</span></span>
<span id="cb570-15"><a href="supervised-learning.html#cb570-15" tabindex="-1"></a>diamonds_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(diamonds_train, <span class="at">v =</span> <span class="dv">10</span>)</span>
<span id="cb570-16"><a href="supervised-learning.html#cb570-16" tabindex="-1"></a>diamonds_results <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(diamonds_workflow, <span class="at">resamples =</span> diamonds_folds)</span>
<span id="cb570-17"><a href="supervised-learning.html#cb570-17" tabindex="-1"></a></span>
<span id="cb570-18"><a href="supervised-learning.html#cb570-18" tabindex="-1"></a><span class="fu">collect_metrics</span>(diamonds_results)</span>
<span id="cb570-19"><a href="supervised-learning.html#cb570-19" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb570-20"><a href="supervised-learning.html#cb570-20" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator     mean     n  std_err .config        </span></span>
<span id="cb570-21"><a href="supervised-learning.html#cb570-21" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          </span></span>
<span id="cb570-22"><a href="supervised-learning.html#cb570-22" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard   1136.       10 19.7     pre0_mod0_post0</span></span>
<span id="cb570-23"><a href="supervised-learning.html#cb570-23" tabindex="-1"></a><span class="co">#&gt; 2 rsq     standard      0.919    10  0.00256 pre0_mod0_post0</span></span></code></pre></div>
<p>We see that it gives us the RMSE and an R squared quite closer to 1, which denotes a high quality of the model to replicate the results.</p>
<p>Let’s use our model to predict the prices of the test data.</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="supervised-learning.html#cb571-1" tabindex="-1"></a><span class="co"># Fit final model</span></span>
<span id="cb571-2"><a href="supervised-learning.html#cb571-2" tabindex="-1"></a><span class="fu">library</span>(discrim)</span>
<span id="cb571-3"><a href="supervised-learning.html#cb571-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb571-4"><a href="supervised-learning.html#cb571-4" tabindex="-1"></a><span class="co">#&gt; Attaching package: &#39;discrim&#39;</span></span>
<span id="cb571-5"><a href="supervised-learning.html#cb571-5" tabindex="-1"></a><span class="co">#&gt; The following object is masked from &#39;package:dials&#39;:</span></span>
<span id="cb571-6"><a href="supervised-learning.html#cb571-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb571-7"><a href="supervised-learning.html#cb571-7" tabindex="-1"></a><span class="co">#&gt;     smoothness</span></span>
<span id="cb571-8"><a href="supervised-learning.html#cb571-8" tabindex="-1"></a>diamonds_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(diamonds_workflow, <span class="at">data =</span> diamonds_train)</span>
<span id="cb571-9"><a href="supervised-learning.html#cb571-9" tabindex="-1"></a></span>
<span id="cb571-10"><a href="supervised-learning.html#cb571-10" tabindex="-1"></a><span class="co"># Extract coefficients</span></span>
<span id="cb571-11"><a href="supervised-learning.html#cb571-11" tabindex="-1"></a>diamonds_fit <span class="sc">|&gt;</span> <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb571-12"><a href="supervised-learning.html#cb571-12" tabindex="-1"></a><span class="co">#&gt; # A tibble: 24 × 5</span></span>
<span id="cb571-13"><a href="supervised-learning.html#cb571-13" tabindex="-1"></a><span class="co">#&gt;    term        estimate std.error statistic   p.value</span></span>
<span id="cb571-14"><a href="supervised-learning.html#cb571-14" tabindex="-1"></a><span class="co">#&gt;    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb571-15"><a href="supervised-learning.html#cb571-15" tabindex="-1"></a><span class="co">#&gt;  1 (Intercept)   6975.      473.      14.7  5.45e- 49</span></span>
<span id="cb571-16"><a href="supervised-learning.html#cb571-16" tabindex="-1"></a><span class="co">#&gt;  2 carat        11437.       60.7    188.   0        </span></span>
<span id="cb571-17"><a href="supervised-learning.html#cb571-17" tabindex="-1"></a><span class="co">#&gt;  3 cut.L          571.       27.1     21.1  7.51e- 98</span></span>
<span id="cb571-18"><a href="supervised-learning.html#cb571-18" tabindex="-1"></a><span class="co">#&gt;  4 cut.Q         -305.       21.7    -14.0  1.07e- 44</span></span>
<span id="cb571-19"><a href="supervised-learning.html#cb571-19" tabindex="-1"></a><span class="co">#&gt;  5 cut.C          139.       18.6      7.48 7.72e- 14</span></span>
<span id="cb571-20"><a href="supervised-learning.html#cb571-20" tabindex="-1"></a><span class="co">#&gt;  6 cut^4          -23.2      14.8     -1.56 1.18e-  1</span></span>
<span id="cb571-21"><a href="supervised-learning.html#cb571-21" tabindex="-1"></a><span class="co">#&gt;  7 color.L      -1980.       20.8    -95.1  0        </span></span>
<span id="cb571-22"><a href="supervised-learning.html#cb571-22" tabindex="-1"></a><span class="co">#&gt;  8 color.Q       -685.       19.0    -36.1  6.69e-281</span></span>
<span id="cb571-23"><a href="supervised-learning.html#cb571-23" tabindex="-1"></a><span class="co">#&gt;  9 color.C       -186.       17.7    -10.5  6.23e- 26</span></span>
<span id="cb571-24"><a href="supervised-learning.html#cb571-24" tabindex="-1"></a><span class="co">#&gt; 10 color^4         36.8      16.2      2.27 2.33e-  2</span></span>
<span id="cb571-25"><a href="supervised-learning.html#cb571-25" tabindex="-1"></a><span class="co">#&gt; # ℹ 14 more rows</span></span>
<span id="cb571-26"><a href="supervised-learning.html#cb571-26" tabindex="-1"></a></span>
<span id="cb571-27"><a href="supervised-learning.html#cb571-27" tabindex="-1"></a><span class="co"># Prediction and Error calculation</span></span>
<span id="cb571-28"><a href="supervised-learning.html#cb571-28" tabindex="-1"></a>diamonds_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(diamonds_fit, <span class="at">new_data =</span> diamonds_test)</span>
<span id="cb571-29"><a href="supervised-learning.html#cb571-29" tabindex="-1"></a></span>
<span id="cb571-30"><a href="supervised-learning.html#cb571-30" tabindex="-1"></a><span class="co"># Mean Squared Error Calculation RMSE:</span></span>
<span id="cb571-31"><a href="supervised-learning.html#cb571-31" tabindex="-1"></a>diamonds_predictions <span class="sc">|&gt;</span></span>
<span id="cb571-32"><a href="supervised-learning.html#cb571-32" tabindex="-1"></a>  <span class="fu">rmse</span>(<span class="at">truth =</span> price, <span class="at">estimate =</span> .pred)</span>
<span id="cb571-33"><a href="supervised-learning.html#cb571-33" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb571-34"><a href="supervised-learning.html#cb571-34" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator .estimate</span></span>
<span id="cb571-35"><a href="supervised-learning.html#cb571-35" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb571-36"><a href="supervised-learning.html#cb571-36" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard       1119.</span></span></code></pre></div>
<p>Thus, we have learned to perform one more machine learning model: linear regression, both simple and multiple.</p>
</div>
<div id="standard-method-for-evaluating-accuracy" class="section level2 hasAnchor" number="12.8">
<h2><span class="header-section-number">12.8</span> Standard Method for Evaluating Accuracy<a href="supervised-learning.html#standard-method-for-evaluating-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we know how to build models we will apply metrics that allow us better accuracy in classification models for <strong>two classes</strong>.</p>
<p>To do this let’s recall the results of the model we created using the k-nearest neighbors algorithm to predict if the S&amp;P index goes up or down.</p>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="supervised-learning.html#cb572-1" tabindex="-1"></a>SP_knn_trained</span>
<span id="cb572-2"><a href="supervised-learning.html#cb572-2" tabindex="-1"></a><span class="co">#&gt; ══ Workflow [trained] ═══════════════════════════════</span></span>
<span id="cb572-3"><a href="supervised-learning.html#cb572-3" tabindex="-1"></a><span class="co">#&gt; Preprocessor: Recipe</span></span>
<span id="cb572-4"><a href="supervised-learning.html#cb572-4" tabindex="-1"></a><span class="co">#&gt; Model: nearest_neighbor()</span></span>
<span id="cb572-5"><a href="supervised-learning.html#cb572-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb572-6"><a href="supervised-learning.html#cb572-6" tabindex="-1"></a><span class="co">#&gt; ── Preprocessor ─────────────────────────────────────</span></span>
<span id="cb572-7"><a href="supervised-learning.html#cb572-7" tabindex="-1"></a><span class="co">#&gt; 1 Recipe Step</span></span>
<span id="cb572-8"><a href="supervised-learning.html#cb572-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb572-9"><a href="supervised-learning.html#cb572-9" tabindex="-1"></a><span class="co">#&gt; • step_normalize()</span></span>
<span id="cb572-10"><a href="supervised-learning.html#cb572-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb572-11"><a href="supervised-learning.html#cb572-11" tabindex="-1"></a><span class="co">#&gt; ── Model ────────────────────────────────────────────</span></span>
<span id="cb572-12"><a href="supervised-learning.html#cb572-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb572-13"><a href="supervised-learning.html#cb572-13" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb572-14"><a href="supervised-learning.html#cb572-14" tabindex="-1"></a><span class="co">#&gt; kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(44L,     data, 5))</span></span>
<span id="cb572-15"><a href="supervised-learning.html#cb572-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb572-16"><a href="supervised-learning.html#cb572-16" tabindex="-1"></a><span class="co">#&gt; Type of response variable: nominal</span></span>
<span id="cb572-17"><a href="supervised-learning.html#cb572-17" tabindex="-1"></a><span class="co">#&gt; Minimal misclassification: 0.0864461</span></span>
<span id="cb572-18"><a href="supervised-learning.html#cb572-18" tabindex="-1"></a><span class="co">#&gt; Best kernel: optimal</span></span>
<span id="cb572-19"><a href="supervised-learning.html#cb572-19" tabindex="-1"></a><span class="co">#&gt; Best k: 44</span></span></code></pre></div>
<p>In the penultimate line it can be read that <strong>accuracy</strong> (<code>accuracy</code>) was used to select the most optimal model using the largest value. However, this is not the only way to determine which is the most optimal model.</p>
<p>Let’s remember how accuracy (<em>accuracy</em>) is calculated by default, we have used the simple rule that if the probability of it being of a certain class is more than 50% then that class is assigned and then we calculate the proportion of hits among the total cases.</p>
<p>However, it doesn’t have to be 50%, we could be more demanding and indicate that if the probability is greater than 60% or 80% then a certain class is assigned. We see that there are different probabilities and that would give us different <code>accuracy</code>.</p>
<p>This is how the area under the Receiver Operating Characteristic curve indicator arises, <em>ROC</em> <span class="citation">(<a href="#ref-Fawcett2005">Fawcett 2005</a>)</span>. This indicator measures how well a model can distinguish between two classes and is considered the standard method for evaluating the accuracy of predictive distribution models <span class="citation">(<a href="#ref-Lobo2007">Jorge M. Lobo 2007</a>)</span> and calculates accuracies not only for when we discriminate starting from 50%, but for more probability values.</p>
<p>To use this metric we will modify our control parameters adding three attributes that will allow calculating the ROC.</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="supervised-learning.html#cb573-1" tabindex="-1"></a>SP2_ctrl <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(roc_auc, accuracy)</span>
<span id="cb573-2"><a href="supervised-learning.html#cb573-2" tabindex="-1"></a></span>
<span id="cb573-3"><a href="supervised-learning.html#cb573-3" tabindex="-1"></a><span class="co"># We define folds</span></span>
<span id="cb573-4"><a href="supervised-learning.html#cb573-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb573-5"><a href="supervised-learning.html#cb573-5" tabindex="-1"></a>SP2_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(SP_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> Direction)</span></code></pre></div>
<p>With these modified parameters we will proceed to re-train our model selecting by ROC AUC.</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb574-1"><a href="supervised-learning.html#cb574-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb574-2"><a href="supervised-learning.html#cb574-2" tabindex="-1"></a></span>
<span id="cb574-3"><a href="supervised-learning.html#cb574-3" tabindex="-1"></a><span class="co"># Tune grid specifying ROC as the metric to optimize</span></span>
<span id="cb574-4"><a href="supervised-learning.html#cb574-4" tabindex="-1"></a>SP2_knn_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb574-5"><a href="supervised-learning.html#cb574-5" tabindex="-1"></a>  knn_workflow,</span>
<span id="cb574-6"><a href="supervised-learning.html#cb574-6" tabindex="-1"></a>  <span class="at">resamples =</span> SP2_folds,</span>
<span id="cb574-7"><a href="supervised-learning.html#cb574-7" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">20</span>,</span>
<span id="cb574-8"><a href="supervised-learning.html#cb574-8" tabindex="-1"></a>  <span class="at">metrics =</span> SP2_ctrl</span>
<span id="cb574-9"><a href="supervised-learning.html#cb574-9" tabindex="-1"></a>)</span>
<span id="cb574-10"><a href="supervised-learning.html#cb574-10" tabindex="-1"></a></span>
<span id="cb574-11"><a href="supervised-learning.html#cb574-11" tabindex="-1"></a><span class="fu">show_best</span>(SP2_knn_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb574-12"><a href="supervised-learning.html#cb574-12" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 7</span></span>
<span id="cb574-13"><a href="supervised-learning.html#cb574-13" tabindex="-1"></a><span class="co">#&gt;   neighbors .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb574-14"><a href="supervised-learning.html#cb574-14" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb574-15"><a href="supervised-learning.html#cb574-15" tabindex="-1"></a><span class="co">#&gt; 1        15 roc_auc binary     0.965     5 0.00586 pre0_mod13_post0</span></span>
<span id="cb574-16"><a href="supervised-learning.html#cb574-16" tabindex="-1"></a><span class="co">#&gt; 2        13 roc_auc binary     0.962     5 0.00632 pre0_mod12_post0</span></span>
<span id="cb574-17"><a href="supervised-learning.html#cb574-17" tabindex="-1"></a><span class="co">#&gt; 3        12 roc_auc binary     0.960     5 0.00667 pre0_mod11_post0</span></span>
<span id="cb574-18"><a href="supervised-learning.html#cb574-18" tabindex="-1"></a><span class="co">#&gt; 4        11 roc_auc binary     0.957     5 0.00717 pre0_mod10_post0</span></span>
<span id="cb574-19"><a href="supervised-learning.html#cb574-19" tabindex="-1"></a><span class="co">#&gt; 5        10 roc_auc binary     0.955     5 0.00739 pre0_mod09_post0</span></span></code></pre></div>
<pre><code>We see that now ROC was used to select the most optimal model. The closer the ROC value is to 1 the better our model will be. With this model we can predict values from the test data.


``` r
# Select best k based on ROC
best_k_roc &lt;- select_best(SP2_knn_res, metric = &quot;roc_auc&quot;)

# Finalize workflow
final_knn_roc &lt;- finalize_workflow(knn_workflow, best_k_roc)

# Fit and predict
SP2_knn_fit &lt;- fit(final_knn_roc, data = SP_train)
SP2_predictions &lt;- augment(SP2_knn_fit, new_data = SP_test)

# Evaluate
SP2_predictions |&gt;
  conf_mat(truth = Direction, estimate = .pred_class)
#&gt;           Truth
#&gt; Prediction Baja Sube
#&gt;       Baja  135   15
#&gt;       Sube   16  147

SP2_predictions |&gt;
  accuracy(truth = Direction, estimate = .pred_class)
#&gt; # A tibble: 1 × 3
#&gt;   .metric  .estimator .estimate
#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
#&gt; 1 accuracy binary         0.901</code></pre>
<p>We see how our accuracy (<em>accuracy</em>) has increased from 91.99% to <strong>93.27%</strong>. This metric is highly recommended to improve the accuracy of our model, in addition to allowing us to more easily use it as a comparator between different models we can create.</p>
</div>
<div id="selection-of-the-most-optimal-model" class="section level2 hasAnchor" number="12.9">
<h2><span class="header-section-number">12.9</span> Selection of the Most Optimal Model<a href="supervised-learning.html#selection-of-the-most-optimal-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have learned how to create some machine learning models. As we must have noticed, with <strong>caret</strong> we follow the same pattern for partitioning, training, and prediction. The variation lies in how to pre-process the data and the parameter tuning. We could thus create multiple models, but finally we have to verify one which will serve us to make our predictions.</p>
<p>In this section, we are going to compare different predictive models accepting their default values and choose the best one using the tools presented in previous sections.</p>
<p>To do this, we are going to use a new case. This time we are evaluating the behavior of our 5,000 clients, some of whom have unsubscribed from our services. We have 19 predictors, most of them numeric, in the <code>mlc_churn</code> dataset. To access the data we have to load the <code>modeldata</code> library.</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb576-1"><a href="supervised-learning.html#cb576-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;modeldata&quot;</span>)</span>
<span id="cb576-2"><a href="supervised-learning.html#cb576-2" tabindex="-1"></a><span class="fu">library</span>(modeldata)</span></code></pre></div>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="supervised-learning.html#cb577-1" tabindex="-1"></a><span class="fu">data</span>(mlc_churn)</span>
<span id="cb577-2"><a href="supervised-learning.html#cb577-2" tabindex="-1"></a></span>
<span id="cb577-3"><a href="supervised-learning.html#cb577-3" tabindex="-1"></a><span class="fu">str</span>(mlc_churn)</span>
<span id="cb577-4"><a href="supervised-learning.html#cb577-4" tabindex="-1"></a><span class="co">#&gt; tibble [5,000 × 20] (S3: tbl_df/tbl/data.frame)</span></span>
<span id="cb577-5"><a href="supervised-learning.html#cb577-5" tabindex="-1"></a><span class="co">#&gt;  $ state                        : Factor w/ 51 levels &quot;AK&quot;,&quot;AL&quot;,&quot;AR&quot;,..: 17 36 32 36 37 2 20 25 19 50 ...</span></span>
<span id="cb577-6"><a href="supervised-learning.html#cb577-6" tabindex="-1"></a><span class="co">#&gt;  $ account_length               : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ...</span></span>
<span id="cb577-7"><a href="supervised-learning.html#cb577-7" tabindex="-1"></a><span class="co">#&gt;  $ area_code                    : Factor w/ 3 levels &quot;area_code_408&quot;,..: 2 2 2 1 2 3 3 2 1 2 ...</span></span>
<span id="cb577-8"><a href="supervised-learning.html#cb577-8" tabindex="-1"></a><span class="co">#&gt;  $ international_plan           : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 2 2 2 1 2 1 2 ...</span></span>
<span id="cb577-9"><a href="supervised-learning.html#cb577-9" tabindex="-1"></a><span class="co">#&gt;  $ voice_mail_plan              : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 1 1 2 1 1 2 ...</span></span>
<span id="cb577-10"><a href="supervised-learning.html#cb577-10" tabindex="-1"></a><span class="co">#&gt;  $ number_vmail_messages        : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ...</span></span>
<span id="cb577-11"><a href="supervised-learning.html#cb577-11" tabindex="-1"></a><span class="co">#&gt;  $ total_day_minutes            : num [1:5000] 265 162 243 299 167 ...</span></span>
<span id="cb577-12"><a href="supervised-learning.html#cb577-12" tabindex="-1"></a><span class="co">#&gt;  $ total_day_calls              : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ...</span></span>
<span id="cb577-13"><a href="supervised-learning.html#cb577-13" tabindex="-1"></a><span class="co">#&gt;  $ total_day_charge             : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ...</span></span>
<span id="cb577-14"><a href="supervised-learning.html#cb577-14" tabindex="-1"></a><span class="co">#&gt;  $ total_eve_minutes            : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ...</span></span>
<span id="cb577-15"><a href="supervised-learning.html#cb577-15" tabindex="-1"></a><span class="co">#&gt;  $ total_eve_calls              : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ...</span></span>
<span id="cb577-16"><a href="supervised-learning.html#cb577-16" tabindex="-1"></a><span class="co">#&gt;  $ total_eve_charge             : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ...</span></span>
<span id="cb577-17"><a href="supervised-learning.html#cb577-17" tabindex="-1"></a><span class="co">#&gt;  $ total_night_minutes          : num [1:5000] 245 254 163 197 187 ...</span></span>
<span id="cb577-18"><a href="supervised-learning.html#cb577-18" tabindex="-1"></a><span class="co">#&gt;  $ total_night_calls            : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ...</span></span>
<span id="cb577-19"><a href="supervised-learning.html#cb577-19" tabindex="-1"></a><span class="co">#&gt;  $ total_night_charge           : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ...</span></span>
<span id="cb577-20"><a href="supervised-learning.html#cb577-20" tabindex="-1"></a><span class="co">#&gt;  $ total_intl_minutes           : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ...</span></span>
<span id="cb577-21"><a href="supervised-learning.html#cb577-21" tabindex="-1"></a><span class="co">#&gt;  $ total_intl_calls             : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ...</span></span>
<span id="cb577-22"><a href="supervised-learning.html#cb577-22" tabindex="-1"></a><span class="co">#&gt;  $ total_intl_charge            : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ...</span></span>
<span id="cb577-23"><a href="supervised-learning.html#cb577-23" tabindex="-1"></a><span class="co">#&gt;  $ number_customer_service_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ...</span></span>
<span id="cb577-24"><a href="supervised-learning.html#cb577-24" tabindex="-1"></a><span class="co">#&gt;  $ churn                        : Factor w/ 2 levels &quot;yes&quot;,&quot;no&quot;: 2 2 2 2 2 2 2 2 2 2 ...</span></span>
<span id="cb577-25"><a href="supervised-learning.html#cb577-25" tabindex="-1"></a></span>
<span id="cb577-26"><a href="supervised-learning.html#cb577-26" tabindex="-1"></a><span class="co"># We translate outputs</span></span>
<span id="cb577-27"><a href="supervised-learning.html#cb577-27" tabindex="-1"></a>mlc_churn <span class="ot">&lt;-</span> mlc_churn <span class="sc">|&gt;</span> </span>
<span id="cb577-28"><a href="supervised-learning.html#cb577-28" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">churn_status =</span> churn) <span class="sc">|&gt;</span> </span>
<span id="cb577-29"><a href="supervised-learning.html#cb577-29" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">churn_status =</span> <span class="fu">ifelse</span>(churn_status <span class="sc">==</span> <span class="st">&quot;yes&quot;</span>, <span class="st">&quot;Sí&quot;</span>, <span class="st">&quot;No&quot;</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb577-30"><a href="supervised-learning.html#cb577-30" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">churn_status =</span> <span class="fu">as.factor</span>(churn_status))</span>
<span id="cb577-31"><a href="supervised-learning.html#cb577-31" tabindex="-1"></a>  </span>
<span id="cb577-32"><a href="supervised-learning.html#cb577-32" tabindex="-1"></a><span class="co"># Proportion of &quot;Yes&quot; and &quot;No&quot;s:</span></span>
<span id="cb577-33"><a href="supervised-learning.html#cb577-33" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(mlc_churn<span class="sc">$</span>churn_status))</span>
<span id="cb577-34"><a href="supervised-learning.html#cb577-34" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb577-35"><a href="supervised-learning.html#cb577-35" tabindex="-1"></a><span class="co">#&gt;     No     Sí </span></span>
<span id="cb577-36"><a href="supervised-learning.html#cb577-36" tabindex="-1"></a><span class="co">#&gt; 0.8586 0.1414</span></span></code></pre></div>
<p>We create now sample of training and test, 70% training.</p>
<p>We create now sample of training and test, 70% training.</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="supervised-learning.html#cb578-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb578-2"><a href="supervised-learning.html#cb578-2" tabindex="-1"></a>churn_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(mlc_churn, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> churn_status)</span>
<span id="cb578-3"><a href="supervised-learning.html#cb578-3" tabindex="-1"></a></span>
<span id="cb578-4"><a href="supervised-learning.html#cb578-4" tabindex="-1"></a>churn_train <span class="ot">&lt;-</span> <span class="fu">training</span>(churn_split)</span>
<span id="cb578-5"><a href="supervised-learning.html#cb578-5" tabindex="-1"></a>churn_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(churn_split)</span></code></pre></div>
<p>Up to here we have done exactly the same step as in previous models. However, previously we have specified the <em>cross-validation</em> method within our control parameters. Now we will create a shared validation set to compare all models fairly.</p>
<p>We will create a list of 5 <em>folds</em> using the function <code>vfold_cv()</code> from <code>rsample</code>.</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="supervised-learning.html#cb579-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb579-2"><a href="supervised-learning.html#cb579-2" tabindex="-1"></a>churn_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(churn_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> churn_status)</span>
<span id="cb579-3"><a href="supervised-learning.html#cb579-3" tabindex="-1"></a>churn_folds</span>
<span id="cb579-4"><a href="supervised-learning.html#cb579-4" tabindex="-1"></a><span class="co">#&gt; #  5-fold cross-validation using stratification </span></span>
<span id="cb579-5"><a href="supervised-learning.html#cb579-5" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 2</span></span>
<span id="cb579-6"><a href="supervised-learning.html#cb579-6" tabindex="-1"></a><span class="co">#&gt;   splits             id   </span></span>
<span id="cb579-7"><a href="supervised-learning.html#cb579-7" tabindex="-1"></a><span class="co">#&gt;   &lt;list&gt;             &lt;chr&gt;</span></span>
<span id="cb579-8"><a href="supervised-learning.html#cb579-8" tabindex="-1"></a><span class="co">#&gt; 1 &lt;split [2799/700]&gt; Fold1</span></span>
<span id="cb579-9"><a href="supervised-learning.html#cb579-9" tabindex="-1"></a><span class="co">#&gt; 2 &lt;split [2799/700]&gt; Fold2</span></span>
<span id="cb579-10"><a href="supervised-learning.html#cb579-10" tabindex="-1"></a><span class="co">#&gt; 3 &lt;split [2799/700]&gt; Fold3</span></span>
<span id="cb579-11"><a href="supervised-learning.html#cb579-11" tabindex="-1"></a><span class="co">#&gt; 4 &lt;split [2799/700]&gt; Fold4</span></span>
<span id="cb579-12"><a href="supervised-learning.html#cb579-12" tabindex="-1"></a><span class="co">#&gt; 5 &lt;split [2800/699]&gt; Fold5</span></span></code></pre></div>
<p>We will use the <strong>ROC</strong> metric for all models. In tidymodels, we define the metrics we want to calculate using a <code>metric_set()</code>.</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="supervised-learning.html#cb580-1" tabindex="-1"></a>churn_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(roc_auc, accuracy, sensitivity, specificity)</span></code></pre></div>
<p>The next step would be to choose the machine learning algorithms we want to use to create our models. <code>parsnip</code> provides a consistent interface for different models. We can check available engines for a model type, for example:</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="supervised-learning.html#cb581-1" tabindex="-1"></a><span class="fu">show_engines</span>(<span class="st">&quot;nearest_neighbor&quot;</span>)</span>
<span id="cb581-2"><a href="supervised-learning.html#cb581-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 2</span></span>
<span id="cb581-3"><a href="supervised-learning.html#cb581-3" tabindex="-1"></a><span class="co">#&gt;   engine mode          </span></span>
<span id="cb581-4"><a href="supervised-learning.html#cb581-4" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;  &lt;chr&gt;         </span></span>
<span id="cb581-5"><a href="supervised-learning.html#cb581-5" tabindex="-1"></a><span class="co">#&gt; 1 kknn   classification</span></span>
<span id="cb581-6"><a href="supervised-learning.html#cb581-6" tabindex="-1"></a><span class="co">#&gt; 2 kknn   regression</span></span></code></pre></div>
<p>We will create a series of models and compare them using ROC AUC. First, let’s define a common recipe for preprocessing.</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="supervised-learning.html#cb582-1" tabindex="-1"></a>churn_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(churn_status <span class="sc">~</span> ., <span class="at">data =</span> churn_train) <span class="sc">|&gt;</span></span>
<span id="cb582-2"><a href="supervised-learning.html#cb582-2" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>(), <span class="sc">-</span>churn_status) <span class="sc">|&gt;</span></span>
<span id="cb582-3"><a href="supervised-learning.html#cb582-3" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span></code></pre></div>
<div id="k-nearest-neighbors-model" class="section level3 hasAnchor" number="12.9.1">
<h3><span class="header-section-number">12.9.1</span> k-Nearest Neighbors Model<a href="supervised-learning.html#k-nearest-neighbors-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although it is a very simple model, it is also very useful. Let’s start with this model that we already learned to create during this chapter.</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="supervised-learning.html#cb583-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb583-2"><a href="supervised-learning.html#cb583-2" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb583-3"><a href="supervised-learning.html#cb583-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb583-4"><a href="supervised-learning.html#cb583-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb583-5"><a href="supervised-learning.html#cb583-5" tabindex="-1"></a></span>
<span id="cb583-6"><a href="supervised-learning.html#cb583-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb583-7"><a href="supervised-learning.html#cb583-7" tabindex="-1"></a>knn_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb583-8"><a href="supervised-learning.html#cb583-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb583-9"><a href="supervised-learning.html#cb583-9" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec)</span>
<span id="cb583-10"><a href="supervised-learning.html#cb583-10" tabindex="-1"></a></span>
<span id="cb583-11"><a href="supervised-learning.html#cb583-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb583-12"><a href="supervised-learning.html#cb583-12" tabindex="-1"></a>knn_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb583-13"><a href="supervised-learning.html#cb583-13" tabindex="-1"></a>  knn_workflow,</span>
<span id="cb583-14"><a href="supervised-learning.html#cb583-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb583-15"><a href="supervised-learning.html#cb583-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb583-16"><a href="supervised-learning.html#cb583-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb583-17"><a href="supervised-learning.html#cb583-17" tabindex="-1"></a>)</span>
<span id="cb583-18"><a href="supervised-learning.html#cb583-18" tabindex="-1"></a></span>
<span id="cb583-19"><a href="supervised-learning.html#cb583-19" tabindex="-1"></a><span class="fu">show_best</span>(knn_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb583-20"><a href="supervised-learning.html#cb583-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 7</span></span>
<span id="cb583-21"><a href="supervised-learning.html#cb583-21" tabindex="-1"></a><span class="co">#&gt;   neighbors .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb583-22"><a href="supervised-learning.html#cb583-22" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb583-23"><a href="supervised-learning.html#cb583-23" tabindex="-1"></a><span class="co">#&gt; 1        15 roc_auc binary     0.684     5 0.0101  pre0_mod10_post0</span></span>
<span id="cb583-24"><a href="supervised-learning.html#cb583-24" tabindex="-1"></a><span class="co">#&gt; 2        13 roc_auc binary     0.679     5 0.00972 pre0_mod09_post0</span></span>
<span id="cb583-25"><a href="supervised-learning.html#cb583-25" tabindex="-1"></a><span class="co">#&gt; 3        11 roc_auc binary     0.676     5 0.0110  pre0_mod08_post0</span></span>
<span id="cb583-26"><a href="supervised-learning.html#cb583-26" tabindex="-1"></a><span class="co">#&gt; 4        10 roc_auc binary     0.674     5 0.0119  pre0_mod07_post0</span></span>
<span id="cb583-27"><a href="supervised-learning.html#cb583-27" tabindex="-1"></a><span class="co">#&gt; 5         8 roc_auc binary     0.665     5 0.0145  pre0_mod06_post0</span></span></code></pre></div>
</div>
<div id="generalized-linear-model---glm" class="section level3 hasAnchor" number="12.9.2">
<h3><span class="header-section-number">12.9.2</span> Generalized Linear Model - GLM<a href="supervised-learning.html#generalized-linear-model---glm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="https://towardsdatascience.com/generalized-linear-models-9cbf848bb8ab">generalized linear model</a> (GLM) is a flexible generalization of ordinary linear regression.</p>
<p>To do this we need to install the <code>glmnet</code> library before creating our model via tidymodels.</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb584-1"><a href="supervised-learning.html#cb584-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;glmnet&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="supervised-learning.html#cb585-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb585-2"><a href="supervised-learning.html#cb585-2" tabindex="-1"></a>glm_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb585-3"><a href="supervised-learning.html#cb585-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb585-4"><a href="supervised-learning.html#cb585-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb585-5"><a href="supervised-learning.html#cb585-5" tabindex="-1"></a></span>
<span id="cb585-6"><a href="supervised-learning.html#cb585-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb585-7"><a href="supervised-learning.html#cb585-7" tabindex="-1"></a>glm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb585-8"><a href="supervised-learning.html#cb585-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb585-9"><a href="supervised-learning.html#cb585-9" tabindex="-1"></a>  <span class="fu">add_model</span>(glm_spec)</span>
<span id="cb585-10"><a href="supervised-learning.html#cb585-10" tabindex="-1"></a></span>
<span id="cb585-11"><a href="supervised-learning.html#cb585-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb585-12"><a href="supervised-learning.html#cb585-12" tabindex="-1"></a>glm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb585-13"><a href="supervised-learning.html#cb585-13" tabindex="-1"></a>  glm_workflow,</span>
<span id="cb585-14"><a href="supervised-learning.html#cb585-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb585-15"><a href="supervised-learning.html#cb585-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb585-16"><a href="supervised-learning.html#cb585-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb585-17"><a href="supervised-learning.html#cb585-17" tabindex="-1"></a>)</span>
<span id="cb585-18"><a href="supervised-learning.html#cb585-18" tabindex="-1"></a></span>
<span id="cb585-19"><a href="supervised-learning.html#cb585-19" tabindex="-1"></a><span class="fu">show_best</span>(glm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb585-20"><a href="supervised-learning.html#cb585-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 8</span></span>
<span id="cb585-21"><a href="supervised-learning.html#cb585-21" tabindex="-1"></a><span class="co">#&gt;         penalty mixture .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb585-22"><a href="supervised-learning.html#cb585-22" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb585-23"><a href="supervised-learning.html#cb585-23" tabindex="-1"></a><span class="co">#&gt; 1 0.00599         1     roc_auc binary     0.819     5 0.00937 pre0_mod08_post0</span></span>
<span id="cb585-24"><a href="supervised-learning.html#cb585-24" tabindex="-1"></a><span class="co">#&gt; 2 0.0774          0.261 roc_auc binary     0.813     5 0.00862 pre0_mod09_post0</span></span>
<span id="cb585-25"><a href="supervised-learning.html#cb585-25" tabindex="-1"></a><span class="co">#&gt; 3 0.000464        0.578 roc_auc binary     0.808     5 0.0102  pre0_mod07_post0</span></span>
<span id="cb585-26"><a href="supervised-learning.html#cb585-26" tabindex="-1"></a><span class="co">#&gt; 4 0.00000278      0.894 roc_auc binary     0.807     5 0.0104  pre0_mod05_post0</span></span>
<span id="cb585-27"><a href="supervised-learning.html#cb585-27" tabindex="-1"></a><span class="co">#&gt; 5 0.00000000129   0.789 roc_auc binary     0.807     5 0.0104  pre0_mod02_post0</span></span></code></pre></div>
</div>
<div id="random-forest-model" class="section level3 hasAnchor" number="12.9.3">
<h3><span class="header-section-number">12.9.3</span> Random Forest Model<a href="supervised-learning.html#random-forest-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Random Forest is a supervised machine learning technique based on decision trees. We will use the <a href="https://dialnet.unirioja.es/descarga/articulo/6230447.pdf">random forest model</a> (RF).</p>
<p>To do this we will first install the <code>ranger</code> library and then create the model via tidymodels.</p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="supervised-learning.html#cb586-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;ranger&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="supervised-learning.html#cb587-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb587-2"><a href="supervised-learning.html#cb587-2" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mtry =</span> <span class="fu">tune</span>(), <span class="at">trees =</span> <span class="dv">1000</span>, <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb587-3"><a href="supervised-learning.html#cb587-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb587-4"><a href="supervised-learning.html#cb587-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb587-5"><a href="supervised-learning.html#cb587-5" tabindex="-1"></a></span>
<span id="cb587-6"><a href="supervised-learning.html#cb587-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb587-7"><a href="supervised-learning.html#cb587-7" tabindex="-1"></a>rf_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb587-8"><a href="supervised-learning.html#cb587-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb587-9"><a href="supervised-learning.html#cb587-9" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_spec)</span>
<span id="cb587-10"><a href="supervised-learning.html#cb587-10" tabindex="-1"></a></span>
<span id="cb587-11"><a href="supervised-learning.html#cb587-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb587-12"><a href="supervised-learning.html#cb587-12" tabindex="-1"></a>rf_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb587-13"><a href="supervised-learning.html#cb587-13" tabindex="-1"></a>  rf_workflow,</span>
<span id="cb587-14"><a href="supervised-learning.html#cb587-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb587-15"><a href="supervised-learning.html#cb587-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb587-16"><a href="supervised-learning.html#cb587-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb587-17"><a href="supervised-learning.html#cb587-17" tabindex="-1"></a>)</span>
<span id="cb587-18"><a href="supervised-learning.html#cb587-18" tabindex="-1"></a><span class="co">#&gt; i Creating pre-processing data to finalize 1 unknown parameter: &quot;mtry&quot;</span></span>
<span id="cb587-19"><a href="supervised-learning.html#cb587-19" tabindex="-1"></a></span>
<span id="cb587-20"><a href="supervised-learning.html#cb587-20" tabindex="-1"></a><span class="fu">show_best</span>(rf_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb587-21"><a href="supervised-learning.html#cb587-21" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 8</span></span>
<span id="cb587-22"><a href="supervised-learning.html#cb587-22" tabindex="-1"></a><span class="co">#&gt;    mtry min_n .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb587-23"><a href="supervised-learning.html#cb587-23" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb587-24"><a href="supervised-learning.html#cb587-24" tabindex="-1"></a><span class="co">#&gt; 1     8    31 roc_auc binary     0.914     5 0.00998 pre0_mod02_post0</span></span>
<span id="cb587-25"><a href="supervised-learning.html#cb587-25" tabindex="-1"></a><span class="co">#&gt; 2    16     2 roc_auc binary     0.912     5 0.0104  pre0_mod03_post0</span></span>
<span id="cb587-26"><a href="supervised-learning.html#cb587-26" tabindex="-1"></a><span class="co">#&gt; 3    23    18 roc_auc binary     0.911     5 0.00975 pre0_mod04_post0</span></span>
<span id="cb587-27"><a href="supervised-learning.html#cb587-27" tabindex="-1"></a><span class="co">#&gt; 4    31    35 roc_auc binary     0.909     5 0.0101  pre0_mod05_post0</span></span>
<span id="cb587-28"><a href="supervised-learning.html#cb587-28" tabindex="-1"></a><span class="co">#&gt; 5    53    40 roc_auc binary     0.906     5 0.00890 pre0_mod08_post0</span></span></code></pre></div>
</div>
<div id="support-vector-machine-model---svm" class="section level3 hasAnchor" number="12.9.4">
<h3><span class="header-section-number">12.9.4</span> Support Vector Machine Model - SVM<a href="supervised-learning.html#support-vector-machine-model---svm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><a href="http://numerentur.org/svm/">Support vector machines</a> or support vector machines are a set of supervised learning algorithms.</p>
<p>To create this model we will use the <code>kernlab</code> engine.</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="supervised-learning.html#cb588-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;kernlab&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="supervised-learning.html#cb589-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb589-2"><a href="supervised-learning.html#cb589-2" tabindex="-1"></a>svm_spec <span class="ot">&lt;-</span> <span class="fu">svm_rbf</span>(<span class="at">cost =</span> <span class="fu">tune</span>(), <span class="at">rbf_sigma =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb589-3"><a href="supervised-learning.html#cb589-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kernlab&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb589-4"><a href="supervised-learning.html#cb589-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb589-5"><a href="supervised-learning.html#cb589-5" tabindex="-1"></a></span>
<span id="cb589-6"><a href="supervised-learning.html#cb589-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb589-7"><a href="supervised-learning.html#cb589-7" tabindex="-1"></a>svm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb589-8"><a href="supervised-learning.html#cb589-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb589-9"><a href="supervised-learning.html#cb589-9" tabindex="-1"></a>  <span class="fu">add_model</span>(svm_spec)</span>
<span id="cb589-10"><a href="supervised-learning.html#cb589-10" tabindex="-1"></a></span>
<span id="cb589-11"><a href="supervised-learning.html#cb589-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb589-12"><a href="supervised-learning.html#cb589-12" tabindex="-1"></a>svm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb589-13"><a href="supervised-learning.html#cb589-13" tabindex="-1"></a>  svm_workflow,</span>
<span id="cb589-14"><a href="supervised-learning.html#cb589-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb589-15"><a href="supervised-learning.html#cb589-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb589-16"><a href="supervised-learning.html#cb589-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb589-17"><a href="supervised-learning.html#cb589-17" tabindex="-1"></a>)</span>
<span id="cb589-18"><a href="supervised-learning.html#cb589-18" tabindex="-1"></a><span class="co">#&gt; maximum number of iterations reached 2.273272e-05 2.273273e-05maximum number of iterations reached 0.001260726 0.001226596maximum number of iterations reached 0.008990742 0.0089403maximum number of iterations reached 4.01911e-05 4.01911e-05maximum number of iterations reached 0.0004458751 0.0004390186maximum number of iterations reached 0.01426775 0.01386837maximum number of iterations reached 2.311619e-05 2.311619e-05maximum number of iterations reached 0.0004666225 0.0004600749maximum number of iterations reached 0.009561785 0.009488703maximum number of iterations reached 4.18965e-05 4.189651e-05maximum number of iterations reached 0.01467671 0.01418266maximum number of iterations reached 2.221129e-05 2.22113e-05maximum number of iterations reached 0.0009695224 0.0009465917maximum number of iterations reached 0.009269646 0.009208682maximum number of iterations reached 3.924845e-05 3.924845e-05maximum number of iterations reached 0.0002350936 0.0002328733maximum number of iterations reached 0.01304753 0.01272522maximum number of iterations reached 2.357812e-05 2.357812e-05maximum number of iterations reached 0.0003822001 0.000377737maximum number of iterations reached 0.009766638 0.009695014maximum number of iterations reached 4.284351e-05 4.284352e-05maximum number of iterations reached 0.01553881 0.01501075maximum number of iterations reached 2.310753e-05 2.310753e-05maximum number of iterations reached 0.0004798964 0.0004730654maximum number of iterations reached 0.009636723 0.009566509maximum number of iterations reached 4.147277e-05 4.147278e-05maximum number of iterations reached 0.0002249601 0.0002227933maximum number of iterations reached 0.01498293 0.01448009</span></span>
<span id="cb589-19"><a href="supervised-learning.html#cb589-19" tabindex="-1"></a></span>
<span id="cb589-20"><a href="supervised-learning.html#cb589-20" tabindex="-1"></a><span class="fu">show_best</span>(svm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb589-21"><a href="supervised-learning.html#cb589-21" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 8</span></span>
<span id="cb589-22"><a href="supervised-learning.html#cb589-22" tabindex="-1"></a><span class="co">#&gt;        cost   rbf_sigma .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb589-23"><a href="supervised-learning.html#cb589-23" tabindex="-1"></a><span class="co">#&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb589-24"><a href="supervised-learning.html#cb589-24" tabindex="-1"></a><span class="co">#&gt; 1  0.00310  0.00599     roc_auc binary     0.864     5 0.00811 pre0_mod02_post0</span></span>
<span id="cb589-25"><a href="supervised-learning.html#cb589-25" tabindex="-1"></a><span class="co">#&gt; 2 32        0.000464    roc_auc binary     0.862     5 0.00900 pre0_mod10_post0</span></span>
<span id="cb589-26"><a href="supervised-learning.html#cb589-26" tabindex="-1"></a><span class="co">#&gt; 3  1        0.0000359   roc_auc binary     0.794     5 0.0103  pre0_mod07_post0</span></span>
<span id="cb589-27"><a href="supervised-learning.html#cb589-27" tabindex="-1"></a><span class="co">#&gt; 4  0.0312   0.00000278  roc_auc binary     0.793     5 0.0114  pre0_mod04_post0</span></span>
<span id="cb589-28"><a href="supervised-learning.html#cb589-28" tabindex="-1"></a><span class="co">#&gt; 5  0.000977 0.000000215 roc_auc binary     0.793     5 0.0114  pre0_mod01_post0</span></span></code></pre></div>
</div>
<div id="naive-bayes-model" class="section level3 hasAnchor" number="12.9.5">
<h3><span class="header-section-number">12.9.5</span> Naive Bayes Model<a href="supervised-learning.html#naive-bayes-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Naïve Bayes (NB), Naive Bayes is one of the simplest, yet powerful, algorithms for classification based on Bayes’ Theorem.</p>
<p>To use this model we will use the <code>naivebayes</code> library within tidymodels.</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="supervised-learning.html#cb590-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;naivebayes&quot;</span>)</span>
<span id="cb590-2"><a href="supervised-learning.html#cb590-2" tabindex="-1"></a><span class="fu">library</span>(naivebayes) <span class="co"># Required for the engine</span></span></code></pre></div>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="supervised-learning.html#cb591-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb591-2"><a href="supervised-learning.html#cb591-2" tabindex="-1"></a>nb_spec <span class="ot">&lt;-</span> <span class="fu">naive_Bayes</span>() <span class="sc">|&gt;</span></span>
<span id="cb591-3"><a href="supervised-learning.html#cb591-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;naivebayes&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb591-4"><a href="supervised-learning.html#cb591-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb591-5"><a href="supervised-learning.html#cb591-5" tabindex="-1"></a></span>
<span id="cb591-6"><a href="supervised-learning.html#cb591-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb591-7"><a href="supervised-learning.html#cb591-7" tabindex="-1"></a>nb_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb591-8"><a href="supervised-learning.html#cb591-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb591-9"><a href="supervised-learning.html#cb591-9" tabindex="-1"></a>  <span class="fu">add_model</span>(nb_spec)</span>
<span id="cb591-10"><a href="supervised-learning.html#cb591-10" tabindex="-1"></a></span>
<span id="cb591-11"><a href="supervised-learning.html#cb591-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb591-12"><a href="supervised-learning.html#cb591-12" tabindex="-1"></a>nb_res <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb591-13"><a href="supervised-learning.html#cb591-13" tabindex="-1"></a>  nb_workflow,</span>
<span id="cb591-14"><a href="supervised-learning.html#cb591-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb591-15"><a href="supervised-learning.html#cb591-15" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb591-16"><a href="supervised-learning.html#cb591-16" tabindex="-1"></a>)</span>
<span id="cb591-17"><a href="supervised-learning.html#cb591-17" tabindex="-1"></a></span>
<span id="cb591-18"><a href="supervised-learning.html#cb591-18" tabindex="-1"></a><span class="fu">collect_metrics</span>(nb_res)</span>
<span id="cb591-19"><a href="supervised-learning.html#cb591-19" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 6</span></span>
<span id="cb591-20"><a href="supervised-learning.html#cb591-20" tabindex="-1"></a><span class="co">#&gt;   .metric     .estimator  mean     n  std_err .config        </span></span>
<span id="cb591-21"><a href="supervised-learning.html#cb591-21" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          </span></span>
<span id="cb591-22"><a href="supervised-learning.html#cb591-22" tabindex="-1"></a><span class="co">#&gt; 1 accuracy    binary     0.859     5 0.000246 pre0_mod0_post0</span></span>
<span id="cb591-23"><a href="supervised-learning.html#cb591-23" tabindex="-1"></a><span class="co">#&gt; 2 roc_auc     binary     0.840     5 0.00983  pre0_mod0_post0</span></span>
<span id="cb591-24"><a href="supervised-learning.html#cb591-24" tabindex="-1"></a><span class="co">#&gt; 3 sensitivity binary     1         5 0        pre0_mod0_post0</span></span>
<span id="cb591-25"><a href="supervised-learning.html#cb591-25" tabindex="-1"></a><span class="co">#&gt; 4 specificity binary     0         5 0        pre0_mod0_post0</span></span></code></pre></div>
</div>
<div id="model-comparison" class="section level3 hasAnchor" number="12.9.6">
<h3><span class="header-section-number">12.9.6</span> Model Comparison<a href="supervised-learning.html#model-comparison" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To compare the models, we can extract the metrics from each tuning result and visualize them.</p>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb592-1"><a href="supervised-learning.html#cb592-1" tabindex="-1"></a><span class="co"># Collect metrics</span></span>
<span id="cb592-2"><a href="supervised-learning.html#cb592-2" tabindex="-1"></a>knn_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(knn_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;kNN&quot;</span>)</span>
<span id="cb592-3"><a href="supervised-learning.html#cb592-3" tabindex="-1"></a>glm_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(glm_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;GLM&quot;</span>)</span>
<span id="cb592-4"><a href="supervised-learning.html#cb592-4" tabindex="-1"></a>rf_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(rf_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;RF&quot;</span>)</span>
<span id="cb592-5"><a href="supervised-learning.html#cb592-5" tabindex="-1"></a>svm_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(svm_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;SVM&quot;</span>)</span>
<span id="cb592-6"><a href="supervised-learning.html#cb592-6" tabindex="-1"></a>nb_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(nb_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;Naive Bayes&quot;</span>)</span>
<span id="cb592-7"><a href="supervised-learning.html#cb592-7" tabindex="-1"></a></span>
<span id="cb592-8"><a href="supervised-learning.html#cb592-8" tabindex="-1"></a><span class="co"># Combine</span></span>
<span id="cb592-9"><a href="supervised-learning.html#cb592-9" tabindex="-1"></a>all_metrics <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(knn_metrics, glm_metrics, rf_metrics, svm_metrics, nb_metrics)</span>
<span id="cb592-10"><a href="supervised-learning.html#cb592-10" tabindex="-1"></a></span>
<span id="cb592-11"><a href="supervised-learning.html#cb592-11" tabindex="-1"></a><span class="co"># Visualize ROC AUC</span></span>
<span id="cb592-12"><a href="supervised-learning.html#cb592-12" tabindex="-1"></a>all_metrics <span class="sc">|&gt;</span></span>
<span id="cb592-13"><a href="supervised-learning.html#cb592-13" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;roc_auc&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb592-14"><a href="supervised-learning.html#cb592-14" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> model, <span class="at">y =</span> mean, <span class="at">fill =</span> model)) <span class="sc">+</span></span>
<span id="cb592-15"><a href="supervised-learning.html#cb592-15" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb592-16"><a href="supervised-learning.html#cb592-16" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;ROC AUC&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Model Comparison&quot;</span>) <span class="sc">+</span></span>
<span id="cb592-17"><a href="supervised-learning.html#cb592-17" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="Data-Science-con-R_files/figure-html/unnamed-chunk-755-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>For this case the random forest model (<em>RF</em>) seems to be the best. This is not surprising given that this algorithm is related to its ability to cope with different input types and require little preprocessing. We can make our models better by pre-processing data and changing the ad-hoc parameters of each model.</p>
</div>
<div id="predicting-using-the-best-model" class="section level3 hasAnchor" number="12.9.7">
<h3><span class="header-section-number">12.9.7</span> Predicting using the best model<a href="supervised-learning.html#predicting-using-the-best-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have our best model (Random Forest), we proceed to perform the prediction on the test set. We need to finalize the workflow with the best hyperparameters from the tuning step first.</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="supervised-learning.html#cb593-1" tabindex="-1"></a><span class="co"># Select best parameters for RF</span></span>
<span id="cb593-2"><a href="supervised-learning.html#cb593-2" tabindex="-1"></a>best_rf <span class="ot">&lt;-</span> <span class="fu">select_best</span>(rf_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb593-3"><a href="supervised-learning.html#cb593-3" tabindex="-1"></a></span>
<span id="cb593-4"><a href="supervised-learning.html#cb593-4" tabindex="-1"></a><span class="co"># Finalize workflow</span></span>
<span id="cb593-5"><a href="supervised-learning.html#cb593-5" tabindex="-1"></a>final_rf_workflow <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(rf_workflow, best_rf)</span>
<span id="cb593-6"><a href="supervised-learning.html#cb593-6" tabindex="-1"></a></span>
<span id="cb593-7"><a href="supervised-learning.html#cb593-7" tabindex="-1"></a><span class="co"># Fit on training data</span></span>
<span id="cb593-8"><a href="supervised-learning.html#cb593-8" tabindex="-1"></a>optimal_model <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_rf_workflow, <span class="at">data =</span> churn_train)</span>
<span id="cb593-9"><a href="supervised-learning.html#cb593-9" tabindex="-1"></a></span>
<span id="cb593-10"><a href="supervised-learning.html#cb593-10" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb593-11"><a href="supervised-learning.html#cb593-11" tabindex="-1"></a>churn_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(optimal_model, <span class="at">new_data =</span> churn_test)</span>
<span id="cb593-12"><a href="supervised-learning.html#cb593-12" tabindex="-1"></a></span>
<span id="cb593-13"><a href="supervised-learning.html#cb593-13" tabindex="-1"></a><span class="co"># Evaluate results</span></span>
<span id="cb593-14"><a href="supervised-learning.html#cb593-14" tabindex="-1"></a>churn_predictions <span class="sc">|&gt;</span></span>
<span id="cb593-15"><a href="supervised-learning.html#cb593-15" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> churn_status, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb593-16"><a href="supervised-learning.html#cb593-16" tabindex="-1"></a><span class="co">#&gt;           Truth</span></span>
<span id="cb593-17"><a href="supervised-learning.html#cb593-17" tabindex="-1"></a><span class="co">#&gt; Prediction   No   Sí</span></span>
<span id="cb593-18"><a href="supervised-learning.html#cb593-18" tabindex="-1"></a><span class="co">#&gt;         No 1285   66</span></span>
<span id="cb593-19"><a href="supervised-learning.html#cb593-19" tabindex="-1"></a><span class="co">#&gt;         Sí    3  147</span></span>
<span id="cb593-20"><a href="supervised-learning.html#cb593-20" tabindex="-1"></a></span>
<span id="cb593-21"><a href="supervised-learning.html#cb593-21" tabindex="-1"></a>churn_predictions <span class="sc">|&gt;</span></span>
<span id="cb593-22"><a href="supervised-learning.html#cb593-22" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> churn_status, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb593-23"><a href="supervised-learning.html#cb593-23" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb593-24"><a href="supervised-learning.html#cb593-24" tabindex="-1"></a><span class="co">#&gt;   .metric  .estimator .estimate</span></span>
<span id="cb593-25"><a href="supervised-learning.html#cb593-25" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb593-26"><a href="supervised-learning.html#cb593-26" tabindex="-1"></a><span class="co">#&gt; 1 accuracy binary         0.954</span></span></code></pre></div>
<p>Thus, we have found how to create a customer churn prediction model given 19 prediction variables with an accuracy of 96%.</p>
</div>
</div>
<div id="exercises-19" class="section level2 hasAnchor" number="12.10">
<h2><span class="header-section-number">12.10</span> Exercises<a href="supervised-learning.html#exercises-19" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol start="114" style="list-style-type: decimal">
<li>The <code>attrition</code> data frame from the <code>modeldata</code> library shows data from a list of almost 1,500 employees of a company. Create a copy of this data frame and store it in the <code>trabajadores</code> object. Then, build an RF model with this data to predict the <code>Attrition</code> field (job desertion). Where the class “Yes” means they resigned and “No” means they still work.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb594-1"><a href="supervised-learning.html#cb594-1" tabindex="-1"></a><span class="fu">data</span>(attrition)</span>
<span id="cb594-2"><a href="supervised-learning.html#cb594-2" tabindex="-1"></a><span class="fu">str</span>(attrition)</span>
<span id="cb594-3"><a href="supervised-learning.html#cb594-3" tabindex="-1"></a></span>
<span id="cb594-4"><a href="supervised-learning.html#cb594-4" tabindex="-1"></a>workers <span class="ot">&lt;-</span> attrition</span>
<span id="cb594-5"><a href="supervised-learning.html#cb594-5" tabindex="-1"></a></span>
<span id="cb594-6"><a href="supervised-learning.html#cb594-6" tabindex="-1"></a>workers <span class="ot">&lt;-</span> workers <span class="sc">|&gt;</span> </span>
<span id="cb594-7"><a href="supervised-learning.html#cb594-7" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">attrition_status =</span> Attrition)</span>
<span id="cb594-8"><a href="supervised-learning.html#cb594-8" tabindex="-1"></a></span>
<span id="cb594-9"><a href="supervised-learning.html#cb594-9" tabindex="-1"></a><span class="co"># 70% for the training data</span></span>
<span id="cb594-10"><a href="supervised-learning.html#cb594-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb594-11"><a href="supervised-learning.html#cb594-11" tabindex="-1"></a>workers_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(workers, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> attrition_status)</span>
<span id="cb594-12"><a href="supervised-learning.html#cb594-12" tabindex="-1"></a></span>
<span id="cb594-13"><a href="supervised-learning.html#cb594-13" tabindex="-1"></a>workers_train <span class="ot">&lt;-</span> <span class="fu">training</span>(workers_split)</span>
<span id="cb594-14"><a href="supervised-learning.html#cb594-14" tabindex="-1"></a>workers_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(workers_split)</span>
<span id="cb594-15"><a href="supervised-learning.html#cb594-15" tabindex="-1"></a></span>
<span id="cb594-16"><a href="supervised-learning.html#cb594-16" tabindex="-1"></a><span class="co"># Recipe</span></span>
<span id="cb594-17"><a href="supervised-learning.html#cb594-17" tabindex="-1"></a>workers_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(attrition_status <span class="sc">~</span> ., <span class="at">data =</span> workers_train) <span class="sc">|&gt;</span></span>
<span id="cb594-18"><a href="supervised-learning.html#cb594-18" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>(), <span class="sc">-</span>attrition_status) <span class="sc">|&gt;</span></span>
<span id="cb594-19"><a href="supervised-learning.html#cb594-19" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span>
<span id="cb594-20"><a href="supervised-learning.html#cb594-20" tabindex="-1"></a></span>
<span id="cb594-21"><a href="supervised-learning.html#cb594-21" tabindex="-1"></a><span class="co"># We create CV folds</span></span>
<span id="cb594-22"><a href="supervised-learning.html#cb594-22" tabindex="-1"></a>workers_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(workers_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> attrition_status)</span>
<span id="cb594-23"><a href="supervised-learning.html#cb594-23" tabindex="-1"></a>workers_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(roc_auc, accuracy)</span>
<span id="cb594-24"><a href="supervised-learning.html#cb594-24" tabindex="-1"></a></span>
<span id="cb594-25"><a href="supervised-learning.html#cb594-25" tabindex="-1"></a><span class="co"># We create the model</span></span>
<span id="cb594-26"><a href="supervised-learning.html#cb594-26" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span></span>
<span id="cb594-27"><a href="supervised-learning.html#cb594-27" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb594-28"><a href="supervised-learning.html#cb594-28" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb594-29"><a href="supervised-learning.html#cb594-29" tabindex="-1"></a></span>
<span id="cb594-30"><a href="supervised-learning.html#cb594-30" tabindex="-1"></a>rf_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb594-31"><a href="supervised-learning.html#cb594-31" tabindex="-1"></a>  <span class="fu">add_recipe</span>(workers_recipe) <span class="sc">|&gt;</span></span>
<span id="cb594-32"><a href="supervised-learning.html#cb594-32" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_spec)</span>
<span id="cb594-33"><a href="supervised-learning.html#cb594-33" tabindex="-1"></a></span>
<span id="cb594-34"><a href="supervised-learning.html#cb594-34" tabindex="-1"></a>workers_rf_res <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb594-35"><a href="supervised-learning.html#cb594-35" tabindex="-1"></a>  rf_wf,</span>
<span id="cb594-36"><a href="supervised-learning.html#cb594-36" tabindex="-1"></a>  <span class="at">resamples =</span> workers_folds,</span>
<span id="cb594-37"><a href="supervised-learning.html#cb594-37" tabindex="-1"></a>  <span class="at">metrics =</span> workers_metrics</span>
<span id="cb594-38"><a href="supervised-learning.html#cb594-38" tabindex="-1"></a>)</span>
<span id="cb594-39"><a href="supervised-learning.html#cb594-39" tabindex="-1"></a></span>
<span id="cb594-40"><a href="supervised-learning.html#cb594-40" tabindex="-1"></a><span class="fu">collect_metrics</span>(workers_rf_res)</span></code></pre></div>
</details>
<ol start="115" style="list-style-type: decimal">
<li>Using the training data from the previous exercise, build the GLM model using tidymodels.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="supervised-learning.html#cb595-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb595-2"><a href="supervised-learning.html#cb595-2" tabindex="-1"></a>glm_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb595-3"><a href="supervised-learning.html#cb595-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb595-4"><a href="supervised-learning.html#cb595-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb595-5"><a href="supervised-learning.html#cb595-5" tabindex="-1"></a></span>
<span id="cb595-6"><a href="supervised-learning.html#cb595-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb595-7"><a href="supervised-learning.html#cb595-7" tabindex="-1"></a>glm_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb595-8"><a href="supervised-learning.html#cb595-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(workers_recipe) <span class="sc">|&gt;</span></span>
<span id="cb595-9"><a href="supervised-learning.html#cb595-9" tabindex="-1"></a>  <span class="fu">add_model</span>(glm_spec)</span>
<span id="cb595-10"><a href="supervised-learning.html#cb595-10" tabindex="-1"></a></span>
<span id="cb595-11"><a href="supervised-learning.html#cb595-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb595-12"><a href="supervised-learning.html#cb595-12" tabindex="-1"></a>workers_glm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb595-13"><a href="supervised-learning.html#cb595-13" tabindex="-1"></a>  glm_wf,</span>
<span id="cb595-14"><a href="supervised-learning.html#cb595-14" tabindex="-1"></a>  <span class="at">resamples =</span> workers_folds,</span>
<span id="cb595-15"><a href="supervised-learning.html#cb595-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb595-16"><a href="supervised-learning.html#cb595-16" tabindex="-1"></a>  <span class="at">metrics =</span> workers_metrics</span>
<span id="cb595-17"><a href="supervised-learning.html#cb595-17" tabindex="-1"></a>)</span>
<span id="cb595-18"><a href="supervised-learning.html#cb595-18" tabindex="-1"></a></span>
<span id="cb595-19"><a href="supervised-learning.html#cb595-19" tabindex="-1"></a><span class="fu">show_best</span>(workers_glm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
</details>
<ol start="116" style="list-style-type: decimal">
<li>Using the training data, build the SVM model.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="supervised-learning.html#cb596-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb596-2"><a href="supervised-learning.html#cb596-2" tabindex="-1"></a>svm_spec <span class="ot">&lt;-</span> <span class="fu">svm_rbf</span>(<span class="at">cost =</span> <span class="fu">tune</span>(), <span class="at">rbf_sigma =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb596-3"><a href="supervised-learning.html#cb596-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kernlab&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb596-4"><a href="supervised-learning.html#cb596-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb596-5"><a href="supervised-learning.html#cb596-5" tabindex="-1"></a></span>
<span id="cb596-6"><a href="supervised-learning.html#cb596-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb596-7"><a href="supervised-learning.html#cb596-7" tabindex="-1"></a>svm_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb596-8"><a href="supervised-learning.html#cb596-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(workers_recipe) <span class="sc">|&gt;</span></span>
<span id="cb596-9"><a href="supervised-learning.html#cb596-9" tabindex="-1"></a>  <span class="fu">add_model</span>(svm_spec)</span>
<span id="cb596-10"><a href="supervised-learning.html#cb596-10" tabindex="-1"></a></span>
<span id="cb596-11"><a href="supervised-learning.html#cb596-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb596-12"><a href="supervised-learning.html#cb596-12" tabindex="-1"></a>workers_svm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb596-13"><a href="supervised-learning.html#cb596-13" tabindex="-1"></a>  svm_wf,</span>
<span id="cb596-14"><a href="supervised-learning.html#cb596-14" tabindex="-1"></a>  <span class="at">resamples =</span> workers_folds,</span>
<span id="cb596-15"><a href="supervised-learning.html#cb596-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb596-16"><a href="supervised-learning.html#cb596-16" tabindex="-1"></a>  <span class="at">metrics =</span> workers_metrics</span>
<span id="cb596-17"><a href="supervised-learning.html#cb596-17" tabindex="-1"></a>)</span>
<span id="cb596-18"><a href="supervised-learning.html#cb596-18" tabindex="-1"></a></span>
<span id="cb596-19"><a href="supervised-learning.html#cb596-19" tabindex="-1"></a><span class="fu">show_best</span>(workers_svm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
</details>
<ol start="117" style="list-style-type: decimal">
<li>From the created models, which is the most optimal?</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="supervised-learning.html#cb597-1" tabindex="-1"></a><span class="co"># We generate model list</span></span>
<span id="cb597-2"><a href="supervised-learning.html#cb597-2" tabindex="-1"></a>lista_de_modelos <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">rf =</span> trabajadores_modelo_rf,</span>
<span id="cb597-3"><a href="supervised-learning.html#cb597-3" tabindex="-1"></a>                         <span class="at">glmmet =</span> workers_model_glm,</span>
<span id="cb597-4"><a href="supervised-learning.html#cb597-4" tabindex="-1"></a>                         <span class="at">svm =</span> workers_model_svm)</span>
<span id="cb597-5"><a href="supervised-learning.html#cb597-5" tabindex="-1"></a></span>
<span id="cb597-6"><a href="supervised-learning.html#cb597-6" tabindex="-1"></a><span class="co"># We compare the models</span></span>
<span id="cb597-7"><a href="supervised-learning.html#cb597-7" tabindex="-1"></a>comparacion_modelos <span class="ot">&lt;-</span> <span class="fu">resamples</span>(lista_de_modelos)</span>
<span id="cb597-8"><a href="supervised-learning.html#cb597-8" tabindex="-1"></a></span>
<span id="cb597-9"><a href="supervised-learning.html#cb597-9" tabindex="-1"></a><span class="co"># We visualize the comparison</span></span>
<span id="cb597-10"><a href="supervised-learning.html#cb597-10" tabindex="-1"></a><span class="fu">bwplot</span>(comparacion_modelos, <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>)</span>
<span id="cb597-11"><a href="supervised-learning.html#cb597-11" tabindex="-1"></a></span>
<span id="cb597-12"><a href="supervised-learning.html#cb597-12" tabindex="-1"></a><span class="co"># We obtain the summary of the comparison</span></span>
<span id="cb597-13"><a href="supervised-learning.html#cb597-13" tabindex="-1"></a><span class="fu">summary</span>(comparacion_modelos, <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>)</span></code></pre></div>
<p>We see how the results overlap, so we could opt for the two that have the highest mean ROC and among them choose the one that gives us a smaller range of values.</p>
</details>
<ol start="118" style="list-style-type: decimal">
<li>Create the confusion matrices for the three models created.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="supervised-learning.html#cb598-1" tabindex="-1"></a>prediccion_rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(trabajadores_modelo_rf, trabajadores_test)</span>
<span id="cb598-2"><a href="supervised-learning.html#cb598-2" tabindex="-1"></a><span class="fu">confusionMatrix</span>(prediccion_rf, trabajadores_test<span class="sc">$</span>renuncia)</span>
<span id="cb598-3"><a href="supervised-learning.html#cb598-3" tabindex="-1"></a></span>
<span id="cb598-4"><a href="supervised-learning.html#cb598-4" tabindex="-1"></a>prediccion_glm <span class="ot">&lt;-</span> <span class="fu">predict</span>(trabajadores_modelo_glm, trabajadores_test)</span>
<span id="cb598-5"><a href="supervised-learning.html#cb598-5" tabindex="-1"></a><span class="fu">confusionMatrix</span>(prediccion_glm, trabajadores_test<span class="sc">$</span>renuncia)</span>
<span id="cb598-6"><a href="supervised-learning.html#cb598-6" tabindex="-1"></a></span>
<span id="cb598-7"><a href="supervised-learning.html#cb598-7" tabindex="-1"></a>prediccion_svm <span class="ot">&lt;-</span> <span class="fu">predict</span>(trabajadores_modelo_svm, trabajadores_test)</span>
<span id="cb598-8"><a href="supervised-learning.html#cb598-8" tabindex="-1"></a><span class="fu">confusionMatrix</span>(prediccion_svm, trabajadores_test<span class="sc">$</span>renuncia)</span></code></pre></div>
<p>Keep in mind that the model with the highest <code>ROC</code> value will not necessarily have the highest <code>accuracy</code>. Therefore the choice of the model was performed in a previous step. The ROC better balances sensitivity with the <a href="https://en.wikipedia.org/wiki/False_positive_rate">false positive rate</a>.</p>
</details>
</details>
</div>
<div id="ethics-bias-in-algorithmic-decision-making" class="section level2 hasAnchor" number="12.11">
<h2><span class="header-section-number">12.11</span> Ethics: Bias in Algorithmic Decision Making<a href="supervised-learning.html#ethics-bias-in-algorithmic-decision-making" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the previous exercise, we built models to predict employee attrition using variables like <code>Gender</code>, <code>Age</code>, and <code>MaritalStatus</code>. While mathematically sound, obtaining a high accuracy score does not mean the model is “good” or “fair” to use in the real world.</p>
<div id="the-risk-of-proxy-variables" class="section level3 hasAnchor" number="12.11.1">
<h3><span class="header-section-number">12.11.1</span> The Risk of Proxy Variables<a href="supervised-learning.html#the-risk-of-proxy-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Even if we remove explicit sensitive attributes (like Gender or Ethnicity), other variables can act as <strong>proxies</strong>.
* <strong>Zip Code:</strong> Often correlates with race or socioeconomic status.
* <strong>Years of Experience:</strong> Strongly correlated with Age.</p>
</div>
<div id="feedback-loops" class="section level3 hasAnchor" number="12.11.2">
<h3><span class="header-section-number">12.11.2</span> Feedback Loops<a href="supervised-learning.html#feedback-loops" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If a company uses an algorithm to decide who to hire or fire based on historical data, they may perpetuate historical biases.
* <strong>Scenario:</strong> If a company historically didn’t hire women for leadership roles, the training data will show that women are “less likely to succeed” in those roles.
* <strong>Result:</strong> The model creates a feedback loop, rejecting qualified female candidates because they don’t match the historical pattern of “success”.</p>
</div>
<div id="what-can-we-do" class="section level3 hasAnchor" number="12.11.3">
<h3><span class="header-section-number">12.11.3</span> What can we do?<a href="supervised-learning.html#what-can-we-do" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Audit your Data:</strong> checking for representation balance (e.g., is one group significantly smaller?).</li>
<li><strong>Model Explainability:</strong> Use tools like <code>DALEX</code> or <code>vip</code> (variable importance) to understand <em>why</em> the model is making a decision. If <code>MaritalStatus</code> is the top predictor for firing someone, is that ethical?</li>
<li><strong>Human in the Loop:</strong> These models should support human decision-making, not replace it entirely.</li>
</ol>
<p>As Data Scientists, our responsibility extends beyond the AUC score. We must ensure our models do not harm individuals or groups.</p>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Fawcett2005" class="csl-entry">
Fawcett, Tom. 2005. <em>An Introduction to ROC Analysis</em>. Elsevier. <a href="https://people.inf.elte.hu/kiss/11dwhdm/roc.pdf">https://people.inf.elte.hu/kiss/11dwhdm/roc.pdf</a>.
</div>
<div id="ref-Lobo2007" class="csl-entry">
Jorge M. Lobo, Raimundo Real, Alberto Jiménez-Valverde. 2007. <em>AUC: A Misleading Measure of the Performance of Predictive Distribution Models</em>. Ecological Sounding. <a href="https://www2.unil.ch/biomapper/Download/Lobo-GloEcoBioGeo-2007.pdf">https://www2.unil.ch/biomapper/Download/Lobo-GloEcoBioGeo-2007.pdf</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="14">
<li id="fn14"><p><a href="https://www.tidymodels.org/" class="uri">https://www.tidymodels.org/</a><a href="supervised-learning.html#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="unsupervised-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": true,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": null
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": null,
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
