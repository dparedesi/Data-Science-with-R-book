<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Supervised Learning | Data Science with R</title>
  <meta name="description" content="A comprehensive guide to data science using R, covering fundamentals, visualization, statistics, machine learning with tidymodels, and generative AI integration. Third Edition by Daniel Paredes." />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Supervised Learning | Data Science with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A comprehensive guide to data science using R, covering fundamentals, visualization, statistics, machine learning with tidymodels, and generative AI integration. Third Edition by Daniel Paredes." />
  <meta name="github-repo" content="dparedesi/Data-Science-with-R-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Supervised Learning | Data Science with R" />
  
  <meta name="twitter:description" content="A comprehensive guide to data science using R, covering fundamentals, visualization, statistics, machine learning with tidymodels, and generative AI integration. Third Edition by Daniel Paredes." />
  

<meta name="author" content="Author: Mg. Daniel Paredes Inilupu" />


<meta name="date" content="2025-12-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-2.html"/>
<link rel="next" href="unsupervised-learning.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics: Sin Vista -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VJJ963010J"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VJJ963010J');
</script>

<!-- Global site tag (gtag.js) - Google Analytics: Vista -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-165839710-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-165839710-1');
</script>

<!-- Global site tag (gtag.js) - Google Analytics: Agentedec4mbio -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-17876479-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-17876479-1');
</script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#support-this-work"><i class="fa fa-check"></i>Support This Work</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#stay-connected"><i class="fa fa-check"></i>Stay Connected</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a>
<ul>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html#family"><i class="fa fa-check"></i>Family</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html#mentors-and-inspirations"><i class="fa fa-check"></i>Mentors and Inspirations</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#why-r"><i class="fa fa-check"></i>Why R?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#installing-r"><i class="fa fa-check"></i>Installing R</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#installing-rstudio"><i class="fa fa-check"></i>Installing RStudio</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#rstudio-sections"><i class="fa fa-check"></i>RStudio Sections</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#essential-keyboard-shortcuts"><i class="fa fa-check"></i>Essential Keyboard Shortcuts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#testing-your-installation"><i class="fa fa-check"></i>Testing Your Installation</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#writing-scripts"><i class="fa fa-check"></i>Writing Scripts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#whats-next"><i class="fa fa-check"></i>What’s Next?</a></li>
</ul></li>
<li class="part"><span><b>I Fundamentals and Key Tools</b></span></li>
<li class="chapter" data-level="1" data-path="objects.html"><a href="objects.html"><i class="fa fa-check"></i><b>1</b> Objects</a>
<ul>
<li class="chapter" data-level="1.1" data-path="objects.html"><a href="objects.html#what-are-objects-in-r"><i class="fa fa-check"></i><b>1.1</b> What are objects in R?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="objects.html"><a href="objects.html#r-as-an-object-oriented-language"><i class="fa fa-check"></i><b>1.1.1</b> R as an object-oriented language</a></li>
<li class="chapter" data-level="1.1.2" data-path="objects.html"><a href="objects.html#the-power-of-abstraction"><i class="fa fa-check"></i><b>1.1.2</b> The power of abstraction</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="objects.html"><a href="objects.html#variables-the-first-objects-on-your-journey"><i class="fa fa-check"></i><b>1.2</b> Variables: The first objects on your journey</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="objects.html"><a href="objects.html#creating-variables-in-r"><i class="fa fa-check"></i><b>1.2.1</b> Creating variables in R</a></li>
<li class="chapter" data-level="1.2.2" data-path="objects.html"><a href="objects.html#operations-with-variables"><i class="fa fa-check"></i><b>1.2.2</b> Operations with variables</a></li>
<li class="chapter" data-level="1.2.3" data-path="objects.html"><a href="objects.html#best-practices-for-naming-variables"><i class="fa fa-check"></i><b>1.2.3</b> Best practices for naming variables</a></li>
<li class="chapter" data-level="1.2.4" data-path="objects.html"><a href="objects.html#data-types"><i class="fa fa-check"></i><b>1.2.4</b> Data types</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="objects.html"><a href="objects.html#object-types-for-complex-data"><i class="fa fa-check"></i><b>1.3</b> Object types for complex data</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="objects.html"><a href="objects.html#vectors-organizing-information-of-the-same-type"><i class="fa fa-check"></i><b>1.3.1</b> Vectors: organizing information of the same type</a></li>
<li class="chapter" data-level="1.3.2" data-path="objects.html"><a href="objects.html#lists-grouping-objects-of-different-types"><i class="fa fa-check"></i><b>1.3.2</b> Lists: grouping objects of different types</a></li>
<li class="chapter" data-level="1.3.3" data-path="objects.html"><a href="objects.html#matrices-organizing-data-in-rows-and-columns"><i class="fa fa-check"></i><b>1.3.3</b> Matrices: organizing data in rows and columns</a></li>
<li class="chapter" data-level="1.3.4" data-path="objects.html"><a href="objects.html#arrays-multidimensional-matrices"><i class="fa fa-check"></i><b>1.3.4</b> Arrays: multidimensional matrices</a></li>
<li class="chapter" data-level="1.3.5" data-path="objects.html"><a href="objects.html#factors-representing-categorical-data"><i class="fa fa-check"></i><b>1.3.5</b> Factors: representing categorical data</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="objects.html"><a href="objects.html#the-universe-of-objects-in-r"><i class="fa fa-check"></i><b>1.4</b> The Universe of Objects in R</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="objects.html"><a href="objects.html#philosophy-of-objects-in-r"><i class="fa fa-check"></i><b>1.4.1</b> Philosophy of objects in R</a></li>
<li class="chapter" data-level="1.4.2" data-path="objects.html"><a href="objects.html#comparison-with-other-languages"><i class="fa fa-check"></i><b>1.4.2</b> Comparison with other languages</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="objects.html"><a href="objects.html#exercises"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>2</b> Functions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="functions.html"><a href="functions.html#introduction-to-the-world-of-functions"><i class="fa fa-check"></i><b>2.1</b> Introduction to the world of functions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="functions.html"><a href="functions.html#what-are-functions"><i class="fa fa-check"></i><b>2.1.1</b> What are functions?</a></li>
<li class="chapter" data-level="2.1.2" data-path="functions.html"><a href="functions.html#why-use-functions"><i class="fa fa-check"></i><b>2.1.2</b> Why use functions?</a></li>
<li class="chapter" data-level="2.1.3" data-path="functions.html"><a href="functions.html#first-functions-exploring-basic-r-functions"><i class="fa fa-check"></i><b>2.1.3</b> First functions: exploring basic R functions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="functions.html"><a href="functions.html#anatomy-of-a-function"><i class="fa fa-check"></i><b>2.2</b> Anatomy of a function</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="functions.html"><a href="functions.html#arguments-the-ingredients-of-the-function"><i class="fa fa-check"></i><b>2.2.1</b> Arguments: the ingredients of the function</a></li>
<li class="chapter" data-level="2.2.2" data-path="functions.html"><a href="functions.html#body-the-instructions-of-the-function"><i class="fa fa-check"></i><b>2.2.2</b> Body: the instructions of the function</a></li>
<li class="chapter" data-level="2.2.3" data-path="functions.html"><a href="functions.html#return-value-the-result-of-the-function"><i class="fa fa-check"></i><b>2.2.3</b> Return value: the result of the function</a></li>
<li class="chapter" data-level="2.2.4" data-path="functions.html"><a href="functions.html#examples-creating-simple-functions-step-by-step"><i class="fa fa-check"></i><b>2.2.4</b> Examples: creating simple functions step by step</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="functions.html"><a href="functions.html#mastering-the-use-of-functions"><i class="fa fa-check"></i><b>2.3</b> Mastering the use of functions</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="functions.html"><a href="functions.html#functions-with-a-variable-number-of-arguments-...-adapting-to-different-situations"><i class="fa fa-check"></i><b>2.3.1</b> Functions with a variable number of arguments (<code>...</code>): Adapting to different situations</a></li>
<li class="chapter" data-level="2.3.2" data-path="functions.html"><a href="functions.html#variable-scope-local-and-global-variables"><i class="fa fa-check"></i><b>2.3.2</b> Variable scope: local and global variables</a></li>
<li class="chapter" data-level="2.3.3" data-path="functions.html"><a href="functions.html#examples-functions-to-calculate-taxes-discounts-etc."><i class="fa fa-check"></i><b>2.3.3</b> Examples: functions to calculate taxes, discounts, etc.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="functions.html"><a href="functions.html#higher-order-functions"><i class="fa fa-check"></i><b>2.4</b> Higher-order functions</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="functions.html"><a href="functions.html#lapply-and-sapply-applying-a-function-to-each-element"><i class="fa fa-check"></i><b>2.4.1</b> <code>lapply()</code> and <code>sapply()</code>: applying a function to each element</a></li>
<li class="chapter" data-level="2.4.2" data-path="functions.html"><a href="functions.html#apply-applying-a-function-to-rows-or-columns"><i class="fa fa-check"></i><b>2.4.2</b> <code>apply()</code>: applying a function to rows or columns</a></li>
<li class="chapter" data-level="2.4.3" data-path="functions.html"><a href="functions.html#mapply-applying-a-function-to-multiple-arguments"><i class="fa fa-check"></i><b>2.4.3</b> <code>mapply()</code>: applying a function to multiple arguments</a></li>
<li class="chapter" data-level="2.4.4" data-path="functions.html"><a href="functions.html#examples-data-analysis-with-higher-order-functions"><i class="fa fa-check"></i><b>2.4.4</b> Examples: data analysis with higher-order functions</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="functions.html"><a href="functions.html#closures-functions-with-memory"><i class="fa fa-check"></i><b>2.5</b> Closures: functions with memory</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="functions.html"><a href="functions.html#concept-functions-that-remember"><i class="fa fa-check"></i><b>2.5.1</b> Concept: functions that “remember”</a></li>
<li class="chapter" data-level="2.5.2" data-path="functions.html"><a href="functions.html#applications-creating-counters-functions-with-internal-state"><i class="fa fa-check"></i><b>2.5.2</b> Applications: creating counters, functions with internal state</a></li>
<li class="chapter" data-level="2.5.3" data-path="functions.html"><a href="functions.html#examples-simulating-a-game-creating-an-operation-history"><i class="fa fa-check"></i><b>2.5.3</b> Examples: simulating a game, creating an operation history</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="functions.html"><a href="functions.html#debugging-and-error-handling-solving-the-mysteries-of-your-code"><i class="fa fa-check"></i><b>2.6</b> Debugging and error handling: solving the mysteries of your code</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="functions.html"><a href="functions.html#identifying-errors-common-error-messages-in-r"><i class="fa fa-check"></i><b>2.6.1</b> Identifying errors: common error messages in R</a></li>
<li class="chapter" data-level="2.6.2" data-path="functions.html"><a href="functions.html#debugging-tools-debug-traceback"><i class="fa fa-check"></i><b>2.6.2</b> Debugging tools: <code>debug()</code>, <code>traceback()</code></a></li>
<li class="chapter" data-level="2.6.3" data-path="functions.html"><a href="functions.html#error-handling-trycatch"><i class="fa fa-check"></i><b>2.6.3</b> Error handling: <code>tryCatch()</code></a></li>
<li class="chapter" data-level="2.6.4" data-path="functions.html"><a href="functions.html#examples-debugging-functions-with-errors-handling-exceptions"><i class="fa fa-check"></i><b>2.6.4</b> Examples: debugging functions with errors, handling exceptions</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="functions.html"><a href="functions.html#exercises-1"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-frames.html"><a href="data-frames.html"><i class="fa fa-check"></i><b>3</b> Data Frames</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-frames.html"><a href="data-frames.html#introduction-to-data-frames"><i class="fa fa-check"></i><b>3.1</b> Introduction to Data Frames</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="data-frames.html"><a href="data-frames.html#what-are-data-frames"><i class="fa fa-check"></i><b>3.1.1</b> What are data frames?</a></li>
<li class="chapter" data-level="3.1.2" data-path="data-frames.html"><a href="data-frames.html#why-data-frames"><i class="fa fa-check"></i><b>3.1.2</b> Why data frames?</a></li>
<li class="chapter" data-level="3.1.3" data-path="data-frames.html"><a href="data-frames.html#data-frames-in-action-exploring-information-about-the-united-states"><i class="fa fa-check"></i><b>3.1.3</b> Data Frames in action: exploring information about the United States</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-frames.html"><a href="data-frames.html#creating-data-frames-building-your-database-for-the-move"><i class="fa fa-check"></i><b>3.2</b> Creating Data Frames: Building your database for the move</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="data-frames.html"><a href="data-frames.html#importing-data-from-files-csv-excel"><i class="fa fa-check"></i><b>3.2.1</b> Importing data from files: CSV, Excel</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-frames.html"><a href="data-frames.html#creating-data-frames-manually"><i class="fa fa-check"></i><b>3.2.2</b> Creating data frames manually</a></li>
<li class="chapter" data-level="3.2.3" data-path="data-frames.html"><a href="data-frames.html#examples"><i class="fa fa-check"></i><b>3.2.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-frames.html"><a href="data-frames.html#exploring-data-frames-discovering-the-secrets-of-your-data"><i class="fa fa-check"></i><b>3.3</b> Exploring Data Frames: Discovering the secrets of your data</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="data-frames.html"><a href="data-frames.html#accessing-rows-columns-and-cells"><i class="fa fa-check"></i><b>3.3.1</b> Accessing rows, columns, and cells</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-frames.html"><a href="data-frames.html#functions-for-exploring-data-frames"><i class="fa fa-check"></i><b>3.3.2</b> Functions for exploring data frames</a></li>
<li class="chapter" data-level="3.3.3" data-path="data-frames.html"><a href="data-frames.html#examples-exploring-data-frames-with-move-information"><i class="fa fa-check"></i><b>3.3.3</b> Examples: exploring data frames with move information</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-frames.html"><a href="data-frames.html#manipulating-data-frames-transforming-your-data"><i class="fa fa-check"></i><b>3.4</b> Manipulating Data Frames: Transforming your data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="data-frames.html"><a href="data-frames.html#introduction-to-the-pipeline-operator"><i class="fa fa-check"></i><b>3.4.1</b> Introduction to the pipeline operator (<code>|&gt;</code>)</a></li>
<li class="chapter" data-level="3.4.2" data-path="data-frames.html"><a href="data-frames.html#transforming-a-table-with-mutate"><i class="fa fa-check"></i><b>3.4.2</b> Transforming a table with <code>mutate()</code></a></li>
<li class="chapter" data-level="3.4.3" data-path="data-frames.html"><a href="data-frames.html#filtering-data-selecting-cities-that-interest-you"><i class="fa fa-check"></i><b>3.4.3</b> Filtering data: selecting cities that interest you</a></li>
<li class="chapter" data-level="3.4.4" data-path="data-frames.html"><a href="data-frames.html#sorting-data-finding-the-safest-cities"><i class="fa fa-check"></i><b>3.4.4</b> Sorting data: finding the safest cities</a></li>
<li class="chapter" data-level="3.4.5" data-path="data-frames.html"><a href="data-frames.html#aggregating-and-summarizing-data-obtaining-general-overview"><i class="fa fa-check"></i><b>3.4.5</b> Aggregating and summarizing data: obtaining general overview</a></li>
<li class="chapter" data-level="3.4.6" data-path="data-frames.html"><a href="data-frames.html#joining-data-frames-combining-information"><i class="fa fa-check"></i><b>3.4.6</b> Joining data frames: combining information</a></li>
<li class="chapter" data-level="3.4.7" data-path="data-frames.html"><a href="data-frames.html#examples-1"><i class="fa fa-check"></i><b>3.4.7</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="data-frames.html"><a href="data-frames.html#exercises-2"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
<li class="chapter" data-level="3.6" data-path="data-frames.html"><a href="data-frames.html#data-frames-in-plots"><i class="fa fa-check"></i><b>3.6</b> Data frames in plots</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="data-frames.html"><a href="data-frames.html#scatter-plots"><i class="fa fa-check"></i><b>3.6.1</b> Scatter plots</a></li>
<li class="chapter" data-level="3.6.2" data-path="data-frames.html"><a href="data-frames.html#histograms"><i class="fa fa-check"></i><b>3.6.2</b> Histograms</a></li>
<li class="chapter" data-level="3.6.3" data-path="data-frames.html"><a href="data-frames.html#box-plot"><i class="fa fa-check"></i><b>3.6.3</b> Box plot</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="data-frames.html"><a href="data-frames.html#data-interpretation"><i class="fa fa-check"></i><b>3.7</b> Data interpretation</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="data-frames.html"><a href="data-frames.html#quartiles"><i class="fa fa-check"></i><b>3.7.1</b> Quartiles</a></li>
<li class="chapter" data-level="3.7.2" data-path="data-frames.html"><a href="data-frames.html#interpretation-of-box-plot"><i class="fa fa-check"></i><b>3.7.2</b> Interpretation of box plot</a></li>
<li class="chapter" data-level="3.7.3" data-path="data-frames.html"><a href="data-frames.html#examples-2"><i class="fa fa-check"></i><b>3.7.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="data-frames.html"><a href="data-frames.html#exercises-3"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="advanced-techniques.html"><a href="advanced-techniques.html"><i class="fa fa-check"></i><b>4</b> Advanced Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="advanced-techniques.html"><a href="advanced-techniques.html#metaprogramming-writing-code-that-writes-code"><i class="fa fa-check"></i><b>4.1</b> Metaprogramming: writing code that writes code</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="advanced-techniques.html"><a href="advanced-techniques.html#manipulating-expressions-the-art-of-sculpting-code"><i class="fa fa-check"></i><b>4.1.1</b> Manipulating expressions: The art of sculpting code</a></li>
<li class="chapter" data-level="4.1.2" data-path="advanced-techniques.html"><a href="advanced-techniques.html#examples-3"><i class="fa fa-check"></i><b>4.1.2</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="advanced-techniques.html"><a href="advanced-techniques.html#functional-programming-a-new-paradigm"><i class="fa fa-check"></i><b>4.2</b> Functional programming: a new paradigm</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="advanced-techniques.html"><a href="advanced-techniques.html#basic-principles-of-functional-programming"><i class="fa fa-check"></i><b>4.2.1</b> Basic principles of functional programming</a></li>
<li class="chapter" data-level="4.2.2" data-path="advanced-techniques.html"><a href="advanced-techniques.html#higher-order-functions-in-r"><i class="fa fa-check"></i><b>4.2.2</b> Higher-order functions in R</a></li>
<li class="chapter" data-level="4.2.3" data-path="advanced-techniques.html"><a href="advanced-techniques.html#examples-4"><i class="fa fa-check"></i><b>4.2.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="advanced-techniques.html"><a href="advanced-techniques.html#r6-the-future-of-oop-in-r"><i class="fa fa-check"></i><b>4.3</b> R6: The future of OOP in R</a></li>
<li class="chapter" data-level="4.4" data-path="advanced-techniques.html"><a href="advanced-techniques.html#exercises-4"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Data Visualization and Summarization</b></span></li>
<li class="chapter" data-level="5" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html"><i class="fa fa-check"></i><b>5</b> Ggplot and dplyr</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#creating-the-ggplot-object"><i class="fa fa-check"></i><b>5.1</b> Creating the ggplot object</a></li>
<li class="chapter" data-level="5.2" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#aesthetic-mapping-layer"><i class="fa fa-check"></i><b>5.2</b> Aesthetic mapping layer</a></li>
<li class="chapter" data-level="5.3" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#geoms-layer"><i class="fa fa-check"></i><b>5.3</b> Geoms layer</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#tweaking-aes-and-geoms"><i class="fa fa-check"></i><b>5.3.1</b> Tweaking aes and geoms</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#scale-layer"><i class="fa fa-check"></i><b>5.4</b> Scale layer</a></li>
<li class="chapter" data-level="5.5" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#label-title-and-legend-layer"><i class="fa fa-check"></i><b>5.5</b> Label, title and legend layer</a></li>
<li class="chapter" data-level="5.6" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#reference-lines"><i class="fa fa-check"></i><b>5.6</b> Reference lines</a></li>
<li class="chapter" data-level="5.7" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#changing-the-plot-style"><i class="fa fa-check"></i><b>5.7</b> Changing the plot style</a></li>
<li class="chapter" data-level="5.8" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#saving-plots"><i class="fa fa-check"></i><b>5.8</b> Saving plots</a></li>
<li class="chapter" data-level="5.9" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#summarizing-data-with-dplyr"><i class="fa fa-check"></i><b>5.9</b> Summarizing data with dplyr</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#summarize-function"><i class="fa fa-check"></i><b>5.9.1</b> Summarize function</a></li>
<li class="chapter" data-level="5.9.2" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#group-by-function"><i class="fa fa-check"></i><b>5.9.2</b> Group By Function</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#exercises-5"><i class="fa fa-check"></i><b>5.10</b> Exercises</a></li>
<li class="chapter" data-level="5.11" data-path="ggplot-and-dplyr.html"><a href="ggplot-and-dplyr.html#key-takeaways"><i class="fa fa-check"></i><b>5.11</b> Key Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gapminder.html"><a href="gapminder.html"><i class="fa fa-check"></i><b>6</b> Gapminder</a>
<ul>
<li class="chapter" data-level="6.1" data-path="gapminder.html"><a href="gapminder.html#initial-gapminder-plots"><i class="fa fa-check"></i><b>6.1</b> Initial gapminder plots</a></li>
<li class="chapter" data-level="6.2" data-path="gapminder.html"><a href="gapminder.html#facets"><i class="fa fa-check"></i><b>6.2</b> Facets</a></li>
<li class="chapter" data-level="6.3" data-path="gapminder.html"><a href="gapminder.html#time-series"><i class="fa fa-check"></i><b>6.3</b> Time series</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="gapminder.html"><a href="gapminder.html#individual-time-series"><i class="fa fa-check"></i><b>6.3.1</b> Individual time series</a></li>
<li class="chapter" data-level="6.3.2" data-path="gapminder.html"><a href="gapminder.html#multiple-time-series"><i class="fa fa-check"></i><b>6.3.2</b> Multiple time series</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="gapminder.html"><a href="gapminder.html#exercises-6"><i class="fa fa-check"></i><b>6.4</b> Exercises</a></li>
<li class="chapter" data-level="6.5" data-path="gapminder.html"><a href="gapminder.html#histograms-with-ggplot"><i class="fa fa-check"></i><b>6.5</b> Histograms with ggplot</a></li>
<li class="chapter" data-level="6.6" data-path="gapminder.html"><a href="gapminder.html#box-plots-with-ggplot"><i class="fa fa-check"></i><b>6.6</b> Box plots with ggplot</a></li>
<li class="chapter" data-level="6.7" data-path="gapminder.html"><a href="gapminder.html#comparison-of-distributions"><i class="fa fa-check"></i><b>6.7</b> Comparison of distributions</a></li>
<li class="chapter" data-level="6.8" data-path="gapminder.html"><a href="gapminder.html#exercises-7"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
<li class="chapter" data-level="6.9" data-path="gapminder.html"><a href="gapminder.html#key-takeaways-1"><i class="fa fa-check"></i><b>6.9</b> Key Takeaways</a></li>
</ul></li>
<li class="part"><span><b>III Statistics</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-probabilities.html"><a href="introduction-to-probabilities.html"><i class="fa fa-check"></i>Introduction to Probabilities</a></li>
<li class="chapter" data-level="7" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html"><i class="fa fa-check"></i><b>7</b> Discrete Probabilities</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#calculation-using-the-mathematical-definition"><i class="fa fa-check"></i><b>7.1</b> Calculation using the mathematical definition</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#monte-carlo-simulation-for-discrete-variables"><i class="fa fa-check"></i><b>7.2</b> Monte Carlo Simulation for Discrete Variables</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#other-functions-to-create-vectors"><i class="fa fa-check"></i><b>7.2.1</b> Other functions to create vectors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#exercises-8"><i class="fa fa-check"></i><b>7.3</b> Exercises</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#combinations-and-permutations"><i class="fa fa-check"></i><b>7.4</b> Combinations and Permutations</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#permutations"><i class="fa fa-check"></i><b>7.4.1</b> Permutations</a></li>
<li class="chapter" data-level="7.4.2" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#combinations"><i class="fa fa-check"></i><b>7.4.2</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#sufficient-experiments-with-monte-carlo-simulation"><i class="fa fa-check"></i><b>7.5</b> Sufficient Experiments with Monte Carlo Simulation</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#case-birthdays-in-classrooms"><i class="fa fa-check"></i><b>7.6</b> Case: Birthdays in Classrooms</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#exercises-9"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#integrative-exercise"><i class="fa fa-check"></i><b>7.8</b> Integrative Exercise</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="discrete-probabilities.html"><a href="discrete-probabilities.html#monty-hall-problem"><i class="fa fa-check"></i><b>7.8.1</b> Monty Hall Problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html"><i class="fa fa-check"></i><b>8</b> Continuous Probabilities</a>
<ul>
<li class="chapter" data-level="8.1" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#learning-objectives"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#empirical-distribution"><i class="fa fa-check"></i><b>8.2</b> Empirical Distribution</a></li>
<li class="chapter" data-level="8.3" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#theoretical-distribution"><i class="fa fa-check"></i><b>8.3</b> Theoretical Distribution</a></li>
<li class="chapter" data-level="8.4" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#key-takeaways-2"><i class="fa fa-check"></i><b>8.4</b> Key Takeaways</a></li>
<li class="chapter" data-level="8.5" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#exercises-10"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
<li class="chapter" data-level="8.6" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#monte-carlo-simulation-for-continuous-variables"><i class="fa fa-check"></i><b>8.6</b> Monte Carlo Simulation for Continuous Variables</a></li>
<li class="chapter" data-level="8.7" data-path="continuous-probabilities.html"><a href="continuous-probabilities.html#exercises-11"><i class="fa fa-check"></i><b>8.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>9</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="9.1" data-path="statistical-inference.html"><a href="statistical-inference.html#learning-objectives-1"><i class="fa fa-check"></i><b>9.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="9.2" data-path="statistical-inference.html"><a href="statistical-inference.html#expected-value"><i class="fa fa-check"></i><b>9.2</b> Expected Value</a></li>
<li class="chapter" data-level="9.3" data-path="statistical-inference.html"><a href="statistical-inference.html#central-limit-theorem"><i class="fa fa-check"></i><b>9.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="9.4" data-path="statistical-inference.html"><a href="statistical-inference.html#key-takeaways-3"><i class="fa fa-check"></i><b>9.4</b> Key Takeaways</a></li>
<li class="chapter" data-level="9.5" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-12"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
<li class="chapter" data-level="9.6" data-path="statistical-inference.html"><a href="statistical-inference.html#parameter-estimation-method"><i class="fa fa-check"></i><b>9.6</b> Parameter Estimation Method</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="statistical-inference.html"><a href="statistical-inference.html#margin-of-error"><i class="fa fa-check"></i><b>9.6.1</b> Margin of Error</a></li>
<li class="chapter" data-level="9.6.2" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>9.6.2</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="statistical-inference.html"><a href="statistical-inference.html#spread-estimation"><i class="fa fa-check"></i><b>9.7</b> Spread Estimation</a></li>
<li class="chapter" data-level="9.8" data-path="statistical-inference.html"><a href="statistical-inference.html#estimates-outside-election-polls"><i class="fa fa-check"></i><b>9.8</b> Estimates Outside Election Polls</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="statistical-inference.html"><a href="statistical-inference.html#example-estimating-average-height"><i class="fa fa-check"></i><b>9.8.1</b> Example: Estimating Average Height</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-13"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Data Wrangling</b></span></li>
<li class="chapter" data-level="" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="10" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html"><i class="fa fa-check"></i><b>10</b> Data import and consolidation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#importing-from-files"><i class="fa fa-check"></i><b>10.1</b> Importing from files</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#working-directory"><i class="fa fa-check"></i><b>10.1.1</b> Working Directory</a></li>
<li class="chapter" data-level="10.1.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#readr-and-readxl-packages"><i class="fa fa-check"></i><b>10.1.2</b> readr and readxl packages</a></li>
<li class="chapter" data-level="10.1.3" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#importing-files-from-the-internet"><i class="fa fa-check"></i><b>10.1.3</b> Importing files from the internet</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#tidy-data"><i class="fa fa-check"></i><b>10.2</b> Tidy data</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#transforming-to-tidy-data"><i class="fa fa-check"></i><b>10.2.1</b> Transforming to tidy data</a></li>
<li class="chapter" data-level="10.2.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#separate-function"><i class="fa fa-check"></i><b>10.2.2</b> separate function</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#exercises-14"><i class="fa fa-check"></i><b>10.3</b> Exercises</a></li>
<li class="chapter" data-level="10.4" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#joining-tables"><i class="fa fa-check"></i><b>10.4</b> Joining tables</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#join-functions"><i class="fa fa-check"></i><b>10.4.1</b> Join functions</a></li>
<li class="chapter" data-level="10.4.2" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#joining-without-a-common-identifier"><i class="fa fa-check"></i><b>10.4.2</b> Joining without a common identifier</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#web-scraping"><i class="fa fa-check"></i><b>10.5</b> Web Scraping</a></li>
<li class="chapter" data-level="10.6" data-path="data-import-and-consolidation.html"><a href="data-import-and-consolidation.html#exercises-15"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Machine learning</b></span></li>
<li class="chapter" data-level="" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="10.7" data-path="introduction-2.html"><a href="introduction-2.html#learning-objectives-2"><i class="fa fa-check"></i><b>10.7</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.8" data-path="introduction-2.html"><a href="introduction-2.html#chapter-structure"><i class="fa fa-check"></i><b>10.8</b> Chapter Structure</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>11</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="11.1" data-path="supervised-learning.html"><a href="supervised-learning.html#classification-and-regression"><i class="fa fa-check"></i><b>11.1</b> Classification and Regression</a></li>
<li class="chapter" data-level="11.2" data-path="supervised-learning.html"><a href="supervised-learning.html#knn-k-nearest-neighbors"><i class="fa fa-check"></i><b>11.2</b> kNN: k-Nearest Neighbors</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="supervised-learning.html"><a href="supervised-learning.html#two-variables-as-input"><i class="fa fa-check"></i><b>11.2.1</b> Two variables as input</a></li>
<li class="chapter" data-level="11.2.2" data-path="supervised-learning.html"><a href="supervised-learning.html#multiple-variables-as-input"><i class="fa fa-check"></i><b>11.2.2</b> Multiple variables as input</a></li>
<li class="chapter" data-level="11.2.3" data-path="supervised-learning.html"><a href="supervised-learning.html#diverse-values-of-k"><i class="fa fa-check"></i><b>11.2.3</b> Diverse values of k</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="supervised-learning.html"><a href="supervised-learning.html#tidymodels-framework"><i class="fa fa-check"></i><b>11.3</b> tidymodels Framework</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="supervised-learning.html"><a href="supervised-learning.html#creation-of-training-and-test-data"><i class="fa fa-check"></i><b>11.3.1</b> Creation of training and test data</a></li>
<li class="chapter" data-level="11.3.2" data-path="supervised-learning.html"><a href="supervised-learning.html#training-our-prediction-algorithm"><i class="fa fa-check"></i><b>11.3.2</b> Training our prediction algorithm</a></li>
<li class="chapter" data-level="11.3.3" data-path="supervised-learning.html"><a href="supervised-learning.html#data-pre-processing-with-recipes"><i class="fa fa-check"></i><b>11.3.3</b> Data Pre-processing with Recipes</a></li>
<li class="chapter" data-level="11.3.4" data-path="supervised-learning.html"><a href="supervised-learning.html#creating-a-workflow"><i class="fa fa-check"></i><b>11.3.4</b> Creating a Workflow</a></li>
<li class="chapter" data-level="11.3.5" data-path="supervised-learning.html"><a href="supervised-learning.html#parameter-tuning-with-cross-validation"><i class="fa fa-check"></i><b>11.3.5</b> Parameter Tuning with Cross-Validation</a></li>
<li class="chapter" data-level="11.3.6" data-path="supervised-learning.html"><a href="supervised-learning.html#finalizing-the-model"><i class="fa fa-check"></i><b>11.3.6</b> Finalizing the Model</a></li>
<li class="chapter" data-level="11.3.7" data-path="supervised-learning.html"><a href="supervised-learning.html#testing-the-prediction-model"><i class="fa fa-check"></i><b>11.3.7</b> Testing the prediction model</a></li>
<li class="chapter" data-level="11.3.8" data-path="supervised-learning.html"><a href="supervised-learning.html#model-evaluation-with-yardstick"><i class="fa fa-check"></i><b>11.3.8</b> Model Evaluation with yardstick</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="supervised-learning.html"><a href="supervised-learning.html#confusion-matrix"><i class="fa fa-check"></i><b>11.4</b> Confusion Matrix</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="supervised-learning.html"><a href="supervised-learning.html#accuracy"><i class="fa fa-check"></i><b>11.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="11.4.2" data-path="supervised-learning.html"><a href="supervised-learning.html#sensitivity"><i class="fa fa-check"></i><b>11.4.2</b> Sensitivity</a></li>
<li class="chapter" data-level="11.4.3" data-path="supervised-learning.html"><a href="supervised-learning.html#specificity"><i class="fa fa-check"></i><b>11.4.3</b> Specificity</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="supervised-learning.html"><a href="supervised-learning.html#exercises-16"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
<li class="chapter" data-level="11.6" data-path="supervised-learning.html"><a href="supervised-learning.html#simple-linear-regression"><i class="fa fa-check"></i><b>11.6</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="11.7" data-path="supervised-learning.html"><a href="supervised-learning.html#multiple-linear-regression"><i class="fa fa-check"></i><b>11.7</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="11.8" data-path="supervised-learning.html"><a href="supervised-learning.html#standard-method-for-evaluating-accuracy"><i class="fa fa-check"></i><b>11.8</b> Standard Method for Evaluating Accuracy</a></li>
<li class="chapter" data-level="11.9" data-path="supervised-learning.html"><a href="supervised-learning.html#selection-of-the-most-optimal-model"><i class="fa fa-check"></i><b>11.9</b> Selection of the Most Optimal Model</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="supervised-learning.html"><a href="supervised-learning.html#k-nearest-neighbors-model"><i class="fa fa-check"></i><b>11.9.1</b> k-Nearest Neighbors Model</a></li>
<li class="chapter" data-level="11.9.2" data-path="supervised-learning.html"><a href="supervised-learning.html#generalized-linear-model---glm"><i class="fa fa-check"></i><b>11.9.2</b> Generalized Linear Model - GLM</a></li>
<li class="chapter" data-level="11.9.3" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forest-model"><i class="fa fa-check"></i><b>11.9.3</b> Random Forest Model</a></li>
<li class="chapter" data-level="11.9.4" data-path="supervised-learning.html"><a href="supervised-learning.html#support-vector-machine-model---svm"><i class="fa fa-check"></i><b>11.9.4</b> Support Vector Machine Model - SVM</a></li>
<li class="chapter" data-level="11.9.5" data-path="supervised-learning.html"><a href="supervised-learning.html#naive-bayes-model"><i class="fa fa-check"></i><b>11.9.5</b> Naive Bayes Model</a></li>
<li class="chapter" data-level="11.9.6" data-path="supervised-learning.html"><a href="supervised-learning.html#model-comparison"><i class="fa fa-check"></i><b>11.9.6</b> Model Comparison</a></li>
<li class="chapter" data-level="11.9.7" data-path="supervised-learning.html"><a href="supervised-learning.html#predicting-using-the-best-model"><i class="fa fa-check"></i><b>11.9.7</b> Predicting using the best model</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="supervised-learning.html"><a href="supervised-learning.html#exercises-17"><i class="fa fa-check"></i><b>11.10</b> Exercises</a></li>
<li class="chapter" data-level="11.11" data-path="supervised-learning.html"><a href="supervised-learning.html#ethics-bias-in-algorithmic-decision-making"><i class="fa fa-check"></i><b>11.11</b> Ethics: Bias in Algorithmic Decision Making</a>
<ul>
<li class="chapter" data-level="11.11.1" data-path="supervised-learning.html"><a href="supervised-learning.html#the-risk-of-proxy-variables"><i class="fa fa-check"></i><b>11.11.1</b> The Risk of Proxy Variables</a></li>
<li class="chapter" data-level="11.11.2" data-path="supervised-learning.html"><a href="supervised-learning.html#feedback-loops"><i class="fa fa-check"></i><b>11.11.2</b> Feedback Loops</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>12</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#learning-objectives-3"><i class="fa fa-check"></i><b>12.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="12.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#applications-of-unsupervised-learning"><i class="fa fa-check"></i><b>12.2</b> Applications of Unsupervised Learning</a></li>
<li class="chapter" data-level="12.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-clustering"><i class="fa fa-check"></i><b>12.3</b> K-Means Clustering</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-with-k-2"><i class="fa fa-check"></i><b>12.3.1</b> Clustering with k = 2</a></li>
<li class="chapter" data-level="12.3.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-with-k-3"><i class="fa fa-check"></i><b>12.3.2</b> Clustering with k &gt;= 3</a></li>
<li class="chapter" data-level="12.3.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#determination-of-optimal-clusters"><i class="fa fa-check"></i><b>12.3.3</b> Determination of Optimal Clusters</a></li>
<li class="chapter" data-level="12.3.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-for-more-than-2-variables"><i class="fa fa-check"></i><b>12.3.4</b> k-means for more than 2 variables</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#hierarchical-clustering"><i class="fa fa-check"></i><b>12.4</b> Hierarchical Clustering</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-with-two-variables"><i class="fa fa-check"></i><b>12.4.1</b> Clustering with two variables</a></li>
<li class="chapter" data-level="12.4.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#determination-of-optimal-clusters-1"><i class="fa fa-check"></i><b>12.4.2</b> Determination of Optimal Clusters</a></li>
<li class="chapter" data-level="12.4.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#obtain-the-grouping"><i class="fa fa-check"></i><b>12.4.3</b> Obtain the grouping</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#dimensionality-reduction"><i class="fa fa-check"></i><b>12.5</b> Dimensionality Reduction</a></li>
<li class="chapter" data-level="12.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#exercises-18"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html"><i class="fa fa-check"></i><b>13</b> String processing and text mining</a>
<ul>
<li class="chapter" data-level="13.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#basic-functions"><i class="fa fa-check"></i><b>13.1</b> Basic functions</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#replacing-characters"><i class="fa fa-check"></i><b>13.1.1</b> Replacing characters</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#regular-expressions"><i class="fa fa-check"></i><b>13.2</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#alternation"><i class="fa fa-check"></i><b>13.2.1</b> Alternation</a></li>
<li class="chapter" data-level="13.2.2" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#anchoring"><i class="fa fa-check"></i><b>13.2.2</b> Anchoring</a></li>
<li class="chapter" data-level="13.2.3" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#repetitions"><i class="fa fa-check"></i><b>13.2.3</b> Repetitions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#from-strings-to-dates"><i class="fa fa-check"></i><b>13.3</b> From strings to dates</a></li>
<li class="chapter" data-level="13.4" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#exercises-19"><i class="fa fa-check"></i><b>13.4</b> Exercises</a></li>
<li class="chapter" data-level="13.5" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#text-mining-using-tidy-data"><i class="fa fa-check"></i><b>13.5</b> Text Mining using Tidy Data</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#importing-data-and-tokenization"><i class="fa fa-check"></i><b>13.5.1</b> Importing data and Tokenization</a></li>
<li class="chapter" data-level="13.5.2" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#text-cleaning-and-tokenization"><i class="fa fa-check"></i><b>13.5.2</b> Text cleaning and Tokenization</a></li>
<li class="chapter" data-level="13.5.3" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#word-cloud"><i class="fa fa-check"></i><b>13.5.3</b> Word Cloud</a></li>
<li class="chapter" data-level="13.5.4" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#word-frequency-plot"><i class="fa fa-check"></i><b>13.5.4</b> Word Frequency Plot</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#sentiment-analysis"><i class="fa fa-check"></i><b>13.6</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="13.7" data-path="string-processing-and-text-mining.html"><a href="string-processing-and-text-mining.html#exercises-20"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Generative AI</b></span></li>
<li class="chapter" data-level="14" data-path="genai-intro.html"><a href="genai-intro.html"><i class="fa fa-check"></i><b>14</b> Data Science in the Age of AI</a>
<ul>
<li class="chapter" data-level="14.1" data-path="genai-intro.html"><a href="genai-intro.html#what-is-a-large-language-model"><i class="fa fa-check"></i><b>14.1</b> What is a Large Language Model?</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="genai-intro.html"><a href="genai-intro.html#its-all-about-probability"><i class="fa fa-check"></i><b>14.1.1</b> It’s all about Probability</a></li>
<li class="chapter" data-level="14.1.2" data-path="genai-intro.html"><a href="genai-intro.html#tokens-vs.-words"><i class="fa fa-check"></i><b>14.1.2</b> Tokens vs. Words</a></li>
<li class="chapter" data-level="14.1.3" data-path="genai-intro.html"><a href="genai-intro.html#temperature-controlling-creativity"><i class="fa fa-check"></i><b>14.1.3</b> Temperature: Controlling Creativity</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="genai-intro.html"><a href="genai-intro.html#setting-up-your-ai-environment"><i class="fa fa-check"></i><b>14.2</b> Setting Up Your AI Environment</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="genai-intro.html"><a href="genai-intro.html#the-solution-local-llms"><i class="fa fa-check"></i><b>14.2.1</b> The Solution: Local LLMs</a></li>
<li class="chapter" data-level="14.2.2" data-path="genai-intro.html"><a href="genai-intro.html#the-.renviron-file"><i class="fa fa-check"></i><b>14.2.2</b> The <code>.Renviron</code> File</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="genai-intro.html"><a href="genai-intro.html#ai-as-the-pair-programmer"><i class="fa fa-check"></i><b>14.3</b> AI as the “Pair Programmer”</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="genai-intro.html"><a href="genai-intro.html#the-great-refactorer"><i class="fa fa-check"></i><b>14.3.1</b> The Great Refactorer</a></li>
<li class="chapter" data-level="14.3.2" data-path="genai-intro.html"><a href="genai-intro.html#the-translator"><i class="fa fa-check"></i><b>14.3.2</b> The Translator</a></li>
<li class="chapter" data-level="14.3.3" data-path="genai-intro.html"><a href="genai-intro.html#pro-tip-prompt-engineering-101"><i class="fa fa-check"></i><b>14.3.3</b> Pro Tip: Prompt Engineering 101</a></li>
<li class="chapter" data-level="14.3.4" data-path="genai-intro.html"><a href="genai-intro.html#the-regex-master"><i class="fa fa-check"></i><b>14.3.4</b> The Regex Master</a></li>
<li class="chapter" data-level="14.3.5" data-path="genai-intro.html"><a href="genai-intro.html#the-error-decoder"><i class="fa fa-check"></i><b>14.3.5</b> The Error Decoder</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="genai-intro.html"><a href="genai-intro.html#the-risks-hallucinations"><i class="fa fa-check"></i><b>14.4</b> The Risks: Hallucinations</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="genai-intro.html"><a href="genai-intro.html#the-package-hallucination"><i class="fa fa-check"></i><b>14.4.1</b> The “Package” Hallucination</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="genai-intro.html"><a href="genai-intro.html#building-a-robust-request"><i class="fa fa-check"></i><b>14.5</b> Building a Robust Request</a></li>
<li class="chapter" data-level="14.6" data-path="genai-intro.html"><a href="genai-intro.html#the-holy-grail-structured-data-extraction"><i class="fa fa-check"></i><b>14.6</b> The Holy Grail: Structured Data extraction</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="genai-intro.html"><a href="genai-intro.html#forcing-json-output"><i class="fa fa-check"></i><b>14.6.1</b> Forcing JSON Output</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="genai-intro.html"><a href="genai-intro.html#batch-processing-the-purrr-workflow"><i class="fa fa-check"></i><b>14.7</b> Batch Processing: The <code>purrr</code> Workflow</a></li>
<li class="chapter" data-level="14.8" data-path="genai-intro.html"><a href="genai-intro.html#summary"><i class="fa fa-check"></i><b>14.8</b> Summary</a></li>
<li class="chapter" data-level="14.9" data-path="genai-intro.html"><a href="genai-intro.html#beyond-generation-embeddings"><i class="fa fa-check"></i><b>14.9</b> Beyond Generation: Embeddings</a>
<ul>
<li class="chapter" data-level="14.9.1" data-path="genai-intro.html"><a href="genai-intro.html#r-implementation"><i class="fa fa-check"></i><b>14.9.1</b> R Implementation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="genai-embeddings.html"><a href="genai-embeddings.html"><i class="fa fa-check"></i><b>15</b> Text Analysis with Embeddings</a>
<ul>
<li class="chapter" data-level="15.1" data-path="genai-embeddings.html"><a href="genai-embeddings.html#beyond-bag-of-words"><i class="fa fa-check"></i><b>15.1</b> Beyond Bag-of-Words</a></li>
<li class="chapter" data-level="15.2" data-path="genai-embeddings.html"><a href="genai-embeddings.html#what-is-an-embedding"><i class="fa fa-check"></i><b>15.2</b> What is an Embedding?</a></li>
<li class="chapter" data-level="15.3" data-path="genai-embeddings.html"><a href="genai-embeddings.html#getting-embeddings-in-r"><i class="fa fa-check"></i><b>15.3</b> Getting Embeddings in R</a></li>
<li class="chapter" data-level="15.4" data-path="genai-embeddings.html"><a href="genai-embeddings.html#visualizing-meaning-dimensionality-reduction"><i class="fa fa-check"></i><b>15.4</b> Visualizing Meaning (Dimensionality Reduction)</a></li>
<li class="chapter" data-level="15.5" data-path="genai-embeddings.html"><a href="genai-embeddings.html#building-a-semantic-search-engine"><i class="fa fa-check"></i><b>15.5</b> Building a Semantic Search Engine</a></li>
<li class="chapter" data-level="15.6" data-path="genai-embeddings.html"><a href="genai-embeddings.html#summary-the-ai-workflow"><i class="fa fa-check"></i><b>15.6</b> Summary: The AI Workflow</a></li>
</ul></li>
<li class="part"><span><b>VII Real Cases</b></span></li>
<li class="chapter" data-level="" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="16" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html"><i class="fa fa-check"></i><b>16</b> Case Study: Real Estate Market Analysis</a>
<ul>
<li class="chapter" data-level="16.1" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#objectives"><i class="fa fa-check"></i><b>16.1</b> Objectives</a></li>
<li class="chapter" data-level="16.2" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#loading-libraries"><i class="fa fa-check"></i><b>16.2</b> Loading Libraries</a></li>
<li class="chapter" data-level="16.3" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#exploring-the-data"><i class="fa fa-check"></i><b>16.3</b> Exploring the Data</a></li>
<li class="chapter" data-level="16.4" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#data-cleaning"><i class="fa fa-check"></i><b>16.4</b> Data Cleaning</a></li>
<li class="chapter" data-level="16.5" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#exploratory-analysis"><i class="fa fa-check"></i><b>16.5</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#market-volume-over-time"><i class="fa fa-check"></i><b>16.5.1</b> Market Volume Over Time</a></li>
<li class="chapter" data-level="16.5.2" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#comparing-cities"><i class="fa fa-check"></i><b>16.5.2</b> Comparing Cities</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#creating-indicators"><i class="fa fa-check"></i><b>16.6</b> Creating Indicators</a></li>
<li class="chapter" data-level="16.7" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#try-it-yourself"><i class="fa fa-check"></i><b>16.7</b> Try It Yourself</a></li>
<li class="chapter" data-level="16.8" data-path="case-study-real-estate-market-analysis.html"><a href="case-study-real-estate-market-analysis.html#conclusions"><i class="fa fa-check"></i><b>16.8</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html"><i class="fa fa-check"></i><b>17</b> Google Analytics from R</a>
<ul>
<li class="chapter" data-level="17.1" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#problem"><i class="fa fa-check"></i><b>17.1</b> Problem</a></li>
<li class="chapter" data-level="17.2" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#access-to-data"><i class="fa fa-check"></i><b>17.2</b> Access to data</a></li>
<li class="chapter" data-level="17.3" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#visualization"><i class="fa fa-check"></i><b>17.3</b> Visualization</a></li>
<li class="chapter" data-level="17.4" data-path="google-analytics-from-r.html"><a href="google-analytics-from-r.html#conclusion"><i class="fa fa-check"></i><b>17.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ethics-checklist.html"><a href="ethics-checklist.html"><i class="fa fa-check"></i><b>18</b> Appendix A: Responsible AI Checklist</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ethics-checklist.html"><a href="ethics-checklist.html#data-quality-lineage"><i class="fa fa-check"></i><b>18.1</b> Data Quality &amp; Lineage</a></li>
<li class="chapter" data-level="18.2" data-path="ethics-checklist.html"><a href="ethics-checklist.html#fairness-bias"><i class="fa fa-check"></i><b>18.2</b> Fairness &amp; Bias</a></li>
<li class="chapter" data-level="18.3" data-path="ethics-checklist.html"><a href="ethics-checklist.html#transparency-explainability"><i class="fa fa-check"></i><b>18.3</b> Transparency &amp; Explainability</a></li>
<li class="chapter" data-level="18.4" data-path="ethics-checklist.html"><a href="ethics-checklist.html#reproducibility-integrity"><i class="fa fa-check"></i><b>18.4</b> Reproducibility &amp; Integrity</a></li>
<li class="chapter" data-level="18.5" data-path="ethics-checklist.html"><a href="ethics-checklist.html#genai-specifics"><i class="fa fa-check"></i><b>18.5</b> GenAI Specifics</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="r6-intro.html"><a href="r6-intro.html"><i class="fa fa-check"></i><b>19</b> Appendix B: Object Oriented Programming with R6</a>
<ul>
<li class="chapter" data-level="19.1" data-path="r6-intro.html"><a href="r6-intro.html#the-r6-package-classes-methods-encapsulation-and-inheritance"><i class="fa fa-check"></i><b>19.1</b> The R6 package: Classes, methods, encapsulation, and inheritance</a></li>
<li class="chapter" data-level="19.2" data-path="r6-intro.html"><a href="r6-intro.html#exercises-21"><i class="fa fa-check"></i><b>19.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-learning" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Supervised Learning<a href="supervised-learning.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>To understand supervised learning intuitively, we can compare it to how humans learn from examples.</p>
<p>Consider a doctor diagnosing patients. The doctor has <strong>trained</strong> for years using textbooks and case studies where the symptoms (inputs) and the correct diagnosis (output) were known. During their residency, they <strong>test</strong> their knowledge under the supervision of experienced mentors. Finally, once licensed, they <strong>apply</strong> this knowledge to diagnose new patients where the outcome is unknown.</p>
<p>This is an example of <strong>supervised learning</strong>.
This process mirrors <strong>supervised learning</strong>. First, the model undergoes a <strong>Training</strong> phase, learning from labeled data (like symptoms and their corresponding diagnoses). Next, during <strong>Testing</strong>, it is evaluated on new, unseen cases where the outcome is already known to verify its accuracy. finally, the model enters the <strong>Prediction</strong> phase, where it applies its learned knowledge to real-world data to generate diagnoses (predictions) for unknown cases.</p>
<p>In machine learning terms:
In machine learning terms, we have <strong>Inputs</strong> (features or predictors) which are the data points used to make a prediction, and <strong>Outputs</strong> (target or response), which are the values we aim to predict. The ultimate <strong>Goal</strong> is to learn the mathematical relationship between these inputs and outputs to accurately forecast outcomes for future data.</p>
<blockquote>
<p>[!TIP]
<strong>Key Terminology</strong>
<strong>Key Terminology</strong>
In supervised learning, the <strong>Input</strong> (or Feature/Independent Variable) refers to the data used to make a prediction, such as patient symptoms or house characteristics. The <strong>Output</strong> (or Target/Dependent Variable) is the value we want to predict, like a medical diagnosis or a house price. We rely on <strong>Labels</strong>, which are the known “answers” in our training data, to teach the model.</p>
</blockquote>
<p>Common applications include:
Common applications of these techniques include <strong>Spam Detection</strong> (classifying emails as “Spam” or “Not Spam”), <strong>Credit Scoring</strong> (predicting the likelihood of a customer repaying a loan), and <strong>House Price Prediction</strong> (estimating a property’s value based on its location and size).</p>
<div id="classification-and-regression" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Classification and Regression<a href="supervised-learning.html#classification-and-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We divide supervised learning into two main types based on the target variable:</p>
<p>We divide supervised learning into two main types based on the nature of the target variable. <strong>Classification</strong> is used when the target is a discrete category, such as determining if an email is spam (Yes/No) or predicting which product a customer will buy (A, B, or C). <strong>Regression</strong>, on the other hand, is used when the target is a continuous number, like estimating the price of a house or forecasting the number of units to be sold next month.</p>
<p>In the following sections, we will learn algorithms for both tasks.</p>
</div>
<div id="knn-k-nearest-neighbors" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> kNN: k-Nearest Neighbors<a href="supervised-learning.html#knn-k-nearest-neighbors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s start with a simple but very useful <strong>classification</strong> algorithm, the k-Nearest Neighbors algorithm (<em>kNN</em>).</p>
<div id="two-variables-as-input" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Two variables as input<a href="supervised-learning.html#two-variables-as-input" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s start by understanding it visually. Imagine that we have two variables as <em>input</em> and as <em>output</em> it gives us whether it is Red Class or Blue Class. This data is our training data.</p>
<blockquote>
<p>[!NOTE]
<strong>When to use kNN?</strong>
kNN is excellent for small datasets with few dimensions (variables) because it is simple and explains non-linear patterns well. However, it becomes very slow and less accurate as the dataset grows in size or number of variables (the “curse of dimensionality”).</p>
</blockquote>
<p><img src="_assets/images/06-machine-learning/kNN-train.png" alt="Training data points on a 2D plane with red and blue class labels" width="80%" style="display: block; margin: auto;" /></p>
<p>Now that we have our training data, we will start using the test data. As we want to predict the class, the <em>output</em>, we will see how one of these data points would look visually and paint it yellow. Next, we calculate the distance between this point and the other data points.</p>
<p><img src="_assets/images/06-machine-learning/kNN-test.png" alt="Test point shown in yellow with distance lines to nearby training data points" width="80%" style="display: block; margin: auto;" /></p>
<p>We have traced only some distances, but we could do it with all of them. For this example, we will take the <strong>k = 3</strong> nearest neighbors. Why 3? It is common to pick an odd number to avoid ties (where the vote is 50/50).</p>
<p><img src="_assets/images/06-machine-learning/kNN-classify.png" alt="k-NN classification showing 3 nearest neighbors (2 red, 1 blue), classifying test point as red" width="80%" style="display: block; margin: auto;" /></p>
<p>We notice that if we focus only on the 3 nearest neighbors, there are more reds than blues, so our prediction will be that this point must be Class R (red).</p>
<p>Calculating the distance on a Cartesian plane is relatively simple, we only have variables as input: on the x-axis and y-axis. However, the same logic can be taken to more variables.</p>
</div>
<div id="multiple-variables-as-input" class="section level3 hasAnchor" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Multiple variables as input<a href="supervised-learning.html#multiple-variables-as-input" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s see how it would be with 4 variables as input. We are going to work again with the <code>iris</code> data frame, which, as we will recall, has 4 attributes of a plant and the last column is the species to which it belongs.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="supervised-learning.html#cb430-1" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb430-2"><a href="supervised-learning.html#cb430-2" tabindex="-1"></a></span>
<span id="cb430-3"><a href="supervised-learning.html#cb430-3" tabindex="-1"></a>iris <span class="sc">|&gt;</span> </span>
<span id="cb430-4"><a href="supervised-learning.html#cb430-4" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb430-5"><a href="supervised-learning.html#cb430-5" tabindex="-1"></a><span class="co">#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width Species</span></span>
<span id="cb430-6"><a href="supervised-learning.html#cb430-6" tabindex="-1"></a><span class="co">#&gt; 1           5.1         3.5          1.4         0.2  setosa</span></span>
<span id="cb430-7"><a href="supervised-learning.html#cb430-7" tabindex="-1"></a><span class="co">#&gt; 2           4.9         3.0          1.4         0.2  setosa</span></span>
<span id="cb430-8"><a href="supervised-learning.html#cb430-8" tabindex="-1"></a><span class="co">#&gt; 3           4.7         3.2          1.3         0.2  setosa</span></span>
<span id="cb430-9"><a href="supervised-learning.html#cb430-9" tabindex="-1"></a><span class="co">#&gt; 4           4.6         3.1          1.5         0.2  setosa</span></span>
<span id="cb430-10"><a href="supervised-learning.html#cb430-10" tabindex="-1"></a><span class="co">#&gt; 5           5.0         3.6          1.4         0.2  setosa</span></span>
<span id="cb430-11"><a href="supervised-learning.html#cb430-11" tabindex="-1"></a><span class="co">#&gt; 6           5.4         3.9          1.7         0.4  setosa</span></span>
<span id="cb430-12"><a href="supervised-learning.html#cb430-12" tabindex="-1"></a><span class="co">#&gt; 7           4.6         3.4          1.4         0.3  setosa</span></span>
<span id="cb430-13"><a href="supervised-learning.html#cb430-13" tabindex="-1"></a><span class="co">#&gt; 8           5.0         3.4          1.5         0.2  setosa</span></span>
<span id="cb430-14"><a href="supervised-learning.html#cb430-14" tabindex="-1"></a><span class="co">#&gt; 9           4.4         2.9          1.4         0.2  setosa</span></span>
<span id="cb430-15"><a href="supervised-learning.html#cb430-15" tabindex="-1"></a><span class="co">#&gt; 10          4.9         3.1          1.5         0.1  setosa</span></span></code></pre></div>
<p>The idea is as follows, we will take training data, 50 data points. From this data, we have the 4 input attributes and the last column is the output, the species. We will use the kNN algorithm taking this training data as input to create our model. Then, with testing data, another 50 data points, we will test our model.</p>
<p>Let’s start by taking a random sample of 100 records and separate half for training and half for testing. Since we have 150 data points in our data frame, let’s take a sample of the indices. In this case, we are going to use the <code>set.seed(n)</code> function to force the random sample values to be the same always. Thus, we can all obtain the same results and the explanation in the book in these chapters is consistent with the results that each reader obtains. For a real exercise, we should not include that line. It is recommended to read the documentation <code>?set.seed()</code>.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="supervised-learning.html#cb431-1" tabindex="-1"></a><span class="co"># 28 is the author&#39;s birthday</span></span>
<span id="cb431-2"><a href="supervised-learning.html#cb431-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb431-3"><a href="supervised-learning.html#cb431-3" tabindex="-1"></a></span>
<span id="cb431-4"><a href="supervised-learning.html#cb431-4" tabindex="-1"></a>sample_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">150</span>, <span class="dv">100</span>)</span>
<span id="cb431-5"><a href="supervised-learning.html#cb431-5" tabindex="-1"></a></span>
<span id="cb431-6"><a href="supervised-learning.html#cb431-6" tabindex="-1"></a>train_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(sample_idx, <span class="dv">50</span>)</span>
<span id="cb431-7"><a href="supervised-learning.html#cb431-7" tabindex="-1"></a></span>
<span id="cb431-8"><a href="supervised-learning.html#cb431-8" tabindex="-1"></a>test_idx <span class="ot">&lt;-</span> sample_idx[<span class="sc">!</span>sample_idx <span class="sc">%in%</span> train_idx]</span></code></pre></div>
<p>Now that we have the indices we can build our training data and our test.</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="supervised-learning.html#cb432-1" tabindex="-1"></a>iris_train <span class="ot">&lt;-</span> iris[train_idx, ]</span>
<span id="cb432-2"><a href="supervised-learning.html#cb432-2" tabindex="-1"></a>iris_test <span class="ot">&lt;-</span> iris[test_idx, ]</span>
<span id="cb432-3"><a href="supervised-learning.html#cb432-3" tabindex="-1"></a></span>
<span id="cb432-4"><a href="supervised-learning.html#cb432-4" tabindex="-1"></a>iris_train_input <span class="ot">&lt;-</span> iris_train[, <span class="sc">-</span><span class="dv">5</span>]</span>
<span id="cb432-5"><a href="supervised-learning.html#cb432-5" tabindex="-1"></a>iris_train_output <span class="ot">&lt;-</span> iris_train[, <span class="dv">5</span>]</span>
<span id="cb432-6"><a href="supervised-learning.html#cb432-6" tabindex="-1"></a></span>
<span id="cb432-7"><a href="supervised-learning.html#cb432-7" tabindex="-1"></a>iris_test_input <span class="ot">&lt;-</span> iris_test[, <span class="sc">-</span><span class="dv">5</span>]</span>
<span id="cb432-8"><a href="supervised-learning.html#cb432-8" tabindex="-1"></a>iris_test_output <span class="ot">&lt;-</span> iris_test[, <span class="dv">5</span>]</span></code></pre></div>
<p>Although we could build the algorithms to calculate the minimum distances for each point, R provides us with libraries that facilitate the creation of these models. To do this, we will load the <code>class</code> library, which will allow us to execute kNN quickly.</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="supervised-learning.html#cb433-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;class&quot;</span>)</span>
<span id="cb433-2"><a href="supervised-learning.html#cb433-2" tabindex="-1"></a></span>
<span id="cb433-3"><a href="supervised-learning.html#cb433-3" tabindex="-1"></a><span class="fu">library</span>(class)</span></code></pre></div>
<p>This library provides us with the <code>knn()</code> function, which will take the training data to create the model and once the model is created it will take the test data to predict the <em>output</em> for our test data.</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="supervised-learning.html#cb434-1" tabindex="-1"></a>iris_test_output_kNN <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> iris_train_input, </span>
<span id="cb434-2"><a href="supervised-learning.html#cb434-2" tabindex="-1"></a>                       <span class="at">cl =</span> iris_train_output, </span>
<span id="cb434-3"><a href="supervised-learning.html#cb434-3" tabindex="-1"></a>                       <span class="at">test =</span> iris_test_input, </span>
<span id="cb434-4"><a href="supervised-learning.html#cb434-4" tabindex="-1"></a>                       <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb434-5"><a href="supervised-learning.html#cb434-5" tabindex="-1"></a></span>
<span id="cb434-6"><a href="supervised-learning.html#cb434-6" tabindex="-1"></a>iris_test_output_kNN</span>
<span id="cb434-7"><a href="supervised-learning.html#cb434-7" tabindex="-1"></a><span class="co">#&gt;  [1] versicolor versicolor versicolor versicolor setosa     versicolor</span></span>
<span id="cb434-8"><a href="supervised-learning.html#cb434-8" tabindex="-1"></a><span class="co">#&gt;  [7] virginica  virginica  virginica  virginica  versicolor versicolor</span></span>
<span id="cb434-9"><a href="supervised-learning.html#cb434-9" tabindex="-1"></a><span class="co">#&gt; [13] virginica  versicolor versicolor versicolor setosa     versicolor</span></span>
<span id="cb434-10"><a href="supervised-learning.html#cb434-10" tabindex="-1"></a><span class="co">#&gt; [19] versicolor virginica  virginica  setosa     versicolor versicolor</span></span>
<span id="cb434-11"><a href="supervised-learning.html#cb434-11" tabindex="-1"></a><span class="co">#&gt; [25] versicolor virginica  setosa     setosa     versicolor versicolor</span></span>
<span id="cb434-12"><a href="supervised-learning.html#cb434-12" tabindex="-1"></a><span class="co">#&gt; [31] virginica  setosa     setosa     virginica  virginica  setosa    </span></span>
<span id="cb434-13"><a href="supervised-learning.html#cb434-13" tabindex="-1"></a><span class="co">#&gt; [37] setosa     virginica  setosa     versicolor setosa     virginica </span></span>
<span id="cb434-14"><a href="supervised-learning.html#cb434-14" tabindex="-1"></a><span class="co">#&gt; [43] setosa     setosa     setosa     virginica  virginica  versicolor</span></span>
<span id="cb434-15"><a href="supervised-learning.html#cb434-15" tabindex="-1"></a><span class="co">#&gt; [49] virginica  versicolor</span></span>
<span id="cb434-16"><a href="supervised-learning.html#cb434-16" tabindex="-1"></a><span class="co">#&gt; Levels: setosa versicolor virginica</span></span></code></pre></div>
<p>Thus, the knn function throws us the prediction just by entering the training data as attributes, the test inputs, and how many nearest neighbors it will look for (k). And not only that, we can compare our prediction with the test <em>output</em> to see how <strong>accurate</strong> (<em>accuracy</em>) our model is. To do this, we calculate the percentage of correct predictions regarding the test <em>output</em>.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="supervised-learning.html#cb435-1" tabindex="-1"></a><span class="fu">mean</span>(iris_test_output_kNN <span class="sc">==</span> iris_test_output)</span>
<span id="cb435-2"><a href="supervised-learning.html#cb435-2" tabindex="-1"></a><span class="co">#&gt; [1] 0.94</span></span></code></pre></div>
<p>In addition, we can place a summary in a table, also known as a <strong>confusion matrix</strong>, to see how many predicted values were equal to the real ones using the <code>table()</code> function.</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="supervised-learning.html#cb436-1" tabindex="-1"></a><span class="fu">table</span>(iris_test_output_kNN, iris_test_output)</span>
<span id="cb436-2"><a href="supervised-learning.html#cb436-2" tabindex="-1"></a><span class="co">#&gt;                     iris_test_output</span></span>
<span id="cb436-3"><a href="supervised-learning.html#cb436-3" tabindex="-1"></a><span class="co">#&gt; iris_test_output_kNN setosa versicolor virginica</span></span>
<span id="cb436-4"><a href="supervised-learning.html#cb436-4" tabindex="-1"></a><span class="co">#&gt;           setosa         14          0         0</span></span>
<span id="cb436-5"><a href="supervised-learning.html#cb436-5" tabindex="-1"></a><span class="co">#&gt;           versicolor      0         18         2</span></span>
<span id="cb436-6"><a href="supervised-learning.html#cb436-6" tabindex="-1"></a><span class="co">#&gt;           virginica       0          1        15</span></span></code></pre></div>
<p>Let’s interpret this result cell by cell:</p>
<ol style="list-style-type: decimal">
<li>Our kNN model predicted 14 values as species “setosa” and it turns out that in our test the real value, <em>output</em>, was also setosa.</li>
<li>Our model predicted 20 as species versicolor. However, in the real-test data, of those 20, only 18 are versicolor and 2 are virginica.</li>
<li>Our model predicted 16 as species virginica. However, in the real-test data, of those 16, only 15 are virginica.</li>
</ol>
</div>
<div id="diverse-values-of-k" class="section level3 hasAnchor" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Diverse values of k<a href="supervised-learning.html#diverse-values-of-k" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So far we have only used a single value for k, 3 nearest neighbors. However, we could see the accuracy for different values of k. Since we have 50 values in our training data, we will see the hits taking a maximum of 50 nearest neighbors.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="supervised-learning.html#cb437-1" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">50</span></span>
<span id="cb437-2"><a href="supervised-learning.html#cb437-2" tabindex="-1"></a>result_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(k, <span class="at">precision =</span> <span class="dv">0</span>)</span>
<span id="cb437-3"><a href="supervised-learning.html#cb437-3" tabindex="-1"></a></span>
<span id="cb437-4"><a href="supervised-learning.html#cb437-4" tabindex="-1"></a><span class="cf">for</span>(n <span class="cf">in</span> k){</span>
<span id="cb437-5"><a href="supervised-learning.html#cb437-5" tabindex="-1"></a>  iris_test_output_kNN <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> iris_train_input, </span>
<span id="cb437-6"><a href="supervised-learning.html#cb437-6" tabindex="-1"></a>                              <span class="at">cl =</span> iris_train_output, </span>
<span id="cb437-7"><a href="supervised-learning.html#cb437-7" tabindex="-1"></a>                              <span class="at">test =</span> iris_test_input, </span>
<span id="cb437-8"><a href="supervised-learning.html#cb437-8" tabindex="-1"></a>                              <span class="at">k =</span> n)</span>
<span id="cb437-9"><a href="supervised-learning.html#cb437-9" tabindex="-1"></a>  </span>
<span id="cb437-10"><a href="supervised-learning.html#cb437-10" tabindex="-1"></a>  result_df<span class="sc">$</span>precision[n] <span class="ot">&lt;-</span> <span class="fu">mean</span>(iris_test_output_kNN <span class="sc">==</span> iris_test_output)</span>
<span id="cb437-11"><a href="supervised-learning.html#cb437-11" tabindex="-1"></a>}</span>
<span id="cb437-12"><a href="supervised-learning.html#cb437-12" tabindex="-1"></a></span>
<span id="cb437-13"><a href="supervised-learning.html#cb437-13" tabindex="-1"></a>result_df <span class="sc">|&gt;</span> </span>
<span id="cb437-14"><a href="supervised-learning.html#cb437-14" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb437-15"><a href="supervised-learning.html#cb437-15" tabindex="-1"></a>  <span class="fu">aes</span>(k, precision) <span class="sc">+</span></span>
<span id="cb437-16"><a href="supervised-learning.html#cb437-16" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="Data-Science-with-R_files/figure-html/unnamed-chunk-581-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>As we can see, the accuracy (precision) changes with <code>k</code>. This illustrates a fundamental concept in Machine Learning:</p>
<ul>
<li><strong>Overfitting (Low k):</strong> When <code>k</code> is too low (e.g., <code>k=1</code>), the model pays excessive attention to individual data points, including noise. It effectively “memorizes” the training data but fails to generalize to new, unseen examples.</li>
<li><strong>Underfitting (High k):</strong> Conversely, if <code>k</code> is too high (e.g., <code>k=50</code>), the model becomes overly simple, averaging out the signal and missing the distinct patterns that differentiate the classes.</li>
</ul>
<p>Finding the sweet spot between these two extremes is the goal of <strong>Hyperparameter Tuning</strong>. It will depend on each case to choose the best “k” for our model to balance this trade-off (often called the <strong>Bias-Variance Tradeoff</strong>).</p>
<p>We have thus built our first machine learning model.</p>
</div>
</div>
<div id="tidymodels-framework" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> tidymodels Framework<a href="supervised-learning.html#tidymodels-framework" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we have created our first machine learning model, we have seen ourselves with many lines of code. For example, to split the sample into training and test, to calculate the optimal “k”, etc. To make the work easier, we will use the <code>tidymodels</code> framework. <a href="https://www.tidymodels.org/">tidymodels</a><a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> is a collection of packages for modeling and machine learning using tidyverse principles. It provides a unified, modern interface for:</p>
<p>It provides a unified, modern interface via a suite of specialized packages: <strong>rsample</strong> for data splitting and resampling, <strong>recipes</strong> for feature engineering and preprocessing, <strong>parsnip</strong> for specifying models, <strong>tune</strong> for hyperparameter optimization, <strong>yardstick</strong> for metrics and model evaluation, and <strong>workflows</strong> to bundle everything together.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="supervised-learning.html#cb438-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;tidymodels&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="supervised-learning.html#cb439-1" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb439-2"><a href="supervised-learning.html#cb439-2" tabindex="-1"></a><span class="co">#&gt; ── Attaching packages ─────────── tidymodels 1.4.1 ──</span></span>
<span id="cb439-3"><a href="supervised-learning.html#cb439-3" tabindex="-1"></a><span class="co">#&gt; ✔ broom        1.0.11     ✔ tailor       0.1.0 </span></span>
<span id="cb439-4"><a href="supervised-learning.html#cb439-4" tabindex="-1"></a><span class="co">#&gt; ✔ dials        1.4.2      ✔ tune         2.0.1 </span></span>
<span id="cb439-5"><a href="supervised-learning.html#cb439-5" tabindex="-1"></a><span class="co">#&gt; ✔ infer        1.1.0      ✔ workflows    1.3.0 </span></span>
<span id="cb439-6"><a href="supervised-learning.html#cb439-6" tabindex="-1"></a><span class="co">#&gt; ✔ parsnip      1.4.0      ✔ workflowsets 1.1.1 </span></span>
<span id="cb439-7"><a href="supervised-learning.html#cb439-7" tabindex="-1"></a><span class="co">#&gt; ✔ recipes      1.3.1      ✔ yardstick    1.3.2 </span></span>
<span id="cb439-8"><a href="supervised-learning.html#cb439-8" tabindex="-1"></a><span class="co">#&gt; ✔ rsample      1.3.1</span></span>
<span id="cb439-9"><a href="supervised-learning.html#cb439-9" tabindex="-1"></a><span class="co">#&gt; ── Conflicts ────────────── tidymodels_conflicts() ──</span></span>
<span id="cb439-10"><a href="supervised-learning.html#cb439-10" tabindex="-1"></a><span class="co">#&gt; ✖ NLP::annotate()         masks ggplot2::annotate()</span></span>
<span id="cb439-11"><a href="supervised-learning.html#cb439-11" tabindex="-1"></a><span class="co">#&gt; ✖ scales::discard()       masks purrr::discard()</span></span>
<span id="cb439-12"><a href="supervised-learning.html#cb439-12" tabindex="-1"></a><span class="co">#&gt; ✖ Matrix::expand()        masks tidyr::expand()</span></span>
<span id="cb439-13"><a href="supervised-learning.html#cb439-13" tabindex="-1"></a><span class="co">#&gt; ✖ dplyr::filter()         masks stats::filter()</span></span>
<span id="cb439-14"><a href="supervised-learning.html#cb439-14" tabindex="-1"></a><span class="co">#&gt; ✖ recipes::fixed()        masks stringr::fixed()</span></span>
<span id="cb439-15"><a href="supervised-learning.html#cb439-15" tabindex="-1"></a><span class="co">#&gt; ✖ dplyr::lag()            masks stats::lag()</span></span>
<span id="cb439-16"><a href="supervised-learning.html#cb439-16" tabindex="-1"></a><span class="co">#&gt; ✖ Matrix::pack()          masks tidyr::pack()</span></span>
<span id="cb439-17"><a href="supervised-learning.html#cb439-17" tabindex="-1"></a><span class="co">#&gt; ✖ rsample::permutations() masks gtools::permutations()</span></span>
<span id="cb439-18"><a href="supervised-learning.html#cb439-18" tabindex="-1"></a><span class="co">#&gt; ✖ dials::prune()          masks dendextend::prune()</span></span>
<span id="cb439-19"><a href="supervised-learning.html#cb439-19" tabindex="-1"></a><span class="co">#&gt; ✖ yardstick::spec()       masks readr::spec()</span></span>
<span id="cb439-20"><a href="supervised-learning.html#cb439-20" tabindex="-1"></a><span class="co">#&gt; ✖ recipes::step()         masks stats::step()</span></span>
<span id="cb439-21"><a href="supervised-learning.html#cb439-21" tabindex="-1"></a><span class="co">#&gt; ✖ Matrix::unpack()        masks tidyr::unpack()</span></span>
<span id="cb439-22"><a href="supervised-learning.html#cb439-22" tabindex="-1"></a><span class="co">#&gt; ✖ recipes::update()       masks Matrix::update(), stats::update()</span></span></code></pre></div>
<p>We are going to do another example with k-nearest neighbors, but this time using the functions of the <strong>tidymodels</strong> framework. The data for this example will be obtained from the <code>ISLR</code> library, which contains the daily percentage returns for the S&amp;P 500 stock index between 2001 and 2005. This data frame has 8 columns that we will use as <em>input</em> and the last column that has two classes (whether the index goes up or down) that we will use as <em>output</em> (See <code>?Smarket</code>).</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="supervised-learning.html#cb440-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;ISLR&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="supervised-learning.html#cb441-1" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb441-2"><a href="supervised-learning.html#cb441-2" tabindex="-1"></a><span class="fu">data</span>(Smarket)</span>
<span id="cb441-3"><a href="supervised-learning.html#cb441-3" tabindex="-1"></a><span class="co"># Data frame that we will use</span></span>
<span id="cb441-4"><a href="supervised-learning.html#cb441-4" tabindex="-1"></a>Smarket <span class="sc">|&gt;</span> </span>
<span id="cb441-5"><a href="supervised-learning.html#cb441-5" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb441-6"><a href="supervised-learning.html#cb441-6" tabindex="-1"></a><span class="co">#&gt;    Year   Lag1   Lag2   Lag3   Lag4   Lag5 Volume  Today Direction</span></span>
<span id="cb441-7"><a href="supervised-learning.html#cb441-7" tabindex="-1"></a><span class="co">#&gt; 1  2001  0.381 -0.192 -2.624 -1.055  5.010 1.1913  0.959        Up</span></span>
<span id="cb441-8"><a href="supervised-learning.html#cb441-8" tabindex="-1"></a><span class="co">#&gt; 2  2001  0.959  0.381 -0.192 -2.624 -1.055 1.2965  1.032        Up</span></span>
<span id="cb441-9"><a href="supervised-learning.html#cb441-9" tabindex="-1"></a><span class="co">#&gt; 3  2001  1.032  0.959  0.381 -0.192 -2.624 1.4112 -0.623      Down</span></span>
<span id="cb441-10"><a href="supervised-learning.html#cb441-10" tabindex="-1"></a><span class="co">#&gt; 4  2001 -0.623  1.032  0.959  0.381 -0.192 1.2760  0.614        Up</span></span>
<span id="cb441-11"><a href="supervised-learning.html#cb441-11" tabindex="-1"></a><span class="co">#&gt; 5  2001  0.614 -0.623  1.032  0.959  0.381 1.2057  0.213        Up</span></span>
<span id="cb441-12"><a href="supervised-learning.html#cb441-12" tabindex="-1"></a><span class="co">#&gt; 6  2001  0.213  0.614 -0.623  1.032  0.959 1.3491  1.392        Up</span></span>
<span id="cb441-13"><a href="supervised-learning.html#cb441-13" tabindex="-1"></a><span class="co">#&gt; 7  2001  1.392  0.213  0.614 -0.623  1.032 1.4450 -0.403      Down</span></span>
<span id="cb441-14"><a href="supervised-learning.html#cb441-14" tabindex="-1"></a><span class="co">#&gt; 8  2001 -0.403  1.392  0.213  0.614 -0.623 1.4078  0.027        Up</span></span>
<span id="cb441-15"><a href="supervised-learning.html#cb441-15" tabindex="-1"></a><span class="co">#&gt; 9  2001  0.027 -0.403  1.392  0.213  0.614 1.1640  1.303        Up</span></span>
<span id="cb441-16"><a href="supervised-learning.html#cb441-16" tabindex="-1"></a><span class="co">#&gt; 10 2001  1.303  0.027 -0.403  1.392  0.213 1.2326  0.287        Up</span></span>
<span id="cb441-17"><a href="supervised-learning.html#cb441-17" tabindex="-1"></a></span>
<span id="cb441-18"><a href="supervised-learning.html#cb441-18" tabindex="-1"></a><span class="co"># We make some translations for ease of analysis</span></span>
<span id="cb441-19"><a href="supervised-learning.html#cb441-19" tabindex="-1"></a>Smarket <span class="ot">&lt;-</span> Smarket <span class="sc">|&gt;</span> </span>
<span id="cb441-20"><a href="supervised-learning.html#cb441-20" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">Direction =</span> Direction) <span class="sc">|&gt;</span> </span>
<span id="cb441-21"><a href="supervised-learning.html#cb441-21" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Direction =</span> <span class="fu">ifelse</span>(Direction <span class="sc">==</span> <span class="st">&quot;Up&quot;</span>, <span class="st">&quot;Up&quot;</span>, <span class="st">&quot;Down&quot;</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb441-22"><a href="supervised-learning.html#cb441-22" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(<span class="st">&quot;Direction&quot;</span>), <span class="sc">~</span><span class="fu">as.factor</span>(.)))</span></code></pre></div>
<div id="creation-of-training-and-test-data" class="section level3 hasAnchor" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Creation of training and test data<a href="supervised-learning.html#creation-of-training-and-test-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From the total of our data frame, we will split a part of the data for training and the other to do the tests. tidymodels provides the <code>initial_split()</code> function from the <code>rsample</code> package which creates a clean split object. We allocate 75% of the data for training using the <code>prop</code> argument, and we can use <code>strata</code> to ensure balanced class distribution.</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="supervised-learning.html#cb442-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb442-2"><a href="supervised-learning.html#cb442-2" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(Smarket, <span class="at">prop =</span> <span class="fl">0.75</span>, <span class="at">strata =</span> Direction)</span>
<span id="cb442-3"><a href="supervised-learning.html#cb442-3" tabindex="-1"></a></span>
<span id="cb442-4"><a href="supervised-learning.html#cb442-4" tabindex="-1"></a>SP_train <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb442-5"><a href="supervised-learning.html#cb442-5" tabindex="-1"></a>SP_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span>
<span id="cb442-6"><a href="supervised-learning.html#cb442-6" tabindex="-1"></a></span>
<span id="cb442-7"><a href="supervised-learning.html#cb442-7" tabindex="-1"></a><span class="co"># Check the split</span></span>
<span id="cb442-8"><a href="supervised-learning.html#cb442-8" tabindex="-1"></a><span class="fu">nrow</span>(SP_train)</span>
<span id="cb442-9"><a href="supervised-learning.html#cb442-9" tabindex="-1"></a><span class="co">#&gt; [1] 937</span></span>
<span id="cb442-10"><a href="supervised-learning.html#cb442-10" tabindex="-1"></a><span class="fu">nrow</span>(SP_test)</span>
<span id="cb442-11"><a href="supervised-learning.html#cb442-11" tabindex="-1"></a><span class="co">#&gt; [1] 313</span></span></code></pre></div>
<p>This function makes sampling data much simpler and returns a split object that we can use with <code>training()</code> and <code>testing()</code> accessor functions.</p>
</div>
<div id="training-our-prediction-algorithm" class="section level3 hasAnchor" number="11.3.2">
<h3><span class="header-section-number">11.3.2</span> Training our prediction algorithm<a href="supervised-learning.html#training-our-prediction-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In tidymodels, we build models in a structured way using three key components:
In <code>tidymodels</code>, we build models in a structured way using three key components: <strong>Model Specification</strong> (via <code>parsnip</code>) to define the algorithm, <strong>Recipes</strong> (via <code>recipes</code>) to define preprocessing steps, and <strong>Workflows</strong> (via <code>workflows</code>) to bundle the model and recipe together into a single execution unit.</p>
<p>Let’s break down these components:</p>
<p>Let’s break down these components. The <strong>Model Specification (<code>parsnip</code>)</strong> tells R <em>what</em> kind of model we want (e.g., “nearest neighbor”) and <em>which</em> computational engine to use (e.g., “kknn”), decoupling intent from implementation. The <strong>Recipe (<code>recipes</code>)</strong> acts as a blueprint for data processing, handling tasks like normalization (scaling variables) and converting categorical variables. Finally, the <strong>Workflow (<code>workflows</code>)</strong> container holds the model and recipe together, ensuring that the exact same preprocessing steps are applied automatically when predicting on new data.</p>
<p>Let’s start by specifying our k-nearest neighbors model. We use <code>tune()</code> as a placeholder for the <code>neighbors</code> parameter to indicate we want to find the optimal value.</p>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="supervised-learning.html#cb443-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb443-2"><a href="supervised-learning.html#cb443-2" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb443-3"><a href="supervised-learning.html#cb443-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb443-4"><a href="supervised-learning.html#cb443-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb443-5"><a href="supervised-learning.html#cb443-5" tabindex="-1"></a></span>
<span id="cb443-6"><a href="supervised-learning.html#cb443-6" tabindex="-1"></a>knn_spec</span>
<span id="cb443-7"><a href="supervised-learning.html#cb443-7" tabindex="-1"></a><span class="co">#&gt; K-Nearest Neighbor Model Specification (classification)</span></span>
<span id="cb443-8"><a href="supervised-learning.html#cb443-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb443-9"><a href="supervised-learning.html#cb443-9" tabindex="-1"></a><span class="co">#&gt; Main Arguments:</span></span>
<span id="cb443-10"><a href="supervised-learning.html#cb443-10" tabindex="-1"></a><span class="co">#&gt;   neighbors = tune()</span></span>
<span id="cb443-11"><a href="supervised-learning.html#cb443-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb443-12"><a href="supervised-learning.html#cb443-12" tabindex="-1"></a><span class="co">#&gt; Computational engine: kknn</span></span></code></pre></div>
</div>
<div id="data-pre-processing-with-recipes" class="section level3 hasAnchor" number="11.3.3">
<h3><span class="header-section-number">11.3.3</span> Data Pre-processing with Recipes<a href="supervised-learning.html#data-pre-processing-with-recipes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>tidymodels uses <code>recipes</code> for preprocessing. The <code>scale</code> method (division by standard deviation) and <code>centering</code> (subtraction of the mean) are implemented with <code>step_normalize()</code>.</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="supervised-learning.html#cb444-1" tabindex="-1"></a><span class="co"># Define preprocessing recipe</span></span>
<span id="cb444-2"><a href="supervised-learning.html#cb444-2" tabindex="-1"></a>knn_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Direction <span class="sc">~</span> ., <span class="at">data =</span> SP_train) <span class="sc">|&gt;</span></span>
<span id="cb444-3"><a href="supervised-learning.html#cb444-3" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span>
<span id="cb444-4"><a href="supervised-learning.html#cb444-4" tabindex="-1"></a></span>
<span id="cb444-5"><a href="supervised-learning.html#cb444-5" tabindex="-1"></a>knn_recipe</span>
<span id="cb444-6"><a href="supervised-learning.html#cb444-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb444-7"><a href="supervised-learning.html#cb444-7" tabindex="-1"></a><span class="co">#&gt; ── Recipe ───────────────────────────────────────────</span></span>
<span id="cb444-8"><a href="supervised-learning.html#cb444-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb444-9"><a href="supervised-learning.html#cb444-9" tabindex="-1"></a><span class="co">#&gt; ── Inputs</span></span>
<span id="cb444-10"><a href="supervised-learning.html#cb444-10" tabindex="-1"></a><span class="co">#&gt; Number of variables by role</span></span>
<span id="cb444-11"><a href="supervised-learning.html#cb444-11" tabindex="-1"></a><span class="co">#&gt; outcome:   1</span></span>
<span id="cb444-12"><a href="supervised-learning.html#cb444-12" tabindex="-1"></a><span class="co">#&gt; predictor: 8</span></span>
<span id="cb444-13"><a href="supervised-learning.html#cb444-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb444-14"><a href="supervised-learning.html#cb444-14" tabindex="-1"></a><span class="co">#&gt; ── Operations</span></span>
<span id="cb444-15"><a href="supervised-learning.html#cb444-15" tabindex="-1"></a><span class="co">#&gt; • Centering and scaling for:</span></span>
<span id="cb444-16"><a href="supervised-learning.html#cb444-16" tabindex="-1"></a><span class="co">#&gt;   all_numeric_predictors()</span></span></code></pre></div>
</div>
<div id="creating-a-workflow" class="section level3 hasAnchor" number="11.3.4">
<h3><span class="header-section-number">11.3.4</span> Creating a Workflow<a href="supervised-learning.html#creating-a-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A workflow bundles the recipe and model specification together for easy training and prediction.</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="supervised-learning.html#cb445-1" tabindex="-1"></a><span class="co"># Bundle into workflow</span></span>
<span id="cb445-2"><a href="supervised-learning.html#cb445-2" tabindex="-1"></a>knn_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb445-3"><a href="supervised-learning.html#cb445-3" tabindex="-1"></a>  <span class="fu">add_recipe</span>(knn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb445-4"><a href="supervised-learning.html#cb445-4" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec)</span>
<span id="cb445-5"><a href="supervised-learning.html#cb445-5" tabindex="-1"></a></span>
<span id="cb445-6"><a href="supervised-learning.html#cb445-6" tabindex="-1"></a>knn_workflow</span>
<span id="cb445-7"><a href="supervised-learning.html#cb445-7" tabindex="-1"></a><span class="co">#&gt; ══ Workflow ═════════════════════════════════════════</span></span>
<span id="cb445-8"><a href="supervised-learning.html#cb445-8" tabindex="-1"></a><span class="co">#&gt; Preprocessor: Recipe</span></span>
<span id="cb445-9"><a href="supervised-learning.html#cb445-9" tabindex="-1"></a><span class="co">#&gt; Model: nearest_neighbor()</span></span>
<span id="cb445-10"><a href="supervised-learning.html#cb445-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb445-11"><a href="supervised-learning.html#cb445-11" tabindex="-1"></a><span class="co">#&gt; ── Preprocessor ─────────────────────────────────────</span></span>
<span id="cb445-12"><a href="supervised-learning.html#cb445-12" tabindex="-1"></a><span class="co">#&gt; 1 Recipe Step</span></span>
<span id="cb445-13"><a href="supervised-learning.html#cb445-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb445-14"><a href="supervised-learning.html#cb445-14" tabindex="-1"></a><span class="co">#&gt; • step_normalize()</span></span>
<span id="cb445-15"><a href="supervised-learning.html#cb445-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb445-16"><a href="supervised-learning.html#cb445-16" tabindex="-1"></a><span class="co">#&gt; ── Model ────────────────────────────────────────────</span></span>
<span id="cb445-17"><a href="supervised-learning.html#cb445-17" tabindex="-1"></a><span class="co">#&gt; K-Nearest Neighbor Model Specification (classification)</span></span>
<span id="cb445-18"><a href="supervised-learning.html#cb445-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb445-19"><a href="supervised-learning.html#cb445-19" tabindex="-1"></a><span class="co">#&gt; Main Arguments:</span></span>
<span id="cb445-20"><a href="supervised-learning.html#cb445-20" tabindex="-1"></a><span class="co">#&gt;   neighbors = tune()</span></span>
<span id="cb445-21"><a href="supervised-learning.html#cb445-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb445-22"><a href="supervised-learning.html#cb445-22" tabindex="-1"></a><span class="co">#&gt; Computational engine: kknn</span></span></code></pre></div>
</div>
<div id="parameter-tuning-with-cross-validation" class="section level3 hasAnchor" number="11.3.5">
<h3><span class="header-section-number">11.3.5</span> Parameter Tuning with Cross-Validation<a href="supervised-learning.html#parameter-tuning-with-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the most important parts of training machine learning models is tuning the parameters. We use <code>vfold_cv()</code> to create cross-validation folds and <code>tune_grid()</code> to search for the best hyperparameters.</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="supervised-learning.html#cb446-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb446-2"><a href="supervised-learning.html#cb446-2" tabindex="-1"></a></span>
<span id="cb446-3"><a href="supervised-learning.html#cb446-3" tabindex="-1"></a><span class="co"># Create 5-fold cross-validation</span></span>
<span id="cb446-4"><a href="supervised-learning.html#cb446-4" tabindex="-1"></a>folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(SP_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> Direction)</span>
<span id="cb446-5"><a href="supervised-learning.html#cb446-5" tabindex="-1"></a></span>
<span id="cb446-6"><a href="supervised-learning.html#cb446-6" tabindex="-1"></a><span class="co"># Create a grid of k values to try</span></span>
<span id="cb446-7"><a href="supervised-learning.html#cb446-7" tabindex="-1"></a>k_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(<span class="fu">neighbors</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">50</span>)), <span class="at">levels =</span> <span class="dv">20</span>)</span>
<span id="cb446-8"><a href="supervised-learning.html#cb446-8" tabindex="-1"></a></span>
<span id="cb446-9"><a href="supervised-learning.html#cb446-9" tabindex="-1"></a><span class="co"># Tune the model</span></span>
<span id="cb446-10"><a href="supervised-learning.html#cb446-10" tabindex="-1"></a>knn_tune_results <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb446-11"><a href="supervised-learning.html#cb446-11" tabindex="-1"></a>  knn_workflow,</span>
<span id="cb446-12"><a href="supervised-learning.html#cb446-12" tabindex="-1"></a>  <span class="at">resamples =</span> folds,</span>
<span id="cb446-13"><a href="supervised-learning.html#cb446-13" tabindex="-1"></a>  <span class="at">grid =</span> k_grid</span>
<span id="cb446-14"><a href="supervised-learning.html#cb446-14" tabindex="-1"></a>)</span>
<span id="cb446-15"><a href="supervised-learning.html#cb446-15" tabindex="-1"></a></span>
<span id="cb446-16"><a href="supervised-learning.html#cb446-16" tabindex="-1"></a>knn_tune_results</span>
<span id="cb446-17"><a href="supervised-learning.html#cb446-17" tabindex="-1"></a><span class="co">#&gt; # Tuning results</span></span>
<span id="cb446-18"><a href="supervised-learning.html#cb446-18" tabindex="-1"></a><span class="co">#&gt; # 5-fold cross-validation using stratification </span></span>
<span id="cb446-19"><a href="supervised-learning.html#cb446-19" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 4</span></span>
<span id="cb446-20"><a href="supervised-learning.html#cb446-20" tabindex="-1"></a><span class="co">#&gt;   splits            id    .metrics          .notes          </span></span>
<span id="cb446-21"><a href="supervised-learning.html#cb446-21" tabindex="-1"></a><span class="co">#&gt;   &lt;list&gt;            &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          </span></span>
<span id="cb446-22"><a href="supervised-learning.html#cb446-22" tabindex="-1"></a><span class="co">#&gt; 1 &lt;split [748/189]&gt; Fold1 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb446-23"><a href="supervised-learning.html#cb446-23" tabindex="-1"></a><span class="co">#&gt; 2 &lt;split [750/187]&gt; Fold2 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb446-24"><a href="supervised-learning.html#cb446-24" tabindex="-1"></a><span class="co">#&gt; 3 &lt;split [750/187]&gt; Fold3 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb446-25"><a href="supervised-learning.html#cb446-25" tabindex="-1"></a><span class="co">#&gt; 4 &lt;split [750/187]&gt; Fold4 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span>
<span id="cb446-26"><a href="supervised-learning.html#cb446-26" tabindex="-1"></a><span class="co">#&gt; 5 &lt;split [750/187]&gt; Fold5 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 4]&gt;</span></span></code></pre></div>
<p>We can visualize the tuning results using <code>autoplot()</code>:</p>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="supervised-learning.html#cb447-1" tabindex="-1"></a><span class="fu">autoplot</span>(knn_tune_results)</span></code></pre></div>
<p><img src="Data-Science-with-R_files/figure-html/unnamed-chunk-591-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>We can see the accuracy for each value of “k”. The <code>show_best()</code> function shows us the top performing values:</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="supervised-learning.html#cb448-1" tabindex="-1"></a><span class="fu">show_best</span>(knn_tune_results, <span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb448-2"><a href="supervised-learning.html#cb448-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 7</span></span>
<span id="cb448-3"><a href="supervised-learning.html#cb448-3" tabindex="-1"></a><span class="co">#&gt;   neighbors .metric  .estimator  mean     n std_err .config         </span></span>
<span id="cb448-4"><a href="supervised-learning.html#cb448-4" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb448-5"><a href="supervised-learning.html#cb448-5" tabindex="-1"></a><span class="co">#&gt; 1        44 accuracy binary     0.905     5  0.0114 pre0_mod18_post0</span></span>
<span id="cb448-6"><a href="supervised-learning.html#cb448-6" tabindex="-1"></a><span class="co">#&gt; 2        42 accuracy binary     0.904     5  0.0116 pre0_mod17_post0</span></span>
<span id="cb448-7"><a href="supervised-learning.html#cb448-7" tabindex="-1"></a><span class="co">#&gt; 3        37 accuracy binary     0.902     5  0.0115 pre0_mod15_post0</span></span>
<span id="cb448-8"><a href="supervised-learning.html#cb448-8" tabindex="-1"></a><span class="co">#&gt; 4        31 accuracy binary     0.902     5  0.0112 pre0_mod13_post0</span></span>
<span id="cb448-9"><a href="supervised-learning.html#cb448-9" tabindex="-1"></a><span class="co">#&gt; 5        47 accuracy binary     0.901     5  0.0119 pre0_mod19_post0</span></span></code></pre></div>
</div>
<div id="finalizing-the-model" class="section level3 hasAnchor" number="11.3.6">
<h3><span class="header-section-number">11.3.6</span> Finalizing the Model<a href="supervised-learning.html#finalizing-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once we’ve found the best hyperparameters, we finalize our workflow with those values:</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="supervised-learning.html#cb449-1" tabindex="-1"></a><span class="co"># Select the best k value</span></span>
<span id="cb449-2"><a href="supervised-learning.html#cb449-2" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> <span class="fu">select_best</span>(knn_tune_results, <span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb449-3"><a href="supervised-learning.html#cb449-3" tabindex="-1"></a>best_k</span>
<span id="cb449-4"><a href="supervised-learning.html#cb449-4" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 2</span></span>
<span id="cb449-5"><a href="supervised-learning.html#cb449-5" tabindex="-1"></a><span class="co">#&gt;   neighbors .config         </span></span>
<span id="cb449-6"><a href="supervised-learning.html#cb449-6" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;           </span></span>
<span id="cb449-7"><a href="supervised-learning.html#cb449-7" tabindex="-1"></a><span class="co">#&gt; 1        44 pre0_mod18_post0</span></span>
<span id="cb449-8"><a href="supervised-learning.html#cb449-8" tabindex="-1"></a></span>
<span id="cb449-9"><a href="supervised-learning.html#cb449-9" tabindex="-1"></a><span class="co"># Finalize the workflow with the best parameters</span></span>
<span id="cb449-10"><a href="supervised-learning.html#cb449-10" tabindex="-1"></a>final_knn_workflow <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(knn_workflow, best_k)</span>
<span id="cb449-11"><a href="supervised-learning.html#cb449-11" tabindex="-1"></a></span>
<span id="cb449-12"><a href="supervised-learning.html#cb449-12" tabindex="-1"></a><span class="co"># Fit the final model on the entire training set</span></span>
<span id="cb449-13"><a href="supervised-learning.html#cb449-13" tabindex="-1"></a>SP_knn_trained <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_knn_workflow, <span class="at">data =</span> SP_train)</span>
<span id="cb449-14"><a href="supervised-learning.html#cb449-14" tabindex="-1"></a></span>
<span id="cb449-15"><a href="supervised-learning.html#cb449-15" tabindex="-1"></a>SP_knn_trained</span>
<span id="cb449-16"><a href="supervised-learning.html#cb449-16" tabindex="-1"></a><span class="co">#&gt; ══ Workflow [trained] ═══════════════════════════════</span></span>
<span id="cb449-17"><a href="supervised-learning.html#cb449-17" tabindex="-1"></a><span class="co">#&gt; Preprocessor: Recipe</span></span>
<span id="cb449-18"><a href="supervised-learning.html#cb449-18" tabindex="-1"></a><span class="co">#&gt; Model: nearest_neighbor()</span></span>
<span id="cb449-19"><a href="supervised-learning.html#cb449-19" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb449-20"><a href="supervised-learning.html#cb449-20" tabindex="-1"></a><span class="co">#&gt; ── Preprocessor ─────────────────────────────────────</span></span>
<span id="cb449-21"><a href="supervised-learning.html#cb449-21" tabindex="-1"></a><span class="co">#&gt; 1 Recipe Step</span></span>
<span id="cb449-22"><a href="supervised-learning.html#cb449-22" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb449-23"><a href="supervised-learning.html#cb449-23" tabindex="-1"></a><span class="co">#&gt; • step_normalize()</span></span>
<span id="cb449-24"><a href="supervised-learning.html#cb449-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb449-25"><a href="supervised-learning.html#cb449-25" tabindex="-1"></a><span class="co">#&gt; ── Model ────────────────────────────────────────────</span></span>
<span id="cb449-26"><a href="supervised-learning.html#cb449-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb449-27"><a href="supervised-learning.html#cb449-27" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb449-28"><a href="supervised-learning.html#cb449-28" tabindex="-1"></a><span class="co">#&gt; kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(44L,     data, 5))</span></span>
<span id="cb449-29"><a href="supervised-learning.html#cb449-29" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb449-30"><a href="supervised-learning.html#cb449-30" tabindex="-1"></a><span class="co">#&gt; Type of response variable: nominal</span></span>
<span id="cb449-31"><a href="supervised-learning.html#cb449-31" tabindex="-1"></a><span class="co">#&gt; Minimal misclassification: 0.0864461</span></span>
<span id="cb449-32"><a href="supervised-learning.html#cb449-32" tabindex="-1"></a><span class="co">#&gt; Best kernel: optimal</span></span>
<span id="cb449-33"><a href="supervised-learning.html#cb449-33" tabindex="-1"></a><span class="co">#&gt; Best k: 44</span></span></code></pre></div>
<p>We see the substantial improvement now that we have adjusted some parameters and made it reprocess first. Note that each time we adjust parameters, the value of “k” can change until the most optimal one is found. In this case, it changed to k = 29. This does not mean that the lower the “k”, the better the algorithm, only that it is the most optimal for this particular case with these adjustments made.</p>
</div>
<div id="testing-the-prediction-model" class="section level3 hasAnchor" number="11.3.7">
<h3><span class="header-section-number">11.3.7</span> Testing the prediction model<a href="supervised-learning.html#testing-the-prediction-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We already have our model trained and ready to test it. tidymodels makes it easy to make predictions using the <code>augment()</code> function which adds predictions directly to our test data.</p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="supervised-learning.html#cb450-1" tabindex="-1"></a><span class="co"># Make predictions on test data</span></span>
<span id="cb450-2"><a href="supervised-learning.html#cb450-2" tabindex="-1"></a>SP_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(SP_knn_trained, <span class="at">new_data =</span> SP_test)</span>
<span id="cb450-3"><a href="supervised-learning.html#cb450-3" tabindex="-1"></a></span>
<span id="cb450-4"><a href="supervised-learning.html#cb450-4" tabindex="-1"></a><span class="co"># View predictions</span></span>
<span id="cb450-5"><a href="supervised-learning.html#cb450-5" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span> </span>
<span id="cb450-6"><a href="supervised-learning.html#cb450-6" tabindex="-1"></a>  <span class="fu">select</span>(Direction, .pred_class, .pred_Down, .pred_Up) <span class="sc">|&gt;</span></span>
<span id="cb450-7"><a href="supervised-learning.html#cb450-7" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb450-8"><a href="supervised-learning.html#cb450-8" tabindex="-1"></a><span class="co">#&gt; # A tibble: 10 × 4</span></span>
<span id="cb450-9"><a href="supervised-learning.html#cb450-9" tabindex="-1"></a><span class="co">#&gt;    Direction .pred_class .pred_Down .pred_Up</span></span>
<span id="cb450-10"><a href="supervised-learning.html#cb450-10" tabindex="-1"></a><span class="co">#&gt;    &lt;fct&gt;     &lt;fct&gt;            &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb450-11"><a href="supervised-learning.html#cb450-11" tabindex="-1"></a><span class="co">#&gt;  1 Up        Up              0.243    0.757 </span></span>
<span id="cb450-12"><a href="supervised-learning.html#cb450-12" tabindex="-1"></a><span class="co">#&gt;  2 Up        Up              0.404    0.596 </span></span>
<span id="cb450-13"><a href="supervised-learning.html#cb450-13" tabindex="-1"></a><span class="co">#&gt;  3 Down      Down            0.611    0.389 </span></span>
<span id="cb450-14"><a href="supervised-learning.html#cb450-14" tabindex="-1"></a><span class="co">#&gt;  4 Down      Down            0.977    0.0231</span></span>
<span id="cb450-15"><a href="supervised-learning.html#cb450-15" tabindex="-1"></a><span class="co">#&gt;  5 Up        Up              0.230    0.770 </span></span>
<span id="cb450-16"><a href="supervised-learning.html#cb450-16" tabindex="-1"></a><span class="co">#&gt;  6 Down      Up              0.472    0.528 </span></span>
<span id="cb450-17"><a href="supervised-learning.html#cb450-17" tabindex="-1"></a><span class="co">#&gt;  7 Down      Down            0.955    0.0447</span></span>
<span id="cb450-18"><a href="supervised-learning.html#cb450-18" tabindex="-1"></a><span class="co">#&gt;  8 Up        Up              0.0361   0.964 </span></span>
<span id="cb450-19"><a href="supervised-learning.html#cb450-19" tabindex="-1"></a><span class="co">#&gt;  9 Down      Down            0.522    0.478 </span></span>
<span id="cb450-20"><a href="supervised-learning.html#cb450-20" tabindex="-1"></a><span class="co">#&gt; 10 Down      Down            1        0</span></span></code></pre></div>
<p>The <code>augment()</code> function adds three columns: <code>.pred_class</code> (the predicted class), and probability columns for each class (<code>.pred_Down</code> and <code>.pred_Up</code>). This makes it very easy to compare predictions with actual values.</p>
<p>As we can see, for each test value the model calculates the estimated probability for each class. The algorithm assigns the class with the highest probability.</p>
</div>
<div id="model-evaluation-with-yardstick" class="section level3 hasAnchor" number="11.3.8">
<h3><span class="header-section-number">11.3.8</span> Model Evaluation with yardstick<a href="supervised-learning.html#model-evaluation-with-yardstick" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To evaluate our model, we use the <code>yardstick</code> package. The <code>conf_mat()</code> function creates a confusion matrix, and we can calculate various metrics like accuracy, sensitivity, and specificity.</p>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="supervised-learning.html#cb451-1" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb451-2"><a href="supervised-learning.html#cb451-2" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span></span>
<span id="cb451-3"><a href="supervised-learning.html#cb451-3" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb451-4"><a href="supervised-learning.html#cb451-4" tabindex="-1"></a><span class="co">#&gt;           Truth</span></span>
<span id="cb451-5"><a href="supervised-learning.html#cb451-5" tabindex="-1"></a><span class="co">#&gt; Prediction Down  Up</span></span>
<span id="cb451-6"><a href="supervised-learning.html#cb451-6" tabindex="-1"></a><span class="co">#&gt;       Down  132   4</span></span>
<span id="cb451-7"><a href="supervised-learning.html#cb451-7" tabindex="-1"></a><span class="co">#&gt;       Up     19 158</span></span>
<span id="cb451-8"><a href="supervised-learning.html#cb451-8" tabindex="-1"></a></span>
<span id="cb451-9"><a href="supervised-learning.html#cb451-9" tabindex="-1"></a><span class="co"># Calculate accuracy</span></span>
<span id="cb451-10"><a href="supervised-learning.html#cb451-10" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span></span>
<span id="cb451-11"><a href="supervised-learning.html#cb451-11" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb451-12"><a href="supervised-learning.html#cb451-12" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb451-13"><a href="supervised-learning.html#cb451-13" tabindex="-1"></a><span class="co">#&gt;   .metric  .estimator .estimate</span></span>
<span id="cb451-14"><a href="supervised-learning.html#cb451-14" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb451-15"><a href="supervised-learning.html#cb451-15" tabindex="-1"></a><span class="co">#&gt; 1 accuracy binary         0.927</span></span>
<span id="cb451-16"><a href="supervised-learning.html#cb451-16" tabindex="-1"></a></span>
<span id="cb451-17"><a href="supervised-learning.html#cb451-17" tabindex="-1"></a><span class="co"># Calculate multiple metrics at once</span></span>
<span id="cb451-18"><a href="supervised-learning.html#cb451-18" tabindex="-1"></a>SP_predictions <span class="sc">|&gt;</span></span>
<span id="cb451-19"><a href="supervised-learning.html#cb451-19" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb451-20"><a href="supervised-learning.html#cb451-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 3</span></span>
<span id="cb451-21"><a href="supervised-learning.html#cb451-21" tabindex="-1"></a><span class="co">#&gt;   .metric  .estimator .estimate</span></span>
<span id="cb451-22"><a href="supervised-learning.html#cb451-22" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb451-23"><a href="supervised-learning.html#cb451-23" tabindex="-1"></a><span class="co">#&gt; 1 accuracy binary         0.927</span></span>
<span id="cb451-24"><a href="supervised-learning.html#cb451-24" tabindex="-1"></a><span class="co">#&gt; 2 kap      binary         0.852</span></span></code></pre></div>
<p>We obtain the accuracy as well as other metrics. The yardstick package provides many evaluation functions including <code>sens()</code> (sensitivity), <code>spec()</code> (specificity), <code>precision()</code>, <code>recall()</code>, and more.</p>
</div>
</div>
<div id="confusion-matrix" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Confusion Matrix<a href="supervised-learning.html#confusion-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have already used confusion matrices in our two previous examples. Now it is our turn to properly understand its definition as well as some of the evaluation metrics of this matrix.</p>
<p>A confusion matrix, also known as an error matrix, allows us to visualize the performance of an algorithm, generally a supervised learning one (in unsupervised learning it is generally called a matching matrix). Each row of the matrix represents the instances in a predicted class, while each column represents the instances in a real class (or vice versa). The name derives from the fact that it makes it easy to see if the system confuses two classes (i.e., commonly mislabeling one as another).</p>
<p>Binary classifications, when the <em>outcome</em> can take only two classes, yield this following confusion matrix.</p>
<p><img src="_assets/images/06-machine-learning/confusion-matrix.png" alt="2x2 confusion matrix with True Positive, False Positive, True Negative, False Negative cells" width="80%" style="display: block; margin: auto;" /></p>
<div id="accuracy" class="section level3 hasAnchor" number="11.4.1">
<h3><span class="header-section-number">11.4.1</span> Accuracy<a href="supervised-learning.html#accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have already been using this term in our examples. The accuracy of the model can be calculated from the confusion matrix:</p>
<p><span class="math inline">\(Accuracy=\frac{TP+TN}{TP+TN+FP+FN}\)</span></p>
<p>The <em>accuracy</em> of the model is the proportion of times the algorithm predicted correctly, regarding the total data evaluated.</p>
</div>
<div id="sensitivity" class="section level3 hasAnchor" number="11.4.2">
<h3><span class="header-section-number">11.4.2</span> Sensitivity<a href="supervised-learning.html#sensitivity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sensitivity (also called true positive rate, recall, or probability of detection in some fields) measures the proportion of real positives that are correctly identified as such (for example, the percentage of sick people who are correctly identified as having the condition).</p>
<p><span class="math inline">\(Sensitivity=\frac{TP}{TP+FN}\)</span></p>
</div>
<div id="specificity" class="section level3 hasAnchor" number="11.4.3">
<h3><span class="header-section-number">11.4.3</span> Specificity<a href="supervised-learning.html#specificity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Specificity (also called true negative rate) measures the proportion of real negatives that are correctly identified as such (for example, the percentage of healthy people who are correctly identified as not having the condition).</p>
<p><span class="math inline">\(Specificity=\frac{TN}{TN+FP}\)</span></p>
</div>
</div>
<div id="exercises-16" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> Exercises<a href="supervised-learning.html#exercises-16" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol start="97" style="list-style-type: decimal">
<li>Using the tidymodels library, partition the <code>iris</code> data frame in such a way as to have 70% training data and 30% test data.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="supervised-learning.html#cb452-1" tabindex="-1"></a>iris_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(iris, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> Species)</span>
<span id="cb452-2"><a href="supervised-learning.html#cb452-2" tabindex="-1"></a></span>
<span id="cb452-3"><a href="supervised-learning.html#cb452-3" tabindex="-1"></a>iris_train <span class="ot">&lt;-</span> <span class="fu">training</span>(iris_split)</span>
<span id="cb452-4"><a href="supervised-learning.html#cb452-4" tabindex="-1"></a>iris_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(iris_split)</span></code></pre></div>
</details>
<ol start="98" style="list-style-type: decimal">
<li>Using tidymodels and the training data obtained in the previous exercise, create a k-nearest neighbor model with tuning. Plot the result.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="supervised-learning.html#cb453-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb453-2"><a href="supervised-learning.html#cb453-2" tabindex="-1"></a>iris_knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb453-3"><a href="supervised-learning.html#cb453-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb453-4"><a href="supervised-learning.html#cb453-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb453-5"><a href="supervised-learning.html#cb453-5" tabindex="-1"></a></span>
<span id="cb453-6"><a href="supervised-learning.html#cb453-6" tabindex="-1"></a><span class="co"># Recipe with preprocessing</span></span>
<span id="cb453-7"><a href="supervised-learning.html#cb453-7" tabindex="-1"></a>iris_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> iris_train) <span class="sc">|&gt;</span></span>
<span id="cb453-8"><a href="supervised-learning.html#cb453-8" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span>
<span id="cb453-9"><a href="supervised-learning.html#cb453-9" tabindex="-1"></a></span>
<span id="cb453-10"><a href="supervised-learning.html#cb453-10" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb453-11"><a href="supervised-learning.html#cb453-11" tabindex="-1"></a>iris_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb453-12"><a href="supervised-learning.html#cb453-12" tabindex="-1"></a>  <span class="fu">add_recipe</span>(iris_recipe) <span class="sc">|&gt;</span></span>
<span id="cb453-13"><a href="supervised-learning.html#cb453-13" tabindex="-1"></a>  <span class="fu">add_model</span>(iris_knn_spec)</span>
<span id="cb453-14"><a href="supervised-learning.html#cb453-14" tabindex="-1"></a></span>
<span id="cb453-15"><a href="supervised-learning.html#cb453-15" tabindex="-1"></a><span class="co"># Cross-validation and tuning</span></span>
<span id="cb453-16"><a href="supervised-learning.html#cb453-16" tabindex="-1"></a>iris_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(iris_train, <span class="at">v =</span> <span class="dv">5</span>)</span>
<span id="cb453-17"><a href="supervised-learning.html#cb453-17" tabindex="-1"></a>iris_tune <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(iris_workflow, <span class="at">resamples =</span> iris_folds, <span class="at">grid =</span> <span class="dv">20</span>)</span>
<span id="cb453-18"><a href="supervised-learning.html#cb453-18" tabindex="-1"></a></span>
<span id="cb453-19"><a href="supervised-learning.html#cb453-19" tabindex="-1"></a><span class="fu">autoplot</span>(iris_tune)</span></code></pre></div>
</details>
<ol start="99" style="list-style-type: decimal">
<li>Use the model created in the previous exercise to predict the <em>outputs</em> of the <code>test</code> object. Report the confusion matrix.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="supervised-learning.html#cb454-1" tabindex="-1"></a><span class="co"># Finalize model with best k</span></span>
<span id="cb454-2"><a href="supervised-learning.html#cb454-2" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> <span class="fu">select_best</span>(iris_tune, <span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb454-3"><a href="supervised-learning.html#cb454-3" tabindex="-1"></a>final_iris_wf <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(iris_workflow, best_k)</span>
<span id="cb454-4"><a href="supervised-learning.html#cb454-4" tabindex="-1"></a>iris_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_iris_wf, <span class="at">data =</span> iris_train)</span>
<span id="cb454-5"><a href="supervised-learning.html#cb454-5" tabindex="-1"></a></span>
<span id="cb454-6"><a href="supervised-learning.html#cb454-6" tabindex="-1"></a><span class="co"># Predict and evaluate</span></span>
<span id="cb454-7"><a href="supervised-learning.html#cb454-7" tabindex="-1"></a>iris_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(iris_fit, <span class="at">new_data =</span> iris_test)</span>
<span id="cb454-8"><a href="supervised-learning.html#cb454-8" tabindex="-1"></a>iris_predictions <span class="sc">|&gt;</span> <span class="fu">conf_mat</span>(<span class="at">truth =</span> Species, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
</details>
</div>
<div id="simple-linear-regression" class="section level2 hasAnchor" number="11.6">
<h2><span class="header-section-number">11.6</span> Simple Linear Regression<a href="supervised-learning.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now we have to predict on continuous variables, the supervision algorithms for these cases are called <strong>regression</strong>.</p>
<p>To understand linear regression we are going to start with an example with a single variable as <em>input</em>, this is known as Simple Linear Regression. To do this we are going to use data from the <code>HistData</code> library where we will find a dataset that enumerates the individual observations of 934 children in 205 families stored in the object <code>GaltonFamilies</code>.</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="supervised-learning.html#cb455-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;HistData&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="supervised-learning.html#cb456-1" tabindex="-1"></a><span class="fu">library</span>(HistData)</span>
<span id="cb456-2"><a href="supervised-learning.html#cb456-2" tabindex="-1"></a><span class="fu">data</span>(GaltonFamilies)</span>
<span id="cb456-3"><a href="supervised-learning.html#cb456-3" tabindex="-1"></a></span>
<span id="cb456-4"><a href="supervised-learning.html#cb456-4" tabindex="-1"></a><span class="co"># We make some filters to have one dad and one son per family</span></span>
<span id="cb456-5"><a href="supervised-learning.html#cb456-5" tabindex="-1"></a>heights_df <span class="ot">&lt;-</span> GaltonFamilies <span class="sc">|&gt;</span></span>
<span id="cb456-6"><a href="supervised-learning.html#cb456-6" tabindex="-1"></a>  <span class="fu">filter</span>(gender <span class="sc">==</span> <span class="st">&quot;male&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb456-7"><a href="supervised-learning.html#cb456-7" tabindex="-1"></a>  <span class="fu">group_by</span>(family) <span class="sc">|&gt;</span></span>
<span id="cb456-8"><a href="supervised-learning.html#cb456-8" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">n =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> <span class="co"># random sample of 1 son per family</span></span>
<span id="cb456-9"><a href="supervised-learning.html#cb456-9" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">|&gt;</span></span>
<span id="cb456-10"><a href="supervised-learning.html#cb456-10" tabindex="-1"></a>  <span class="fu">select</span>(father, childHeight) <span class="sc">|&gt;</span></span>
<span id="cb456-11"><a href="supervised-learning.html#cb456-11" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">son =</span> childHeight) <span class="sc">|&gt;</span> </span>
<span id="cb456-12"><a href="supervised-learning.html#cb456-12" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">father =</span> father<span class="sc">/</span><span class="fl">39.37</span>) <span class="sc">|&gt;</span> <span class="co"># From inches to meters</span></span>
<span id="cb456-13"><a href="supervised-learning.html#cb456-13" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">son =</span> son<span class="sc">/</span><span class="fl">39.37</span>) <span class="co"># From inches to meters</span></span></code></pre></div>
<p>Visually we could see if there is a relationship between the heights of dad and son:</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="supervised-learning.html#cb457-1" tabindex="-1"></a>heights_df <span class="sc">|&gt;</span> </span>
<span id="cb457-2"><a href="supervised-learning.html#cb457-2" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb457-3"><a href="supervised-learning.html#cb457-3" tabindex="-1"></a>  <span class="fu">aes</span>(father, son) <span class="sc">+</span></span>
<span id="cb457-4"><a href="supervised-learning.html#cb457-4" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb457-5"><a href="supervised-learning.html#cb457-5" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Data-Science-with-R_files/figure-html/unnamed-chunk-605-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>As we can see, there is a positive correlation, such that the taller the father, the son grows to be taller as an adult. This line, however, is nothing more than a default line. The challenge lies in finding which line minimizes the distance of the points to this line, known as error minimization.</p>
<p>We could try to predict the height the son will have from the father’s height using the equation of this line:</p>
<p><span class="math inline">\(Y = \beta_0+\beta_1X\)</span></p>
<p>Where <span class="math inline">\(X\)</span> is an independent, explanatory variable, in this case the dad’s height. <span class="math inline">\(\beta_1\)</span> is a parameter that measures the influence that the explanatory variable has on the dependent variable <span class="math inline">\(Y\)</span> and <span class="math inline">\(\beta_0\)</span> is the intercept or constant term. In our case, the son’s height.</p>
<p>In statistics, <strong>linear regression</strong> or linear adjustment is a mathematical model used to approximate the dependency relationship between a dependent variable <span class="math inline">\(Y\)</span> and the independent variables <span class="math inline">\(X_i\)</span>.</p>
<p>Thus, our problem boils down to training our model to find the values of the intercept, <span class="math inline">\(\beta_0\)</span>, and the value of the parameter accompanying <span class="math inline">\(X_1\)</span>, <span class="math inline">\(\beta_1\)</span>, to then use these data as prediction in our test data.</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="supervised-learning.html#cb458-1" tabindex="-1"></a>heights_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(heights_df, <span class="at">prop =</span> <span class="fl">0.5</span>)</span>
<span id="cb458-2"><a href="supervised-learning.html#cb458-2" tabindex="-1"></a></span>
<span id="cb458-3"><a href="supervised-learning.html#cb458-3" tabindex="-1"></a>heights_train <span class="ot">&lt;-</span> <span class="fu">training</span>(heights_split)</span>
<span id="cb458-4"><a href="supervised-learning.html#cb458-4" tabindex="-1"></a>heights_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(heights_split)</span></code></pre></div>
<p>Now that we have our data we can train our model using tidymodels. We specify a linear regression model with <code>linear_reg()</code>.</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="supervised-learning.html#cb459-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb459-2"><a href="supervised-learning.html#cb459-2" tabindex="-1"></a>lm_spec <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">|&gt;</span></span>
<span id="cb459-3"><a href="supervised-learning.html#cb459-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb459-4"><a href="supervised-learning.html#cb459-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb459-5"><a href="supervised-learning.html#cb459-5" tabindex="-1"></a></span>
<span id="cb459-6"><a href="supervised-learning.html#cb459-6" tabindex="-1"></a><span class="co"># Recipe</span></span>
<span id="cb459-7"><a href="supervised-learning.html#cb459-7" tabindex="-1"></a>lm_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(son <span class="sc">~</span> father, <span class="at">data =</span> heights_train)</span>
<span id="cb459-8"><a href="supervised-learning.html#cb459-8" tabindex="-1"></a></span>
<span id="cb459-9"><a href="supervised-learning.html#cb459-9" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb459-10"><a href="supervised-learning.html#cb459-10" tabindex="-1"></a>lm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb459-11"><a href="supervised-learning.html#cb459-11" tabindex="-1"></a>  <span class="fu">add_recipe</span>(lm_recipe) <span class="sc">|&gt;</span></span>
<span id="cb459-12"><a href="supervised-learning.html#cb459-12" tabindex="-1"></a>  <span class="fu">add_model</span>(lm_spec)</span>
<span id="cb459-13"><a href="supervised-learning.html#cb459-13" tabindex="-1"></a></span>
<span id="cb459-14"><a href="supervised-learning.html#cb459-14" tabindex="-1"></a><span class="co"># Cross-validation</span></span>
<span id="cb459-15"><a href="supervised-learning.html#cb459-15" tabindex="-1"></a>heights_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(heights_train, <span class="at">v =</span> <span class="dv">10</span>)</span>
<span id="cb459-16"><a href="supervised-learning.html#cb459-16" tabindex="-1"></a>lm_results <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(lm_workflow, <span class="at">resamples =</span> heights_folds)</span>
<span id="cb459-17"><a href="supervised-learning.html#cb459-17" tabindex="-1"></a></span>
<span id="cb459-18"><a href="supervised-learning.html#cb459-18" tabindex="-1"></a><span class="co"># View results</span></span>
<span id="cb459-19"><a href="supervised-learning.html#cb459-19" tabindex="-1"></a><span class="fu">collect_metrics</span>(lm_results)</span>
<span id="cb459-20"><a href="supervised-learning.html#cb459-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb459-21"><a href="supervised-learning.html#cb459-21" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator   mean     n std_err .config        </span></span>
<span id="cb459-22"><a href="supervised-learning.html#cb459-22" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          </span></span>
<span id="cb459-23"><a href="supervised-learning.html#cb459-23" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard   0.0584    10 0.00362 pre0_mod0_post0</span></span>
<span id="cb459-24"><a href="supervised-learning.html#cb459-24" tabindex="-1"></a><span class="co">#&gt; 2 rsq     standard   0.362     10 0.0821  pre0_mod0_post0</span></span></code></pre></div>
<p>We see as main results the RMSE, which stands for root mean square error, and is the value that linear regression seeks to minimize. In addition, we have the R squared or <span class="math inline">\(R^2\)</span>, which is the coefficient of determination which determines the quality of the model to replicate the results. The higher and closer to 1, the better the quality of the model.</p>
<blockquote>
<p>[!WARNING]
<strong>Correlation implies association, not causation</strong>: A high <span class="math inline">\(R^2\)</span> or strong correlation means the variables move together, but it does <strong>not</strong> prove that one causes the other. There could be confounding variables at play.</p>
</blockquote>
<p>Now let’s fit the final model and make predictions:</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="supervised-learning.html#cb460-1" tabindex="-1"></a><span class="co"># Fit final model</span></span>
<span id="cb460-2"><a href="supervised-learning.html#cb460-2" tabindex="-1"></a>heights_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(lm_workflow, <span class="at">data =</span> heights_train)</span>
<span id="cb460-3"><a href="supervised-learning.html#cb460-3" tabindex="-1"></a></span>
<span id="cb460-4"><a href="supervised-learning.html#cb460-4" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb460-5"><a href="supervised-learning.html#cb460-5" tabindex="-1"></a>heights_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(heights_fit, <span class="at">new_data =</span> heights_test)</span>
<span id="cb460-6"><a href="supervised-learning.html#cb460-6" tabindex="-1"></a></span>
<span id="cb460-7"><a href="supervised-learning.html#cb460-7" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb460-8"><a href="supervised-learning.html#cb460-8" tabindex="-1"></a>heights_predictions <span class="sc">|&gt;</span></span>
<span id="cb460-9"><a href="supervised-learning.html#cb460-9" tabindex="-1"></a>  <span class="fu">rmse</span>(<span class="at">truth =</span> son, <span class="at">estimate =</span> .pred)</span>
<span id="cb460-10"><a href="supervised-learning.html#cb460-10" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb460-11"><a href="supervised-learning.html#cb460-11" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator .estimate</span></span>
<span id="cb460-12"><a href="supervised-learning.html#cb460-12" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb460-13"><a href="supervised-learning.html#cb460-13" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard      0.0642</span></span></code></pre></div>
<blockquote>
<p>[!TIP]
<strong>Model Diagnostics</strong>: In a rigorous analysis, you should also inspect the <strong>residuals</strong> (the difference between predicted and actual values). The <code>augment()</code> function includes a <code>.resid</code> column for this purpose. Plotting residuals helps verify that your model isn’t missing non-linear patterns.</p>
</blockquote>
<p>If we wish we can also report the coefficients of the equation and visualize them:</p>
<p><span class="math inline">\(Y = \beta_0+\beta_1X\)</span></p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="supervised-learning.html#cb461-1" tabindex="-1"></a><span class="co"># Extract model coefficients</span></span>
<span id="cb461-2"><a href="supervised-learning.html#cb461-2" tabindex="-1"></a>heights_fit <span class="sc">|&gt;</span> <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb461-3"><a href="supervised-learning.html#cb461-3" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 5</span></span>
<span id="cb461-4"><a href="supervised-learning.html#cb461-4" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic      p.value</span></span>
<span id="cb461-5"><a href="supervised-learning.html#cb461-5" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;</span></span>
<span id="cb461-6"><a href="supervised-learning.html#cb461-6" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)    0.644     0.183      3.51 0.000708    </span></span>
<span id="cb461-7"><a href="supervised-learning.html#cb461-7" tabindex="-1"></a><span class="co">#&gt; 2 father         0.631     0.104      6.05 0.0000000361</span></span>
<span id="cb461-8"><a href="supervised-learning.html#cb461-8" tabindex="-1"></a></span>
<span id="cb461-9"><a href="supervised-learning.html#cb461-9" tabindex="-1"></a>model_coefs <span class="ot">&lt;-</span> heights_fit <span class="sc">|&gt;</span> <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb461-10"><a href="supervised-learning.html#cb461-10" tabindex="-1"></a>intercept_val <span class="ot">&lt;-</span> model_coefs<span class="sc">$</span>estimate[<span class="dv">1</span>]</span>
<span id="cb461-11"><a href="supervised-learning.html#cb461-11" tabindex="-1"></a>slope_val <span class="ot">&lt;-</span> model_coefs<span class="sc">$</span>estimate[<span class="dv">2</span>]</span>
<span id="cb461-12"><a href="supervised-learning.html#cb461-12" tabindex="-1"></a></span>
<span id="cb461-13"><a href="supervised-learning.html#cb461-13" tabindex="-1"></a><span class="co">#Visualization</span></span>
<span id="cb461-14"><a href="supervised-learning.html#cb461-14" tabindex="-1"></a>heights_df <span class="sc">|&gt;</span> </span>
<span id="cb461-15"><a href="supervised-learning.html#cb461-15" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb461-16"><a href="supervised-learning.html#cb461-16" tabindex="-1"></a>  <span class="fu">aes</span>(father, son) <span class="sc">+</span></span>
<span id="cb461-17"><a href="supervised-learning.html#cb461-17" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb461-18"><a href="supervised-learning.html#cb461-18" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">lty =</span> <span class="dv">2</span>, <span class="at">intercept =</span> intercept_val, <span class="at">slope =</span> slope_val, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Data-Science-with-R_files/figure-html/unnamed-chunk-609-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="multiple-linear-regression" class="section level2 hasAnchor" number="11.7">
<h2><span class="header-section-number">11.7</span> Multiple Linear Regression<a href="supervised-learning.html#multiple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we know linear regression we can execute a multiple linear regression model, which involves more than 1 variable as <em>input</em>. To do this, we will use the <code>diamonds</code> dataset containing the prices and other attributes of almost 54,000 diamonds.</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="supervised-learning.html#cb462-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb462-2"><a href="supervised-learning.html#cb462-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;diamonds&quot;</span>)</span>
<span id="cb462-3"><a href="supervised-learning.html#cb462-3" tabindex="-1"></a></span>
<span id="cb462-4"><a href="supervised-learning.html#cb462-4" tabindex="-1"></a>diamonds <span class="ot">&lt;-</span> diamonds <span class="sc">|&gt;</span> </span>
<span id="cb462-5"><a href="supervised-learning.html#cb462-5" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">price =</span> price)</span>
<span id="cb462-6"><a href="supervised-learning.html#cb462-6" tabindex="-1"></a></span>
<span id="cb462-7"><a href="supervised-learning.html#cb462-7" tabindex="-1"></a>diamonds <span class="sc">|&gt;</span> </span>
<span id="cb462-8"><a href="supervised-learning.html#cb462-8" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb462-9"><a href="supervised-learning.html#cb462-9" tabindex="-1"></a><span class="co">#&gt; # A tibble: 10 × 10</span></span>
<span id="cb462-10"><a href="supervised-learning.html#cb462-10" tabindex="-1"></a><span class="co">#&gt;    carat cut       color clarity depth table price     x     y     z</span></span>
<span id="cb462-11"><a href="supervised-learning.html#cb462-11" tabindex="-1"></a><span class="co">#&gt;    &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb462-12"><a href="supervised-learning.html#cb462-12" tabindex="-1"></a><span class="co">#&gt;  1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43</span></span>
<span id="cb462-13"><a href="supervised-learning.html#cb462-13" tabindex="-1"></a><span class="co">#&gt;  2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31</span></span>
<span id="cb462-14"><a href="supervised-learning.html#cb462-14" tabindex="-1"></a><span class="co">#&gt;  3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31</span></span>
<span id="cb462-15"><a href="supervised-learning.html#cb462-15" tabindex="-1"></a><span class="co">#&gt;  4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63</span></span>
<span id="cb462-16"><a href="supervised-learning.html#cb462-16" tabindex="-1"></a><span class="co">#&gt;  5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75</span></span>
<span id="cb462-17"><a href="supervised-learning.html#cb462-17" tabindex="-1"></a><span class="co">#&gt;  6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48</span></span>
<span id="cb462-18"><a href="supervised-learning.html#cb462-18" tabindex="-1"></a><span class="co">#&gt;  7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47</span></span>
<span id="cb462-19"><a href="supervised-learning.html#cb462-19" tabindex="-1"></a><span class="co">#&gt;  8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53</span></span>
<span id="cb462-20"><a href="supervised-learning.html#cb462-20" tabindex="-1"></a><span class="co">#&gt;  9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49</span></span>
<span id="cb462-21"><a href="supervised-learning.html#cb462-21" tabindex="-1"></a><span class="co">#&gt; 10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39</span></span></code></pre></div>
<p>We split the data in two taking 70% of data for training:</p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="supervised-learning.html#cb463-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb463-2"><a href="supervised-learning.html#cb463-2" tabindex="-1"></a>diamonds_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(diamonds, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> price)</span>
<span id="cb463-3"><a href="supervised-learning.html#cb463-3" tabindex="-1"></a></span>
<span id="cb463-4"><a href="supervised-learning.html#cb463-4" tabindex="-1"></a>diamonds_train <span class="ot">&lt;-</span> <span class="fu">training</span>(diamonds_split)</span>
<span id="cb463-5"><a href="supervised-learning.html#cb463-5" tabindex="-1"></a>diamonds_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(diamonds_split)</span></code></pre></div>
<p>We now create our multiple linear regression model and report both the error results and the coefficients of the linear equation using a tidymodels workflow.</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="supervised-learning.html#cb464-1" tabindex="-1"></a><span class="co"># Model specification</span></span>
<span id="cb464-2"><a href="supervised-learning.html#cb464-2" tabindex="-1"></a>diamonds_spec <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">|&gt;</span></span>
<span id="cb464-3"><a href="supervised-learning.html#cb464-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb464-4"><a href="supervised-learning.html#cb464-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb464-5"><a href="supervised-learning.html#cb464-5" tabindex="-1"></a></span>
<span id="cb464-6"><a href="supervised-learning.html#cb464-6" tabindex="-1"></a><span class="co"># Recipe</span></span>
<span id="cb464-7"><a href="supervised-learning.html#cb464-7" tabindex="-1"></a>diamonds_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(price <span class="sc">~</span> ., <span class="at">data =</span> diamonds_train)</span>
<span id="cb464-8"><a href="supervised-learning.html#cb464-8" tabindex="-1"></a></span>
<span id="cb464-9"><a href="supervised-learning.html#cb464-9" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb464-10"><a href="supervised-learning.html#cb464-10" tabindex="-1"></a>diamonds_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb464-11"><a href="supervised-learning.html#cb464-11" tabindex="-1"></a>  <span class="fu">add_recipe</span>(diamonds_recipe) <span class="sc">|&gt;</span></span>
<span id="cb464-12"><a href="supervised-learning.html#cb464-12" tabindex="-1"></a>  <span class="fu">add_model</span>(diamonds_spec)</span>
<span id="cb464-13"><a href="supervised-learning.html#cb464-13" tabindex="-1"></a></span>
<span id="cb464-14"><a href="supervised-learning.html#cb464-14" tabindex="-1"></a><span class="co"># Cross-validation</span></span>
<span id="cb464-15"><a href="supervised-learning.html#cb464-15" tabindex="-1"></a>diamonds_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(diamonds_train, <span class="at">v =</span> <span class="dv">10</span>)</span>
<span id="cb464-16"><a href="supervised-learning.html#cb464-16" tabindex="-1"></a>diamonds_results <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(diamonds_workflow, <span class="at">resamples =</span> diamonds_folds)</span>
<span id="cb464-17"><a href="supervised-learning.html#cb464-17" tabindex="-1"></a></span>
<span id="cb464-18"><a href="supervised-learning.html#cb464-18" tabindex="-1"></a><span class="fu">collect_metrics</span>(diamonds_results)</span>
<span id="cb464-19"><a href="supervised-learning.html#cb464-19" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb464-20"><a href="supervised-learning.html#cb464-20" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator     mean     n  std_err .config        </span></span>
<span id="cb464-21"><a href="supervised-learning.html#cb464-21" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          </span></span>
<span id="cb464-22"><a href="supervised-learning.html#cb464-22" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard   1136.       10 19.7     pre0_mod0_post0</span></span>
<span id="cb464-23"><a href="supervised-learning.html#cb464-23" tabindex="-1"></a><span class="co">#&gt; 2 rsq     standard      0.919    10  0.00256 pre0_mod0_post0</span></span></code></pre></div>
<p>We see that it gives us the RMSE and an R squared quite closer to 1, which denotes a high quality of the model to replicate the results.</p>
<p>Let’s use our model to predict the prices of the test data.</p>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="supervised-learning.html#cb465-1" tabindex="-1"></a><span class="co"># Fit final model</span></span>
<span id="cb465-2"><a href="supervised-learning.html#cb465-2" tabindex="-1"></a>diamonds_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(diamonds_workflow, <span class="at">data =</span> diamonds_train)</span>
<span id="cb465-3"><a href="supervised-learning.html#cb465-3" tabindex="-1"></a></span>
<span id="cb465-4"><a href="supervised-learning.html#cb465-4" tabindex="-1"></a><span class="co"># Extract coefficients</span></span>
<span id="cb465-5"><a href="supervised-learning.html#cb465-5" tabindex="-1"></a>diamonds_fit <span class="sc">|&gt;</span> <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb465-6"><a href="supervised-learning.html#cb465-6" tabindex="-1"></a><span class="co">#&gt; # A tibble: 24 × 5</span></span>
<span id="cb465-7"><a href="supervised-learning.html#cb465-7" tabindex="-1"></a><span class="co">#&gt;    term        estimate std.error statistic   p.value</span></span>
<span id="cb465-8"><a href="supervised-learning.html#cb465-8" tabindex="-1"></a><span class="co">#&gt;    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb465-9"><a href="supervised-learning.html#cb465-9" tabindex="-1"></a><span class="co">#&gt;  1 (Intercept)   6975.      473.      14.7  5.45e- 49</span></span>
<span id="cb465-10"><a href="supervised-learning.html#cb465-10" tabindex="-1"></a><span class="co">#&gt;  2 carat        11437.       60.7    188.   0        </span></span>
<span id="cb465-11"><a href="supervised-learning.html#cb465-11" tabindex="-1"></a><span class="co">#&gt;  3 cut.L          571.       27.1     21.1  7.51e- 98</span></span>
<span id="cb465-12"><a href="supervised-learning.html#cb465-12" tabindex="-1"></a><span class="co">#&gt;  4 cut.Q         -305.       21.7    -14.0  1.07e- 44</span></span>
<span id="cb465-13"><a href="supervised-learning.html#cb465-13" tabindex="-1"></a><span class="co">#&gt;  5 cut.C          139.       18.6      7.48 7.72e- 14</span></span>
<span id="cb465-14"><a href="supervised-learning.html#cb465-14" tabindex="-1"></a><span class="co">#&gt;  6 cut^4          -23.2      14.8     -1.56 1.18e-  1</span></span>
<span id="cb465-15"><a href="supervised-learning.html#cb465-15" tabindex="-1"></a><span class="co">#&gt;  7 color.L      -1980.       20.8    -95.1  0        </span></span>
<span id="cb465-16"><a href="supervised-learning.html#cb465-16" tabindex="-1"></a><span class="co">#&gt;  8 color.Q       -685.       19.0    -36.1  6.69e-281</span></span>
<span id="cb465-17"><a href="supervised-learning.html#cb465-17" tabindex="-1"></a><span class="co">#&gt;  9 color.C       -186.       17.7    -10.5  6.23e- 26</span></span>
<span id="cb465-18"><a href="supervised-learning.html#cb465-18" tabindex="-1"></a><span class="co">#&gt; 10 color^4         36.8      16.2      2.27 2.33e-  2</span></span>
<span id="cb465-19"><a href="supervised-learning.html#cb465-19" tabindex="-1"></a><span class="co">#&gt; # ℹ 14 more rows</span></span>
<span id="cb465-20"><a href="supervised-learning.html#cb465-20" tabindex="-1"></a></span>
<span id="cb465-21"><a href="supervised-learning.html#cb465-21" tabindex="-1"></a><span class="co"># Prediction and Error calculation</span></span>
<span id="cb465-22"><a href="supervised-learning.html#cb465-22" tabindex="-1"></a>diamonds_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(diamonds_fit, <span class="at">new_data =</span> diamonds_test)</span>
<span id="cb465-23"><a href="supervised-learning.html#cb465-23" tabindex="-1"></a></span>
<span id="cb465-24"><a href="supervised-learning.html#cb465-24" tabindex="-1"></a><span class="co"># Mean Squared Error Calculation RMSE:</span></span>
<span id="cb465-25"><a href="supervised-learning.html#cb465-25" tabindex="-1"></a>diamonds_predictions <span class="sc">|&gt;</span></span>
<span id="cb465-26"><a href="supervised-learning.html#cb465-26" tabindex="-1"></a>  <span class="fu">rmse</span>(<span class="at">truth =</span> price, <span class="at">estimate =</span> .pred)</span>
<span id="cb465-27"><a href="supervised-learning.html#cb465-27" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb465-28"><a href="supervised-learning.html#cb465-28" tabindex="-1"></a><span class="co">#&gt;   .metric .estimator .estimate</span></span>
<span id="cb465-29"><a href="supervised-learning.html#cb465-29" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb465-30"><a href="supervised-learning.html#cb465-30" tabindex="-1"></a><span class="co">#&gt; 1 rmse    standard       1119.</span></span></code></pre></div>
<p>Thus, we have learned to perform one more machine learning model: linear regression, both simple and multiple.</p>
</div>
<div id="standard-method-for-evaluating-accuracy" class="section level2 hasAnchor" number="11.8">
<h2><span class="header-section-number">11.8</span> Standard Method for Evaluating Accuracy<a href="supervised-learning.html#standard-method-for-evaluating-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we know how to build models we will apply metrics that allow us better accuracy in classification models for <strong>two classes</strong>.</p>
<p>To do this let’s recall the results of the model we created using the k-nearest neighbors algorithm to predict if the S&amp;P index goes up or down.</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="supervised-learning.html#cb466-1" tabindex="-1"></a>SP_knn_trained</span>
<span id="cb466-2"><a href="supervised-learning.html#cb466-2" tabindex="-1"></a><span class="co">#&gt; ══ Workflow [trained] ═══════════════════════════════</span></span>
<span id="cb466-3"><a href="supervised-learning.html#cb466-3" tabindex="-1"></a><span class="co">#&gt; Preprocessor: Recipe</span></span>
<span id="cb466-4"><a href="supervised-learning.html#cb466-4" tabindex="-1"></a><span class="co">#&gt; Model: nearest_neighbor()</span></span>
<span id="cb466-5"><a href="supervised-learning.html#cb466-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb466-6"><a href="supervised-learning.html#cb466-6" tabindex="-1"></a><span class="co">#&gt; ── Preprocessor ─────────────────────────────────────</span></span>
<span id="cb466-7"><a href="supervised-learning.html#cb466-7" tabindex="-1"></a><span class="co">#&gt; 1 Recipe Step</span></span>
<span id="cb466-8"><a href="supervised-learning.html#cb466-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb466-9"><a href="supervised-learning.html#cb466-9" tabindex="-1"></a><span class="co">#&gt; • step_normalize()</span></span>
<span id="cb466-10"><a href="supervised-learning.html#cb466-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb466-11"><a href="supervised-learning.html#cb466-11" tabindex="-1"></a><span class="co">#&gt; ── Model ────────────────────────────────────────────</span></span>
<span id="cb466-12"><a href="supervised-learning.html#cb466-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb466-13"><a href="supervised-learning.html#cb466-13" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb466-14"><a href="supervised-learning.html#cb466-14" tabindex="-1"></a><span class="co">#&gt; kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(44L,     data, 5))</span></span>
<span id="cb466-15"><a href="supervised-learning.html#cb466-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb466-16"><a href="supervised-learning.html#cb466-16" tabindex="-1"></a><span class="co">#&gt; Type of response variable: nominal</span></span>
<span id="cb466-17"><a href="supervised-learning.html#cb466-17" tabindex="-1"></a><span class="co">#&gt; Minimal misclassification: 0.0864461</span></span>
<span id="cb466-18"><a href="supervised-learning.html#cb466-18" tabindex="-1"></a><span class="co">#&gt; Best kernel: optimal</span></span>
<span id="cb466-19"><a href="supervised-learning.html#cb466-19" tabindex="-1"></a><span class="co">#&gt; Best k: 44</span></span></code></pre></div>
<p>In the penultimate line it can be read that <strong>accuracy</strong> (<code>accuracy</code>) was used to select the most optimal model using the largest value. However, this is not the only way to determine which is the most optimal model.</p>
<p>Let’s remember how accuracy (<em>accuracy</em>) is calculated by default, we have used the simple rule that if the probability of it being of a certain class is more than 50% then that class is assigned and then we calculate the proportion of hits among the total cases.</p>
<p>However, it doesn’t have to be 50%, we could be more demanding and indicate that if the probability is greater than 60% or 80% then a certain class is assigned. We see that there are different probabilities and that would give us different <code>accuracy</code>.</p>
<p>This is how the area under the Receiver Operating Characteristic curve indicator arises, <em>ROC</em> <span class="citation">(<a href="#ref-Fawcett2005">Fawcett 2005</a>)</span>. This indicator measures how well a model can distinguish between two classes and is considered the standard method for evaluating the accuracy of predictive distribution models <span class="citation">(<a href="#ref-Lobo2007">Jorge M. Lobo 2007</a>)</span> and calculates accuracies not only for when we discriminate starting from 50%, but for more probability values.</p>
<p>To use this metric we will modify our control parameters adding three attributes that will allow calculating the ROC.</p>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="supervised-learning.html#cb467-1" tabindex="-1"></a>SP2_ctrl <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(roc_auc, accuracy)</span>
<span id="cb467-2"><a href="supervised-learning.html#cb467-2" tabindex="-1"></a></span>
<span id="cb467-3"><a href="supervised-learning.html#cb467-3" tabindex="-1"></a><span class="co"># We define folds</span></span>
<span id="cb467-4"><a href="supervised-learning.html#cb467-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb467-5"><a href="supervised-learning.html#cb467-5" tabindex="-1"></a>SP2_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(SP_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> Direction)</span></code></pre></div>
<p>With these modified parameters we will proceed to re-train our model selecting by ROC AUC.</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="supervised-learning.html#cb468-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb468-2"><a href="supervised-learning.html#cb468-2" tabindex="-1"></a></span>
<span id="cb468-3"><a href="supervised-learning.html#cb468-3" tabindex="-1"></a><span class="co"># Tune grid specifying ROC as the metric to optimize</span></span>
<span id="cb468-4"><a href="supervised-learning.html#cb468-4" tabindex="-1"></a>SP2_knn_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb468-5"><a href="supervised-learning.html#cb468-5" tabindex="-1"></a>  knn_workflow,</span>
<span id="cb468-6"><a href="supervised-learning.html#cb468-6" tabindex="-1"></a>  <span class="at">resamples =</span> SP2_folds,</span>
<span id="cb468-7"><a href="supervised-learning.html#cb468-7" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">20</span>,</span>
<span id="cb468-8"><a href="supervised-learning.html#cb468-8" tabindex="-1"></a>  <span class="at">metrics =</span> SP2_ctrl</span>
<span id="cb468-9"><a href="supervised-learning.html#cb468-9" tabindex="-1"></a>)</span>
<span id="cb468-10"><a href="supervised-learning.html#cb468-10" tabindex="-1"></a></span>
<span id="cb468-11"><a href="supervised-learning.html#cb468-11" tabindex="-1"></a><span class="fu">show_best</span>(SP2_knn_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb468-12"><a href="supervised-learning.html#cb468-12" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 7</span></span>
<span id="cb468-13"><a href="supervised-learning.html#cb468-13" tabindex="-1"></a><span class="co">#&gt;   neighbors .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb468-14"><a href="supervised-learning.html#cb468-14" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb468-15"><a href="supervised-learning.html#cb468-15" tabindex="-1"></a><span class="co">#&gt; 1        15 roc_auc binary     0.965     5 0.00586 pre0_mod13_post0</span></span>
<span id="cb468-16"><a href="supervised-learning.html#cb468-16" tabindex="-1"></a><span class="co">#&gt; 2        13 roc_auc binary     0.962     5 0.00632 pre0_mod12_post0</span></span>
<span id="cb468-17"><a href="supervised-learning.html#cb468-17" tabindex="-1"></a><span class="co">#&gt; 3        12 roc_auc binary     0.960     5 0.00667 pre0_mod11_post0</span></span>
<span id="cb468-18"><a href="supervised-learning.html#cb468-18" tabindex="-1"></a><span class="co">#&gt; 4        11 roc_auc binary     0.957     5 0.00717 pre0_mod10_post0</span></span>
<span id="cb468-19"><a href="supervised-learning.html#cb468-19" tabindex="-1"></a><span class="co">#&gt; 5        10 roc_auc binary     0.955     5 0.00739 pre0_mod09_post0</span></span></code></pre></div>
<p>We see that now ROC was used to select the most optimal model. The closer the ROC value is to 1 the better our model will be. With this model we can predict values from the test data.</p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="supervised-learning.html#cb469-1" tabindex="-1"></a><span class="co"># Select best k based on ROC</span></span>
<span id="cb469-2"><a href="supervised-learning.html#cb469-2" tabindex="-1"></a>best_k_roc <span class="ot">&lt;-</span> <span class="fu">select_best</span>(SP2_knn_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb469-3"><a href="supervised-learning.html#cb469-3" tabindex="-1"></a></span>
<span id="cb469-4"><a href="supervised-learning.html#cb469-4" tabindex="-1"></a><span class="co"># Finalize workflow</span></span>
<span id="cb469-5"><a href="supervised-learning.html#cb469-5" tabindex="-1"></a>final_knn_roc <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(knn_workflow, best_k_roc)</span>
<span id="cb469-6"><a href="supervised-learning.html#cb469-6" tabindex="-1"></a></span>
<span id="cb469-7"><a href="supervised-learning.html#cb469-7" tabindex="-1"></a><span class="co"># Fit and predict</span></span>
<span id="cb469-8"><a href="supervised-learning.html#cb469-8" tabindex="-1"></a>SP2_knn_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_knn_roc, <span class="at">data =</span> SP_train)</span>
<span id="cb469-9"><a href="supervised-learning.html#cb469-9" tabindex="-1"></a>SP2_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(SP2_knn_fit, <span class="at">new_data =</span> SP_test)</span>
<span id="cb469-10"><a href="supervised-learning.html#cb469-10" tabindex="-1"></a></span>
<span id="cb469-11"><a href="supervised-learning.html#cb469-11" tabindex="-1"></a><span class="co"># Evaluate</span></span>
<span id="cb469-12"><a href="supervised-learning.html#cb469-12" tabindex="-1"></a>SP2_predictions <span class="sc">|&gt;</span></span>
<span id="cb469-13"><a href="supervised-learning.html#cb469-13" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb469-14"><a href="supervised-learning.html#cb469-14" tabindex="-1"></a><span class="co">#&gt;           Truth</span></span>
<span id="cb469-15"><a href="supervised-learning.html#cb469-15" tabindex="-1"></a><span class="co">#&gt; Prediction Down  Up</span></span>
<span id="cb469-16"><a href="supervised-learning.html#cb469-16" tabindex="-1"></a><span class="co">#&gt;       Down  135  15</span></span>
<span id="cb469-17"><a href="supervised-learning.html#cb469-17" tabindex="-1"></a><span class="co">#&gt;       Up     16 147</span></span>
<span id="cb469-18"><a href="supervised-learning.html#cb469-18" tabindex="-1"></a></span>
<span id="cb469-19"><a href="supervised-learning.html#cb469-19" tabindex="-1"></a>SP2_predictions <span class="sc">|&gt;</span></span>
<span id="cb469-20"><a href="supervised-learning.html#cb469-20" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Direction, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb469-21"><a href="supervised-learning.html#cb469-21" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb469-22"><a href="supervised-learning.html#cb469-22" tabindex="-1"></a><span class="co">#&gt;   .metric  .estimator .estimate</span></span>
<span id="cb469-23"><a href="supervised-learning.html#cb469-23" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb469-24"><a href="supervised-learning.html#cb469-24" tabindex="-1"></a><span class="co">#&gt; 1 accuracy binary         0.901</span></span></code></pre></div>
<p>We see how our accuracy (<em>accuracy</em>) has increased from 91.99% to <strong>93.27%</strong>. This metric is highly recommended to improve the accuracy of our model, in addition to allowing us to more easily use it as a comparator between different models we can create.</p>
</div>
<div id="selection-of-the-most-optimal-model" class="section level2 hasAnchor" number="11.9">
<h2><span class="header-section-number">11.9</span> Selection of the Most Optimal Model<a href="supervised-learning.html#selection-of-the-most-optimal-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have learned how to create some machine learning models. As we must have noticed, with <strong>tidymodels</strong> we follow the same pattern for partitioning, training, and prediction. The variation lies in how to pre-process the data and the parameter tuning. We could thus create multiple models, but finally we have to verify one which will serve us to make our predictions.</p>
<p>In this section, we are going to compare different predictive models accepting their default values and choose the best one using the tools presented in previous sections.</p>
<p>To do this, we are going to use a new case. This time we are evaluating the behavior of our 5,000 clients, some of whom have unsubscribed from our services. We have 19 predictors, most of them numeric, in the <code>mlc_churn</code> dataset. To access the data we have to load the <code>modeldata</code> library.</p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="supervised-learning.html#cb470-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;modeldata&quot;</span>)</span>
<span id="cb470-2"><a href="supervised-learning.html#cb470-2" tabindex="-1"></a><span class="fu">library</span>(modeldata)</span></code></pre></div>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="supervised-learning.html#cb471-1" tabindex="-1"></a><span class="fu">data</span>(mlc_churn)</span>
<span id="cb471-2"><a href="supervised-learning.html#cb471-2" tabindex="-1"></a></span>
<span id="cb471-3"><a href="supervised-learning.html#cb471-3" tabindex="-1"></a><span class="fu">str</span>(mlc_churn)</span>
<span id="cb471-4"><a href="supervised-learning.html#cb471-4" tabindex="-1"></a><span class="co">#&gt; tibble [5,000 × 20] (S3: tbl_df/tbl/data.frame)</span></span>
<span id="cb471-5"><a href="supervised-learning.html#cb471-5" tabindex="-1"></a><span class="co">#&gt;  $ state                        : Factor w/ 51 levels &quot;AK&quot;,&quot;AL&quot;,&quot;AR&quot;,..: 17 36 32 36 37 2 20 25 19 50 ...</span></span>
<span id="cb471-6"><a href="supervised-learning.html#cb471-6" tabindex="-1"></a><span class="co">#&gt;  $ account_length               : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ...</span></span>
<span id="cb471-7"><a href="supervised-learning.html#cb471-7" tabindex="-1"></a><span class="co">#&gt;  $ area_code                    : Factor w/ 3 levels &quot;area_code_408&quot;,..: 2 2 2 1 2 3 3 2 1 2 ...</span></span>
<span id="cb471-8"><a href="supervised-learning.html#cb471-8" tabindex="-1"></a><span class="co">#&gt;  $ international_plan           : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 2 2 2 1 2 1 2 ...</span></span>
<span id="cb471-9"><a href="supervised-learning.html#cb471-9" tabindex="-1"></a><span class="co">#&gt;  $ voice_mail_plan              : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 1 1 2 1 1 2 ...</span></span>
<span id="cb471-10"><a href="supervised-learning.html#cb471-10" tabindex="-1"></a><span class="co">#&gt;  $ number_vmail_messages        : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ...</span></span>
<span id="cb471-11"><a href="supervised-learning.html#cb471-11" tabindex="-1"></a><span class="co">#&gt;  $ total_day_minutes            : num [1:5000] 265 162 243 299 167 ...</span></span>
<span id="cb471-12"><a href="supervised-learning.html#cb471-12" tabindex="-1"></a><span class="co">#&gt;  $ total_day_calls              : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ...</span></span>
<span id="cb471-13"><a href="supervised-learning.html#cb471-13" tabindex="-1"></a><span class="co">#&gt;  $ total_day_charge             : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ...</span></span>
<span id="cb471-14"><a href="supervised-learning.html#cb471-14" tabindex="-1"></a><span class="co">#&gt;  $ total_eve_minutes            : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ...</span></span>
<span id="cb471-15"><a href="supervised-learning.html#cb471-15" tabindex="-1"></a><span class="co">#&gt;  $ total_eve_calls              : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ...</span></span>
<span id="cb471-16"><a href="supervised-learning.html#cb471-16" tabindex="-1"></a><span class="co">#&gt;  $ total_eve_charge             : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ...</span></span>
<span id="cb471-17"><a href="supervised-learning.html#cb471-17" tabindex="-1"></a><span class="co">#&gt;  $ total_night_minutes          : num [1:5000] 245 254 163 197 187 ...</span></span>
<span id="cb471-18"><a href="supervised-learning.html#cb471-18" tabindex="-1"></a><span class="co">#&gt;  $ total_night_calls            : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ...</span></span>
<span id="cb471-19"><a href="supervised-learning.html#cb471-19" tabindex="-1"></a><span class="co">#&gt;  $ total_night_charge           : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ...</span></span>
<span id="cb471-20"><a href="supervised-learning.html#cb471-20" tabindex="-1"></a><span class="co">#&gt;  $ total_intl_minutes           : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ...</span></span>
<span id="cb471-21"><a href="supervised-learning.html#cb471-21" tabindex="-1"></a><span class="co">#&gt;  $ total_intl_calls             : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ...</span></span>
<span id="cb471-22"><a href="supervised-learning.html#cb471-22" tabindex="-1"></a><span class="co">#&gt;  $ total_intl_charge            : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ...</span></span>
<span id="cb471-23"><a href="supervised-learning.html#cb471-23" tabindex="-1"></a><span class="co">#&gt;  $ number_customer_service_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ...</span></span>
<span id="cb471-24"><a href="supervised-learning.html#cb471-24" tabindex="-1"></a><span class="co">#&gt;  $ churn                        : Factor w/ 2 levels &quot;yes&quot;,&quot;no&quot;: 2 2 2 2 2 2 2 2 2 2 ...</span></span>
<span id="cb471-25"><a href="supervised-learning.html#cb471-25" tabindex="-1"></a></span>
<span id="cb471-26"><a href="supervised-learning.html#cb471-26" tabindex="-1"></a><span class="co"># We translate outputs</span></span>
<span id="cb471-27"><a href="supervised-learning.html#cb471-27" tabindex="-1"></a>mlc_churn <span class="ot">&lt;-</span> mlc_churn <span class="sc">|&gt;</span> </span>
<span id="cb471-28"><a href="supervised-learning.html#cb471-28" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">churn_status =</span> churn) <span class="sc">|&gt;</span> </span>
<span id="cb471-29"><a href="supervised-learning.html#cb471-29" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">churn_status =</span> <span class="fu">ifelse</span>(churn_status <span class="sc">==</span> <span class="st">&quot;yes&quot;</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb471-30"><a href="supervised-learning.html#cb471-30" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">churn_status =</span> <span class="fu">as.factor</span>(churn_status))</span>
<span id="cb471-31"><a href="supervised-learning.html#cb471-31" tabindex="-1"></a>  </span>
<span id="cb471-32"><a href="supervised-learning.html#cb471-32" tabindex="-1"></a><span class="co"># Proportion of &quot;Yes&quot; and &quot;No&quot;s:</span></span>
<span id="cb471-33"><a href="supervised-learning.html#cb471-33" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(mlc_churn<span class="sc">$</span>churn_status))</span>
<span id="cb471-34"><a href="supervised-learning.html#cb471-34" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb471-35"><a href="supervised-learning.html#cb471-35" tabindex="-1"></a><span class="co">#&gt;     No    Yes </span></span>
<span id="cb471-36"><a href="supervised-learning.html#cb471-36" tabindex="-1"></a><span class="co">#&gt; 0.8586 0.1414</span></span></code></pre></div>
<p>We create now sample of training and test, 70% training.</p>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb472-1"><a href="supervised-learning.html#cb472-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb472-2"><a href="supervised-learning.html#cb472-2" tabindex="-1"></a>churn_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(mlc_churn, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> churn_status)</span>
<span id="cb472-3"><a href="supervised-learning.html#cb472-3" tabindex="-1"></a></span>
<span id="cb472-4"><a href="supervised-learning.html#cb472-4" tabindex="-1"></a>churn_train <span class="ot">&lt;-</span> <span class="fu">training</span>(churn_split)</span>
<span id="cb472-5"><a href="supervised-learning.html#cb472-5" tabindex="-1"></a>churn_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(churn_split)</span></code></pre></div>
<p>Up to here we have done exactly the same step as in previous models. However, previously we have specified the <em>cross-validation</em> method within our control parameters. Now we will create a shared validation set to compare all models fairly.</p>
<p>We will create a list of 5 <em>folds</em> using the function <code>vfold_cv()</code> from <code>rsample</code>.</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="supervised-learning.html#cb473-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb473-2"><a href="supervised-learning.html#cb473-2" tabindex="-1"></a>churn_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(churn_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> churn_status)</span>
<span id="cb473-3"><a href="supervised-learning.html#cb473-3" tabindex="-1"></a>churn_folds</span>
<span id="cb473-4"><a href="supervised-learning.html#cb473-4" tabindex="-1"></a><span class="co">#&gt; #  5-fold cross-validation using stratification </span></span>
<span id="cb473-5"><a href="supervised-learning.html#cb473-5" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 2</span></span>
<span id="cb473-6"><a href="supervised-learning.html#cb473-6" tabindex="-1"></a><span class="co">#&gt;   splits             id   </span></span>
<span id="cb473-7"><a href="supervised-learning.html#cb473-7" tabindex="-1"></a><span class="co">#&gt;   &lt;list&gt;             &lt;chr&gt;</span></span>
<span id="cb473-8"><a href="supervised-learning.html#cb473-8" tabindex="-1"></a><span class="co">#&gt; 1 &lt;split [2799/700]&gt; Fold1</span></span>
<span id="cb473-9"><a href="supervised-learning.html#cb473-9" tabindex="-1"></a><span class="co">#&gt; 2 &lt;split [2799/700]&gt; Fold2</span></span>
<span id="cb473-10"><a href="supervised-learning.html#cb473-10" tabindex="-1"></a><span class="co">#&gt; 3 &lt;split [2799/700]&gt; Fold3</span></span>
<span id="cb473-11"><a href="supervised-learning.html#cb473-11" tabindex="-1"></a><span class="co">#&gt; 4 &lt;split [2799/700]&gt; Fold4</span></span>
<span id="cb473-12"><a href="supervised-learning.html#cb473-12" tabindex="-1"></a><span class="co">#&gt; 5 &lt;split [2800/699]&gt; Fold5</span></span></code></pre></div>
<p>We will use the <strong>ROC</strong> metric for all models. In tidymodels, we define the metrics we want to calculate using a <code>metric_set()</code>.</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb474-1"><a href="supervised-learning.html#cb474-1" tabindex="-1"></a>churn_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(roc_auc, accuracy, sensitivity, specificity)</span></code></pre></div>
<p>The next step would be to choose the machine learning algorithms we want to use to create our models. <code>parsnip</code> provides a consistent interface for different models. We can check available engines for a model type, for example:</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="supervised-learning.html#cb475-1" tabindex="-1"></a><span class="fu">show_engines</span>(<span class="st">&quot;nearest_neighbor&quot;</span>)</span>
<span id="cb475-2"><a href="supervised-learning.html#cb475-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 2</span></span>
<span id="cb475-3"><a href="supervised-learning.html#cb475-3" tabindex="-1"></a><span class="co">#&gt;   engine mode          </span></span>
<span id="cb475-4"><a href="supervised-learning.html#cb475-4" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;  &lt;chr&gt;         </span></span>
<span id="cb475-5"><a href="supervised-learning.html#cb475-5" tabindex="-1"></a><span class="co">#&gt; 1 kknn   classification</span></span>
<span id="cb475-6"><a href="supervised-learning.html#cb475-6" tabindex="-1"></a><span class="co">#&gt; 2 kknn   regression</span></span></code></pre></div>
<p>We will create a series of models and compare them using ROC AUC. First, let’s define a common recipe for preprocessing.</p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="supervised-learning.html#cb476-1" tabindex="-1"></a>churn_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(churn_status <span class="sc">~</span> ., <span class="at">data =</span> churn_train) <span class="sc">|&gt;</span></span>
<span id="cb476-2"><a href="supervised-learning.html#cb476-2" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>(), <span class="sc">-</span>churn_status) <span class="sc">|&gt;</span></span>
<span id="cb476-3"><a href="supervised-learning.html#cb476-3" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span></code></pre></div>
<div id="k-nearest-neighbors-model" class="section level3 hasAnchor" number="11.9.1">
<h3><span class="header-section-number">11.9.1</span> k-Nearest Neighbors Model<a href="supervised-learning.html#k-nearest-neighbors-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although it is a very simple model, it is also very useful. Let’s start with this model that we already learned to create during this chapter.</p>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="supervised-learning.html#cb477-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb477-2"><a href="supervised-learning.html#cb477-2" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb477-3"><a href="supervised-learning.html#cb477-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb477-4"><a href="supervised-learning.html#cb477-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb477-5"><a href="supervised-learning.html#cb477-5" tabindex="-1"></a></span>
<span id="cb477-6"><a href="supervised-learning.html#cb477-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb477-7"><a href="supervised-learning.html#cb477-7" tabindex="-1"></a>knn_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb477-8"><a href="supervised-learning.html#cb477-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb477-9"><a href="supervised-learning.html#cb477-9" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec)</span>
<span id="cb477-10"><a href="supervised-learning.html#cb477-10" tabindex="-1"></a></span>
<span id="cb477-11"><a href="supervised-learning.html#cb477-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb477-12"><a href="supervised-learning.html#cb477-12" tabindex="-1"></a>knn_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb477-13"><a href="supervised-learning.html#cb477-13" tabindex="-1"></a>  knn_workflow,</span>
<span id="cb477-14"><a href="supervised-learning.html#cb477-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb477-15"><a href="supervised-learning.html#cb477-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb477-16"><a href="supervised-learning.html#cb477-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb477-17"><a href="supervised-learning.html#cb477-17" tabindex="-1"></a>)</span>
<span id="cb477-18"><a href="supervised-learning.html#cb477-18" tabindex="-1"></a></span>
<span id="cb477-19"><a href="supervised-learning.html#cb477-19" tabindex="-1"></a><span class="fu">show_best</span>(knn_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb477-20"><a href="supervised-learning.html#cb477-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 7</span></span>
<span id="cb477-21"><a href="supervised-learning.html#cb477-21" tabindex="-1"></a><span class="co">#&gt;   neighbors .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb477-22"><a href="supervised-learning.html#cb477-22" tabindex="-1"></a><span class="co">#&gt;       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb477-23"><a href="supervised-learning.html#cb477-23" tabindex="-1"></a><span class="co">#&gt; 1        15 roc_auc binary     0.684     5 0.0101  pre0_mod10_post0</span></span>
<span id="cb477-24"><a href="supervised-learning.html#cb477-24" tabindex="-1"></a><span class="co">#&gt; 2        13 roc_auc binary     0.679     5 0.00972 pre0_mod09_post0</span></span>
<span id="cb477-25"><a href="supervised-learning.html#cb477-25" tabindex="-1"></a><span class="co">#&gt; 3        11 roc_auc binary     0.676     5 0.0110  pre0_mod08_post0</span></span>
<span id="cb477-26"><a href="supervised-learning.html#cb477-26" tabindex="-1"></a><span class="co">#&gt; 4        10 roc_auc binary     0.674     5 0.0119  pre0_mod07_post0</span></span>
<span id="cb477-27"><a href="supervised-learning.html#cb477-27" tabindex="-1"></a><span class="co">#&gt; 5         8 roc_auc binary     0.665     5 0.0145  pre0_mod06_post0</span></span></code></pre></div>
</div>
<div id="generalized-linear-model---glm" class="section level3 hasAnchor" number="11.9.2">
<h3><span class="header-section-number">11.9.2</span> Generalized Linear Model - GLM<a href="supervised-learning.html#generalized-linear-model---glm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="https://towardsdatascience.com/generalized-linear-models-9cbf848bb8ab">generalized linear model</a> (GLM) is a flexible generalization of ordinary linear regression.</p>
<p>To do this we need to install the <code>glmnet</code> library before creating our model via tidymodels.</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="supervised-learning.html#cb478-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;glmnet&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="supervised-learning.html#cb479-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb479-2"><a href="supervised-learning.html#cb479-2" tabindex="-1"></a>glm_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb479-3"><a href="supervised-learning.html#cb479-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb479-4"><a href="supervised-learning.html#cb479-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb479-5"><a href="supervised-learning.html#cb479-5" tabindex="-1"></a></span>
<span id="cb479-6"><a href="supervised-learning.html#cb479-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb479-7"><a href="supervised-learning.html#cb479-7" tabindex="-1"></a>glm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb479-8"><a href="supervised-learning.html#cb479-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb479-9"><a href="supervised-learning.html#cb479-9" tabindex="-1"></a>  <span class="fu">add_model</span>(glm_spec)</span>
<span id="cb479-10"><a href="supervised-learning.html#cb479-10" tabindex="-1"></a></span>
<span id="cb479-11"><a href="supervised-learning.html#cb479-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb479-12"><a href="supervised-learning.html#cb479-12" tabindex="-1"></a>glm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb479-13"><a href="supervised-learning.html#cb479-13" tabindex="-1"></a>  glm_workflow,</span>
<span id="cb479-14"><a href="supervised-learning.html#cb479-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb479-15"><a href="supervised-learning.html#cb479-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb479-16"><a href="supervised-learning.html#cb479-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb479-17"><a href="supervised-learning.html#cb479-17" tabindex="-1"></a>)</span>
<span id="cb479-18"><a href="supervised-learning.html#cb479-18" tabindex="-1"></a></span>
<span id="cb479-19"><a href="supervised-learning.html#cb479-19" tabindex="-1"></a><span class="fu">show_best</span>(glm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb479-20"><a href="supervised-learning.html#cb479-20" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 8</span></span>
<span id="cb479-21"><a href="supervised-learning.html#cb479-21" tabindex="-1"></a><span class="co">#&gt;         penalty mixture .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb479-22"><a href="supervised-learning.html#cb479-22" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb479-23"><a href="supervised-learning.html#cb479-23" tabindex="-1"></a><span class="co">#&gt; 1 0.00599         1     roc_auc binary     0.819     5 0.00937 pre0_mod08_post0</span></span>
<span id="cb479-24"><a href="supervised-learning.html#cb479-24" tabindex="-1"></a><span class="co">#&gt; 2 0.0774          0.261 roc_auc binary     0.813     5 0.00862 pre0_mod09_post0</span></span>
<span id="cb479-25"><a href="supervised-learning.html#cb479-25" tabindex="-1"></a><span class="co">#&gt; 3 0.000464        0.578 roc_auc binary     0.808     5 0.0102  pre0_mod07_post0</span></span>
<span id="cb479-26"><a href="supervised-learning.html#cb479-26" tabindex="-1"></a><span class="co">#&gt; 4 0.00000278      0.894 roc_auc binary     0.807     5 0.0104  pre0_mod05_post0</span></span>
<span id="cb479-27"><a href="supervised-learning.html#cb479-27" tabindex="-1"></a><span class="co">#&gt; 5 0.00000000129   0.789 roc_auc binary     0.807     5 0.0104  pre0_mod02_post0</span></span></code></pre></div>
</div>
<div id="random-forest-model" class="section level3 hasAnchor" number="11.9.3">
<h3><span class="header-section-number">11.9.3</span> Random Forest Model<a href="supervised-learning.html#random-forest-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Random Forest is a supervised machine learning technique based on decision trees. We will use the <a href="https://dialnet.unirioja.es/descarga/articulo/6230447.pdf">random forest model</a> (RF).</p>
<p>To do this we will first install the <code>ranger</code> library and then create the model via tidymodels.</p>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="supervised-learning.html#cb480-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;ranger&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="supervised-learning.html#cb481-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb481-2"><a href="supervised-learning.html#cb481-2" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mtry =</span> <span class="fu">tune</span>(), <span class="at">trees =</span> <span class="dv">1000</span>, <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb481-3"><a href="supervised-learning.html#cb481-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb481-4"><a href="supervised-learning.html#cb481-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb481-5"><a href="supervised-learning.html#cb481-5" tabindex="-1"></a></span>
<span id="cb481-6"><a href="supervised-learning.html#cb481-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb481-7"><a href="supervised-learning.html#cb481-7" tabindex="-1"></a>rf_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb481-8"><a href="supervised-learning.html#cb481-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb481-9"><a href="supervised-learning.html#cb481-9" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_spec)</span>
<span id="cb481-10"><a href="supervised-learning.html#cb481-10" tabindex="-1"></a></span>
<span id="cb481-11"><a href="supervised-learning.html#cb481-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb481-12"><a href="supervised-learning.html#cb481-12" tabindex="-1"></a>rf_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb481-13"><a href="supervised-learning.html#cb481-13" tabindex="-1"></a>  rf_workflow,</span>
<span id="cb481-14"><a href="supervised-learning.html#cb481-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb481-15"><a href="supervised-learning.html#cb481-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb481-16"><a href="supervised-learning.html#cb481-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb481-17"><a href="supervised-learning.html#cb481-17" tabindex="-1"></a>)</span>
<span id="cb481-18"><a href="supervised-learning.html#cb481-18" tabindex="-1"></a><span class="co">#&gt; i Creating pre-processing data to finalize 1 unknown parameter: &quot;mtry&quot;</span></span>
<span id="cb481-19"><a href="supervised-learning.html#cb481-19" tabindex="-1"></a></span>
<span id="cb481-20"><a href="supervised-learning.html#cb481-20" tabindex="-1"></a><span class="fu">show_best</span>(rf_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb481-21"><a href="supervised-learning.html#cb481-21" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 8</span></span>
<span id="cb481-22"><a href="supervised-learning.html#cb481-22" tabindex="-1"></a><span class="co">#&gt;    mtry min_n .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb481-23"><a href="supervised-learning.html#cb481-23" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb481-24"><a href="supervised-learning.html#cb481-24" tabindex="-1"></a><span class="co">#&gt; 1     8    31 roc_auc binary     0.914     5 0.00998 pre0_mod02_post0</span></span>
<span id="cb481-25"><a href="supervised-learning.html#cb481-25" tabindex="-1"></a><span class="co">#&gt; 2    16     2 roc_auc binary     0.912     5 0.0104  pre0_mod03_post0</span></span>
<span id="cb481-26"><a href="supervised-learning.html#cb481-26" tabindex="-1"></a><span class="co">#&gt; 3    23    18 roc_auc binary     0.911     5 0.00975 pre0_mod04_post0</span></span>
<span id="cb481-27"><a href="supervised-learning.html#cb481-27" tabindex="-1"></a><span class="co">#&gt; 4    31    35 roc_auc binary     0.909     5 0.0101  pre0_mod05_post0</span></span>
<span id="cb481-28"><a href="supervised-learning.html#cb481-28" tabindex="-1"></a><span class="co">#&gt; 5    53    40 roc_auc binary     0.906     5 0.00890 pre0_mod08_post0</span></span></code></pre></div>
</div>
<div id="support-vector-machine-model---svm" class="section level3 hasAnchor" number="11.9.4">
<h3><span class="header-section-number">11.9.4</span> Support Vector Machine Model - SVM<a href="supervised-learning.html#support-vector-machine-model---svm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><a href="http://numerentur.org/svm/">Support vector machines</a> or support vector machines are a set of supervised learning algorithms.</p>
<p>To create this model we will use the <code>kernlab</code> engine.</p>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="supervised-learning.html#cb482-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;kernlab&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="supervised-learning.html#cb483-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb483-2"><a href="supervised-learning.html#cb483-2" tabindex="-1"></a>svm_spec <span class="ot">&lt;-</span> <span class="fu">svm_rbf</span>(<span class="at">cost =</span> <span class="fu">tune</span>(), <span class="at">rbf_sigma =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb483-3"><a href="supervised-learning.html#cb483-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kernlab&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb483-4"><a href="supervised-learning.html#cb483-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb483-5"><a href="supervised-learning.html#cb483-5" tabindex="-1"></a></span>
<span id="cb483-6"><a href="supervised-learning.html#cb483-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb483-7"><a href="supervised-learning.html#cb483-7" tabindex="-1"></a>svm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb483-8"><a href="supervised-learning.html#cb483-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb483-9"><a href="supervised-learning.html#cb483-9" tabindex="-1"></a>  <span class="fu">add_model</span>(svm_spec)</span>
<span id="cb483-10"><a href="supervised-learning.html#cb483-10" tabindex="-1"></a></span>
<span id="cb483-11"><a href="supervised-learning.html#cb483-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb483-12"><a href="supervised-learning.html#cb483-12" tabindex="-1"></a>svm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb483-13"><a href="supervised-learning.html#cb483-13" tabindex="-1"></a>  svm_workflow,</span>
<span id="cb483-14"><a href="supervised-learning.html#cb483-14" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb483-15"><a href="supervised-learning.html#cb483-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb483-16"><a href="supervised-learning.html#cb483-16" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb483-17"><a href="supervised-learning.html#cb483-17" tabindex="-1"></a>)</span>
<span id="cb483-18"><a href="supervised-learning.html#cb483-18" tabindex="-1"></a><span class="co">#&gt; maximum number of iterations reached 2.273272e-05 2.273273e-05maximum number of iterations reached 0.001260726 0.001226596maximum number of iterations reached 0.008990742 0.0089403maximum number of iterations reached 4.01911e-05 4.01911e-05maximum number of iterations reached 0.0004458751 0.0004390186maximum number of iterations reached 0.01426775 0.01386837maximum number of iterations reached 2.311619e-05 2.311619e-05maximum number of iterations reached 0.0004666225 0.0004600749maximum number of iterations reached 0.009561785 0.009488703maximum number of iterations reached 4.18965e-05 4.189651e-05maximum number of iterations reached 0.01467671 0.01418266maximum number of iterations reached 2.221129e-05 2.22113e-05maximum number of iterations reached 0.0009695224 0.0009465917maximum number of iterations reached 0.009269646 0.009208682maximum number of iterations reached 3.924845e-05 3.924845e-05maximum number of iterations reached 0.0002350936 0.0002328733maximum number of iterations reached 0.01304753 0.01272522maximum number of iterations reached 2.357812e-05 2.357812e-05maximum number of iterations reached 0.0003822001 0.000377737maximum number of iterations reached 0.009766638 0.009695014maximum number of iterations reached 4.284351e-05 4.284352e-05maximum number of iterations reached 0.01553881 0.01501075maximum number of iterations reached 2.310753e-05 2.310753e-05maximum number of iterations reached 0.0004798964 0.0004730654maximum number of iterations reached 0.009636723 0.009566509maximum number of iterations reached 4.147277e-05 4.147278e-05maximum number of iterations reached 0.0002249601 0.0002227933maximum number of iterations reached 0.01498293 0.01448009</span></span>
<span id="cb483-19"><a href="supervised-learning.html#cb483-19" tabindex="-1"></a></span>
<span id="cb483-20"><a href="supervised-learning.html#cb483-20" tabindex="-1"></a><span class="fu">show_best</span>(svm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb483-21"><a href="supervised-learning.html#cb483-21" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 8</span></span>
<span id="cb483-22"><a href="supervised-learning.html#cb483-22" tabindex="-1"></a><span class="co">#&gt;        cost   rbf_sigma .metric .estimator  mean     n std_err .config         </span></span>
<span id="cb483-23"><a href="supervised-learning.html#cb483-23" tabindex="-1"></a><span class="co">#&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           </span></span>
<span id="cb483-24"><a href="supervised-learning.html#cb483-24" tabindex="-1"></a><span class="co">#&gt; 1  0.00310  0.00599     roc_auc binary     0.864     5 0.00811 pre0_mod02_post0</span></span>
<span id="cb483-25"><a href="supervised-learning.html#cb483-25" tabindex="-1"></a><span class="co">#&gt; 2 32        0.000464    roc_auc binary     0.862     5 0.00900 pre0_mod10_post0</span></span>
<span id="cb483-26"><a href="supervised-learning.html#cb483-26" tabindex="-1"></a><span class="co">#&gt; 3  1        0.0000359   roc_auc binary     0.794     5 0.0103  pre0_mod07_post0</span></span>
<span id="cb483-27"><a href="supervised-learning.html#cb483-27" tabindex="-1"></a><span class="co">#&gt; 4  0.0312   0.00000278  roc_auc binary     0.793     5 0.0114  pre0_mod04_post0</span></span>
<span id="cb483-28"><a href="supervised-learning.html#cb483-28" tabindex="-1"></a><span class="co">#&gt; 5  0.000977 0.000000215 roc_auc binary     0.793     5 0.0114  pre0_mod01_post0</span></span></code></pre></div>
</div>
<div id="naive-bayes-model" class="section level3 hasAnchor" number="11.9.5">
<h3><span class="header-section-number">11.9.5</span> Naive Bayes Model<a href="supervised-learning.html#naive-bayes-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Naïve Bayes (NB) is one of the simplest, yet powerful, algorithms for classification. It is based on <strong>Bayes’ Theorem</strong>, which describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if cancer is related to age, then, using Bayes’ theorem, a person’s age can be used to more accurately assess the probability that they have cancer.</p>
<p>To use this model we will use the <code>naivebayes</code> library within tidymodels.</p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="supervised-learning.html#cb484-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">c</span>(<span class="st">&quot;naivebayes&quot;</span>, <span class="st">&quot;discrim&quot;</span>))</span>
<span id="cb484-2"><a href="supervised-learning.html#cb484-2" tabindex="-1"></a><span class="fu">library</span>(naivebayes) </span>
<span id="cb484-3"><a href="supervised-learning.html#cb484-3" tabindex="-1"></a><span class="fu">library</span>(discrim) <span class="co"># Required for parsnip integration</span></span></code></pre></div>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="supervised-learning.html#cb485-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb485-2"><a href="supervised-learning.html#cb485-2" tabindex="-1"></a><span class="fu">library</span>(discrim)</span>
<span id="cb485-3"><a href="supervised-learning.html#cb485-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb485-4"><a href="supervised-learning.html#cb485-4" tabindex="-1"></a><span class="co">#&gt; Attaching package: &#39;discrim&#39;</span></span>
<span id="cb485-5"><a href="supervised-learning.html#cb485-5" tabindex="-1"></a><span class="co">#&gt; The following object is masked from &#39;package:dials&#39;:</span></span>
<span id="cb485-6"><a href="supervised-learning.html#cb485-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb485-7"><a href="supervised-learning.html#cb485-7" tabindex="-1"></a><span class="co">#&gt;     smoothness</span></span>
<span id="cb485-8"><a href="supervised-learning.html#cb485-8" tabindex="-1"></a>nb_spec <span class="ot">&lt;-</span> <span class="fu">naive_Bayes</span>() <span class="sc">|&gt;</span></span>
<span id="cb485-9"><a href="supervised-learning.html#cb485-9" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;naivebayes&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb485-10"><a href="supervised-learning.html#cb485-10" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb485-11"><a href="supervised-learning.html#cb485-11" tabindex="-1"></a></span>
<span id="cb485-12"><a href="supervised-learning.html#cb485-12" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb485-13"><a href="supervised-learning.html#cb485-13" tabindex="-1"></a>nb_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb485-14"><a href="supervised-learning.html#cb485-14" tabindex="-1"></a>  <span class="fu">add_recipe</span>(churn_recipe) <span class="sc">|&gt;</span></span>
<span id="cb485-15"><a href="supervised-learning.html#cb485-15" tabindex="-1"></a>  <span class="fu">add_model</span>(nb_spec)</span>
<span id="cb485-16"><a href="supervised-learning.html#cb485-16" tabindex="-1"></a></span>
<span id="cb485-17"><a href="supervised-learning.html#cb485-17" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb485-18"><a href="supervised-learning.html#cb485-18" tabindex="-1"></a>nb_res <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb485-19"><a href="supervised-learning.html#cb485-19" tabindex="-1"></a>  nb_workflow,</span>
<span id="cb485-20"><a href="supervised-learning.html#cb485-20" tabindex="-1"></a>  <span class="at">resamples =</span> churn_folds,</span>
<span id="cb485-21"><a href="supervised-learning.html#cb485-21" tabindex="-1"></a>  <span class="at">metrics =</span> churn_metrics</span>
<span id="cb485-22"><a href="supervised-learning.html#cb485-22" tabindex="-1"></a>)</span>
<span id="cb485-23"><a href="supervised-learning.html#cb485-23" tabindex="-1"></a></span>
<span id="cb485-24"><a href="supervised-learning.html#cb485-24" tabindex="-1"></a><span class="fu">collect_metrics</span>(nb_res)</span>
<span id="cb485-25"><a href="supervised-learning.html#cb485-25" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 6</span></span>
<span id="cb485-26"><a href="supervised-learning.html#cb485-26" tabindex="-1"></a><span class="co">#&gt;   .metric     .estimator  mean     n  std_err .config        </span></span>
<span id="cb485-27"><a href="supervised-learning.html#cb485-27" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          </span></span>
<span id="cb485-28"><a href="supervised-learning.html#cb485-28" tabindex="-1"></a><span class="co">#&gt; 1 accuracy    binary     0.859     5 0.000246 pre0_mod0_post0</span></span>
<span id="cb485-29"><a href="supervised-learning.html#cb485-29" tabindex="-1"></a><span class="co">#&gt; 2 roc_auc     binary     0.840     5 0.00983  pre0_mod0_post0</span></span>
<span id="cb485-30"><a href="supervised-learning.html#cb485-30" tabindex="-1"></a><span class="co">#&gt; 3 sensitivity binary     1         5 0        pre0_mod0_post0</span></span>
<span id="cb485-31"><a href="supervised-learning.html#cb485-31" tabindex="-1"></a><span class="co">#&gt; 4 specificity binary     0         5 0        pre0_mod0_post0</span></span></code></pre></div>
</div>
<div id="model-comparison" class="section level3 hasAnchor" number="11.9.6">
<h3><span class="header-section-number">11.9.6</span> Model Comparison<a href="supervised-learning.html#model-comparison" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To compare the models, we can extract the metrics from each tuning result and visualize them.</p>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="supervised-learning.html#cb486-1" tabindex="-1"></a><span class="co"># Collect metrics</span></span>
<span id="cb486-2"><a href="supervised-learning.html#cb486-2" tabindex="-1"></a>knn_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(knn_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;kNN&quot;</span>)</span>
<span id="cb486-3"><a href="supervised-learning.html#cb486-3" tabindex="-1"></a>glm_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(glm_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;GLM&quot;</span>)</span>
<span id="cb486-4"><a href="supervised-learning.html#cb486-4" tabindex="-1"></a>rf_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(rf_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;RF&quot;</span>)</span>
<span id="cb486-5"><a href="supervised-learning.html#cb486-5" tabindex="-1"></a>svm_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(svm_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;SVM&quot;</span>)</span>
<span id="cb486-6"><a href="supervised-learning.html#cb486-6" tabindex="-1"></a>nb_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(nb_res) <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;Naive Bayes&quot;</span>)</span>
<span id="cb486-7"><a href="supervised-learning.html#cb486-7" tabindex="-1"></a></span>
<span id="cb486-8"><a href="supervised-learning.html#cb486-8" tabindex="-1"></a><span class="co"># Combine</span></span>
<span id="cb486-9"><a href="supervised-learning.html#cb486-9" tabindex="-1"></a>all_metrics <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(knn_metrics, glm_metrics, rf_metrics, svm_metrics, nb_metrics)</span>
<span id="cb486-10"><a href="supervised-learning.html#cb486-10" tabindex="-1"></a></span>
<span id="cb486-11"><a href="supervised-learning.html#cb486-11" tabindex="-1"></a><span class="co"># Visualize ROC AUC</span></span>
<span id="cb486-12"><a href="supervised-learning.html#cb486-12" tabindex="-1"></a>all_metrics <span class="sc">|&gt;</span></span>
<span id="cb486-13"><a href="supervised-learning.html#cb486-13" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;roc_auc&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb486-14"><a href="supervised-learning.html#cb486-14" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> model, <span class="at">y =</span> mean, <span class="at">fill =</span> model)) <span class="sc">+</span></span>
<span id="cb486-15"><a href="supervised-learning.html#cb486-15" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb486-16"><a href="supervised-learning.html#cb486-16" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;ROC AUC&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Model Comparison&quot;</span>) <span class="sc">+</span></span>
<span id="cb486-17"><a href="supervised-learning.html#cb486-17" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="Data-Science-with-R_files/figure-html/unnamed-chunk-634-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>For this case the random forest model (<em>RF</em>) seems to be the best. This is not surprising given that this algorithm is related to its ability to cope with different input types and require little preprocessing. We can make our models better by pre-processing data and changing the ad-hoc parameters of each model.</p>
</div>
<div id="predicting-using-the-best-model" class="section level3 hasAnchor" number="11.9.7">
<h3><span class="header-section-number">11.9.7</span> Predicting using the best model<a href="supervised-learning.html#predicting-using-the-best-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have our best model (Random Forest), we proceed to perform the prediction on the test set. We need to finalize the workflow with the best hyperparameters from the tuning step first.</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="supervised-learning.html#cb487-1" tabindex="-1"></a><span class="co"># Select best parameters for RF</span></span>
<span id="cb487-2"><a href="supervised-learning.html#cb487-2" tabindex="-1"></a>best_rf <span class="ot">&lt;-</span> <span class="fu">select_best</span>(rf_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb487-3"><a href="supervised-learning.html#cb487-3" tabindex="-1"></a></span>
<span id="cb487-4"><a href="supervised-learning.html#cb487-4" tabindex="-1"></a><span class="co"># Finalize workflow</span></span>
<span id="cb487-5"><a href="supervised-learning.html#cb487-5" tabindex="-1"></a>final_rf_workflow <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(rf_workflow, best_rf)</span>
<span id="cb487-6"><a href="supervised-learning.html#cb487-6" tabindex="-1"></a></span>
<span id="cb487-7"><a href="supervised-learning.html#cb487-7" tabindex="-1"></a><span class="co"># Fit on training data</span></span>
<span id="cb487-8"><a href="supervised-learning.html#cb487-8" tabindex="-1"></a>optimal_model <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_rf_workflow, <span class="at">data =</span> churn_train)</span>
<span id="cb487-9"><a href="supervised-learning.html#cb487-9" tabindex="-1"></a></span>
<span id="cb487-10"><a href="supervised-learning.html#cb487-10" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb487-11"><a href="supervised-learning.html#cb487-11" tabindex="-1"></a>churn_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(optimal_model, <span class="at">new_data =</span> churn_test)</span>
<span id="cb487-12"><a href="supervised-learning.html#cb487-12" tabindex="-1"></a></span>
<span id="cb487-13"><a href="supervised-learning.html#cb487-13" tabindex="-1"></a><span class="co"># Evaluate results</span></span>
<span id="cb487-14"><a href="supervised-learning.html#cb487-14" tabindex="-1"></a>churn_predictions <span class="sc">|&gt;</span></span>
<span id="cb487-15"><a href="supervised-learning.html#cb487-15" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> churn_status, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb487-16"><a href="supervised-learning.html#cb487-16" tabindex="-1"></a><span class="co">#&gt;           Truth</span></span>
<span id="cb487-17"><a href="supervised-learning.html#cb487-17" tabindex="-1"></a><span class="co">#&gt; Prediction   No  Yes</span></span>
<span id="cb487-18"><a href="supervised-learning.html#cb487-18" tabindex="-1"></a><span class="co">#&gt;        No  1285   66</span></span>
<span id="cb487-19"><a href="supervised-learning.html#cb487-19" tabindex="-1"></a><span class="co">#&gt;        Yes    3  147</span></span>
<span id="cb487-20"><a href="supervised-learning.html#cb487-20" tabindex="-1"></a></span>
<span id="cb487-21"><a href="supervised-learning.html#cb487-21" tabindex="-1"></a>churn_predictions <span class="sc">|&gt;</span></span>
<span id="cb487-22"><a href="supervised-learning.html#cb487-22" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> churn_status, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb487-23"><a href="supervised-learning.html#cb487-23" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span id="cb487-24"><a href="supervised-learning.html#cb487-24" tabindex="-1"></a><span class="co">#&gt;   .metric  .estimator .estimate</span></span>
<span id="cb487-25"><a href="supervised-learning.html#cb487-25" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb487-26"><a href="supervised-learning.html#cb487-26" tabindex="-1"></a><span class="co">#&gt; 1 accuracy binary         0.954</span></span></code></pre></div>
<p>Thus, we have found how to create a customer churn prediction model given 19 prediction variables with an accuracy of 96%.</p>
</div>
</div>
<div id="exercises-17" class="section level2 hasAnchor" number="11.10">
<h2><span class="header-section-number">11.10</span> Exercises<a href="supervised-learning.html#exercises-17" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol start="100" style="list-style-type: decimal">
<li>The <code>attrition</code> data frame from the <code>modeldata</code> library shows data from a list of almost 1,500 employees of a company. Create a copy of this data frame and store it in the <code>workers</code> object. Then, build an RF model with this data to predict the <code>Attrition</code> field (job desertion). Where the class “Yes” means they resigned and “No” means they still work.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="supervised-learning.html#cb488-1" tabindex="-1"></a><span class="fu">data</span>(attrition)</span>
<span id="cb488-2"><a href="supervised-learning.html#cb488-2" tabindex="-1"></a><span class="fu">str</span>(attrition)</span>
<span id="cb488-3"><a href="supervised-learning.html#cb488-3" tabindex="-1"></a></span>
<span id="cb488-4"><a href="supervised-learning.html#cb488-4" tabindex="-1"></a>workers <span class="ot">&lt;-</span> attrition</span>
<span id="cb488-5"><a href="supervised-learning.html#cb488-5" tabindex="-1"></a></span>
<span id="cb488-6"><a href="supervised-learning.html#cb488-6" tabindex="-1"></a>workers <span class="ot">&lt;-</span> workers <span class="sc">|&gt;</span> </span>
<span id="cb488-7"><a href="supervised-learning.html#cb488-7" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">attrition_status =</span> Attrition)</span>
<span id="cb488-8"><a href="supervised-learning.html#cb488-8" tabindex="-1"></a></span>
<span id="cb488-9"><a href="supervised-learning.html#cb488-9" tabindex="-1"></a><span class="co"># 70% for the training data</span></span>
<span id="cb488-10"><a href="supervised-learning.html#cb488-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">28</span>)</span>
<span id="cb488-11"><a href="supervised-learning.html#cb488-11" tabindex="-1"></a>workers_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(workers, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> attrition_status)</span>
<span id="cb488-12"><a href="supervised-learning.html#cb488-12" tabindex="-1"></a></span>
<span id="cb488-13"><a href="supervised-learning.html#cb488-13" tabindex="-1"></a>workers_train <span class="ot">&lt;-</span> <span class="fu">training</span>(workers_split)</span>
<span id="cb488-14"><a href="supervised-learning.html#cb488-14" tabindex="-1"></a>workers_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(workers_split)</span>
<span id="cb488-15"><a href="supervised-learning.html#cb488-15" tabindex="-1"></a></span>
<span id="cb488-16"><a href="supervised-learning.html#cb488-16" tabindex="-1"></a><span class="co"># Recipe</span></span>
<span id="cb488-17"><a href="supervised-learning.html#cb488-17" tabindex="-1"></a>workers_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(attrition_status <span class="sc">~</span> ., <span class="at">data =</span> workers_train) <span class="sc">|&gt;</span></span>
<span id="cb488-18"><a href="supervised-learning.html#cb488-18" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>(), <span class="sc">-</span>attrition_status) <span class="sc">|&gt;</span></span>
<span id="cb488-19"><a href="supervised-learning.html#cb488-19" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>())</span>
<span id="cb488-20"><a href="supervised-learning.html#cb488-20" tabindex="-1"></a></span>
<span id="cb488-21"><a href="supervised-learning.html#cb488-21" tabindex="-1"></a><span class="co"># We create CV folds</span></span>
<span id="cb488-22"><a href="supervised-learning.html#cb488-22" tabindex="-1"></a>workers_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(workers_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> attrition_status)</span>
<span id="cb488-23"><a href="supervised-learning.html#cb488-23" tabindex="-1"></a>workers_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(roc_auc, accuracy)</span>
<span id="cb488-24"><a href="supervised-learning.html#cb488-24" tabindex="-1"></a></span>
<span id="cb488-25"><a href="supervised-learning.html#cb488-25" tabindex="-1"></a><span class="co"># We create the model</span></span>
<span id="cb488-26"><a href="supervised-learning.html#cb488-26" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span></span>
<span id="cb488-27"><a href="supervised-learning.html#cb488-27" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb488-28"><a href="supervised-learning.html#cb488-28" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb488-29"><a href="supervised-learning.html#cb488-29" tabindex="-1"></a></span>
<span id="cb488-30"><a href="supervised-learning.html#cb488-30" tabindex="-1"></a>rf_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb488-31"><a href="supervised-learning.html#cb488-31" tabindex="-1"></a>  <span class="fu">add_recipe</span>(workers_recipe) <span class="sc">|&gt;</span></span>
<span id="cb488-32"><a href="supervised-learning.html#cb488-32" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_spec)</span>
<span id="cb488-33"><a href="supervised-learning.html#cb488-33" tabindex="-1"></a></span>
<span id="cb488-34"><a href="supervised-learning.html#cb488-34" tabindex="-1"></a>workers_rf_res <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb488-35"><a href="supervised-learning.html#cb488-35" tabindex="-1"></a>  rf_wf,</span>
<span id="cb488-36"><a href="supervised-learning.html#cb488-36" tabindex="-1"></a>  <span class="at">resamples =</span> workers_folds,</span>
<span id="cb488-37"><a href="supervised-learning.html#cb488-37" tabindex="-1"></a>  <span class="at">metrics =</span> workers_metrics</span>
<span id="cb488-38"><a href="supervised-learning.html#cb488-38" tabindex="-1"></a>)</span>
<span id="cb488-39"><a href="supervised-learning.html#cb488-39" tabindex="-1"></a></span>
<span id="cb488-40"><a href="supervised-learning.html#cb488-40" tabindex="-1"></a><span class="fu">collect_metrics</span>(workers_rf_res)</span></code></pre></div>
</details>
<ol start="101" style="list-style-type: decimal">
<li>Using the training data from the previous exercise, build the GLM model using tidymodels.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="supervised-learning.html#cb489-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb489-2"><a href="supervised-learning.html#cb489-2" tabindex="-1"></a>glm_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb489-3"><a href="supervised-learning.html#cb489-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb489-4"><a href="supervised-learning.html#cb489-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb489-5"><a href="supervised-learning.html#cb489-5" tabindex="-1"></a></span>
<span id="cb489-6"><a href="supervised-learning.html#cb489-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb489-7"><a href="supervised-learning.html#cb489-7" tabindex="-1"></a>glm_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb489-8"><a href="supervised-learning.html#cb489-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(workers_recipe) <span class="sc">|&gt;</span></span>
<span id="cb489-9"><a href="supervised-learning.html#cb489-9" tabindex="-1"></a>  <span class="fu">add_model</span>(glm_spec)</span>
<span id="cb489-10"><a href="supervised-learning.html#cb489-10" tabindex="-1"></a></span>
<span id="cb489-11"><a href="supervised-learning.html#cb489-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb489-12"><a href="supervised-learning.html#cb489-12" tabindex="-1"></a>workers_glm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb489-13"><a href="supervised-learning.html#cb489-13" tabindex="-1"></a>  glm_wf,</span>
<span id="cb489-14"><a href="supervised-learning.html#cb489-14" tabindex="-1"></a>  <span class="at">resamples =</span> workers_folds,</span>
<span id="cb489-15"><a href="supervised-learning.html#cb489-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb489-16"><a href="supervised-learning.html#cb489-16" tabindex="-1"></a>  <span class="at">metrics =</span> workers_metrics</span>
<span id="cb489-17"><a href="supervised-learning.html#cb489-17" tabindex="-1"></a>)</span>
<span id="cb489-18"><a href="supervised-learning.html#cb489-18" tabindex="-1"></a></span>
<span id="cb489-19"><a href="supervised-learning.html#cb489-19" tabindex="-1"></a><span class="fu">show_best</span>(workers_glm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
</details>
<ol start="102" style="list-style-type: decimal">
<li>Using the training data, build the SVM model.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="supervised-learning.html#cb490-1" tabindex="-1"></a><span class="co"># Spec</span></span>
<span id="cb490-2"><a href="supervised-learning.html#cb490-2" tabindex="-1"></a>svm_spec <span class="ot">&lt;-</span> <span class="fu">svm_rbf</span>(<span class="at">cost =</span> <span class="fu">tune</span>(), <span class="at">rbf_sigma =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb490-3"><a href="supervised-learning.html#cb490-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kernlab&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb490-4"><a href="supervised-learning.html#cb490-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb490-5"><a href="supervised-learning.html#cb490-5" tabindex="-1"></a></span>
<span id="cb490-6"><a href="supervised-learning.html#cb490-6" tabindex="-1"></a><span class="co"># Workflow</span></span>
<span id="cb490-7"><a href="supervised-learning.html#cb490-7" tabindex="-1"></a>svm_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb490-8"><a href="supervised-learning.html#cb490-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(workers_recipe) <span class="sc">|&gt;</span></span>
<span id="cb490-9"><a href="supervised-learning.html#cb490-9" tabindex="-1"></a>  <span class="fu">add_model</span>(svm_spec)</span>
<span id="cb490-10"><a href="supervised-learning.html#cb490-10" tabindex="-1"></a></span>
<span id="cb490-11"><a href="supervised-learning.html#cb490-11" tabindex="-1"></a><span class="co"># Tune</span></span>
<span id="cb490-12"><a href="supervised-learning.html#cb490-12" tabindex="-1"></a>workers_svm_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb490-13"><a href="supervised-learning.html#cb490-13" tabindex="-1"></a>  svm_wf,</span>
<span id="cb490-14"><a href="supervised-learning.html#cb490-14" tabindex="-1"></a>  <span class="at">resamples =</span> workers_folds,</span>
<span id="cb490-15"><a href="supervised-learning.html#cb490-15" tabindex="-1"></a>  <span class="at">grid =</span> <span class="dv">10</span>,</span>
<span id="cb490-16"><a href="supervised-learning.html#cb490-16" tabindex="-1"></a>  <span class="at">metrics =</span> workers_metrics</span>
<span id="cb490-17"><a href="supervised-learning.html#cb490-17" tabindex="-1"></a>)</span>
<span id="cb490-18"><a href="supervised-learning.html#cb490-18" tabindex="-1"></a></span>
<span id="cb490-19"><a href="supervised-learning.html#cb490-19" tabindex="-1"></a><span class="fu">show_best</span>(workers_svm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
</details>
<ol start="103" style="list-style-type: decimal">
<li>From the created models, which is the most optimal?</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="supervised-learning.html#cb491-1" tabindex="-1"></a><span class="co"># Collect best metrics from each model</span></span>
<span id="cb491-2"><a href="supervised-learning.html#cb491-2" tabindex="-1"></a>rf_best <span class="ot">&lt;-</span> <span class="fu">show_best</span>(workers_rf_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb491-3"><a href="supervised-learning.html#cb491-3" tabindex="-1"></a>glm_best <span class="ot">&lt;-</span> <span class="fu">show_best</span>(workers_glm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb491-4"><a href="supervised-learning.html#cb491-4" tabindex="-1"></a>svm_best <span class="ot">&lt;-</span> <span class="fu">show_best</span>(workers_svm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb491-5"><a href="supervised-learning.html#cb491-5" tabindex="-1"></a></span>
<span id="cb491-6"><a href="supervised-learning.html#cb491-6" tabindex="-1"></a><span class="co"># Create comparison tibble</span></span>
<span id="cb491-7"><a href="supervised-learning.html#cb491-7" tabindex="-1"></a>model_comparison <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb491-8"><a href="supervised-learning.html#cb491-8" tabindex="-1"></a>  rf_best <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;Random Forest&quot;</span>),</span>
<span id="cb491-9"><a href="supervised-learning.html#cb491-9" tabindex="-1"></a>  glm_best <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;GLM&quot;</span>),</span>
<span id="cb491-10"><a href="supervised-learning.html#cb491-10" tabindex="-1"></a>  svm_best <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;SVM&quot;</span>)</span>
<span id="cb491-11"><a href="supervised-learning.html#cb491-11" tabindex="-1"></a>)</span>
<span id="cb491-12"><a href="supervised-learning.html#cb491-12" tabindex="-1"></a></span>
<span id="cb491-13"><a href="supervised-learning.html#cb491-13" tabindex="-1"></a><span class="co"># Visualize</span></span>
<span id="cb491-14"><a href="supervised-learning.html#cb491-14" tabindex="-1"></a>model_comparison <span class="sc">|&gt;</span></span>
<span id="cb491-15"><a href="supervised-learning.html#cb491-15" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(model, mean), <span class="at">y =</span> mean, <span class="at">fill =</span> model)) <span class="sc">+</span></span>
<span id="cb491-16"><a href="supervised-learning.html#cb491-16" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb491-17"><a href="supervised-learning.html#cb491-17" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> mean <span class="sc">-</span> std_err, <span class="at">ymax =</span> mean <span class="sc">+</span> std_err), <span class="at">width =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb491-18"><a href="supervised-learning.html#cb491-18" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;ROC AUC&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Model&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Model Comparison by ROC AUC&quot;</span>) <span class="sc">+</span></span>
<span id="cb491-19"><a href="supervised-learning.html#cb491-19" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="sc">+</span></span>
<span id="cb491-20"><a href="supervised-learning.html#cb491-20" tabindex="-1"></a>  <span class="fu">coord_flip</span>()</span></code></pre></div>
<p>We see how the results overlap, so we could opt for the two that have the highest mean ROC and among them choose the one that gives us a smaller range of values.</p>
</details>
<ol start="104" style="list-style-type: decimal">
<li>Create the confusion matrices for the three models created.</li>
</ol>
<details>
<summary type="button">
Solution
</summary>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb492-1"><a href="supervised-learning.html#cb492-1" tabindex="-1"></a><span class="co"># Finalize and fit each model</span></span>
<span id="cb492-2"><a href="supervised-learning.html#cb492-2" tabindex="-1"></a>best_rf <span class="ot">&lt;-</span> <span class="fu">select_best</span>(workers_rf_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb492-3"><a href="supervised-learning.html#cb492-3" tabindex="-1"></a>final_rf_wf <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(rf_wf, best_rf)</span>
<span id="cb492-4"><a href="supervised-learning.html#cb492-4" tabindex="-1"></a>rf_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_rf_wf, <span class="at">data =</span> workers_train)</span>
<span id="cb492-5"><a href="supervised-learning.html#cb492-5" tabindex="-1"></a></span>
<span id="cb492-6"><a href="supervised-learning.html#cb492-6" tabindex="-1"></a>best_glm <span class="ot">&lt;-</span> <span class="fu">select_best</span>(workers_glm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb492-7"><a href="supervised-learning.html#cb492-7" tabindex="-1"></a>final_glm_wf <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(glm_wf, best_glm)</span>
<span id="cb492-8"><a href="supervised-learning.html#cb492-8" tabindex="-1"></a>glm_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_glm_wf, <span class="at">data =</span> workers_train)</span>
<span id="cb492-9"><a href="supervised-learning.html#cb492-9" tabindex="-1"></a></span>
<span id="cb492-10"><a href="supervised-learning.html#cb492-10" tabindex="-1"></a>best_svm <span class="ot">&lt;-</span> <span class="fu">select_best</span>(workers_svm_res, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb492-11"><a href="supervised-learning.html#cb492-11" tabindex="-1"></a>final_svm_wf <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(svm_wf, best_svm)</span>
<span id="cb492-12"><a href="supervised-learning.html#cb492-12" tabindex="-1"></a>svm_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_svm_wf, <span class="at">data =</span> workers_train)</span>
<span id="cb492-13"><a href="supervised-learning.html#cb492-13" tabindex="-1"></a></span>
<span id="cb492-14"><a href="supervised-learning.html#cb492-14" tabindex="-1"></a><span class="co"># Predictions and confusion matrices</span></span>
<span id="cb492-15"><a href="supervised-learning.html#cb492-15" tabindex="-1"></a>rf_preds <span class="ot">&lt;-</span> <span class="fu">augment</span>(rf_fit, <span class="at">new_data =</span> workers_test)</span>
<span id="cb492-16"><a href="supervised-learning.html#cb492-16" tabindex="-1"></a>rf_preds <span class="sc">|&gt;</span> <span class="fu">conf_mat</span>(<span class="at">truth =</span> attrition_status, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb492-17"><a href="supervised-learning.html#cb492-17" tabindex="-1"></a></span>
<span id="cb492-18"><a href="supervised-learning.html#cb492-18" tabindex="-1"></a>glm_preds <span class="ot">&lt;-</span> <span class="fu">augment</span>(glm_fit, <span class="at">new_data =</span> workers_test)</span>
<span id="cb492-19"><a href="supervised-learning.html#cb492-19" tabindex="-1"></a>glm_preds <span class="sc">|&gt;</span> <span class="fu">conf_mat</span>(<span class="at">truth =</span> attrition_status, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb492-20"><a href="supervised-learning.html#cb492-20" tabindex="-1"></a></span>
<span id="cb492-21"><a href="supervised-learning.html#cb492-21" tabindex="-1"></a>svm_preds <span class="ot">&lt;-</span> <span class="fu">augment</span>(svm_fit, <span class="at">new_data =</span> workers_test)</span>
<span id="cb492-22"><a href="supervised-learning.html#cb492-22" tabindex="-1"></a>svm_preds <span class="sc">|&gt;</span> <span class="fu">conf_mat</span>(<span class="at">truth =</span> attrition_status, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
<p>Keep in mind that the model with the highest <code>ROC</code> value will not necessarily have the highest <code>accuracy</code>. Therefore the choice of the model was performed in a previous step. The ROC better balances sensitivity with the <a href="https://en.wikipedia.org/wiki/False_positive_rate">false positive rate</a>.</p>
</details>
</details>
</div>
<div id="ethics-bias-in-algorithmic-decision-making" class="section level2 hasAnchor" number="11.11">
<h2><span class="header-section-number">11.11</span> Ethics: Bias in Algorithmic Decision Making<a href="supervised-learning.html#ethics-bias-in-algorithmic-decision-making" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the previous exercise, we built models to predict employee attrition using variables like <code>Gender</code>, <code>Age</code>, and <code>MaritalStatus</code>. While mathematically sound, obtaining a high accuracy score does not mean the model is “good” or “fair” to use in the real world.</p>
<div id="the-risk-of-proxy-variables" class="section level3 hasAnchor" number="11.11.1">
<h3><span class="header-section-number">11.11.1</span> The Risk of Proxy Variables<a href="supervised-learning.html#the-risk-of-proxy-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Even if we remove explicit sensitive attributes (like Gender or Ethnicity), other variables can act as <strong>proxies</strong>.
* <strong>Zip Code:</strong> Often correlates with race or socioeconomic status.
* <strong>Years of Experience:</strong> Strongly correlated with Age.</p>
</div>
<div id="feedback-loops" class="section level3 hasAnchor" number="11.11.2">
<h3><span class="header-section-number">11.11.2</span> Feedback Loops<a href="supervised-learning.html#feedback-loops" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If a company uses an algorithm to decide who to hire or fire based on historical data, they may perpetuate historical biases.
* <strong>Scenario:</strong> If a company historically didn’t hire women for leadership roles, the training data will show that women are “less likely to succeed” in those roles.
* <strong>Result:</strong> The model creates a feedback loop, rejecting qualified female candidates because they don’t match the historical pattern of “success”.</p>
<blockquote>
<p>[!IMPORTANT]
<strong>What can we do?</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Audit your Data:</strong> checking for representation balance (e.g., is one group significantly smaller?).</li>
<li><strong>Model Explainability:</strong> Use tools like <code>DALEX</code> or <code>vip</code> (variable importance) to understand <em>why</em> the model is making a decision. If <code>MaritalStatus</code> is the top predictor for firing someone, is that ethical?</li>
<li><strong>Human in the Loop:</strong> These models should support human decision-making, not replace it entirely.</li>
</ol>
</blockquote>
<p>As Data Scientists, our responsibility extends beyond the AUC score. We must ensure our models do not harm individuals or groups.</p>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Fawcett2005" class="csl-entry">
Fawcett, Tom. 2005. <em>An Introduction to ROC Analysis</em>. Elsevier. <a href="https://people.inf.elte.hu/kiss/11dwhdm/roc.pdf">https://people.inf.elte.hu/kiss/11dwhdm/roc.pdf</a>.
</div>
<div id="ref-Lobo2007" class="csl-entry">
Jorge M. Lobo, Raimundo Real, Alberto Jiménez-Valverde. 2007. <em>AUC: A Misleading Measure of the Performance of Predictive Distribution Models</em>. Ecological Sounding. <a href="https://www2.unil.ch/biomapper/Download/Lobo-GloEcoBioGeo-2007.pdf">https://www2.unil.ch/biomapper/Download/Lobo-GloEcoBioGeo-2007.pdf</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="10">
<li id="fn10"><p><a href="https://www.tidymodels.org/" class="uri">https://www.tidymodels.org/</a><a href="supervised-learning.html#fnref10" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="unsupervised-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": true,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": null
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": null,
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
