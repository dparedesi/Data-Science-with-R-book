# Data Science in the Age of AI {#genai-intro}

The field of Data Science is evolving rapidly. Just as the transition from base R to the tidyverse transformed how we write code, the emergence of **Large Language Models (LLMs)** and **Generative AI** is transforming how we solve problems.

In this chapter, we will explore how to integrate these powerful tools into your R workflowâ€”not to replace your skills, but to amplify them.

## What is a Large Language Model?

At its core, a Large Language Model (like GPT-4, Claude, or Llama) is a probabilistic engine. It has been trained on vast amounts of text to predict the "next most likely token" (piece of a word) in a sequence. 

While they can seem intelligent, it is crucial to remember:
*   **They do not "know" facts:** They generate plausible-sounding text based on patterns.
*   **They can hallucinate:** They can confidently state things that are completely false (especially about R packages that don't exist!).
*   **They are non-deterministic:** Asking the same question twice might yield different answers.

> [!WARNING]
> **Trust, but Verify.** Never run code generated by an AI without understanding what it does. Always test it on a small sample of your data first.

## Coding with AI: The "Pair Programmer"

The most immediate application of GenAI for a Data Scientist is as a **Pair Programmer**. Tools like GitHub Copilot or simply chatting with ChatGPT/Claude can significantly speed up your coding.

### 1. Explaining Complex Code
Have you ever inherited a project with a complex chunk of code you don't understand? Paste it into an LLM and ask: *"Explain this R code step-by-step."*

**Example Prompt:**
> "I have this R code using `purrr::map`. Can you explain what it does in simple terms and suggest if there is a more modern way to write it?"

### 2. Generating Boilerplate
Writing the skeleton for a Shiny app or a complex ggplot theme can be tedious.

**Example Prompt:**
> "Create an R script that sets up a basic Shiny dashboard with a sidebar layout. It should generate a histogram of the `palmerpenguins` dataset."

### 3. Regex: The Ultimate Use Case
Regular Expressions (Regex) are powerful but famously difficult to remember. This is one of the best use cases for AI.

**Scenario:** You have a dataset with messy phone numbers like `(51) 999-999-999`, `51 999 999 999`, and `+51999999999`. You want to extract just the digits.

**Bad Way:** Spending an hour reading StackOverflow.
**AI Way:** 

> **Prompt:** "I have a column in R with Peruvian phone numbers in inconsistent formats (e.g., `(51) 987-654-321`). Write a regular expression to extract only the 9 digits of the mobile number, ignoring the country code +51. Show me how to use it with `stringr`."

**Potential Output:**
```{r eval=FALSE}
library(stringr)

phones <- c("(51) 987-654-321", "+51 987654321", "987 654 321")
digits <- str_extract(phones, "(?<=51\\D{0,2})\\d{9}|\\d{9}")
```
*(Note: Always test the regex provided! AI often struggles with lookbehinds)*

## Ethics & Risks in the AI Era

While these tools are powerful, they come with significant risks that every Data Scientist must manage.

### 1. Hallucinations & Fabrication
LLMs are designed to generate *plausible* text, not *truth*.
*   **The "Package" Problem:** An LLM might invent an R package like `shiny.dashboard.plus.ultra` because it sounds real. Always check CRAN.
*   **False Confidence:** It will explain a concept incorrectly with 100% confidence.

### 2. The Reproducibility Crisis
Data Science relies on reproducibility. If you ask ChatGPT to write code for you:
*   Will it write the same code tomorrow? (No).
*   Can you cite "ChatGPT" as an author in a scientific paper? (Generally no).
*   **Best Practice:** Treat AI-generated code as a first draft. You must review, test, and own the final code.

### 3. Data Privacy & IP
When using free external tools (like ChatGPT), remember: **If the service is free, you (and your data) might be the product.**

*   **Never** paste PII (Personally Identifiable Information) like client names, IDs, or private financial data into a public LLM.
*   **Corporate Policy:** Many companies ban public LLMs. Check if you have an internal instance (e.g., Enterprise Copilot).
*   **Anonymize:** If you must use a public tool, rename columns (`Client_A`, `Revenue_X`) and inject fake values before prompting.

In the next section, we will go a step further: interacting with LLMs programmatically using R.
